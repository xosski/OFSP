import win32security
import winreg
import win32api, win32con, win32process
import queue
import ctypes.wintypes
import struct
import logging.config
import os
import binascii
import hashlib
import logging
import shutil
from pathlib import Path
from typing import List, Dict
import psutil
import logging
from pathlib import Path
import yara
import requests
import json
from pathlib import Path
import tkinter as tk
from tkinter import ttk
import threading
import time
from datetime import datetime
import re
import glob
import ctypes
import sys
import threading 
import ctypes, ctypes.wintypes
import pywintypes
import base64
import struct
import subprocess
import socket
import traceback
from ctypes import windll, byref, sizeof, Structure, wintypes, POINTER, c_char
from ctypes.wintypes import DWORD, HANDLE, LPVOID, LPWSTR, ULONG
import win32con
import win32process
import win32api
import sqlite3
import math
from collections import defaultdict
import uuid
import dis
import inspect
import types
import win32security
import pythoncom
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(filename)s:%(lineno)d - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
# Set up debug logging at the start
class PROCESSENTRY32(ctypes.Structure):
        _fields_ = [
            ("dwSize", ctypes.c_ulong),
            ("cntUsage", ctypes.c_ulong),
            ("th32ProcessID", ctypes.c_ulong),
            ("th32DefaultHeapID", ctypes.POINTER(ctypes.c_ulong)),
            ("th32ModuleID", ctypes.c_ulong),
            ("cntThreads", ctypes.c_ulong),
            ("th32ParentProcessID", ctypes.c_ulong),
            ("pcPriClassBase", ctypes.c_long),
            ("dwFlags", ctypes.c_ulong),
            ("szExeFile", ctypes.c_char * 260)
        ]

# Define structure for THREADENTRY32
class THREADENTRY32(ctypes.Structure):
    _fields_ = [
        ("dwSize", ctypes.c_ulong),
        ("cntUsage", ctypes.c_ulong),
        ("th32ThreadID", ctypes.c_ulong),
        ("th32OwnerProcessID", ctypes.c_ulong),
        ("tpBasePri", ctypes.c_long),
        ("tpDeltaPri", ctypes.c_long),
        ("dwFlags", ctypes.c_ulong)
    ]

# Define structure for MEMORY_BASIC_INFORMATION
class MEMORY_BASIC_INFORMATION(ctypes.Structure):
    _fields_ = [
        ("BaseAddress", ctypes.c_void_p),
        ("AllocationBase", ctypes.c_void_p),
        ("AllocationProtect", ctypes.c_ulong),
        ("RegionSize", ctypes.c_size_t),
        ("State", ctypes.c_ulong),
        ("Protect", ctypes.c_ulong),
        ("Type", ctypes.c_ulong)
    ]
class GUID(Structure):
    _fields_ = [
        ('Data1', DWORD),
        ('Data2', wintypes.WORD),
        ('Data3', wintypes.WORD),
        ('Data4', c_char * 8)
    ]
class WINTRUST_FILE_INFO(Structure):
    _fields_ = [
        ('cbStruct', DWORD),
        ('pcwszFilePath', LPWSTR),
        ('hFile', HANDLE),
        ('pgKnownSubject', POINTER(GUID))
    ]



class WINTRUST_DATA(Structure):
    _fields_ = [
        ('cbStruct', wintypes.DWORD),
        ('pPolicyCallbackData', wintypes.LPVOID),
        ('pSIPClientData', wintypes.LPVOID),
        ('dwUIChoice', wintypes.DWORD),
        ('fdwRevocationChecks', wintypes.DWORD),
        ('dwUnionChoice', wintypes.DWORD),
        ('pFile', POINTER(WINTRUST_FILE_INFO)),
        ('pCatalog', wintypes.LPVOID),
        ('pBlob', wintypes.LPVOID),
        ('pSgnr', wintypes.LPVOID),
        ('pCert', wintypes.LPVOID),
        ('dwStateAction', wintypes.DWORD),
        ('hWVTStateData', wintypes.HANDLE),
        ('pwszURLReference', wintypes.LPCWSTR),
        ('dwProvFlags', wintypes.DWORD),
        ('dwUIContext', wintypes.DWORD),
        ('pSignatureSettings', wintypes.LPVOID)
    ]
class UNICODE_STRING(Structure):
    _fields_ = [
        ("Length", wintypes.USHORT),
        ("MaximumLength", wintypes.USHORT),
        ("Buffer", wintypes.LPWSTR),
    ]

class SYSTEM_MODULE_INFORMATION(Structure):
    _fields_ = [
        ("Reserved", LPVOID * 2),
        ("ImageBase", LPVOID),
        ("ImageSize", ULONG),
        ("Flags", ULONG),
        ("LoadOrderIndex", wintypes.USHORT),
        ("InitOrderIndex", wintypes.USHORT),
        ("LoadCount", wintypes.USHORT),
        ("ModuleNameOffset", wintypes.USHORT),
        ("ImageName", c_char * 256),
    ]

class MIB_TCPROW_OWNER_PID(Structure):
    _fields_ = [
        ("dwState", DWORD),
        ("dwLocalAddr", DWORD),
        ("dwLocalPort", DWORD),
        ("dwRemoteAddr", DWORD),
        ("dwRemotePort", DWORD),
        ("dwOwningPid", DWORD),
    ]

class MIB_UDPROW_OWNER_PID(Structure):
    _fields_ = [
        ("dwLocalAddr", DWORD),
        ("dwLocalPort", DWORD),
        ("dwOwningPid", DWORD),
    ]
class IMAGE_DOS_HEADER(ctypes.Structure):
    _fields_ = [
        ("e_magic", ctypes.c_uint16),
        ("e_cblp", ctypes.c_uint16),
        ("e_cp", ctypes.c_uint16),
        ("e_crlc", ctypes.c_uint16),
        ("e_cparhdr", ctypes.c_uint16),
        ("e_minalloc", ctypes.c_uint16),
        ("e_maxalloc", ctypes.c_uint16),
        ("e_ss", ctypes.c_uint16),
        ("e_sp", ctypes.c_uint16),
        ("e_csum", ctypes.c_uint16),
        ("e_ip", ctypes.c_uint16),
        ("e_cs", ctypes.c_uint16),
        ("e_lfarlc", ctypes.c_uint16),
        ("e_ovno", ctypes.c_uint16),
        ("e_res", ctypes.c_uint16 * 4),
        ("e_oemid", ctypes.c_uint16),
        ("e_oeminfo", ctypes.c_uint16),
        ("e_res2", ctypes.c_uint16 * 10),
        ("e_lfanew", ctypes.c_int32)
    ]

class IMAGE_DATA_DIRECTORY(ctypes.Structure):
    _fields_ = [
        ("VirtualAddress", ctypes.c_uint32),
        ("Size", ctypes.c_uint32)
    ]

class IMAGE_OPTIONAL_HEADER(ctypes.Structure):
    _fields_ = [
        ("Magic", ctypes.c_uint16),
        ("MajorLinkerVersion", ctypes.c_uint8),
        ("MinorLinkerVersion", ctypes.c_uint8),
        ("SizeOfCode", ctypes.c_uint32),
        ("SizeOfInitializedData", ctypes.c_uint32),
        ("SizeOfUninitializedData", ctypes.c_uint32),
        ("AddressOfEntryPoint", ctypes.c_uint32),
        ("BaseOfCode", ctypes.c_uint32),
        ("BaseOfData", ctypes.c_uint32),
        ("ImageBase", ctypes.c_uint32),
        ("SectionAlignment", ctypes.c_uint32),
        ("FileAlignment", ctypes.c_uint32),
        ("MajorOperatingSystemVersion", ctypes.c_uint16),
        ("MinorOperatingSystemVersion", ctypes.c_uint16),
        ("MajorImageVersion", ctypes.c_uint16),
        ("MinorImageVersion", ctypes.c_uint16),
        ("MajorSubsystemVersion", ctypes.c_uint16),
        ("MinorSubsystemVersion", ctypes.c_uint16),
        ("Win32VersionValue", ctypes.c_uint32),
        ("SizeOfImage", ctypes.c_uint32),
        ("SizeOfHeaders", ctypes.c_uint32),
        ("CheckSum", ctypes.c_uint32),
        ("Subsystem", ctypes.c_uint16),
        ("DllCharacteristics", ctypes.c_uint16),
        ("SizeOfStackReserve", ctypes.c_uint32),
        ("SizeOfStackCommit", ctypes.c_uint32),
        ("SizeOfHeapReserve", ctypes.c_uint32),
        ("SizeOfHeapCommit", ctypes.c_uint32),
        ("LoaderFlags", ctypes.c_uint32),
        ("NumberOfRvaAndSizes", ctypes.c_uint32),
        ("DataDirectory", IMAGE_DATA_DIRECTORY * 16)
    ]

class IMAGE_FILE_HEADER(ctypes.Structure):
    _fields_ = [
        ("Machine", ctypes.c_uint16),
        ("NumberOfSections", ctypes.c_uint16),
        ("TimeDateStamp", ctypes.c_uint32),
        ("PointerToSymbolTable", ctypes.c_uint32),
        ("NumberOfSymbols", ctypes.c_uint32),
        ("SizeOfOptionalHeader", ctypes.c_uint16),
        ("Characteristics", ctypes.c_uint16)
    ]

class IMAGE_NT_HEADERS(ctypes.Structure):
    _fields_ = [
        ("Signature", ctypes.c_uint32),
        ("FileHeader", IMAGE_FILE_HEADER),
        ("OptionalHeader", IMAGE_OPTIONAL_HEADER)
    ]

class IMAGE_EXPORT_DIRECTORY(ctypes.Structure):
    _fields_ = [
        ("Characteristics", ctypes.c_uint32),
        ("TimeDateStamp", ctypes.c_uint32),
        ("MajorVersion", ctypes.c_uint16),
        ("MinorVersion", ctypes.c_uint16),
        ("Name", ctypes.c_uint32),
        ("Base", ctypes.c_uint32),
        ("NumberOfFunctions", ctypes.c_uint32),
        ("NumberOfNames", ctypes.c_uint32),
        ("AddressOfFunctions", ctypes.c_uint32),
        ("AddressOfNames", ctypes.c_uint32),
        ("AddressOfNameOrdinals", ctypes.c_uint32)
    ]
class ScannerGui:
    _instance = None

    def __new__(cls, root=None):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._initialized = False
        return cls._instance
    
    class MEMORY_BASIC_INFORMATION(ctypes.Structure):
        MEM_COMMIT = 0x1000
        MEM_RESERVE = 0x2000
        MEM_RELEASE = 0x8000
        PAGE_NOACCESS = 0x01
        PAGE_READONLY = 0x02
        PAGE_READWRITE = 0x04
        PAGE_WRITECOPY = 0x08
        PAGE_EXECUTE = 0x10
        PAGE_EXECUTE_READ = 0x20
        PAGE_EXECUTE_READWRITE = 0x40
        PAGE_EXECUTE_WRITECOPY = 0x80
        PAGE_GUARD = 0x100
        PAGE_NOCACHE = 0x200
        PAGE_WRITECOMBINE = 0x400
        DEFAULT_PAGE_SIZE = 4096
        pmmap_ext_size = ()
        _fields_ = [
            ("BaseAddress", ctypes.c_void_p),
            ("AllocationBase", ctypes.c_void_p),
            ("AllocationProtect", ctypes.c_ulong),
            ("RegionSize", ctypes.c_size_t),
            ("State", ctypes.c_ulong),
            ("Protect", ctypes.c_ulong),
            ("Type", ctypes.c_ulong)
        ]
    
    def __init__(self, master=None):
        # Prevent double initialization
        if hasattr(self, '_initialized') and self._initialized:
            return
            
        self.root = root
        self.root.title("Memory Protection Scanner")
        self.root.geometry("800x600")
        
        # Initialize variables only (no GUI widgets yet)
        self.signature_db = set()
        self.total_processes_scanned = 0
        self._initialized = True
        self.critical_processes = {
            'explorer.exe', 'svchost.exe', 'lsass.exe', 
            'winlogon.exe', 'csrss.exe', 'services.exe'
        }
        self.monitoring_active = False
        self.quarantine_dir = Path("quarantine")
        self.injection_patterns = {
            'shellcode': rb'\x55\x8B\xEC|\x90{4,}',
            'script_injection': rb'(eval|exec|system|subprocess.run)',
            'memory_manipulation': rb'(VirtualAlloc|WriteProcessMemory)',
            'dll_injection': rb'(LoadLibrary|GetProcAddress)',
            'code_execution': rb'(WScript.Shell|cmd.exe|powershell.exe)',
            'encoded_commands': rb'([A-Za-z0-9+/]{40,}={0,2})'
        }
        self.process_handle = None
        self.detections = []
        self.signature_status = True
        self.scanning = False
        self.detections_list = None
        
        # Initialize backend components
        self._setup_logging()
        logging.info("Application initialized")
        
        # Initialize YARA and detection components
        yara_manager = YaraRuleManager()
        yara_manager.create_repo_directories()
        
        # Verify rules are properly loaded
        report = yara_manager.verify_rules_loaded()
        print("\n=== YARA Rules Loading Status ===")
        print(f"Directories exist: {report['directories_exist']}")
        print(f"Rule files exist: {report['rule_files_exist']}")
        print(f"Rule files count: {report['rule_files_count']}")
        print(f"Compilation success: {report['compilation_success']}")
        
        self.logger = logging.getLogger(__name__)
        if report["error_message"]:
            self.logger.info(f"Error: {report['error_message']}")

        if not report["compilation_success"]:
            print("Trying to create basic rules directly...")
            yara_manager.create_basic_rules()
            report = yara_manager.verify_rules_loaded()
            print("\n=== YARA Rules Loading Status (After Retry) ===")
            print(f"Rule files count: {report['rule_files_count']}")
            print(f"Compilation success: {report['compilation_success']}")
        
        # Initialize detection components
        self.Detector = ShellcodeDetector()
        self.disassembler = CodeDisassembler()
        self.tome = ShellCodeTome()
        self.scanner = MemoryScanner()
        
        # Initialize YARA manager
        self.yara_manager = YaraRuleManager()
        self.compiled_rules = self.yara_manager.compile_combined_rules()
        self.yara_manager.fetch_all_rules()
        self.yara_manager.create_missing_rules()
        
        # Make sure rules are loaded
        if not getattr(self.yara_manager, '_rules_loaded', False):
            logging.info("YARA rules not loaded, loading now...")
            self.yara_manager.fetch_all_rules()
            self.yara_manager.create_missing_rules()
            self.yara_manager.combined_rules = self.yara_manager.compile_combined_rules()
            self.yara_manager._rules_loaded = self.yara_manager.combined_rules is not None
        
        # Check and report rule loading status
        if self.yara_manager._rules_loaded:
            logging.info("YARA rules successfully loaded for scanning")
            self.rules_loaded = True
        else:
            logging.warning("YARA rules could not be loaded!")
            self.rules_loaded = False
        
        # Initialize GUI variables
        self.quarantine_var = tk.BooleanVar(value=True)
        self.threshold_var = tk.IntVar(value=75)
        
        # Create utility functions
        self.create_utility_functions()
        
        # Setup GUI after all initialization is complete
        self.setup_gui()
        
        # Final rule check after GUI is setup
        self.update_rule_status()
        
        # Start protection
        self.initial_protection()
        
    def create_utility_functions(self):
        """Create utility functions and aliases"""
        # Tree utility functions will be created after the tree widget exists
        self.additem = None
        self.clear = None
        
    def update_rule_status(self):
        """Update GUI with rule loading status"""
        if hasattr(self, 'status_label'):
            rules_actually_loaded = (hasattr(self, 'yara_manager') and 
                                   hasattr(self.yara_manager, 'combined_rules') and 
                                   self.yara_manager.combined_rules is not None)
            
            if rules_actually_loaded:
                self.set_status_label("Rules Loaded", "green")
                self.rules_loaded = True
                logging.info("GUI status updated: Rules loaded successfully")
            else:
                self.set_status_label("Rules Failed to Load", "red")
                self.rules_loaded = False
                logging.warning("GUI status updated: Rules failed to load")
            
            self.root.update_idletasks()
    def initialize_security_patches(self):
        """Apply security patches to prevent PyHANDLE errors"""
        # Define a fallback method that will log when called and return safe values
        def handle_get_system_info(self, *args, **kwargs):
            stack = traceback.format_stack()
            logging.error(f"CRITICAL: _get_system_info incorrectly called on {type(self).__name__} object")
            logging.error(f"Call stack:\n{''.join(stack)}")
            
            # Return dummy data to prevent crashes
            return {
                'system_info': None,
                'processor_architecture': 0,
                'page_size': 4096,
                'min_address': 0,
                'max_address': 0,
                'processor_count': 1,
                'processor_type': 0,
                'allocation_granularity': 0,
                'processor_level': 0,
                'processor_revision': 0,
                'error': 'Method called on handle object',
                'handle_type': str(type(self).__name__)
            }
        
        # Collect possible handle types SAFELY
        handle_types = []
        
        # Try HANDLE from ctypes
        try:
            handle_cls = ctypes.wintypes.HANDLE
            if handle_cls is not int and not isinstance(handle_cls, int):
                handle_types.append(handle_cls)
        except Exception as e:
            logging.debug(f"Could not add HANDLE type: {str(e)}")
        
        # Try PyHANDLE from win32api
        try:
            handle = win32api.GetCurrentProcess()
            handle_cls = type(handle)
            if handle_cls is not int and not isinstance(handle_cls, int):
                handle_types.append(handle_cls)
        except Exception as e:
            logging.debug(f"Could not add PyHANDLE type: {str(e)}")
        
        # Apply the patch to patchable types only
        for handle_type in handle_types:
            try:
                if not hasattr(handle_type, '_get_system_info'):
                    setattr(handle_type, '_get_system_info', handle_get_system_info)
                    logging.info(f"Patched {handle_type.__name__} with _get_system_info method")
            except (TypeError, AttributeError) as e:
                logging.debug(f"Could not patch {handle_type}: {str(e)}")
        
        logging.info(f"Security patches applied to {len(handle_types)} handle types")
    def update_gui_detections(self, detections_data, clear_existing=True):
        
        # Get reference to your detections display widget (whatever type it is)
        detections_widget = self.ui.detections_widget  # Adjust to your actual widget name
        
        # Clear existing items if requested - use the appropriate method for your widget
        if clear_existing:
            # Different frameworks have different clearing methods:
            try:
                clear = lambda: detections_widget.delete(0, 'end')  # Tkinter style
                DeleteAllItems = lambda: detections_widget.DeleteAllItems()  # wxPython style
                # Try common clearing methods depending on your framework
                if hasattr(detections_widget, 'clear'):
                    detections_widget.clear()
                elif hasattr(detections_widget, 'delete'):
                    detections_widget.delete(0, 'end')  # Tkinter style
                elif hasattr(detections_widget, 'DeleteAllItems'):
                    detections_widget.DeleteAllItems()  # wxPython style
                # Add more clearing methods as needed for your framework
            except Exception as e:
                print(f"Error clearing detections: {e}")
        
        # Add new detection items - adapt this to your specific framework
        for detection in detections_data:
            try:
                # The specific code here depends on your GUI framework
                # Here's a framework-agnostic approach using string representation
                detection_text = f"{detection.get('timestamp', '')} - {detection.get('name', 'Unknown')} - {detection.get('severity', '')}"
                
                # Insert into widget - use the appropriate method for your framework
                if hasattr(detections_widget, 'addItem'):
                    detections_widget.addItem(detection_text)  # QListWidget style
                elif hasattr(detections_widget, 'insert'):
                    detections_widget.insert('end', detection_text)  # Tkinter Listbox style
                elif hasattr(detections_widget, 'Append'):
                    detections_widget.Append(detection_text)  # wxPython style
                # Add more insertion methods as needed
                    
            except Exception as e:
                print(f"Error adding detection to GUI: {str(e)}")
        
        # Update count label if it exists
        try:
            if hasattr(self.ui, 'detection_count_label'):
                # Set text using the appropriate method for your framework
                if hasattr(self.ui.detection_count_label, 'setText'):
                    self.ui.detection_count_label.setText(f"Detections: {len(detections_data)}")
                elif hasattr(self.ui.detection_count_label, 'configure'):
                    self.ui.detection_count_label.configure(text=f"Detections: {len(detections_data)}")
                elif hasattr(self.ui.detection_count_label, 'SetLabel'):
                    self.ui.detection_count_label.SetLabel(f"Detections: {len(detections_data)}")
        except Exception as e:
            print(f"Error updating detection count: {e}")
        
        # Update status if it exists
        try:
            if hasattr(self, 'update_status'):
                self.update_status(f"Found {len(detections_data)} detections")
        except Exception as e:
            print(f"Error updating status: {e}")
    def update_status(self, message):
        """Updates status label with current operation message"""
        if hasattr(self, 'status_label'):
            self.status_label.config(text=message)
            # Force GUI update
            self.status_label.update()
    def create_detection_item(self, detection):
       
        # Determine what GUI framework we're using based on available widgets/methods
        if hasattr(self, 'ui') and hasattr(self.ui, 'detections_treeview'):
            widget = self.ui.detections_treeview
        elif hasattr(self, 'ui') and hasattr(self.ui, 'detections_listview'):
            widget = self.ui.detections_listview
        else:
            widget = None
        
        # Create appropriate item based on detected widget type
        if widget is None:
            # If no widget identified, return a dictionary that can be used later
            return detection
        
        # --- Tkinter approach ---
        elif hasattr(widget, 'insert') and 'tk' in str(type(widget)).lower():
            # Format the values for Tkinter Treeview
            values = (
                detection.get('timestamp', ''),
                detection.get('name', 'Unknown'),
                detection.get('type', ''),
                detection.get('severity', ''),
                detection.get('location', ''),
                detection.get('description', '')
            )
            # Return the values and an ID that can be used when inserting
            return {'values': values, 'id': detection.get('id', '')}
        
        # --- wxPython approach ---
        elif hasattr(widget, 'InsertItem') and 'wx' in str(type(widget)).lower():
              # Only import if we're using wxPython
            # For wxPython ListCtrl
            index = widget.GetItemCount()
            item_data = {
                'index': index,
                'label': detection.get('name', 'Unknown'),
                'data': detection
            }
            return item_data
        
        # --- PyQt/PySide approach (if available) ---
        elif 'Qt' in str(type(widget)):
            try:
                # Try to import QTreeWidgetItem dynamically
                # This will only work if PyQt or PySide is installed
                if 'PySide2' in sys.modules:
                    from PySide2.QtWidgets import QTreeWidgetItem
                elif 'PySide6' in sys.modules:
                    from PySide6.QtWidgets import QTreeWidgetItem
                elif 'PyQt5' in sys.modules:
                    from PyQt5.QtWidgets import QTreeWidgetItem
                elif 'PyQt6' in sys.modules:
                    from PyQt6.QtWidgets import QTreeWidgetItem
                else:
                    # Fallback - just return the raw data
                    return detection
                    
                item = QTreeWidgetItem()
                item.setText(0, detection.get('timestamp', ''))
                item.setText(1, detection.get('name', 'Unknown'))
                item.setText(2, detection.get('type', ''))
                item.setText(3, detection.get('severity', ''))
                item.setText(4, detection.get('location', ''))
                item.setText(5, detection.get('description', ''))
                return item
            except ImportError:
                # If we can't import Qt widgets, return the raw detection data
                return detection
        
        # --- Default case ---
        else:
            # For any other framework or custom widget, return the raw detection
            # The calling function can handle it appropriately
            return detection
    def update_quarantine_settings(self):
        self.scanner.quarantine_enabled = self.quarantine_var.get()
        self.scanner.quarantine_threshold = self.threshold_var.get()
    def trace_pyhandle_errors(self):
        """Set up a simple tracer for PyHANDLE errors"""
        import sys
        import logging
        import traceback
        
        original_excepthook = sys.excepthook
        
        def custom_excepthook(exc_type, exc_value, exc_traceback):
            if "'PyHANDLE' object has no attribute" in str(exc_value):
                error_msg = f"\n{'='*60}\nCRITICAL ERROR: {str(exc_value)}\n"
                tb_lines = traceback.format_exception(exc_type, exc_value, exc_traceback)
                error_msg += "".join(tb_lines)
                error_msg += f"{'='*60}\n"
                
                # Log to file and console
                logging.critical(error_msg)
                
                # Also write to a separate file
                with open("pyhandle_error.log", "a") as f:
                    f.write(error_msg)
            
            # Call the original handler
            original_excepthook(exc_type, exc_value, exc_traceback)
        
        sys.excepthook = custom_excepthook
        
    
    def set_status_label(self, text, color):
        """Set the status label with logging to track changes"""
            # Use direct config, NOT another call to set_status_label
        self.status_label.config(text=text, foreground=color)
        self.root.update_idletasks()
    def is_rules_loaded(self):
        """Check if YARA rules are loaded and ready for scanning"""
        return (hasattr(self, 'yara_manager') and 
                getattr(self.yara_manager, '_rules_loaded', False) and
                hasattr(self.yara_manager, 'combined_rules') and 
                self.yara_manager.combined_rules is not None)
    def update_rule_status_display(self):
        """Update the GUI to reflect the current rule loading status"""
        if hasattr(self, 'status_label'):
            if self.is_rules_loaded():
                self.set_status_label("Rules Loaded", "green")
                self.rules_loaded = True
            else:
                self.set_status_label("Rules Failed to Load", "red")
                self.rules_loaded = False
        
        # Force GUI update
        self.root.update_idletasks()
    def initial_protection(self):
        # Basic memory pattern monitoring
        self.injection_patterns = {
            'shellcode': rb'\x55\x8B\xEC|\x90{4,}',
            'script_injection': rb'(eval|exec|system|subprocess.run)',
            'memory_manipulation': rb'(VirtualAlloc|WriteProcessMemory)',
            'dll_injection': rb'(LoadLibrary|GetProcAddress)',
            'code_execution': rb'(WScript.Shell|cmd.exe|powershell.exe)',
            'encoded_commands': rb'([A-Za-z0-9+/]{40,}={0,2})'
        }
        # Start immediate monitoring
        
        self.scan_progress = ttk.Progressbar(root, mode='determinate')  # Initialize here
        self.scan_progress.grid(row=5, column=0, columnspan=2, pady=5, sticky=(tk.W, tk.E))
        self.stop_button = ttk.Button(self.root, text="Stop Scan", command=self.stop_scan)
        self.stop_button.grid(row=6, column=0, columnspan=2, pady=5)
    
    def _delayed_monitoring_start(self):
        # Give GUI time to initialize fully
        time.sleep(5)
    def play_alert_sound(self):
        """
        Plays an alert sound to notify the user of critical security events.
        Uses a more attention-grabbing sound than regular notifications.
        """
        try:
            # Try to use Windows built-in sounds first for a critical alert
            if sys.platform == 'win32':
                import winsound
                # Play a more urgent sound for alerts (SystemHand = Critical Stop sound)
                winsound.PlaySound('SystemHand', winsound.SND_ALIAS)
                
                # For persistent alerts, you might want to play multiple times
                time.sleep(0.3)
                winsound.PlaySound('SystemHand', winsound.SND_ALIAS)
            # For non-Windows platforms
            if hasattr(self, 'alert_sound_path') and os.path.exists(self.alert_sound_path):
                
                # Use platform-specific sound playing methods
                if sys.platform == 'darwin':  # macOS
                    os.system(f"afplay {self.alert_sound_path}")
                    time.sleep(0.3)
                    os.system(f"afplay {self.alert_sound_path}")
                elif sys.platform.startswith('linux'):
                    os.system(f"aplay {self.alert_sound_path}")
                    time.sleep(0.3)
                    os.system(f"aplay {self.alert_sound_path}")
            else:
                # If no sound file is specified, log the event
                logging.debug("Alert sound requested but no sound file specified")
                if hasattr(self, 'root') and self.root:
                    for _ in range(3):
                        self.root.bell()
                        time.sleep(0.2)
        except Exception as e:
            logging.debug(f"Failed to play alert sound: {str(e)}")
            # Fall back to visual notification only
            if hasattr(self, 'root') and self.root:
                try:
                    for _ in range(3):
                        self.root.bell()  # Use Tkinter's bell as fallback
                        time.sleep(0.2)
                except:
                    pass
    def alert_soun_path(self):
        """Set the path to the alert sound file"""
        self.alert_sound_path = "alert.wav"
    
    def _log_detection_internal(self, detection):
        self.root.after(0, lambda: self.scan_log.insert(tk.END, "Message\n"))
        self.scan_log.see(tk.END)
    def is_critical_process(self, process_name):
        """
        Determine if a process is a critical system process.
        
        Args:
            process_name (str): Name of the process
            
        Returns:
            bool: True if it's a critical process, False otherwise
        """
        critical_processes = {
            'winlogon.exe', 'lsass.exe', 'services.exe', 'csrss.exe', 
            'smss.exe', 'wininit.exe', 'system', 'svchost.exe'
        }
        return process_name.lower() in critical_processes

    def get_scan_priority(self, process_name, pid):
        """
        Determine the scanning priority for a process.
        Higher priority means it will be scanned earlier.
        
        Args:
            process_name (str): Name of the process
            pid (int): Process ID
            
        Returns:
            int: Scan priority (0-10, higher means scan first)
        """
        # Potentially suspicious processes get highest priority
        suspicious_processes = {'cmd.exe', 'powershell.exe', 'wscript.exe', 'cscript.exe', 'rundll32.exe'}
        if process_name.lower() in suspicious_processes:
            return 10
            
        # User processes get medium-high priority
        if pid > 1000 and not self.is_critical_process(process_name):
            return 7
            
        # Critical system processes get medium priority
        if self.is_critical_process(process_name):
            return 5
            
        # Default priority
        return 3

    def should_scan_process(self, process_info):
        """
        Decide whether a process should be scanned based on its properties.
        
        Args:
            process_info (dict): Process information dictionary
            
        Returns:
            bool: True if the process should be scanned, False otherwise
        """
        # Skip the current scanner process
        if process_info['pid'] == os.getpid():
            return False
            
        # Skip certain system processes that shouldn't be scanned
        excluded_processes = {'system idle process', 'memory compression'}
        if process_info['name'].lower() in excluded_processes:
            return False
            
        # Add your own exclusion logic here based on your scanning requirements
        
        return True                  
    def setup_gui(self):
        """Setup the GUI using only grid geometry manager"""
        # Configure root window
        self.root.columnconfigure(0, weight=1)
        self.root.rowconfigure(0, weight=1)
        
        # Main container frame
        main_container = ttk.Frame(self.root)
        main_container.grid(row=0, column=0, sticky=(tk.N, tk.S, tk.E, tk.W), padx=5, pady=5)
        main_container.columnconfigure(0, weight=1)
        main_container.rowconfigure(2, weight=1)  # Make the notebook expand
        
        # Status Panel at top (row 0)
        status_frame = ttk.LabelFrame(main_container, text="System Status", padding="5")
        status_frame.grid(row=0, column=0, sticky=(tk.W, tk.E), pady=(0, 5))
        status_frame.columnconfigure(1, weight=1)
        
        self.status_label = ttk.Label(status_frame, text="Protected", foreground="green")
        self.status_label.grid(row=0, column=0, padx=5)
        
        # Scan Progress Panel
        scan_frame = ttk.Frame(status_frame)
        scan_frame.grid(row=0, column=1, padx=5, sticky=(tk.W, tk.E))
        scan_frame.columnconfigure(0, weight=1)
        
        self.scan_progress = ttk.Progressbar(scan_frame, mode='determinate', length=200)
        self.scan_progress.grid(row=0, column=0, sticky=(tk.W, tk.E), padx=(0, 5))
        
        self.processes_scanned_label = ttk.Label(scan_frame, text="Processes: 0")
        self.processes_scanned_label.grid(row=0, column=1, padx=5)
        
        self.threats_found_label = ttk.Label(scan_frame, text="Threats: 0")
        self.threats_found_label.grid(row=0, column=2, padx=5)
        
        # Control Panel (row 1)
        control_panel = ttk.LabelFrame(main_container, text="Controls", padding="5")
        control_panel.grid(row=1, column=0, sticky=(tk.W, tk.E), pady=5)
        
        # Scan Controls
        scan_buttons = ttk.Frame(control_panel)
        scan_buttons.grid(row=0, column=0, sticky=(tk.W, tk.E))
        
        self.start_quick_scan_button = ttk.Button(scan_buttons, text="Quick Scan", command=self.start_quick_scan)
        self.start_quick_scan_button.grid(row=0, column=0, padx=2)
        
        self.start_deep_scan_button = ttk.Button(scan_buttons, text="Deep Scan", command=self.start_deep_scan)
        self.start_deep_scan_button.grid(row=0, column=1, padx=2)
        
        self.stop_scan_button = ttk.Button(scan_buttons, text="Stop Scan", command=self.stop_scan)
        self.stop_scan_button.grid(row=0, column=2, padx=2)
        
        # Alternative scan buttons for backward compatibility
        self.run_quick_scan_button = self.start_quick_scan_button
        self.run_deep_scan_button = self.start_deep_scan_button
        self.stop_button = self.stop_scan_button
        
        # Settings in control panel
        settings_controls = ttk.Frame(control_panel)
        settings_controls.grid(row=0, column=1, padx=10, sticky=(tk.W, tk.E))
        
        # Quarantine checkbox
        self.quarantine_checkbox = ttk.Checkbutton(
            settings_controls, 
            text="Auto Quarantine", 
            variable=self.quarantine_var,
            command=self.update_quarantine_settings
        )
        self.quarantine_checkbox.grid(row=0, column=0, padx=5)
        
        # Threshold controls
        threshold_frame = ttk.Frame(settings_controls)
        threshold_frame.grid(row=0, column=1, padx=5, sticky=(tk.W, tk.E))
        
        ttk.Label(threshold_frame, text="Threshold:").grid(row=0, column=0)
        self.threshold_slider = ttk.Scale(
            threshold_frame, 
            from_=0, to=100, 
            orient="horizontal",
            variable=self.threshold_var,
            length=100,
            command=lambda _: self.update_quarantine_settings()
        )
        self.threshold_slider.grid(row=0, column=1, padx=5, sticky=(tk.W, tk.E))
        ttk.Label(threshold_frame, textvariable=self.threshold_var).grid(row=0, column=2)
        
        # Detection count
        self.detection_count_label = ttk.Label(control_panel, text="Detections: 0")
        self.detection_count_label.grid(row=0, column=2, padx=5)
        # Process Control Buttons (row 1)
        process_buttons = ttk.LabelFrame(control_panel, text="Process Controls", padding="5")
        process_buttons.grid(row=1, column=0, sticky=(tk.W, tk.E), pady=5)
        ttk.Button(process_buttons, text="Create Test Detection", command=self.create_test_detection).grid(row=0, column=0, padx=2)
        ttk.Button(process_buttons, text="Terminate Process", command=self.kill_selected_process).grid(row=0, column=1, padx=2)
        ttk.Button(process_buttons, text="Terminate Region", command=self.terminate_selected_region).grid(row=0, column=2, padx=2)
        ttk.Button(process_buttons, text="Quarantine Memory", command=self.quarantine_selected_memory).grid(row=0, column=3, padx=2)
        
        # Detection Management Buttons (row 1, column 1)
        detection_buttons = ttk.LabelFrame(control_panel, text="Detection Management", padding="5")
        detection_buttons.grid(row=1, column=1, columnspan=2, sticky=(tk.W, tk.E), pady=5)
        
        ttk.Button(detection_buttons, text="Remove Infected File", command=self.remove_infected_file).grid(row=0, column=0, padx=2)
        ttk.Button(detection_buttons, text="Quarantine Selected", command=self.quarantine_file).grid(row=0, column=1, padx=2)
        ttk.Button(detection_buttons, text="Remove Selected Detection", command=self.remove_selected_detection).grid(row=0, column=2, padx=2)
        ttk.Button(detection_buttons, text="Restore Selected", command=self.restore_selected).grid(row=0, column=3, padx=2)
        
        # Notebook for tabs (row 2 - main content area)
        self.notebook = ttk.Notebook(main_container)
        self.notebook.grid(row=2, column=0, sticky=(tk.N, tk.S, tk.E, tk.W), pady=5)
        
        # Create tabs
        self.create_tabs()
        
        # Status bar at bottom (row 3)
        self.status_bar = ttk.Label(main_container, text="Ready", relief=tk.SUNKEN, anchor="w")
        self.status_bar.grid(row=3, column=0, sticky=(tk.W, tk.E), pady=(5, 0))
        
        # Create utility functions for tree operations
        self.create_tree_utilities()
        
    def create_tabs(self):
        """Create all notebook tabs"""
        # Active Detections Tab
        detections_frame = ttk.Frame(self.notebook)
        detections_frame.columnconfigure(0, weight=1)
        detections_frame.rowconfigure(0, weight=1)
        
        self.detections_treeview = ttk.Treeview(detections_frame, 
            columns=("timestamp", "name", "type", "severity", "location", "description"),
            show="headings")
        
        # Configure detection columns
        self.detections_treeview.heading("timestamp", text="Timestamp")
        self.detections_treeview.heading("name", text="Name")
        self.detections_treeview.heading("type", text="Type")
        self.detections_treeview.heading("severity", text="Severity")
        self.detections_treeview.heading("location", text="Location")
        self.detections_treeview.heading("description", text="Description")
        
        for col in ("timestamp", "name", "type", "severity", "location", "description"):
            self.detections_treeview.column(col, width=100)
        
        # Add scrollbar for detections
        detection_scroll = ttk.Scrollbar(detections_frame, orient="vertical", command=self.detections_treeview.yview)
        self.detections_treeview.configure(yscrollcommand=detection_scroll.set)
        
        self.detections_treeview.grid(row=0, column=0, sticky=(tk.N, tk.S, tk.E, tk.W))
        detection_scroll.grid(row=0, column=1, sticky=(tk.N, tk.S))
        
        self.notebook.add(detections_frame, text="Active Detections")
        
        # Scan Details Tab
        scan_details_frame = ttk.Frame(self.notebook)
        scan_details_frame.columnconfigure(0, weight=1)
        scan_details_frame.rowconfigure(0, weight=1)
        
        self.scan_log = tk.Text(scan_details_frame, height=10, wrap=tk.WORD)
        scan_log_scroll = ttk.Scrollbar(scan_details_frame, orient="vertical", command=self.scan_log.yview)
        self.scan_log.configure(yscrollcommand=scan_log_scroll.set)
        
        self.scan_log.grid(row=0, column=0, sticky=(tk.N, tk.S, tk.E, tk.W))
        scan_log_scroll.grid(row=0, column=1, sticky=(tk.N, tk.S))
        
        self.notebook.add(scan_details_frame, text="Scan Details")
        
        # Process Monitor Tab  
        process_frame = ttk.Frame(self.notebook)
        process_frame.columnconfigure(0, weight=1)
        process_frame.rowconfigure(0, weight=1)
        
        self.process_tree = ttk.Treeview(process_frame, 
            columns=("PID", "Name", "Status"),
            show="headings")
        
        for col in ("PID", "Name", "Status"):
            self.process_tree.heading(col, text=col)
            
        process_scroll = ttk.Scrollbar(process_frame, orient="vertical", command=self.process_tree.yview)
        self.process_tree.configure(yscrollcommand=process_scroll.set)
        
        self.process_tree.grid(row=0, column=0, sticky=(tk.N, tk.S, tk.E, tk.W))
        process_scroll.grid(row=0, column=1, sticky=(tk.N, tk.S))
        
        self.notebook.add(process_frame, text="Process Monitor")
        
        # Memory Analysis Tab
        memory_frame = ttk.Frame(self.notebook)
        memory_frame.columnconfigure(0, weight=1)
        memory_frame.rowconfigure(0, weight=1)
        
        self.memory_tree = ttk.Treeview(memory_frame, 
            columns=("PID", "Process", "Region", "Type", "Offset"),
            show="headings")
        
        for col in ("PID", "Process", "Region", "Type", "Offset"):
            self.memory_tree.heading(col, text=col)
            
        memory_scroll = ttk.Scrollbar(memory_frame, orient="vertical", command=self.memory_tree.yview)
        self.memory_tree.configure(yscrollcommand=memory_scroll.set)
        
        self.memory_tree.grid(row=0, column=0, sticky=(tk.N, tk.S, tk.E, tk.W))
        memory_scroll.grid(row=0, column=1, sticky=(tk.N, tk.S))
        
        self.notebook.add(memory_frame, text="Memory Analysis")
        
        # File Detections Tab
        file_frame = ttk.Frame(self.notebook)
        file_frame.columnconfigure(0, weight=1)
        file_frame.rowconfigure(0, weight=1)
        
        self.file_tree = ttk.Treeview(file_frame, 
            columns=("Path", "Type", "Hash", "Status"),
            show="headings")
        
        for col in ("Path", "Type", "Hash", "Status"):
            self.file_tree.heading(col, text=col)
            
        file_scroll = ttk.Scrollbar(file_frame, orient="vertical", command=self.file_tree.yview)
        self.file_tree.configure(yscrollcommand=file_scroll.set)
        
        self.file_tree.grid(row=0, column=0, sticky=(tk.N, tk.S, tk.E, tk.W))
        file_scroll.grid(row=0, column=1, sticky=(tk.N, tk.S))
        
        self.notebook.add(file_frame, text="File Detections")
        
        # Set widget references for compatibility
        self.detections_widget = self.detections_treeview
        self.detections_frame = detections_frame
        
    def create_tree_utilities(self):
        """Create utility functions for tree operations"""
        # Create a basic tree for backward compatibility
        tree = self.detections_treeview
        self.additem = lambda *args: tree.insert(*args)
        self.clear = lambda: tree.delete(*tree.get_children())
    
    def _update_scan_ui_start(self):
        """Thread-safe method to update UI when scan starts"""
        if hasattr(self, 'run_quick_scan_button'):
            self.run_quick_scan_button.configure(state='disabled')
        if hasattr(self, 'run_deep_scan_button'):
            self.run_deep_scan_button.configure(state='disabled')
        if hasattr(self, 'scan_progress'):
            self.scan_progress['value'] = 0
        if hasattr(self, 'stop_button'):
            self.stop_button.config(state='normal')
            
    def _update_scan_ui_end(self):
        """Thread-safe method to update UI when scan ends"""
        if hasattr(self, 'run_quick_scan_button'):
            self.run_quick_scan_button.configure(state='normal')
        if hasattr(self, 'run_deep_scan_button'):
            self.run_deep_scan_button.configure(state='normal')
        if hasattr(self, 'stop_button'):
            self.stop_button.config(state='disabled')
    
    def update_gui(self, process_info):
        """Update the GUI with process information"""
        logging.debug(f"Updating GUI with process: {process_info}")
        
        
            
        try:
            # Check if this is a real process before updating the UI
            if process_info.get('pid', 0) > 0 and process_info.get('name'):
                # Add to process tree or update existing entry
                item_id = f"proc_{process_info['pid']}"
                
                # Check if this process is already in the tree
                existing_items = self.process_tree.get_children("")
                for item in existing_items:
                    if self.process_tree.item(item, "values")[0] == str(process_info['pid']):
                        # Update existing entry
                        self.process_tree.item(item, values=(
                            process_info['pid'],
                            process_info['name'],
                            "Scanning",  # Status
                            ""  # Additional info
                        ))
                        return
                        
                # Add new entry if not found
                self.process_tree.insert("", tk.END, iid=item_id, values=(
                    process_info['pid'],
                    process_info['name'],
                    "Scanning",  # Status
                    ""  # Additional info
                ))
        except Exception as e:
            logging.error(f"Error updating process tree: {str(e)}")
    def update_scan_summary(self, processes_scanned, threats_found):
        self.processes_scanned_label.config(text=f"Processes Scanned: {processes_scanned}")
        self.threats_found_label.config(text=f"Threats Found: {threats_found}")
        self.root.update_idletasks()
    def stop_scan(self):
        self.scanning = False
        # Use thread-safe GUI updates
        self.root.after(0, self._update_scan_ui_end)

    def update_scan_progress(self, process_info):
        # Update progress bar
        if hasattr(self, 'scan_progress'):
            # Calculate progress based on total processes
            total_processes = len(psutil.process_iter())
            current = next((i for i, p in enumerate(self.process_list_data) 
                        if p['pid'] == process_info['pid']), 0)
            progress = min(100, int((current / total_processes) * 100))
            self.scan_progress['value'] = progress
        
        # Update status in process list
        for i, proc in enumerate(self.process_list_data):
            if proc['pid'] == process_info['pid']:
                self.process_list_data[i]['status'] = 'Scanned'
                break
        
        # Re-render the process tree
        self.process_tree.delete(*self.process_tree.get_children())
        for proc in self.process_list_data:
            self.process_tree.insert("", tk.END, values=(
                proc['pid'],
                proc['name'],
                proc['status'],
                len(proc['patterns']) > 0  # True if there are patterns
            ))
    def process_list_data(self, processes):
        """Process and format data for the process list display"""
        formatted_data = []
        for process in processes:
            try:
                pid = process.pid
                name = process.name()
                memory_info = process.memory_info()
                memory_usage = f"{memory_info.rss / 1024 / 1024:.2f} MB"
                
                formatted_data.append({
                    'PID': pid,
                    'Name': name,
                    'Memory': memory_usage,
                    'Status': 'Running'
                })
                
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                continue
                
        return formatted_data
    def load_signatures(self):
        try:
            self.load_signatures("signatures/malware.db")
            self.signature_status = True
            self.set_status_label("Signatures Loaded", "green")
        except Exception:
            logging.error(f"Failed to load signatures: {str(e)}")
            logging.debug(f'Signatures loaded: {self.signature_status}')
            self.set_status_label("Signatures Failed to Load", "red")
    def log_detection(self, detection):
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        """Log detected threats to GUI"""
        self.threats_found += 1
        self.threats_found_label.config(text=f"Threats Found: {self.threats_found}")
        
        # Add to detections tree
        self.detections_treeview.insert("", "end", values=(
            detection['pid'],
            detection['process'],
            detection['type'],
            detection.get('details', '')
        ))
        # Get current selection and view position
        selected_items = self.detections_treeview.selection()
        visible_items = self.detections_treeview.yview()
        
        # Insert new detection and store the reference
        new_item = self.detections_treeview.insert("", 0, values=(
            timestamp,
            detection.get('pid', ''),
            detection.get('process', ''),
            detection.get('type', ''),
            detection.get('location', ''),
            'Active'
        ))
        
        # Use new_item for selection if no existing selection
        if not selected_items:
            self.detections_treeview.selection_set(new_item)
            self.detections_treeview.focus(new_item)
        else:
            # Restore previous selection and view
            self.detections_treeview.selection_set(selected_items)
            self.detections_treeview.yview_moveto(visible_items[0])
        
        log_entry = f"[{timestamp}] {detection.get('type', 'Unknown')} detected in {detection.get('process', 'Unknown')} (PID: {detection.get('pid', 'N/A')})\n"
        self.scan_log.insert(tk.END, log_entry)
    def remove_selected_detection(self):
        selected = self.detections_treeview.selection()
        if selected:
            self.detections_treeview.delete(selected)
            self.scan_log.insert(tk.END, "Detection removed from list\n")
    def remove_infected_file(self):
        selected = self.detections_treeview.selection()
        if selected:
            item = self.detections_treeview.item(selected[0])
            filepath = item['values'][3]  # Location column
            try:
                os.remove(filepath)
                self.detections_treeview.delete(selected)
                self.scan_log.insert(tk.END, f"Removed infected file: {filepath}\n")
            except Exception as e:
                self.scan_log.insert(tk.END, f"Failed to remove file: {str(e)}\n")
    def quarantine_memory_region(self, pid: int, region_address: int, region_size: int) -> bool:
        logging.debug(f"\n=== Quarantining Memory Region ===")
        logging.debug(f"Process ID: {pid}")
        logging.debug(f"Region Address: {hex(region_address)}")
        logging.debug(f"Region Size: {region_size}")
        self.scanner = MemoryScanner()
        try:
            process = psutil.Process(pid)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

            # Ensure quarantine/dumps directory exists
            quarantine_base = self.quarantine_dir / "dumps"
            quarantine_base.mkdir(parents=True, exist_ok=True)

            # Create quarantine entry
            quarantine_id = f"mem_{pid}_{hex(region_address)}_{timestamp}"
            quarantine_path = quarantine_base / quarantine_id
            quarantine_path.mkdir(exist_ok=True)

            # Dump memory content
            process_handle = win32api.OpenProcess(
                win32con.PROCESS_QUERY_INFORMATION | win32con.PROCESS_VM_READ | win32con.PROCESS_VM_OPERATION,
                False,
                pid
            )
            # region_address and region_size are already ints
            memory_content = win32process.ReadProcessMemory(
                process_handle,
                region_address,
                region_size
            )

            # Save memory dump
            with open(quarantine_path / "memory.dump", "wb") as f:
                f.write(memory_content)

            # Zero out original memory
            null_bytes = b'\x00' * region_size
            win32process.WriteProcessMemory(
                process_handle,
                region_address,
                null_bytes,
                region_size
            )

            # Save metadata
            metadata = {
                'pid': pid,
                'process_name': process.name(),
                'region_address': hex(region_address),
                'region_size': region_size,
                'timestamp': timestamp,
                'quarantine_id': quarantine_id
            }

            with open(quarantine_path / "metadata.json", "w") as f:
                json.dump(metadata, f, indent=4)

            # Update quarantine tracking
            if not hasattr(MemoryScanner, "memory_quarantine"):
                MemoryScanner.memory_quarantine = {'active': {}, 'quarantined': []}
            MemoryScanner.memory_quarantine['active'][quarantine_id] = metadata
            MemoryScanner.memory_quarantine.setdefault('quarantined', []).append(quarantine_id)
            logging.debug(f"Memory region successfully quarantined: {quarantine_id}")
            return True

        except Exception as e:
            logging.error(f"Quarantine failed: {str(e)}")
            logging.error(traceback.format_exc())
            return False
    def terminate_selected_region(self):
        selected = self.detections_treeview.selection()
        if selected:
            item = self.detections_treeview.item(selected)
            pid_value = item['values'][1]  # PID column
            location = item['values'][4]  # Location column

            # Only proceed if pid_value is a digit
            if isinstance(pid_value, (int, float)) or (isinstance(pid_value, str) and pid_value.isdigit()):
                pid = int(pid_value)
            # Check if location is a memory address or file path
            if location.startswith('0x'):
                offset = int(location, 16)
                region_size = 4096  # Default memory page size
                
                try:
                    process = psutil.Process(pid)
                    if process.is_running():
                        process_handle = win32api.OpenProcess(
                        win32con.PROCESS_QUERY_INFORMATION | win32con.PROCESS_VM_READ,
                        False,
                        pid
                    )
                        
                        # Zero out the memory region
                        win32process.WriteProcessMemory(process_handle, offset, b'\x00' * region_size, region_size)
                        win32api.CloseHandle(process_handle)
                        
                        self.detections_treeview.delete(selected)
                        self.scan_log.insert(tk.END, f"Terminated memory region at {hex(offset)} in PID {pid}\n")
                        logging.info(f"Memory region terminated successfully in PID {pid}")
                except Exception:
                    self.scan_log.insert(tk.END, f"Failed to terminate memory region: {str(e)}\n")
                    logging.error(f"Memory termination failed: {str(e)}")
                    logging.debug(f'Memory termination failed: {str(e)}')
            else:
                self.scan_log.insert(tk.END, f"Selected item is not a memory region\n")
                
    def terminate_selected_process(self):
        selected = self.detections_treeview.selection()
        if selected:
            item = self.detections_treeview.item(selected)
            pid = item['values'][1]  # PID is in second column
            process_name = item['values'][2]  # Process name in third column
            
            # Handle test detection
            if process_name == 'test_process.exe':
                self.detections_treeview.delete(selected)
                self.scan_log.insert(tk.END, f"Removed test detection process {process_name}\n")
                return
                
            # Handle real process
            try:
                pid = int(pid)
                process = psutil.Process(pid)
                process.terminate()  # Try graceful termination first
                process.wait(timeout=3)  # Wait for termination
                if process.is_running():
                    process.kill()  # Force kill if still running
                self.detections_treeview.delete(selected)
                self.scan_log.insert(tk.END, f"Process {pid} terminated\n")
            except psutil.NoSuchProcess:
                self.scan_log.insert(tk.END, f"Process {pid} already terminated\n")
                self.detections_treeview.delete(selected)
            except Exception:
                self.scan_log.insert(tk.END, f"Failed to terminate process {pid}: {str(e)}\n")
    def remove_selected(self):
        selected = self.process_tree.selection()
        if selected:
            item = self.process_tree.item(selected)
            quarantine_id = item['values']
            logging.info(f"Removing quarantined process {quarantine_id}")
            if self.remove_quarantined(quarantine_id):
                self.scan_log.insert(tk.END, f"Removed quarantined process {quarantine_id}\n")
                self.process_tree.delete(selected)
                
    def quarantine_selected_memory(self):
        selected = self.detections_treeview.selection()
        if selected:
            item = self.detections_treeview.item(selected[0])
            values = item['values']
            try:
                pid = int(values[1])  # PID column
                location = values[4]  # Location column (should be hex address)
                if isinstance(location, str) and location.startswith('0x'):
                    region_address = int(location, 16)
                    region_size = 4096  # Or extract from another column if available
                    success = self.quarantine_memory_region(pid, region_address, region_size)
                    if success:
                        self.scan_log.insert(tk.END, f"Memory region at {location} in PID {pid} quarantined.\n")
                    else:
                        self.scan_log.insert(tk.END, f"Failed to quarantine memory region at {location} in PID {pid}.\n")
                else:
                    self.scan_log.insert(tk.END, "Selected detection does not have a valid memory address.\n")
            except Exception as e:
                self.scan_log.insert(tk.END, f"Error: {str(e)}\n")
        else:
            self.scan_log.insert(tk.END, "No detection selected.\n")
    def quarantine_file(self, filepath: str) -> bool:
        try:
            MalwareScanner.quarantine_dir.mkdir(exist_ok=True)
            filename = Path(filepath).name
            quarantine_path = MalwareScanner.quarantine_dir / f"{filename}.quarantine"
            shutil.move(filepath, quarantine_path)
            logging.info(f"Quarantined {filepath} to {quarantine_path}")
            return True
        except Exception as e:
            logging.error(f"Quarantine failed for {filepath}: {str(e)}")
            logging.debug(f"Qarantine failed: {str(e)}")
        # Add to quarantine_selected
            logging.info(f"Quarantining File {filepath}")
    def remove_file(self, filepath: str) -> bool:
        try:
            os.remove(filepath)
            logging.info(f"Removed infected file: {filepath}")
            return True
        except Exception as e:
            logging.error(f"Removal failed for {filepath}: {str(e)}")
            logging.debug(f"Removal failed: {str(e)}")
        # Add to remove_infected_file
    def kill_process(self, pid: int) -> bool:
        try:
            process = psutil.Process(pid)
            process.kill()
            logging.info(f"Terminated suspicious process: PID {pid}")
            return True
        except Exception as e:
            logging.error(f"Failed to terminate process {pid}: {str(e)}")
            logging.debug(f"failing to terminate process: {str(e)}")
            return False
    def kill_selected_process(self):
        selected = self.process_tree.selection()
        if selected:
            item = self.process_tree.item(selected)
            # item['values'] is a tuple/list, e.g. (pid, name, status)
            pid_value = item['values'][0]  # Assuming PID is the first column
            try:
                pid = int(pid_value)
                process = psutil.Process(pid)
                process.kill()
                self.scan_log.insert(tk.END, f"Process {pid} terminated successfully\n")
                self.process_tree.delete(selected)
                logging.info(f"Terminated process {pid}")
            except Exception as e:
                self.scan_log.insert(tk.END, f"Failed to terminate process {pid_value}: {str(e)}\n")
                logging.error(f"Process termination failed: {str(e)}")
    def restore_process(self, quarantine_id: str) -> bool:
        quarantine_path = MalwareScanner.quarantine_dir / quarantine_id
        try:
            with open(quarantine_path / 'metadata.json', 'r') as f:
                metadata = json.load(f)
    # Restore process executable
                shutil.copy2(metadata['exe'], metadata['exe'] + '.restored')
            return True
        except Exception as e:
            logging.error(f"Restore failed for {quarantine_id}: {str(e)}")
            logging.debug(f"Restore failed: {str(e)}")
            return False
    def remove_quarantined(self, quarantine_id: str) -> bool:
        try:
            quarantine_path = MalwareScanner.quarantine_dir / quarantine_id
            shutil.rmtree(quarantine_path)
            return True
        except Exception as e:
            logging.error(f"Remove failed for {quarantine_id}: {str(e)}")
            return False
    def restore_selected(self):
        selected = self.process_tree.selection()
        if selected:
            item = self.process_tree.item(selected)
            quarantine_id = item['values']
            if self.restore_process(quarantine_id):
                self.scan_log.insert(tk.END, f"Process {quarantine_id} restored successfully\n")
                self.process_tree.delete(selected)
                logging.info(f"Restoring quarantined process {quarantine_id}")
    def create_test_detection(self):
        # Create a mock detection entry
        test_detection = {
            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'name': 'test_process.exe',
            'type': 'TEST_DETECTION',
            'severity': 'High',
            'location': 'C:\\test\\path',
            'description': 'Mock detection for testing purposes'
        }
        
        # Insert into detections tree with correct column format
        self.detections_treeview.insert("", tk.END, values=(
            test_detection['timestamp'],
            test_detection['name'],
            test_detection['type'],
            test_detection['severity'],
            test_detection['location'],
            test_detection['description']
        ))
    def update_process_list(self, results):
        self.process_tree.delete(*self.process_tree.get_children())
        for result in results:
            status = "Clean"
            threat_details = []
            
            if result['patterns']:
                status = "Suspicious"
                # Build threat details
                for pattern_type, details in result['patterns'].items():
                    threat_info = f"Pattern: {pattern_type}"
                    if 'yara_rule' in details:
                        threat_info += f" (Rule: {details['yara_rule']})"
                    if 'offset' in details:
                        threat_info += f" at {details['offset']}"
                    threat_details.append(threat_info)
                
                # Update memory tree
                if 'memory_region' in result:
                    self.memory_tree.insert("", tk.END, values=(
                        result['pid'],
                        result['name'],
                        result.get('memory_region', ''),
                        '\n'.join(threat_details),  # Display all threat details
                        details.get('offset', '')
                    ))
                
                # Update file tree
                if 'filepath' in result:
                    self.file_tree.insert("", tk.END, values=(
                        result['filepath'],
                        '\n'.join(threat_details),  # Display all threat details
                        result.get('hash', ''),
                        status
                    ))
                
                # Log detection with full details
                self.log_detection(result, threat_details)
                
                # Display threat details window
                self.display_threat_details({
                    'pid': result['pid'],
                    'name': result['name'],
                    'exe': result.get('exe', ''),
                    'patterns': result['patterns'],
                    'threat_details': threat_details
                })
    
    def load_rules_async(self):
            self.yara_manager = YaraRuleManager()
            self.yara_manager.fetch_all_rules()
            self.rules_loaded = True
            self.update_rule_status_display()  # Add this line
           
        
    def start_scan(self):
        # Create a scanning thread
        self.scanning = True
        scan_thread = threading.Thread(target=self.scanning_loop, daemon=True)
        scan_thread.start()
    def start_quick_scan(self):
        if not self.rules_loaded:
            self.scan_log.insert(tk.END, "Please wait for YARA rules to load\n")
            return
        self.scan_progress['value'] = 0
        threading.Thread(target=self.run_quick_scan, daemon=True).start()

    def start_deep_scan(self):
        if not self.rules_loaded:
            self.scan_log.insert(tk.END, "Please wait for YARA rules to load\n")
            return
        self.scan_progress['value'] = 0
        threading.Thread(target=self.run_deep_scan, daemon=True).start()
    
    def handle_detection_alert(self, detection):
        """Handle real-time detection alerts"""
        # Update GUI with detection info
        self.scan_log.insert(tk.END, f"ALERT: Threat detected in process {detection['process']} (PID: {detection['pid']})\n")
        self.scan_log.see(tk.END)
        
        # Update detection trees
        self.update_detection_trees(detection)
        
        # Flash status indicator
        self.status_label.config(foreground="red")
        self.root.after(1000, lambda: self.status_label.config(foreground="green"))
    def update_detection_trees(self, detection):
        """Updates both memory and file detection trees with new threats"""
        
        # Update memory detections tree
        self.memory_tree.insert("", tk.END, values=(
            detection['pid'],
            detection['process'],
            hex(detection['region']),
            detection['matches'][0].rule,  # Show first matching rule
            hex(detection['matches'].strings)  # Show first match offset
        ))
        
        # If process has associated file path, update file detections
        if 'filepath' in detection:
            self.file_tree.insert("", tk.END, values=(
                detection['filepath'],
                'Memory Injection',
                hashlib.md5(open(detection['filepath'], 'rb').read()).hexdigest(),
                'Suspicious'
            ))
        
        # Ensure newest detections are visible
        self.memory_tree.see(self.memory_tree.get_children()[-1])
        self.file_tree.see(self.file_tree.get_children()[-1])    
       
    
    def scanning_loop(self, pid):
        
        logging.debug("Entering scanning_loop")
        
        # Initialize scanner
        logging.debug("Initializing scanner")
        self.scanner = MemoryScanner()
        self.scanner.alert_callback = self.log_detection
        logging.debug("Scanner initialized")
        
        # Type safety check
        if isinstance(pid, MemoryScanner):
            logging.warning("Invalid PID type detected - scanner object passed as PID")
            return
        
        # Memory protection constants
        PAGE_EXECUTE = win32con.PAGE_EXECUTE
        PAGE_EXECUTE_READ = win32con.PAGE_EXECUTE_READ
        PAGE_EXECUTE_READWRITE = win32con.PAGE_EXECUTE_READWRITE
        PAGE_EXECUTE_WRITECOPY = win32con.PAGE_EXECUTE_WRITECOPY
        PAGE_NOACCESS = win32con.PAGE_NOACCESS
        PAGE_READONLY = win32con.PAGE_READONLY
        PAGE_READWRITE = win32con.PAGE_READWRITE
        PAGE_WRITECOPY = win32con.PAGE_WRITECOPY
        PAGE_TARGETS_INVALID = 0x40000000
        MEM_COMMIT = win32con.MEM_COMMIT
        MEM_IMAGE = 0x1000000
        KNOWN_PROTECTED_APPS = {
            "chrome.exe", "msedge.exe", "firefox.exe", "discord.exe", "spotify.exe",
            "code.exe", "githubdesktop.exe", "runtimebroker.exe", "conhost.exe",
            "razerappengine.exe", "wudfhost.exe", "dllhost.exe", "pwsh.exe"
        }

        def is_known_protected_app(process_name):
            return process_name.lower() in KNOWN_PROTECTED_APPS

        # In your scan loop, when access is denied:
        if not self.scanner.is_critical_process(proc.name()) and not is_known_protected_app(proc.name()):
            self.root.after(0, self.log_suspicious_region, {
                'pid': proc.pid,
                'process': proc.name(),
                'type': 'Access Denied',
                'details': f"Non-system process denied access (Error {error_code})"
            })
        else:
            logging.info(f"Access denied to known protected app: {proc.name()} (PID {proc.pid})")
        # Memory region enumeration function
        def enumerate_memory_regions(handle):
            class MEMORY_BASIC_INFORMATION(ctypes.Structure):
                _fields_ = [
                    ("BaseAddress", ctypes.c_void_p),
                    ("AllocationBase", ctypes.c_void_p),
                    ("AllocationProtect", ctypes.c_ulong),
                    ("RegionSize", ctypes.c_size_t),
                    ("State", ctypes.c_ulong),
                    ("Protect", ctypes.c_ulong),
                    ("Type", ctypes.c_ulong)
                ]
            
            regions = []
            address = 0
            mbi = MEMORY_BASIC_INFORMATION()
            logging.debug("Starting memory region enumeration")
            try:
                process_handle = win32api.OpenProcess(
                    win32con.PROCESS_ALL_ACCESS | win32con.PROCESS_VM_READ | win32con.PROCESS_VM_OPERATION,
                    False, proc.pid)
                if not process_handle:
                    error_code = ctypes.GetLastError()
                    logging.warning(f"Access denied to PID {proc.pid} ({proc.name()}) [Error {error_code}]")
                    # Optionally flag as suspicious if not a system process
                    if not self.scanner.is_critical_process(proc.name()):
                        self.root.after(0, self.log_suspicious_region, {
                            'pid': proc.pid,
                            'process': proc.name(),
                            'type': 'Access Denied',
                            'details': f"Non-system process denied access (Error {error_code})"
                        })  # Skip to next process
            except Exception as e:
                logging.error(f"Failed to open process {proc.pid}: {str(e)}")
            while True:
                if ctypes.windll.kernel32.VirtualQueryEx(handle, ctypes.c_void_p(address), 
                                                        ctypes.byref(mbi), ctypes.sizeof(mbi)) == 0:
                    break
                
                regions.append({
                    'BaseAddress': mbi.BaseAddress,
                    'AllocationBase': mbi.AllocationBase,
                    'RegionSize': mbi.RegionSize,
                    'State': mbi.State,
                    'Protect': mbi.Protect,
                    'Type': mbi.Type
                })
                
                logging.debug(f"Memory region: {mbi.BaseAddress} - {mbi.RegionSize}")
                address = int(mbi.BaseAddress) + mbi.RegionSize
            
            return regions
        
        # Process selection based on pid parameter
        logging.debug(f"Setting up process selection with pid: {pid}")
        processes_to_scan = []
        
        if pid and isinstance(pid, int) and pid > 0:
            try:
                proc = psutil.Process(pid)
                processes_to_scan = [proc]
                logging.info(f"Scanning specific process: {proc.name()} (PID: {pid})")
            except psutil.NoSuchProcess:
                logging.error(f"Process with PID {pid} not found")
                return
        else:
             processes_to_scan = list(psutil.process_iter(['pid', 'name']))
             logging.info(f"Found {len(processes_to_scan)} running processes")
        
        # Main scan loop
        for proc in processes_to_scan:
            logging.debug(f"Scanning process: {proc.name()} (PID: {proc.pid})")
            if not self.scanning:
                break
            
            try:
                # Only call update_gui with valid process information
                if proc.pid > 0 and proc.name():
                    process_info = {'pid': proc.pid, 'name': proc.name()}
                    self.root.after(0, self.update_gui, process_info)
                
                if proc.pid in (0, 4):  # Skip system processes
                    continue
                
                process_handle = None
                try:
                    process_handle = win32api.OpenProcess(
                        win32con.PROCESS_ALL_ACCESS | win32con.PROCESS_VM_READ | win32con.PROCESS_VM_OPERATION,
                        False, proc.pid)
                    try:
                        # Check for injection techniques
                        if hasattr(self.scanner, 'detect_injection_techniques'):
                            injection_findings = self.scanner.detect_injection_techniques(process_handle, proc.pid)
                            for finding in injection_findings:
                                self.root.after(0, self.log_suspicious_region, {
                                    'pid': proc.pid,
                                    'process': proc.name(),
                                    'type': f'Injection Technique: {finding["technique"]}',
                                    'details': finding.get('details', '')
                                })
                    except Exception as inj_error:
                        logging.error(f"Error detecting injection techniques: {str(inj_error)}")
                    try:
                        # Check for suspicious threads
                        if hasattr(self.scanner, 'inspect_threads'):
                            thread_findings = self.scanner.inspect_threads(proc.pid)
                            for finding in thread_findings:
                                self.root.after(0, self.log_suspicious_region, {
                                    'pid': proc.pid,
                                    'process': proc.name(),
                                    'type': 'Suspicious Thread',
                                    'details': f"TID: {finding.get('tid')} - {finding.get('details')}"
                                })
                    except Exception as thread_error:
                        logging.error(f"Error inspecting threads: {str(thread_error)}")
                    try:
                        # Check for suspicious network connections
                        if hasattr(self.scanner, 'check_network_connections'):
                            connections = self.scanner.check_network_connections(proc.pid)
                            for conn in connections:
                                if conn.get('suspicious', False):
                                    self.root.after(0, self.log_suspicious_region, {
                                        'pid': proc.pid,
                                        'process': proc.name(),
                                        'type': 'Suspicious Network Connection',
                                        'details': f"Remote: {conn.get('remote_addr')}:{conn.get('remote_port')} Status: {conn.get('status')}"
                                    })
                    except Exception as net_error:
                        logging.error(f"Error checking network connections: {str(net_error)}")
                    
                    try:
                        # Registry verification for suspicious keys
                        if hasattr(self.scanner, 'verify_registry'):
                            registry_findings = self.scanner.verify_registry(proc.pid)
                            for finding in registry_findings:
                                self.root.after(0, self.log_suspicious_region, {
                                    'pid': proc.pid,
                                    'process': proc.name(),
                                    'type': f'Registry Anomaly: {finding["type"]}',
                                    'details': finding["details"]
                                })
                    except Exception as reg_error:
                        logging.error(f"Error during registry verification: {str(reg_error)}") 
                    try:
                        # Verify loaded modules
                        if hasattr(self.scanner, 'verify_modules'):
                            module_findings = self.scanner.verify_modules(process_handle, proc.pid)
                            for finding in module_findings:
                                self.root.after(0, self.log_suspicious_region, {
                                    'pid': proc.pid,
                                    'process': proc.name(),
                                    'address': finding.get('address', 'Unknown'),
                                    'type': f'Module Anomaly: {finding["type"]}',
                                    'details': finding.get('path', '') + ' - ' + finding.get('details', '')
                                })
                    except Exception as mod_error:
                        logging.error(f"Error during module verification: {str(mod_error)}")
                    # Track region types
                    rwx_regions = []
                    wx_regions = []
                    readonly_regions = []
                    noaccess_regions = []
                    writecopy_regions = []
                    executable_regions = []
                    targets_invalid_regions = []
                    execute_read_regions = []
                    shellcode_patterns = [
                        (b"\xfc\xe8\x89\x00\x00\x00\x60", "Metasploit shellcode signature"),
                        (b"\x48\x31\xc0\x48\x31\xff\x48\x31\xd2\x48\x31\xf6", "Null-free shellcode"),
                        (b"\x55\x8b\xec\x83\xec", "Function prologue with stack adjustment"),
                        (b"\x33\xc0\x50\x68", "XOR EAX + PUSH sequence (common in shellcode)"),
                        (b"\xe9\x00\x00\x00\x00", "JMP instruction (common shellcode redirector)")
                    ]

                    for pattern, desc in shellcode_patterns:
                        if pattern in memory_content:
                            self.root.after(0, self.log_suspicious_region, {
                                'pid': proc.pid,
                                'process': proc.name(),
                                'address': hex(base_addr_int),
                                'protection': hex(protection),
                                'type': f'Shellcode Pattern Detected',
                                'details': desc
                            })
                    for region in enumerate_memory_regions(process_handle):
                        if not self.scanning:
                            break
                        
                        # Skip non-committed or tiny memory regions
                        if not (region['State'] & MEM_COMMIT) or region['RegionSize'] < 4096:
                            continue
                        
                        protection = region['Protect']
                        base_addr = region['BaseAddress']
                        base_addr_int = self.scanner.safe_int_conversion(base_addr)
                        
                        # Determine region characteristics
                        is_executable = bool(protection & (PAGE_EXECUTE | PAGE_EXECUTE_READ | 
                                        PAGE_EXECUTE_READWRITE | PAGE_EXECUTE_WRITECOPY))
                        is_rwx = bool(protection & PAGE_EXECUTE_READWRITE)
                        is_wx = bool((protection & PAGE_EXECUTE) and (protection & PAGE_READWRITE))
                        is_system_process = proc.name().lower() in ['lsass.exe', 'csrss.exe', 'svchost.exe', 'winlogon.exe']
                        
                        # Categorize the region
                        if is_executable:
                            executable_regions.append(base_addr)
                            
                            # Check for executable regions in unusual locations
                            if region['Type'] == MEM_COMMIT and region['RegionSize'] > 4096:
                                self.root.after(0, self.log_suspicious_region, {
                                    'pid': proc.pid,
                                    'process': proc.name(),
                                    'address': hex(base_addr_int),
                                    'size': region['RegionSize'],
                                    'protection': hex(protection),
                                    'location': hex(base_addr_int) if region['Type'] != MEM_IMAGE else None,
                                    'type': 'Large private executable memory (Potential unpacked code)'
                                })
                            
                            # Check for executable regions near the top of memory (often used by exploits)
                            if base_addr_int > 0x70000000:
                                self.root.after(0, self.log_suspicious_region, {
                                    'pid': proc.pid,
                                    'process': proc.name(),
                                    'address': hex(base_addr_int),
                                    'size': region['RegionSize'],
                                    'protection': hex(protection),
                                    'location': hex(base_addr_int) if region['Type'] != MEM_IMAGE else None,
                                    'type': 'High memory address executable region (Potential exploit)'
                                })
                            
                            # For system processes, check for small executable regions
                            if is_system_process:
                                logging.debug(f"System process {proc.name()} has executable region at {hex(base_addr_int)}")
                                
                                if region['RegionSize'] < 8192 and region['Type'] != MEM_IMAGE:
                                    self.root.after(0, self.log_suspicious_region, {
                                        'pid': proc.pid,
                                        'process': proc.name(),
                                        'address': hex(base_addr_int),
                                        'size': region['RegionSize'],
                                        'protection': hex(protection),
                                        'location': hex(base_addr_int) if region['Type'] != MEM_IMAGE else None,
                                        'type': 'Small executable region in system process (Suspicious)'
                                    })
                        
                        # Check specific protection types
                        if protection & PAGE_READONLY:
                            readonly_regions.append(base_addr)
                            # Check for large readonly regions in private memory (can hide data)
                            if region['Type'] & 0x20000 and region['RegionSize'] > 5*1024*1024:
                                self.root.after(0, self.log_suspicious_region, {
                                    'pid': proc.pid,
                                    'process': proc.name(),
                                    'address': hex(base_addr_int),
                                    'size': region['RegionSize'],
                                    'protection': hex(protection),
                                    'location': hex(base_addr_int) if region['Type'] != MEM_IMAGE else None,
                                    'type': 'Large PAGE_READONLY private memory (potential hidden data)'
                                })
                        
                        if protection & PAGE_EXECUTE_READ:
                            execute_read_regions.append(base_addr)
                            
                            # Check if this region was previously writable and now executable
                            if hasattr(self, 'previous_scan_regions') and base_addr_int in self.previous_scan_regions:
                                prev_protection = self.previous_scan_regions[base_addr_int]
                                if prev_protection & PAGE_READWRITE and not (prev_protection & PAGE_EXECUTE):
                                    self.root.after(0, self.log_suspicious_region, {
                                        'pid': proc.pid,
                                        'process': proc.name(),
                                        'address': hex(base_addr_int),
                                        'size': region['RegionSize'],
                                        'protection': hex(protection),
                                        'type': 'Changed from RW to PAGE_EXECUTE_READ (Potential dynamic code)'
                                    })
                            
                            # For non-image memory, PAGE_EXECUTE_READ can be suspicious
                            if region['Type'] != MEM_IMAGE:
                                self.root.after(0, self.log_suspicious_region, {
                                    'pid': proc.pid,
                                    'process': proc.name(),
                                    'address': hex(base_addr_int),
                                    'size': region['RegionSize'],
                                    'protection': hex(protection),
                                    'location': hex(base_addr_int) if region['Type'] != MEM_IMAGE else None,
                                    'type': 'PAGE_EXECUTE_READ in non-image memory (Suspicious)'
                                })
                                
                                # Check memory content for suspicious patterns
                                try:
                                    size_to_read = min(region['RegionSize'], 1024 * 1024)  # 1MB max for performance
                                    memory_content = win32process.ReadProcessMemory(
                                        process_handle, base_addr_int, size_to_read)
                                    
                                    # Check for specific shellcode markers
                                    if memory_content and len(memory_content) > 64:
                                        if b"\xff\x34\x8f" in memory_content or b"\x89\xe5\x81\xc4" in memory_content:
                                            self.root.after(0, self.log_suspicious_region, {
                                                'pid': proc.pid,
                                                'process': proc.name(),
                                                'address': hex(base_addr_int),
                                                'size': region['RegionSize'],
                                                'protection': hex(protection),
                                                'location': hex(base_addr_int) if region['Type'] != MEM_IMAGE else None,
                                                'type': 'PAGE_EXECUTE_READ with shellcode patterns'
                                            })
                                except Exception as e:
                                    logging.debug(f"Error scanning XR region at {hex(base_addr_int)}: {str(e)}")
                        
                        if protection & PAGE_NOACCESS:
                            noaccess_regions.append(base_addr)
                            if region['Type'] == MEM_IMAGE:
                                self.root.after(0, self.log_suspicious_region, {
                                    'pid': proc.pid,
                                    'process': proc.name(),
                                    'address': hex(base_addr_int),
                                    'size': region['RegionSize'],
                                    'protection': hex(protection),
                                    'location': hex(base_addr_int) if region['Type'] != MEM_IMAGE else None,
                                    'type': 'PAGE_NOACCESS in image memory (possibly hidden code)'
                                })
                        
                        if protection & PAGE_WRITECOPY:
                            writecopy_regions.append(base_addr)
                            if region['Type'] != MEM_IMAGE:
                                self.root.after(0, self.log_suspicious_region, {
                                    'pid': proc.pid,
                                    'process': proc.name(),
                                    'address': hex(base_addr_int),
                                    'size': region['RegionSize'],
                                    'protection': hex(protection),
                                    'location': hex(base_addr_int) if region['Type'] != MEM_IMAGE else None,
                                    'type': 'PAGE_WRITECOPY in non-image memory (unusual)'
                                })
                        
                        if protection & PAGE_TARGETS_INVALID:
                            targets_invalid_regions.append(base_addr)
                            self.root.after(0, self.log_suspicious_region, {
                                'pid': proc.pid,
                                'process': proc.name(),
                                'address': hex(base_addr_int),
                                'size': region['RegionSize'],
                                'protection': hex(protection),
                                'location': hex(base_addr_int) if region['Type'] != MEM_IMAGE else None,
                                'type': 'PAGE_TARGETS_INVALID region detected (CFG bypass)'
                            })
                            
                            # More suspicious in system processes
                            if is_system_process:
                                self.root.after(0, self.log_suspicious_region, {
                                    'pid': proc.pid,
                                    'process': proc.name(),
                                    'address': hex(base_addr_int),
                                    'size': region['RegionSize'],
                                    'protection': hex(protection),
                                    'location': hex(base_addr_int) if region['Type'] != MEM_IMAGE else None,
                                    'type': 'CRITICAL: System process with CFG bypass'
                                })
                        
                        # Check for RWX memory
                        if is_rwx:
                            rwx_regions.append(base_addr)
                            self.root.after(0, self.log_suspicious_region, {
                                'pid': proc.pid,
                                'process': proc.name(),
                                'address': hex(base_addr_int),
                                'size': region['RegionSize'],
                                'protection': hex(protection),
                                'location': hex(base_addr_int) if region['Type'] != MEM_IMAGE else None,
                                'type': 'RWX Memory (Potential Code Injection)'
                            })
                        
                        # Check for WX memory
                        if is_wx:
                            wx_regions.append(base_addr)
                            self.root.after(0, self.log_suspicious_region, {
                                'pid': proc.pid,
                                'process': proc.name(),
                                'address': hex(base_addr_int),
                                'size': region['RegionSize'],
                                'protection': hex(protection),
                                'location': hex(base_addr_int) if region['Type'] != MEM_IMAGE else None,
                                'type': 'Write+Execute Memory (Potential Shellcode)'
                            })
                        
                        # Check writable+executable image files
                        if (is_rwx or protection & PAGE_EXECUTE_WRITECOPY) and region['Type'] == MEM_IMAGE:
                            self.root.after(0, self.log_suspicious_region, {
                                'pid': proc.pid,
                                'process': proc.name(),
                                'address': hex(base_addr_int),
                                'size': region['RegionSize'],
                                'protection': hex(protection),
                                'location': hex(base_addr_int) if region['Type'] != MEM_IMAGE else None,
                                'type': 'Executable Image with writable+executable permissions'
                            })
                        
                        # Deep scan suspicious regions
                        should_scan = (is_rwx or is_wx or (protection & PAGE_TARGETS_INVALID) or
                                    (hasattr(self.scanner, 'should_scan_region') and
                                    self.scanner.should_scan_region(region)))
                        
                        if should_scan:
                            try:
                                size_to_read = min(region['RegionSize'], 10 * 1024 * 1024)  # Limit size to 10MB
                                memory_content = win32process.ReadProcessMemory(
                                    process_handle, base_addr_int, size_to_read)
                                
                                if memory_content:
                                    # Check injection patterns
                                    if hasattr(self.scanner, 'injection_patterns'):
                                        for name, pattern in self.scanner.injection_patterns.items():
                                            try:
                                                if isinstance(pattern, bytes):
                                                    if pattern in memory_content:
                                                        self.root.after(0, self.log_suspicious_region, {
                                                            'pid': proc.pid,
                                                            'process': proc.name(),
                                                            'address': hex(base_addr_int),
                                                            'protection': hex(protection),
                                                            'type': f'Injection Pattern: {name}'
                                                        })
                                                elif hasattr(pattern, 'search'):  # Regex pattern
                                                    if pattern.search(memory_content):
                                                        self.root.after(0, self.log_suspicious_region, {
                                                            'pid': proc.pid,
                                                            'process': proc.name(),
                                                            'address': hex(base_addr_int),
                                                            'protection': hex(protection),
                                                            'type': f'Injection Pattern: {name}'
                                                        })
                                                elif isinstance(pattern, str):
                                                    pattern_bytes = pattern.encode() if isinstance(memory_content, bytes) else pattern
                                                    if re.search(pattern_bytes, memory_content):
                                                        self.root.after(0, self.log_suspicious_region, {
                                                            'pid': proc.pid,
                                                            'process': proc.name(),
                                                            'address': hex(base_addr_int),
                                                            'protection': hex(protection),
                                                            'type': f'Injection Pattern: {name}'
                                                        })
                                            except Exception as pattern_error:
                                                logging.debug(f"Pattern match error: {str(pattern_error)}")
                                    
                                    # YARA scanning
                                    if hasattr(self.scanner, 'combined_rules') and self.scanner.combined_rules:
                                        try:
                                            matches = self.scanner.combined_rules.match(data=memory_content)
                                            for match in matches:
                                                self.root.after(0, self.log_suspicious_region, {
                                                    'pid': proc.pid,
                                                    'process': proc.name(),
                                                    'address': hex(base_addr_int),
                                                    'protection': hex(protection),
                                                    'type': f'YARA Rule: {match.rule}',
                                                    'details': f'Match in {region["RegionSize"]} byte region at {hex(base_addr_int)}'
                                                })
                                        except Exception as yara_error:
                                            logging.debug(f"YARA scan error: {str(yara_error)}")
                            except Exception as mem_error:
                                logging.debug(f"Error reading memory at {hex(base_addr_int)}: {str(mem_error)}")
                    
                    # Process summary and statistics
                    logging.info(f"Process {proc.name()} scan summary:")
                    logging.info(f"  Executable regions: {len(executable_regions)}")
                    logging.info(f"  EXECUTE_READ regions: {len(execute_read_regions)}")
                    logging.info(f"  READONLY regions: {len(readonly_regions)}")
                    logging.info(f"  NOACCESS regions: {len(noaccess_regions)}")
                    logging.info(f"  WRITECOPY regions: {len(writecopy_regions)}")
                    logging.info(f"  RWX regions: {len(rwx_regions)}")
                    logging.info(f"  WX regions: {len(wx_regions)}")
                    logging.info(f"  CFG INVALID regions: {len(targets_invalid_regions)}")
                    
                    # Log suspicious combinations
                    if len(rwx_regions) > 0:
                        logging.warning(f"Process {proc.name()} has {len(rwx_regions)} RWX memory regions")
                    
                    if len(wx_regions) > 0:
                        logging.warning(f"Process {proc.name()} has {len(wx_regions)} WX memory regions")
                    
                    if len(targets_invalid_regions) > 0:
                        logging.warning(f"Process {proc.name()} has {len(targets_invalid_regions)} CFG disabled regions")
                    
                    # Store current scan info for comparison in future scans
                    if not hasattr(self, 'previous_scan_regions'):
                        self.previous_scan_regions = {}
                    
                    # Update previous scan data for this process
                    for region in enumerate_memory_regions(process_handle):
                        base_addr_int = self.scanner.safe_int_conversion(region['BaseAddress'])
                        self.previous_scan_regions[base_addr_int] = region['Protect']
                    
                except Exception as proc_error:
                    logging.error(f"Error scanning process {proc.name()}: {str(proc_error)}")
            
                finally:
                    # Always close the handle
                    if process_handle:
                        try:
                            win32api.CloseHandle(process_handle)
                        except:
                            pass
              


                # Update progress
                self.root.after(0, self.update_scan_progress, process_info)
                
            except Exception as e:
                logging.error(f"Error processing process {getattr(proc, 'name', lambda: 'Unknown')()}: {str(e)}")
                
    def log_suspicious_region(self, info):
        # This would display the suspicious region in the UI
        # Update memory tree
        self.memory_tree.insert("", tk.END, values=(
            info['pid'],
            info['process'],
            info['address'],
            info['type'],
            info['protection']
        ))
        
        # Also log to the text widget
        self.scan_log.insert(tk.END, f"Suspicious region found in {info['process']} (PID: {info['pid']}): "
                                    f"{info['type']} at {info['address']}\n")
        self.scan_log.see(tk.END)
    def display_threat_details(self, detection):
        threat_window = tk.Toplevel(self.root)
        threat_window.title("Threat Analysis")
        threat_window.geometry("600x400")
        
        # Process info section
        info_frame = ttk.LabelFrame(threat_window, text="Process Details")
        info_frame.pack(fill=tk.X, padx=5, pady=5)
        
        ttk.Label(info_frame, text=f"PID: {detection['pid']}").pack()
        ttk.Label(info_frame, text=f"Process: {detection['name']}").pack()
        ttk.Label(info_frame, text=f"Path: {detection['exe']}").pack()
        
        # Detection patterns section
        patterns_frame = ttk.LabelFrame(threat_window, text="Detection Patterns")
        patterns_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        for pattern_type, details in detection['patterns'].items():
            pattern_info = f"Type: {pattern_type}\n"
            
            if 'yara_rule' in details:
                pattern_info += f"Rule: {details['yara_rule']}\n"
                pattern_info += f"Strings: {details['yara_strings']}\n"
                pattern_info += f"Tags: {details['yara_tags']}\n"
                pattern_info += f"Location: {details['offset']}\n"
                pattern_info += f"Context: {details['context']}\n"
            elif isinstance(details, dict):
                for key, value in details.items():
                    pattern_info += f"{key}: {value}\n"
            
            ttk.Label(patterns_frame, text=pattern_info, wraplength=550).pack(pady=5)
        
        # Action buttons
        button_frame = ttk.Frame(threat_window)
        button_frame.pack(fill=tk.X, padx=5, pady=5)
        
        ttk.Button(button_frame, text="Quarantine",
                command=lambda: self.quarantine_selected()).pack(side=tk.LEFT)
        ttk.Button(button_frame, text="Terminate Process",
                command=lambda: self.kill_selected_process()).pack(side=tk.LEFT)
        ttk.Button(button_frame, text="Remove Detection",
                command=lambda: self.remove_selected_detection()).pack(side=tk.LEFT)
        ttk.Button(button_frame, text="Ignore",
                command=threat_window.destroy).pack(side=tk.LEFT)
    def run_quick_scan(self):
        # Initialization - only needs to happen once
        self.scanner = MemoryScanner()
        self.processes_scanned = 0
        
        # Initialize YARA rules and scanner properly
        self.yara_manager = YaraRuleManager()
        self.yara_manager.fetch_all_rules()
        self.combined_rules = self.yara_manager.compile_combined_rules()
        self.injection_patterns = getattr(self.yara_manager, 'injection_patterns', {})
        
        # Update UI elements using thread-safe method
        self.root.after(0, self._update_scan_ui_start)
        
        # Setup shellcode detection function
        self.shellcode_indicators = self.Detector.detect_shellcode
        
        logging.debug("Starting quick scan...")
        logging.debug("Initializing scanner components...")
        self.clear_ui_elements()
        self.scanning = True
        self.threats_found = 0
        
        # Force flush the logging buffer
        logging.getLogger().handlers[0].flush()
        
        # Set logging level to capture everything
        logging.getLogger().setLevel(logging.DEBUG)
        
        # Define memory protection constants for enhanced analysis
        PAGE_EXECUTE = 0x10
        PAGE_EXECUTE_READ = 0x20
        PAGE_EXECUTE_READWRITE = 0x40
        PAGE_EXECUTE_WRITECOPY = 0x80
        PAGE_NOACCESS = 0x01
        PAGE_READONLY = 0x02
        PAGE_READWRITE = 0x04
        PAGE_WRITECOPY = 0x08
        PAGE_TARGETS_INVALID = 0x40000000
        PAGE_TARGETS_NO_UPDATE = 0x40000000
        
        # Clear displays
        self.detections_treeview.delete(*self.detections_treeview.get_children())
        self.file_tree.delete(*self.file_tree.get_children())
        self.scan_log.delete(1.0, tk.END)
        self.process_tree.delete(*self.process_tree.get_children())
        
        # Initialize scan statistics
        processes_scanned = 0
        processes_skipped = 0
        self.threats_found = 0
        
        self.scan_log.insert(tk.END, "Starting quick scan with enhanced memory protection analysis...\n")
        self.root.update()
        
        # Initialize variables
        process_handle = None
        
        # Statistics tracking
        stats = {
            'processes_scanned': 0,
            'processes_skipped': 0,
            'memory_regions_scanned': 0,
            'threats_found': 0
        }
        
        try:
            # System info initialization (do this once)
            try:
                system_info = self.scanner._get_system_info_winapi()
                self.scan_log.insert(tk.END, f"System: {system_info.get('os_name', 'Unknown')} {system_info.get('os_version', '')}\n")
            except Exception as e:
                logging.debug(f"Error getting system info: {str(e)}")
                system_info = {'os_name': 'Unknown', 'os_version': ''}
            
            # Get all processes once
            try:
                all_processes = list(psutil.process_iter(['pid', 'name', 'exe', 'cmdline', 'username']))
                total_processes = len(all_processes)
                logging.info(f"Found {total_processes} running processes")
            except Exception as e:
                logging.error(f"Failed to enumerate processes: {str(e)}")
                return
            
            # Main scanning loop
            for i, process in enumerate(all_processes):
                if not self.scanning:
                    break
                    
                try:
                    # Get detailed info using process.pid
                    pid = process.pid
                    detailed_info = self.scanner._get_process_info_winapi(pid)
                    if detailed_info is None:
                        processes_skipped += 1
                        continue

                    process_name = detailed_info.get('name', process.name())
                    # Skip system processes
                    if pid in (0, 4):
                        processes_skipped += 1
                        continue
                    
                    # Validate PID early
                    pid = self.scanner.safe_process_validation(pid)
                    if pid is None:
                        processes_skipped += 1
                        continue
                    
                    # Safe process name resolution
                    try:
                        process_name = detailed_info.get('basic', {}).get('name', process.name())
                        if not process_name:
                            process_name = self.scanner.get_process_name(pid)
                        
                        # Final fallback for truly unknown processes
                        if not process_name:
                            try:
                                import wmi
                                c = wmi.WMI()
                                for proc in c.Win32_Process(ProcessId=pid):
                                    process_name = proc.Name
                                    break
                            except:
                                pass
                        
                        # Last resort fallback
                        if not process_name:
                            process_name = f"Process_{pid}"
                    except Exception as e:
                        logging.debug(f"Error resolving process name for PID {pid}: {str(e)}")
                        process_name = f"Process_{pid}"
                    
                    # Get command line and modules
                    cmd_line = detailed_info.get('command_line', '')
                    modules = detailed_info.get('modules', [])
                    
                    # Update UI
                    self.process_tree.insert("", tk.END, values=(
                        pid,
                        process_name,
                        "Scanning..."
                    ))
                    self.root.update_idletasks()
                    
                    # Check registry entries
                    try:
                        if cmd_line and process_name:
                            registry_issues = self.scanner.verify_process_registry(process_name, cmd_line)
                            if registry_issues:
                                self.threats_found += 1
                                detection = {
                                    'pid': pid,
                                    'process': process_name,
                                    'type': 'Registry Anomaly',
                                    'details': f'Suspicious registry configuration: {registry_issues}',
                                    'location': 'System Registry'
                                }
                                self.log_detection(detection)
                    except Exception as e:
                        logging.debug(f"Error verifying registry for {process_name}: {str(e)}")
                    
                    # Check for suspicious command line arguments
                    try:
                        if cmd_line:
                            suspicious_args = [
                                '--hidden', '-H', 'bypass', 'secretmode', '-noprofile',
                                '-windowstyle hidden', '-encodedcommand', '-enc',
                                '-exec bypass', 'regsvr32', '/i:http', 'downloadstring'
                            ]
                            
                            cmd_lower = cmd_line.lower()
                            for arg in suspicious_args:
                                if arg.lower() in cmd_lower:
                                    self.threats_found += 1
                                    detection = {
                                        'pid': pid,
                                        'process': process_name,
                                        'type': 'Suspicious Command Line',
                                        'details': f'Command contains suspicious argument: {arg}',
                                        'location': f'Command line: {cmd_line[:100]}' + ('...' if len(cmd_line) > 100 else '')
                                    }
                                    self.log_detection(detection)
                                    break
                            
                            # Check for encoded PowerShell commands
                            if 'powershell' in cmd_lower and ('-enc' in cmd_lower or '-encodedcommand' in cmd_lower):
                                try:
                                    encoded_parts = re.findall(r'(?:-enc|-encodedcommand)\s+([A-Za-z0-9+/=]+)', cmd_line)
                                    if encoded_parts:
                                        decoded = base64.b64decode(encoded_parts[0]).decode('utf-16-le', errors='ignore')
                                        self.threats_found += 1
                                        detection = {
                                            'pid': pid,
                                            'process': process_name,
                                            'type': 'Encoded PowerShell Command',
                                            'details': f'Decoded content: {decoded[:100]}' + ('...' if len(decoded) > 100 else ''),
                                            'location': f'Command line: {cmd_line[:100]}' + ('...' if len(cmd_line) > 100 else '')
                                        }
                                        self.log_detection(detection)
                                except Exception as decode_error:
                                    logging.debug(f"Error decoding PowerShell command: {str(decode_error)}")
                    except Exception as e:
                        logging.debug(f"Error analyzing command line for {process_name}: {str(e)}")
                    
                    # Verify signatures
                    try:
                        # Verify main executable signature
                        if hasattr(self.scanner, 'verify_signature'):
                            exe_path = detailed_info.get('exe_path', '')
                            signature_info = self.scanner.verify_signature(exe_path)
                            if signature_info.get('status') == 'unsigned' or signature_info.get('status') == 'invalid':
                                self.threats_found += 1
                                detection = {
                                    'pid': pid,
                                    'process': process_name,
                                    'type': 'Unsigned Executable',
                                    'details': f"Process executable is {signature_info.get('status', 'unsigned')}",
                                    'location': exe_path
                                }
                                self.log_detection(detection)
                        
                        # Verify modules signatures
                        if modules:
                            for module in modules:
                                module_name = module.get('name', '')
                                module_path = module.get('path', '')
                                
                                # Skip verification for standard Windows modules if needed
                                if module_path.lower().startswith('c:\\windows\\system32\\') and not self.scanner.verify_system_modules:
                                    continue
                                
                                # Check signature
                                if hasattr(self.scanner, 'verify_signature'):
                                    module_signature = self.scanner.verify_signature(module_path)
                                    if module_signature.get('status') == 'unsigned' or module_signature.get('status') == 'invalid':
                                        self.threats_found += 1
                                        detection = {
                                            'pid': pid,
                                            'process': process_name,
                                            'type': 'Unsigned Module',
                                            'details': f"Module {module_name} is {module_signature.get('status', 'unsigned')}",
                                            'location': module_path
                                        }
                                        self.log_detection(detection)
                    except Exception as e:
                        logging.debug(f"Error verifying signatures for {process_name}: {str(e)}")
                    
                    # Check for unusual module locations
                    try:
                        if modules:
                            unusual_paths = [
                                '\\temp\\', '\\tmp\\', '\\appdata\\local\\temp\\',
                                '\\downloads\\', '\\public\\', '\\users\\public\\'
                            ]
                            
                            for module in modules:
                                module_path = module.get('path', '').lower()
                                
                                # Skip empty paths
                                if not module_path:
                                    continue
                                
                                # Check for modules in unusual locations
                                for unusual_path in unusual_paths:
                                    if unusual_path in module_path:
                                        self.threats_found += 1
                                        detection = {
                                            'pid': pid,
                                            'process': process_name,
                                            'type': 'Suspicious Module Location',
                                            'details': f'Module loaded from unusual location: {unusual_path}',
                                            'location': module.get('path', 'Unknown path')
                                        }
                                        self.log_detection(detection)
                                        break
                                
                                # Check for hidden/temporary module names
                                suspicious_names = ['.tmp', '.temp', '~', 'dllhost', 'svchost', 'rundll']
                                module_name = module.get('name', '').lower()
                                
                                if any(sus_name in module_name for sus_name in suspicious_names):
                                    self.threats_found += 1
                                    detection = {
                                        'pid': pid,
                                        'process': process_name,
                                        'type': 'Suspicious Module Name',
                                        'details': f'Module has suspicious name: {module.get("name", "")}',
                                        'location': module.get('path', 'Unknown path')
                                    }
                                    self.log_detection(detection)
                    except Exception as e:
                        logging.debug(f"Error analyzing module paths for {process_name}: {str(e)}")
                    
                    # Try process hollowing check
                    if hasattr(self.scanner, 'detect_process_hollowing'):
                        try:
                            # First try normal hollowing detection
                            hollowing_result = self.scanner.detect_process_hollowing(pid)
                            
                            # Check if normal detection failed due to access denied
                            if hollowing_result is None or hollowing_result == False:
                                # Try alternative detection that doesn't require direct memory access
                                logging.debug(f"Using alternative hollowing detection for PID {pid}")
                                
                                # Get parent PID
                                parent_pid = self.scanner.get_parent_pid(pid)
                                
                                # Try alternative detection methods
                                is_suspicious = False
                                details = ""
                                
                                # Check parent-child relationship
                                if self.scanner.is_unusual_parent(pid, parent_pid):
                                    is_suspicious = True
                                    details = "Suspicious parent-child relationship"
                                
                                # Check for path discrepancy
                                elif self.scanner.check_path_discrepancy(pid):
                                    is_suspicious = True
                                    details = "Executable path discrepancy detected"
                                
                                # Check for suspicious handle operations
                                elif self.scanner.check_handle_operations(pid):
                                    is_suspicious = True
                                    details = "Suspicious handle operations detected"
                                
                                # If any alternative detection found something suspicious
                                if is_suspicious:
                                    # Create a hollowing result with alternative detection info
                                    hollowing_result = {
                                        'executable_found': True,
                                        'detection_method': 'alternative',
                                        'details': details
                                    }
                                # Process hollowing detection (from either method)
                                if hollowing_result and hollowing_result.get('executable_found', False):process_handle = None
                                try:
                                    process_handle = self.scanner.get_process_handle(pid)
                                    if process_handle:
                                        extended_info = self.scanner.get_extended_process_info(pid)
                                except Exception as e:
                                    logging.debug(f"Failed to get extended info: {str(e)}")
                                finally:
                                    if process_handle:
                                        try:
                                            win32api.CloseHandle(process_handle)
                                        except:
                                            pass
                                
                                # Log detection but CONTINUE scanning
                                detection = {
                                    'pid': pid,
                                    'process': process_name,
                                    'type': 'Process Hollowing',
                                    'details': hollowing_result.get('details', 'Suspected process hollowing detected'),
                                    'detection_method': hollowing_result.get('detection_method', 'standard'),
                                    'extended_info': extended_info
                                }
                                self.threats_found += 1
                                self.log_detection(detection)
                        except Exception as e:
                            logging.debug(f"Process hollowing check failed for {process_name}: {str(e)}")
                    
                    # Memory region scanning with proper handle management
                    process_handle = None
                    try:
                        process_handle = self.scanner.get_process_handle(pid)
                        if not process_handle:
                            processes_skipped += 1
                            continue
                        
                        # Initialize region tracking
                        rwx_regions = []
                        wx_regions = []
                        cfg_bypass_regions = []
                        noaccess_regions = []
                        writecopy_regions = []
                        
                        # Scan regions
                        for region in self.scanner._enumerate_memory_regions_winapi(process_handle):
                            if not self.scanning:
                                break
                            
                            # Handle region dict vs object properly
                            if isinstance(region, dict):
                                if not (region.get('State', 0) & self.scanner.MEM_COMMIT):
                                    continue
                                protection = region.get('Protect', 0)
                                base_addr = region.get('BaseAddress', 0)
                                region_size = region.get('RegionSize', 0)
                            else:
                                if not (region.State & self.scanner.MEM_COMMIT):
                                    continue
                                protection = region.Protect
                                base_addr = region.BaseAddress
                                region_size = region.RegionSize
                            
                            # Convert base address safely
                            base_addr_int = self.scanner.safe_int_conversion(base_addr)
                            
                            # Check for various suspicious protection combinations
                            is_executable = bool(protection & (PAGE_EXECUTE | PAGE_EXECUTE_READ |
                                        PAGE_EXECUTE_READWRITE | PAGE_EXECUTE_WRITECOPY))
                            
                            # Check for NOACCESS memory
                            if protection & PAGE_NOACCESS:
                                noaccess_regions.append(base_addr)
                                if process_name.lower() in ['svchost.exe', 'lsass.exe', 'csrss.exe', 'services.exe']:
                                    self.threats_found += 1
                                    detection = {
                                        'pid': pid,
                                        'process': process_name,
                                        'type': 'Suspicious Memory Protection',
                                        'details': 'NOACCESS Memory in System Process (Potential Hidden Code)',
                                        'location': f'Memory region at {hex(base_addr_int)}, size: {region_size}'
                                    }
                                    self.log_detection(detection)
                            
                            # Check for WRITECOPY with executable permissions
                            if protection & PAGE_WRITECOPY:
                                writecopy_regions.append(base_addr)
                                if protection & (PAGE_EXECUTE | PAGE_EXECUTE_READ | PAGE_EXECUTE_WRITECOPY):
                                    self.threats_found += 1
                                    detection = {
                                        'pid': pid,
                                        'process': process_name,
                                        'type': 'Suspicious Memory Protection',
                                        'details': 'Executable WRITECOPY Memory (Unusual, Potential Code Injection)',
                                        'location': f'Memory region at {hex(base_addr_int)}, size: {region_size}'
                                    }
                                    self.log_detection(detection)
                            
                            # Check for CFG bypass (PAGE_TARGETS_INVALID)
                            if protection & PAGE_TARGETS_INVALID:
                                cfg_bypass_regions.append(base_addr)
                                
                                # This is a critical security issue, especially in system processes
                                self.threats_found += 1
                                detection = {
                                    'pid': pid,
                                    'process': process_name,
                                    'type': 'Security Protection Bypass',
                                    'details': 'Control Flow Guard disabled (PAGE_TARGETS_INVALID)',
                                    'location': f'Memory region at {hex(base_addr_int)}, size: {region_size}'
                                }
                                self.log_detection(detection)
                                
                                # Extra warning for system processes with CFG disabled
                                if process_name.lower() in ['svchost.exe', 'lsass.exe', 'csrss.exe', 'winlogon.exe']:
                                    self.threats_found += 1
                                    detection = {
                                        'pid': pid,
                                        'process': process_name,
                                        'type': 'Critical Security Bypass',
                                        'details': 'CFG Protection Disabled in System Process (Severe Security Risk)',
                                        'location': f'Memory region at {hex(base_addr_int)}, size: {region_size}'
                                    }
                                    self.log_detection(detection)
                            
                            # Check for PAGE_TARGETS_NO_UPDATE
                            if protection & PAGE_TARGETS_NO_UPDATE:
                                cfg_bypass_regions.append(base_addr)
                                if process_name.lower() in ['svchost.exe', 'lsass.exe', 'csrss.exe', 'winlogon.exe']:
                                    self.threats_found += 1
                                    detection = {
                                        'pid': pid,
                                        'process': process_name,
                                        'type': 'Control Flow Guard Bypass',
                                        'details': f'PAGE_TARGETS_NO_UPDATE detected at {hex(base_addr_int)}',
                                        'location': f'Memory region at {hex(base_addr_int)}, size: {region_size}'
                                    }
                                    self.log_detection(detection)
                            
                            # Check for RWX memory
                            if protection & PAGE_EXECUTE_READWRITE:
                                rwx_regions.append(base_addr)
                                self.threats_found += 1
                                detection = {
                                    'pid': pid,
                                    'process': process_name,
                                    'type': 'Suspicious Memory Protection',
                                    'details': 'RWX Memory (Read-Write-Execute)',
                                    'location': f'Memory region at {hex(base_addr_int)}, size: {region_size}'
                                }
                                self.log_detection(detection)
                            
                            # Check for WX memory (Write+Execute without Read)
                            if (protection & PAGE_EXECUTE) and (protection & PAGE_READWRITE) and not (protection & PAGE_READONLY):
                                wx_regions.append(base_addr)
                                self.threats_found += 1
                                detection = {
                                    'pid': pid,
                                    'process': process_name,
                                    'type': 'High Risk Memory Protection',
                                    'details': 'Write+Execute Memory (No Read Permission)',
                                    'location': f'Memory region at {hex(base_addr_int)}, size: {region_size}'
                                }
                                self.log_detection(detection)
                            
                            # Scan executable memory for malicious content
                            if is_executable:
                                try:
                                    self.disassembler = CodeDisassembler()
                                    # Read memory content using our helper function
                                    memory_content = self.scanner._read_memory_in_chunks_winapi(
                                        process_handle,
                                        base_addr_int,
                                        region_size
                                    )
                                    
                                    if not memory_content:
                                        continue
                                    
                                    # Check for shellcode patterns
                                    if len(memory_content) > 64:
                                        shellcode_findings = self.Detector.detect_shellcode(memory_content)
                                        if shellcode_findings:
                                            for pattern_name, offset in shellcode_findings:
                                                self.threats_found += 1
                                                self.log_detection({
                                                    'pid': pid,
                                                    'process': process_name,
                                                    'type': 'Shellcode Pattern',
                                                    'details': f'{pattern_name} at offset {offset} from {hex(base_addr_int)}',
                                                    'location': f'Memory region at {hex(base_addr_int)}, size: {region_size}'
                                                })
                                    # Check for shellcode patterns with disassembly and Tome integration
                                    if len(memory_content) > 64:
                                                                                
                                        shellcode_findings = self.Detector.detect_shellcode(memory_content)
                                            
                                                                                                                        
                                    if shellcode_findings:
                                        for pattern_name, offset in shellcode_findings:
                                            # Create a unique identifier for this detection
                                            detection_id = f"{pid}_{hex(base_addr_int + offset)}_{pattern_name}"
                                            
                                            # Disassemble the suspicious region for better analysis
                                            disassembly = None
                                            try:
                                                # Get a sample of the code at the detection point (100 bytes)
                                                code_sample = memory_content[offset:offset+100]
                                                disassembly = self.disassembler.disassemble_bytes(code_sample, base_addr_int + offset)
                                            except Exception as disasm_err:
                                                logging.debug(f"Disassembly error: {str(disasm_err)}")
                                                disassembly = "Disassembly failed"
                                            
                                            # Calculate entropy and other statistical properties
                                            entropy = self.disassembler.calculate_entropy(memory_content[offset:offset+100])
                                            has_api_calls = self.disassembler.detect_api_references(memory_content[offset:offset+200])
                                            
                                            # Create detailed detection record
                                            detection_details = {
                                                'pid': pid,
                                                'process': process_name,
                                                'type': 'Shellcode Pattern',
                                                'pattern_name': pattern_name,
                                                'base_address': hex(base_addr_int),
                                                'offset': offset,
                                                'absolute_address': hex(base_addr_int + offset),
                                                'entropy': entropy,
                                                'has_api_calls': has_api_calls,
                                                'disassembly': disassembly,
                                                'detection_time': time.time(),
                                                'memory_protection': hex(protection)
                                            }
                                            
                                            # Log detection with enhanced details
                                            self.threats_found += 1
                                            user_friendly_details = f"{pattern_name} at {hex(base_addr_int + offset)}"
                                            if disassembly and isinstance(disassembly, list) and len(disassembly) > 0:
                                                # Add first 3 disassembled instructions to the summary
                                                disasm_preview = "; ".join([f"{instr}" for instr in disassembly[:3]])
                                                user_friendly_details += f"\nDisassembly: {disasm_preview}..."
                                            
                                            self.log_detection({
                                                'pid': pid,
                                                'process': process_name,
                                                'type': 'Shellcode Pattern',
                                                'details': user_friendly_details,
                                                'location': f'Memory region at {hex(base_addr_int)}, size: {region_size}',
                                                'extended_data': detection_details
                                            })
                                            
                                            # Add to Tome knowledge base for future reference
                                            if hasattr(self, 'tome') and self.tome:
                                                try:
                                                    # Create a knowledge entry for this shellcode pattern
                                                    tome_entry = {
                                                        'detection_id': detection_id,
                                                        'pattern_name': pattern_name,
                                                        'process_name': process_name,
                                                        'pid': pid,
                                                        'memory_address': hex(base_addr_int + offset),
                                                        'detection_time': time.time(),
                                                        'disassembly': disassembly,
                                                        'binary_signature': self.disassembler.create_binary_signature(
                                                            memory_content[offset:offset+100]
                                                        ),
                                                        'entropy': entropy,
                                                        'code_sample': binascii.hexlify(memory_content[offset:offset+100]).decode(),
                                                        'has_api_calls': has_api_calls,
                                                        'classification': 'malicious',  # Initial classification
                                                        'confidence': 0.85,  # Initial confidence score
                                                        'memory_protection': hex(protection)
                                                    }
                                                    
                                                    # Store in Tome knowledge base
                                                    self.tome.add_entry('shellcode_patterns', tome_entry)
                                                    
                                                    # Schedule learning task for this pattern
                                                    self.disassembler.schedule_pattern_learning(detection_id, memory_content[offset:offset+200])
                                                    
                                                    logging.info(f"Added shellcode pattern to Tome: {detection_id}")
                                                except Exception as tome_err:
                                                    logging.debug(f"Error adding to Tome: {str(tome_err)}")
                                            
                                            # Add to disassembly viewer if one is available
                                            if hasattr(self, 'show_disassembly') and callable(self.disassembler.show_disassembly):
                                                try:
                                                    # Get a sample of the code at the detection point (100 bytes)
                                                    self.root.after(10, lambda: self.disassembler.show_disassembly(
                                                        disassembly, 
                                                        base_addr_int + offset,
                                                        pattern_name,
                                                        process_name,
                                                        pid
                                                    ))
                                                except Exception as viewer_err:
                                                    logging.debug(f"Error showing disassembly: {str(viewer_err)}")
                                    # Check for injection patterns using scan_bytes
                                    scan_results = self.scanner.scan_bytes(memory_content)
                                    if scan_results:
                                        for result in scan_results:
                                            self.threats_found += 1
                                            detection = {
                                                'pid': pid,
                                                'process': process_name,
                                                'type': result.get('type', 'Code Injection'),
                                                'details': result.get('details', f'Found at {hex(base_addr_int)}'),
                                                'location': f'Memory region at {hex(base_addr_int)}, size: {region_size}'
                                            }
                                            self.log_detection(detection)
                                    
                                    # Check for specific injection patterns
                                    for pattern_name, pattern in self.injection_patterns.items():
                                        try:
                                            if isinstance(pattern, bytes):
                                                if pattern in memory_content:
                                                    self.threats_found += 1
                                                    detection = {
                                                        'pid': pid,
                                                        'process': process_name,
                                                        'type': f'Injection Pattern: {pattern_name}',
                                                        'details': f'Found at {hex(base_addr_int)}',
                                                        'location': f'Memory region at {hex(base_addr_int)}, size: {region_size}'
                                                    }
                                                    self.log_detection(detection)
                                            elif hasattr(pattern, 'search'):  # Compiled regex
                                                if pattern.search(memory_content):
                                                    self.threats_found += 1
                                                    detection = {
                                                        'pid': pid,
                                                        'process': process_name,
                                                        'type': f'Injection Pattern: {pattern_name}',
                                                        'details': f'Found at {hex(base_addr_int)}',
                                                        'location': f'Memory region at {hex(base_addr_int)}, size: {region_size}'
                                                    }
                                                    self.log_detection(detection)
                                            elif isinstance(pattern, str):  # String pattern, needs compilation
                                                compiled_pattern = re.compile(pattern.encode(), re.DOTALL)
                                                if compiled_pattern.search(memory_content):
                                                    self.threats_found += 1
                                                    detection = {
                                                        'pid': pid,
                                                        'process': process_name,
                                                        'type': f'Injection Pattern: {pattern_name}',
                                                        'details': f'Found at {hex(base_addr_int)}',
                                                        'location': f'Memory region at {hex(base_addr_int)}, size: {region_size}'
                                                    }
                                                    self.log_detection(detection)
                                        except Exception as e:
                                            logging.debug(f"Error scanning for {pattern_name}: {str(e)}")
                                    
                                    # Scan with YARA rules
                                    if hasattr(self, 'combined_rules') and self.combined_rules:
                                        try:
                                            matches = self.combined_rules.match(data=memory_content)
                                            if matches:
                                                for match in matches:
                                                    self.threats_found += 1
                                                    
                                                    extended_info = None
                                                    if hasattr(self.scanner, 'get_extended_process_info'):
                                                        try:
                                                            extended_info = self.scanner.get_extended_process_info(pid)
                                                        except Exception as e:
                                                            logging.debug(f"Failed to get extended info: {str(e)}")
                                                    
                                                    detection = {
                                                        'pid': pid,
                                                        'process': process_name,
                                                        'type': f'YARA Rule: {match.rule}',
                                                        'location': f'Memory region at {hex(base_addr_int)}',
                                                        'extended_info': extended_info
                                                    }
                                                    self.log_detection(detection)
                                        except Exception as yara_error:
                                            logging.debug(f"YARA scanning error: {str(yara_error)}")
                                except Exception as region_error:
                                    logging.debug(f"Error scanning region in {process_name}: {str(region_error)}")
                        
                        # Summary for suspicious memory protections
                        if rwx_regions or wx_regions or cfg_bypass_regions:
                            logging.warning(f"Process {process_name} (PID: {pid}) has suspicious memory protections: "
                                        f"{len(rwx_regions)} RWX, {len(wx_regions)} WX, {len(cfg_bypass_regions)} CFG bypass")
                    
                    except Exception as e:
                        logging.debug(f"Error scanning process {process_name}: {str(e)}")
                    finally:
                        # Always close the process handle
                        if process_handle:
                            try:
                                win32api.CloseHandle(process_handle)
                            except:
                                pass
                    
                    # Update status in process tree
                    for item in self.process_tree.get_children():
                        values = self.process_tree.item(item)['values']
                        if values and values[0] == pid:
                            self.process_tree.item(item, values=(
                                pid,
                                process_name,
                                "Scanned"
                            ))
                    
                    # Update scan statistics
                    processes_scanned += 1
                    stats['processes_scanned'] = processes_scanned
                    stats['threats_found'] = self.threats_found
                    # Update progress
                    progress = (i / total_processes) * 100
                    self.scan_progress['value'] = progress
                    self.processes_scanned_label.config(text=f"Processes Scanned: {processes_scanned}")
                    self.threats_found_label.config(text=f"Threats Found: {self.threats_found}")
                    self.root.update_idletasks()
                    
                except Exception as e:
                    logging.error(f"Error processing {getattr(process, 'name', 'PID ' + str(getattr(process, 'pid', 'unknown')))}): {str(e)}")
                    processes_skipped += 1
                    continue
            
            # Post-scan analysis
            self.scan_log.insert(tk.END, f"\nAnalyzing scan results...\n")
            self.scan_log.see(tk.END)
            self.root.update_idletasks()
            
            # Look for unusual relationships between processes
            if hasattr(self.scanner, 'detect_unusual_relationships'):
                try:
                    unusual_relationships = self.scanner.detect_unusual_relationships()
                    for relation in unusual_relationships:
                        self.threats_found += 1
                        detection = {
                            'pid': relation.get('child_pid', 0),
                            'process': relation.get('child_name', 'Unknown'),
                            'type': 'Unusual Process Relationship',
                            'details': relation.get('description', 'Unusual parent-child relationship detected'),
                            'location': 'Process hierarchy'
                        }
                        self.log_detection(detection)
                except Exception as e:
                    logging.debug(f"Error detecting unusual relationships: {str(e)}")
            
            # Check for common persistence techniques
            if hasattr(self.scanner, 'detect_persistence_methods'):
                try:
                    persistence_findings = self.scanner.detect_persistence_methods()
                    for finding in persistence_findings:
                        self.threats_found += 1
                        detection = {
                            'pid': 0,  # Often persistence doesn't have an active PID
                            'process': finding.get('name', 'Unknown'),
                            'type': 'Persistence Mechanism',
                            'details': finding.get('description', 'Unknown persistence method'),
                            'location': finding.get('location', 'Registry or filesystem')
                        }
                        self.log_detection(detection)
                except Exception as e:
                    logging.debug(f"Error detecting persistence methods: {str(e)}")

        except Exception as e:
            logging.error(f"Scan error: {str(e)}")
            traceback.print_exc()
            self.scan_log.insert(tk.END, f"\nError during scan: {str(e)}\n")
            self.scan_log.see(tk.END)
        finally:
            # Cleanup and finalize
            self.cleanup_scan()
            
            # Scan completion
            self.scan_progress['value'] = 100
            
            # Calculate scan statistics
            scan_duration = time.time() - getattr(self, 'scan_start_time', time.time())
            minutes, seconds = divmod(int(scan_duration), 60)
            
            self.scan_log.insert(tk.END, f"\nQuick scan completed in {minutes}m {seconds}s!\n")
            self.scan_log.insert(tk.END, f"Scanned {processes_scanned} processes, skipped {processes_skipped}, found {self.threats_found} threats.\n")
            
            if self.threats_found > 0:
                self.scan_log.insert(tk.END, "Threats detected! Review the Detections tab for details.\n")
                # Play alert sound if enabled
                if hasattr(self, 'play_alert_sound') and self.play_alert_sound:
                    self.play_notification_sound()
            else:
                self.scan_log.insert(tk.END, "No threats detected. System appears clean.\n")
            
            self.scan_log.see(tk.END)
            
            # Always execute this code to clean up and update UI
            self.run_quick_scan_button.configure(state='normal')
            self.stop_button.config(state='disabled')
            self.scanning = False
            
            # Force UI update
            self.root.update_idletasks()
            
            # If we were asked to quit after scan, do it now
            if getattr(self, 'quit_after_scan', False):
                self.root.after(1000, self.root.destroy)
            
            return self.threats_found
    def play_notification_sound(self):
        """
        Plays a notification sound to alert the user.
        Handles different platforms (Windows, macOS, Linux) with appropriate fallbacks.
        """
        try:
            # Windows platform handling
            if sys.platform == 'win32':
                import winsound
                winsound.PlaySound('SystemAsterisk', winsound.SND_ALIAS)
                
            # macOS and Linux handling
            elif hasattr(self, 'alert_sound_path') and os.path.exists(self.alert_sound_path):
                if sys.platform == 'darwin':  # macOS
                    os.system(f"afplay {self.alert_sound_path}")
                elif sys.platform.startswith('linux'):
                    os.system(f"aplay {self.alert_sound_path}")
                    
            # Fallback to system bell if no sound file available
            else:
                logging.debug("Notification sound requested but no sound file specified")
                if hasattr(self, 'root') and self.root:
                    self.root.bell()
                    
        except Exception as e:
            logging.debug(f"Failed to play notification sound: {str(e)}")
            # Fallback to visual bell
            if hasattr(self, 'root') and self.root:
                try:
                    self.root.bell()
                except:
                    pass

    def cleanup_scan(self):
        """Clean up after scan completion"""
        self.scan_progress['value'] = 100
        self.scan_log.insert(tk.END, f"\nScan completed! Scanned {self.processes_scanned} processes\n")
        self.scan_log.see(tk.END)
        
        self.run_quick_scan_button.configure(state='normal')
        self.stop_button.config(state='disabled')
        
        # Use the instance variable we initialized
        self.processes_scanned_label.config(text=f"Processes Scanned: {self.processes_scanned}")
        self.threats_found_label.config(text=f"Threats Found: {self.threats_found}")
        
        self.root.update_idletasks()
        self.scanning = False
    def clear_ui_elements(self):
        """Reset all UI elements to initial state"""
        # Clear tree views
        self.detections_treeview.delete(*self.detections_treeview.get_children())
        self.file_tree.delete(*self.file_tree.get_children()) 
        self.process_tree.delete(*self.process_tree.get_children())
        
        # Clear text widgets
        self.scan_log.delete(1.0, tk.END)
        
        # Reset progress indicators
        self.scan_progress['value'] = 0
        self.processes_scanned_label.config(text="Processes Scanned: 0")
        self.threats_found_label.config(text="Threats Found: 0")
        
        # Configure buttons
        self.run_quick_scan_button.configure(state='disabled')
        self.stop_button.config(state='normal')

    def run_deep_scan(self):
        """
        Performs a deep, comprehensive scan of all processes to detect malicious code, suspicious memory regions,
        and security bypasses. More thorough than quick scan with additional checks.
        """
        # Update UI state using thread-safe method
        self.root.after(0, self._update_scan_ui_start)
        self.scanning = True  # Enable scanning
        
        # Define memory protection constants for enhanced analysis
        PAGE_EXECUTE = 0x10
        PAGE_EXECUTE_READ = 0x20
        PAGE_EXECUTE_READWRITE = 0x40
        PAGE_EXECUTE_WRITECOPY = 0x80
        PAGE_NOACCESS = 0x01
        PAGE_READONLY = 0x02
        PAGE_READWRITE = 0x04
        PAGE_WRITECOPY = 0x08
        PAGE_TARGETS_INVALID = 0x40000000
        PAGE_TARGETS_NO_UPDATE = 0x40000000
        process_name = 'Unknown'
        # Clear displays
        self.detections_treeview.delete(*self.detections_treeview.get_children())
        self.file_tree.delete(*self.file_tree.get_children())
        self.scan_log.delete(1.0, tk.END)
        self.process_tree.delete(*self.process_tree.get_children())
        
        # Initialize YARA rules and scanner
        self.yara_manager = YaraRuleManager()
        self.combined_rules = self.yara_manager.compile_combined_rules()
        self.injection_patterns = getattr(self.yara_manager, 'injection_patterns', {})
        
        # Initialize counters
        processes_scanned = 0
        self.threats_found = 0
        
        # Update UI with initial message
        self.scan_log.insert(tk.END, "Starting deep scan with enhanced memory protection analysis...\n")
        self.root.update()
        
        logging.debug("Starting deep scan...")
        
        # Set up detection callback to process alerts
        def detection_callback(detection):
            try:
                self.threats_found += 1
                
                # Add extended information if not already included
                if 'extended_info' not in detection and hasattr(self.scanner, 'get_extended_process_info'):
                    try:
                        process_handle = self.scanner.get_process_handle(detection['pid'])
                        if process_handle:
                            detection['extended_info'] = self.scanner.get_extended_process_info(detection['pid'], process_handle)
                            # Clean up handle after use
                            win32api.CloseHandle(process_handle)
                    except Exception as e:
                        logging.debug(f"Failed to get extended process info: {str(e)}")
                
                self.log_detection(detection)
                self.threats_found_label.config(text=f"Threats Found: {self.threats_found}")
            except Exception as e:
                logging.error(f"Error in detection callback: {str(e)}")
        
        self.scanner.alert_callback = detection_callback
        
        try:
            # Get system info for context
            logging.debug("Getting system info...")
            system_info = MemoryScanner._get_system_info_winapi()
            logging.debug(f"System info retrieved: {system_info}")
            self.scan_log.insert(tk.END, f"System: {system_info.get('os_name', 'Unknown')} {system_info.get('os_version', '')}\n")
            
            # Main scanning loop
            logging.debug("Enumerating processes...")
            all_processes = list(psutil.process_iter(['pid', 'name', 'exe', 'cmdline', 'username']))
            total_processes = len(all_processes)
            logging.debug(f"Found {len(all_processes)} processes")
            
            for i, proc in enumerate(all_processes):
                if not self.scanning:
                    break
                    
                process_info = proc.info
                
                # Skip system processes
                if process_info.get('pid') in (0, 4):
                    continue
                    
                processes_scanned += 1
                pid = process_info.get('pid')
                
                if not isinstance(pid, int):
                    continue
                    
                logging.debug(f"Analyzing process {pid}")
                
                # Update process tree
                self.process_tree.insert("", tk.END, values=(
                    pid,
                    process_info.get('name', 'Unknown'),
                    "Deep Scanning..."
                ))
                
                # Check for process hollowing
                if hasattr(self.scanner, 'detect_process_hollowing'):
                    try:
                        # Ensure process_name is defined before using it
                        process_name = self.scanner.get_process_name(pid) or process_info.get('name', 'Unknown')
                        
                        hollowing_result = self.scanner.detect_process_hollowing(process_info)
                        if hollowing_result and hollowing_result.get('executable_found', False):
                            extended_info = None
                            if hasattr(self.scanner, 'get_extended_process_info'):
                                # Get process handle properly
                                process_handle = self.scanner.get_process_handle(pid)
                                if process_handle:
                                    extended_info = self.scanner.get_extended_process_info(pid)
                                    
                                    # Close handle if opened
                                    try:
                                        win32api.CloseHandle(process_handle)
                                    except:
                                        pass
                            
                            detection = {
                                'pid': pid,
                                'process': process_name,  # Now safely using process_name
                                'type': 'process_hollowing',
                                'details': 'Suspected process hollowing detected',
                                'extended_info': extended_info
                            }
                            self.threats_found += 1
                            self.log_detection(detection)
                            return detection
                    except Exception as e:
                        logging.debug(f"Process hollowing check failed: {str(e)}")
                
                # Open process handle for memory scanning
                process_handle = None
                try:
                    process_handle = win32api.OpenProcess(
                        win32con.PROCESS_QUERY_INFORMATION | win32con.PROCESS_VM_READ,
                        False, pid
                    )
                    
                    if not process_handle:
                        continue
                    
                    # Initialize region tracking lists
                    executable_regions = []
                    rwx_regions = []
                    wx_regions = []
                    readonly_regions = []
                    noaccess_regions = []
                    writecopy_regions = []
                    targets_invalid_regions = []
                    execute_read_regions = []
                    
                    for region in self.scanner._enumerate_memory_regions_winapi(process_handle):
                        if not self.scanning:
                            break
                        
                        # Skip non-committed memory - Handle dictionary return type properly
                        if isinstance(region, dict):
                            # Dictionary-style access
                            if not (region.get('State', 0) & self.scanner.MEM_COMMIT):
                                continue
                            
                            # Use dictionary access throughout this block
                            protection = region.get('Protect', 0)
                            base_addr = region.get('BaseAddress', 0)
                            region_size = region.get('RegionSize', 0)
                        else:
                            # Object-style access (original code path)
                            if not (region.State & self.scanner.MEM_COMMIT):
                                continue
                            
                            # Original attribute access
                            protection = region.Protect
                            base_addr = region.BaseAddress
                            region_size = region.RegionSize
                        
                        # Convert base address safely
                        base_addr_int = self.scanner.safe_int_conversion(base_addr)
                        
                        
                        # Get memory protection and address
                        protection = region.Protect
                        base_addr = region.BaseAddress
                        base_addr_int = self.scanner.safe_int_conversion(base_addr)
                        process_name = process_info.get('name', 'Unknown')
                        
                        # Process each protection type
                        is_executable = bool(protection & (PAGE_EXECUTE | PAGE_EXECUTE_READ |
                                        PAGE_EXECUTE_READWRITE | PAGE_EXECUTE_WRITECOPY))
                        if is_executable:
                            executable_regions.append(base_addr)
                            
                            # Check for executable regions in unusual locations
                            if region.Type == 0x1000 and region.RegionSize > 4096:  # MEM_PRIVATE
                                self.log_detection({
                                    'pid': pid,
                                    'process': process_name,
                                    'type': 'Suspicious Memory Region',
                                    'details': 'Large private executable memory (Potential unpacked code)'
                                })
                        
                        # Check for PAGE_EXECUTE_READ specifically
                        if protection & PAGE_EXECUTE_READ:
                            execute_read_regions.append(base_addr)
                            # Non-image XR regions can be suspicious
                            if region.Type != 0x1000000:  # Not MEM_IMAGE
                                try:
                                    size_to_read = min(region.RegionSize, 1024 * 1024)
                                    memory_content = win32process.ReadProcessMemory(
                                        process_handle,
                                        base_addr_int,
                                        size_to_read
                                    )
                                    if memory_content and len(memory_content) > 64:
                                        if b"\xff\x34\x8f" in memory_content or b"\x89\xe5\x81\xc4" in memory_content:
                                            self.log_detection({
                                                'pid': pid,
                                                'process': process_name,
                                                'type': 'Suspicious Memory Content',
                                                'details': 'PAGE_EXECUTE_READ with shellcode patterns'
                                            })
                                except Exception as e:
                                    logging.debug(f"Error reading memory: {str(e)}")
                        
                        # Check for various suspicious protection combinations
                        # RWX Memory
                        if protection & PAGE_EXECUTE_READWRITE:
                            rwx_regions.append(base_addr)
                            self.log_detection({
                                'pid': pid,
                                'process': process_name,
                                'type': 'Suspicious Memory Protection',
                                'details': 'RWX Memory (Read-Write-Execute)'
                            })
                        
                        # WX Memory
                        if (protection & PAGE_EXECUTE) and (protection & PAGE_READWRITE) and not (protection & PAGE_READONLY):
                            wx_regions.append(base_addr)
                            self.log_detection({
                                'pid': pid,
                                'process': process_name,
                                'type': 'High Risk Memory Protection',
                                'details': 'Write+Execute Memory (No Read Permission)'
                            })
                        
                        # Check for NOACCESS memory
                        if protection & PAGE_NOACCESS:
                            noaccess_regions.append(base_addr)
                            if process_name.lower() in ['svchost.exe', 'lsass.exe', 'csrss.exe', 'services.exe']:
                                self.threats_found += 1
                                detection = {
                                    'pid': pid,
                                    'process': process_name,
                                    'type': 'Suspicious Memory Protection',
                                    'details': 'NOACCESS Memory in System Process (Potential Hidden Code)',
                                    'location': f'Memory region at {hex(base_addr_int)}, size: {region_size}'
                                }
                                self.log_detection(detection)
                                return detection
                        
                         # Check for WRITECOPY with executable permissions
                        if protection & PAGE_WRITECOPY:
                            writecopy_regions.append(base_addr)
                            if protection & (PAGE_EXECUTE | PAGE_EXECUTE_READ | PAGE_EXECUTE_WRITECOPY):
                                self.threats_found += 1
                                detection = {
                                    'pid': pid,
                                    'process': process_name,
                                    'type': 'Suspicious Memory Protection',
                                    'details': 'Executable WRITECOPY Memory (Unusual, Potential Code Injection)',
                                    'location': f'Memory region at {hex(base_addr_int)}, size: {region_size}'
                                }
                                self.log_detection(detection)
                                return detection
                        
                        # CFG bypass - PAGE_TARGETS_INVALID
                        if protection & PAGE_TARGETS_INVALID:
                            targets_invalid_regions.append(base_addr)
                            process_name_lower = process_name.lower()
                            if process_name_lower in ['svchost.exe', 'lsass.exe', 'csrss.exe', 'winlogon.exe']:
                                self.log_detection({
                                    'pid': pid,
                                    'process': process_name,
                                    'type': 'Critical Security Bypass',
                                    'details': 'CFG Protection Disabled in System Process',
                                    'location': f'Memory region at {hex(base_addr_int)}, size: {region_size}'
                                })
                        
                        # Also check for PAGE_TARGETS_NO_UPDATE (same value as PAGE_TARGETS_INVALID)
                        if protection & PAGE_TARGETS_NO_UPDATE:
                            process_name_lower = process_name.lower()
                            self.log_detection({
                                'pid': pid,
                                'process': process_name,
                                'type': 'Control Flow Guard Bypass',
                                'details': f'PAGE_TARGETS_NO_UPDATE detected at {hex(base_addr_int)}',
                                'location': f'Memory region at {hex(base_addr_int)}, size: {region_size}'
                            })
                            
                            # This is especially critical for system processes
                            if process_name_lower in ['svchost.exe', 'lsass.exe', 'csrss.exe', 'winlogon.exe', 'services.exe']:
                                self.log_detection({
                                    'pid': pid,
                                    'process': process_name,
                                    'type': 'Critical Security Vulnerability',
                                    'details': 'PAGE_TARGETS_NO_UPDATE in system process - serious security risk',
                                    'location': f'Memory region at {hex(base_addr_int)}, size: {region_size}'
                                })
                        
                        # Scan memory content for patterns and YARA matches
                        if is_executable or protection & PAGE_TARGETS_INVALID:
                            try:
                                memory_content = self.scanner._read_memory_in_chunks_winapi(
                                    process_handle, base_addr_int, region.RegionSize
                                )
                                
                                if memory_content:
                                    # Check for injection patterns
                                    for pattern_name, pattern in self.injection_patterns.items():
                                        try:
                                            if isinstance(pattern, bytes):
                                                if pattern in memory_content:
                                                    self.log_detection({
                                                        'pid': pid,
                                                        'process': process_name,
                                                        'type': f'Injection Pattern: {pattern_name}',
                                                        'details': f'Found at {hex(base_addr_int)}',
                                                        'location': f'Memory region at {hex(base_addr_int)}, size: {region_size}'
                                                    })
                                            elif hasattr(pattern, 'search'):  # Compiled regex
                                                if pattern.search(memory_content):
                                                    self.log_detection({
                                                        'pid': pid,
                                                        'process': process_name,
                                                        'type': f'Injection Pattern: {pattern_name}',
                                                        'details': f'Found at {hex(base_addr_int)}',
                                                        'location': f'Memory region at {hex(base_addr_int)}, size: {region_size}'
                                                    })
                                            elif isinstance(pattern, str):
                                                if re.search(pattern.encode() if isinstance(memory_content, bytes) else pattern, 
                                                        memory_content):
                                                    self.log_detection({
                                                        'pid': pid,
                                                        'process': process_name,
                                                        'type': f'Injection Pattern: {pattern_name}',
                                                        'details': f'Found at {hex(base_addr_int)}',
                                                        'location': f'Memory region at {hex(base_addr_int)}, size: {region_size}'
                                                    })
                                        except Exception as pattern_error:
                                            logging.debug(f"Pattern scan error: {str(pattern_error)}")
                                    if self.combined_rules:
                                        try:
                                            matches = self.combined_rules.match(data=memory_content)
                                            if matches:
                                                for match in matches:
                                                    self.log_detection({
                                                        'pid': pid,
                                                        'process': process_name,
                                                        'type': f'YARA Rule: {match.rule}',
                                                        'details': f'Found at {hex(base_addr_int)}',
                                                        'location': f'Memory region at {hex(base_addr_int)}',
                                                        'location': f'Memory region at {hex(base_addr_int)}, size: {region_size}'
                                                    })
                                        except Exception as yara_error:
                                            logging.debug(f"YARA scanning error: {str(yara_error)}")
                            except Exception as memory_error:
                                logging.debug(f"Error scanning memory: {str(memory_error)}")
                    
                    # Log summary for this process when all regions have been scanned
                    logging.info(f"Process {process_name} scan summary:")
                    logging.info(f"  Executable regions: {len(executable_regions)}")
                    logging.info(f"  EXECUTE_READ regions: {len(execute_read_regions)}")
                    logging.info(f"  READONLY regions: {len(readonly_regions)}")
                    logging.info(f"  NOACCESS regions: {len(noaccess_regions)}")
                    logging.info(f"  WRITECOPY regions: {len(writecopy_regions)}")
                    logging.info(f"  RWX regions: {len(rwx_regions)}")
                    logging.info(f"  WX regions: {len(wx_regions)}")
                    logging.info(f"  CFG INVALID regions: {len(targets_invalid_regions)}")
                    
                    # Check for suspicious combinations or unusual counts
                    if len(rwx_regions) > 0 or len(wx_regions) > 0:
                        self.log_detection({
                            'pid': pid,
                            'process': process_name,
                            'type': 'Memory Protection Summary',
                            'details': f'RWX: {len(rwx_regions)}, WX: {len(wx_regions)} - Potentially dangerous memory regions',
                            'extended_info': {
                                'executable_regions': len(executable_regions),
                                'execute_read_regions': len(execute_read_regions),
                                'readonly_regions': len(readonly_regions),
                                'noaccess_regions': len(noaccess_regions),
                                'writecopy_regions': len(writecopy_regions),
                                'rwx_regions': len(rwx_regions),
                                'wx_regions': len(wx_regions),
                                'cfg_invalid_regions': len(targets_invalid_regions)
                            }
                        })
                    
                    # Update status in process tree
                    for item in self.process_tree.get_children():
                        values: tuple = self.process_tree.item(item)['values']
                        if values and values[0] == pid:
                            self.process_tree.item(item, values=(
                                pid,
                                process_name,
                                "Scanned",
                                len(executable_regions),
                                len(execute_read_regions),
                                len(readonly_regions),
                                len(noaccess_regions),
                                len(writecopy_regions),
                                len(rwx_regions),
                                len(wx_regions),
                                len(targets_invalid_regions)
                            ))
                    
                except Exception as proc_error:
                    logging.error(f"Error in deep scan of process {process_info.get('name', 'Unknown')}: {str(proc_error)}")
                finally:
                    # Always close the handle
                    if process_handle:
                        try:
                            win32api.CloseHandle(process_handle)
                        except:
                            pass
                
                # Update progress
                progress = (i / total_processes) * 100
                self.scan_progress['value'] = progress
                self.processes_scanned_label.config(text=f"Processes Scanned: {processes_scanned}")
                self.threats_found_label.config(text=f"Threats Found: {self.threats_found}")
                self.root.update_idletasks()
                
        except Exception as e:
            logging.error(f"Error in deep scan: {str(e)}")
            traceback.print_exc()
        finally:
            # Always execute this code to clean up and update UI
            self.scan_progress['value'] = 100
            self.scan_log.insert(tk.END, f"\nDeep scan completed! Scanned {processes_scanned} processes, found {self.threats_found} threats.\n")
            self.scan_log.see(tk.END)
            self.run_deep_scan_button.configure(state='normal')
            self.stop_button.config(state='disabled')
            self.scanning = False
    def load_signatures(self, signature_file=None):
        if signature_file is None:
            # Use a default path or skip loading signatures
            logging.warning("No signature file provided, skipping signature loading")
            self.signature_db = set()  # Initialize with empty set
            return False
        
        if not os.path.exists(signature_file):
            logging.warning(f"Signature file not found: {signature_file}")
            self.signature_db = set()
            return False
        
        with open(signature_file, 'r') as f:
            self.signature_db = set(line.strip() for line in f)
        return True
    def check_signatures(self, filepath):
        try:
            file_hash = self.calculate_file_hash(filepath)
            return file_hash in self.signature_db
        except Exception as e:
            logging.error(f"Signature check failed for {filepath}: {str(e)}")
            return False
    def _setup_logging(self):
        # Create logs directory if it doesn't exist
        log_dir = Path('logs')
        log_dir.mkdir(exist_ok=True)
        
        log_file = log_dir / 'scanner.log'
        
        # Configure handlers
        file_handler = logging.FileHandler(str(log_file))
        file_handler.setLevel(logging.DEBUG)
        
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        
        # Formatter
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        file_handler.setFormatter(formatter)
        console_handler.setFormatter(formatter)
        
        # Get logger instance
        logger = logging.getLogger('MemoryScanner')
        logger.setLevel(logging.DEBUG)
        
        # Remove existing handlers
        if logger.handlers:
            logger.handlers.clear()
        
        # Add handlers
        logger.addHandler(file_handler)
        logger.addHandler(console_handler)
        
        return logger
    def calculate_file_hash(self, filepath):
        if not filepath or not os.path.exists(filepath):
            return None
            
        sha256_hash = hashlib.sha256()
        try:
            with open(filepath, "rb") as f:
                for byte_block in iter(lambda: f.read(4096), b""):
                    sha256_hash.update(byte_block)
            return sha256_hash.hexdigest()
        except Exception as e:
            logging.debug(f"Hash calculation skipped for {filepath}: {str(e)}")
            return None
    def scan_file(self, filepath: str) -> bool:
        try:
            file_hash = self.calculate_file_hash(filepath)
            return file_hash in self.signature_db
        except Exception as e:
            logging.error(f"Error scanning {filepath}: {str(e)}")
            return False

class YaraRuleManager:
    _initialized = True
    _instance = None
    _rules_compiled = False
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        if self._initialized:
            return
        self._initialized = True
        if getattr(self, '_initialized', False):
            return
        logging.basicConfig(level=logging.DEBUG)
        base_dir = self.rules_dir
        if base_dir:
            self.rules_dir = base_dir
        else:
            self.rules_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "yara_rules")
        if hasattr(self, '_initialized') and self._initialized:
            return
        self.rules_directory = self.rules_dir  # For backward compatibility
        if not self._rules_compiled:
            self.compile_combined_rules()
            YaraRuleManager._rules_compiled = True
        # Create rules directory if it doesn't exist
        
        self.rules_dir = Path("yara_rules")
        os.makedirs(self.rules_dir, exist_ok=True)
        self.mkdir = self.rules_dir.mkdir
        self.rules_dir.mkdir(parents=True, exist_ok=True)
        self.mkdir("yara_rules/memory_rules")
        self.mkdir("yara_rules/shellcode_rules")
        self.mkdir("yara_rules/injection_rules")
        self.mkdir("yara_rules/malware_rules")
        self.mkdir("yara_rules/custom_rules")  
        self.compiled_rules = {}
        self.combined_rules = None
        self._rules_loaded = False
        
        # Create injection patterns
        self.injection_patterns = {
            'reflective_loader': rb'\x4D\x5A.{128,1024}?ReflectiveLoader',
            'shellcode_xor': rb'\x48[\x31\x33]\xc0[\x48\x83]\xc0.',
            'api_hashing': rb'[\x33\x35\x8b]\xc9.{1,10}?[\xc1\xd3][\xe0\xe1\xe2].{1,10}?[\x03\x33]\xc1',
            'stack_strings': rb'[\x6a\x68][\x00-\xff][\x00-\xff][\x00-\xff][\x00-\xff][\x6a\x68]',
            'process_inject': rb'CreateRemoteThread|VirtualAllocEx|WriteProcessMemory',
        }
        
        # Convert rules_dir to a Path object for easier path manipulation
        self.rules_dir = Path(self.rules_dir)
        
        # Create rules directory structure
        os.makedirs(self.rules_dir, exist_ok=True)
        
        # Create category subdirectories
        for subdir in [
            "memory_rules", "shellcode_rules", "injection_rules", 
            "malware_rules", "custom_rules"
        ]:
            os.makedirs(self.rules_dir / subdir, exist_ok=True)
        
        # Define repository sources
        self.repo_sources = {
            "awesome-yara": "https://github.com/InQuest/awesome-yara",
            "cape-sandbox": "https://github.com/kevoreilly/CAPEv2",
            "fireeye": "https://github.com/mandiant/red_team_tool_countermeasures",
            "otx": "https://github.com/xosski/OTX-Python-SDK",
            "neo23x0": "https://github.com/Neo23x0/signature-base"
        }
        
        logging.debug("=== YaraRuleManager Initialization ===")
        logging.debug(f"Rules directory: {self.rules_dir}")
        logging.debug("Initializing rule sources:")
        
        for source, url in self.repo_sources.items():
            logging.debug(f"  {source}: {url}")
        
        # Add this line to fetch GitHub rules during initialization
        try:
            self.fetch_github_rules()
        except Exception as e:
            logging.error(f"Error fetching GitHub rules: {str(e)}")
        try:
            # Create directories and fetch rules
            self.create_repo_directories()
            self.fetch_github_rules()
            
            # If no rules were loaded from repos, create defaults
            if not self.are_rules_loaded():
                self._create_default_rules()
                
            # Finally compile all rules
            self.combined_rules = self.compile_combined_rules()
        except Exception as e:
            logging.error(f"Error during rule initialization: {str(e)}")  
        try:
            # Direct approach: create basic rules that are guaranteed to work
            print("Initializing YARA rules with basic detection patterns...")
            self.create_basic_rules()
            
            # Try to compile these basic rules
            self.combined_rules = self.compile_combined_rules()
            
            # Set rules as loaded if compilation succeeded
            self._rules_loaded = self.combined_rules is not None
            self.create_missing_rules()
    
            # Now compile all rules
            self.combined_rules = self.compile_combined_rules()
            self._rules_loaded = True
            self._rules_loaded = hasattr(self, 'combined_rules') and self.combined_rules is not None
            if self._rules_loaded:
                logging.info("YARA rules loaded successfully")
            else:
                logging.warning("YARA rules not properly loaded")
        except Exception as e:
            logging.error(f"Error creating missing rules: {str(e)}")
            self._rules_loaded = False           
    def process_yara_files(self, directory: Path):
      
      self.combined_rules = self.compile_combined_rules()
      if not directory.exists():              
            externals = {
                'filepath': '',
                'filename': '',
                'extension': '',
                'filetype': '',
                'file_type': '',
                'file_name': '',
                'file_path': '',
                'md5': '',
                'owner': '',
                'proc_name': '',
                'process_name': '',
                'module_path': '',
                'module_name': '',
                'time_date': 0,
                'currentdir': '',
                'executable': '',
                'compiled': True,
                'source': '',
                'description': '',
                'version': '',
                'fullpath': '',
                'ext': '',
                'path': '',
                'root': '',
                'name': '',
                'type': '',
                'size': 0,
                'sha1': '',
                'sha256': '',
                'signatures': [],
                'filesize': 0
            }
            
            for yara_file in directory.glob('**/*.yar*'):
                try:
                    # Read the rule file content
                    with open(yara_file, 'r') as f:
                        content = f.read()
                    
                    # Add external variable declarations at the start
                    external_declarations = 'global private rule declare_externals { condition: true }\n'
                    for var_name in externals.keys():
                        external_declarations += f'global private rule declare_{var_name} {{ condition: true }}\n'
                    
                    # Combine declarations with original content
                    modified_content = external_declarations + content
                    
                    # Compile the modified rule
                    compiled_rule = yara.compile(source=modified_content)
                    self.combined_rules[yara_file.stem] = compiled_rule
                    logging.info(f"Successfully compiled rule: {yara_file.name}")
                    
                except Exception as e:
                    logging.warning(f"Invalid rule file {yara_file} in category {directory.name}: {str(e)}") 
    def fetch_github_rules(self):
        """Fetch YARA rules from GitHub repositories"""
        # Only fetch if not already initialized
        if hasattr(self, '_github_rules_fetched'):
            return
        
        # Make sure git module is available
        try:
            import git
        except ImportError:
            logging.error("Git module not installed. Please install with 'pip install GitPython'")
            return
        
        # Ensure repo_sources is properly defined
        if not hasattr(self, 'repo_sources') or not self.repo_sources:
            # Redefine repo_sources if it's missing
           
            self.repo_sources = {
                "awesome-yara": "https://github.com/InQuest/awesome-yara",
                "cape-sandbox": "https://github.com/kevoreilly/CAPEv2",
                "fireeye": "https://github.com/mandiant/red_team_tool_countermeasures",
                "otx": "https://github.com/xosski/OTX-Python-SDK",
                "neo23x0": "https://github.com/Neo23x0/signature-base"
            }
            logging.info("Repository sources have been restored")
        
        logging.info(f"Fetching rules from {len(self.repo_sources)} repositories...")
        
        # Make sure rules_dir is a Path object
        if isinstance(self.rules_dir, str):
            self.rules_dir = Path(self.rules_dir)
        
        # Create each repo directory explicitly before trying to clone
        for repo_name in self.repo_sources:
            repo_dir = self.rules_dir / repo_name
            os.makedirs(repo_dir, exist_ok=True)
        
        # Now try to clone repositories
        for repo_name, repo_url in self.repo_sources.items():
            if repo_name == 'otx':
                continue  # Skip OTX repository for now
            
            repo_dir = self.rules_dir / repo_name
            logging.info(f"Checking repository: {repo_name} at {repo_url}")
            
            # Clear directory if it exists but is empty
            if repo_dir.exists() and not any(repo_dir.iterdir()):
                try:
                    logging.info(f"Cloning {repo_name} repository from {repo_url}...")
                    git.Repo.clone_from(repo_url, repo_dir, depth=1)
                    logging.info(f"Successfully cloned {repo_name} repository")
                except Exception as e:
                    logging.error(f"Error cloning repository {repo_name}: {str(e)}")
                    
                    # Try using subprocess as fallback
                    try:
                        logging.info(f"Trying alternative cloning method for {repo_name}...")
                        subprocess.run([
                            'git', 'clone',
                            '--depth', '1',
                            repo_url,
                            str(repo_dir)
                        ], check=True)
                        logging.info(f"Successfully cloned {repo_name} using subprocess")
                    except Exception as e2:
                        logging.error(f"All cloning methods failed for {repo_name}: {str(e2)}")
                        continue
            else:
                logging.info(f"Repository {repo_name} already exists at {repo_dir}")
        
        # Process rules from cloned repositories
        try:
            self._process_cloned_rules()
        except Exception as e:
            logging.error(f"Error processing cloned rules: {str(e)}")
        
        # Mark as fetched
        self._github_rules_fetched = True
        logging.info("GitHub rules fetching completed")
    def _process_cloned_rules(self, rules):
        """
        Process and validate cloned Yara rules.
        Returns a list of validated rule objects.
        """
        processed_rules = []
        rules = self.rules_dir.glob('**/*.yar*')
        for rule in rules:
            try:
                # Compile and validate the rule
                compiled_rule = yara.compile(source=rule)
                
                # Add to processed rules if compilation succeeds
                processed_rules.append(compiled_rule)
                
                # Log successful rule processing
                logging.info(f"Successfully processed cloned rule: {rule[:50]}...")
                
            except yara.Error as e:
                # Log invalid rules but continue processing others
                logging.warning(f"Invalid cloned rule detected: {str(e)}")
                continue
                
        return processed_rules
    def fetch_and_process_repo_rules(self):
        """Fetch and process YARA rules from GitHub repositories"""
        print("Fetching and processing repository rules...")
        
        # First make sure GitPython is available
        try:
            import git
        except ImportError:
            print("GitPython not installed. Installing now...")
            subprocess.check_call([sys.executable, "-m", "pip", "install", "GitPython"])
            import git
        
        # Ensure repo directories exist
        for repo_name in self.repo_sources:
            repo_dir = self.rules_dir / repo_name
            os.makedirs(repo_dir, exist_ok=True)
        
        # Clone repositories
        for repo_name, repo_url in self.repo_sources.items():
            if repo_name == 'otx':
                continue  # Handle OTX repository separately
            
            repo_dir = self.rules_dir / repo_name
            print(f"Processing repository: {repo_name} from {repo_url}")
            
            # Skip if already contains files (assuming already cloned)
            if repo_dir.exists() and any(repo_dir.iterdir()):
                print(f"Repository {repo_name} already exists and contains files")
            else:
                try:
                    print(f"Cloning {repo_name} repository...")
                    git.Repo.clone_from(repo_url, str(repo_dir), depth=1)
                    print(f"Successfully cloned {repo_name}")
                except Exception as e:
                    print(f"Error cloning with GitPython: {str(e)}")
                    try:
                        # Fallback to subprocess
                        print("Trying alternative cloning method...")
                        subprocess.run([
                            'git', 'clone', '--depth', '1', repo_url, str(repo_dir)
                        ], check=True)
                        print(f"Successfully cloned {repo_name} using subprocess")
                    except Exception as e2:
                        print(f"All cloning methods failed: {str(e2)}")
                        continue
        
        # Process rules from repositories
        rule_count = 0
        
        # This is the corrected loop - we iterate through items() and correctly unpack key/value
        for repo_name, repo_url in self.repo_sources.items():
            if repo_name == 'otx':
                continue
            
            repo_dir = self.rules_dir / repo_name
            if not repo_dir.exists():
                print(f"Repository directory {repo_dir} does not exist")
                continue
            
            # Find all YARA rule files in the repository
            yara_files = []
            for ext in ['*.yar', '*.yara']:
                yara_files.extend(list(repo_dir.glob(f'**/{ext}')))
            
            if not yara_files:
                print(f"No YARA rules found in {repo_name} repository")
                continue
            
            print(f"Found {len(yara_files)} YARA rules in {repo_name} repository")
            
            # Process each rule file
            for yara_file in yara_files:
                try:
                    # Read the rule content
                    with open(yara_file, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read().lower()
                    
                    # Determine appropriate category based on content
                    if 'memory' in content or 'process' in content:
                        dest_dir = self.rules_dir / 'memory_rules'
                    elif 'shellcode' in content:
                        dest_dir = self.rules_dir / 'shellcode_rules'
                    elif 'inject' in content:
                        dest_dir = self.rules_dir / 'injection_rules'
                    elif any(kw in content for kw in ['malware', 'trojan', 'backdoor', 'exploit']):
                        dest_dir = self.rules_dir / 'malware_rules'
                    else:
                        dest_dir = self.rules_dir / 'custom_rules'
                    
                    # Create a unique destination filename
                    dest_file = dest_dir / f"{repo_name}_{yara_file.stem}.yar"
                    
                    # Copy the rule content
                    with open(yara_file, 'r', encoding='utf-8', errors='ignore') as src:
                        with open(dest_file, 'w', encoding='utf-8') as dst:
                            dst.write(f"// From {repo_name} repository: {yara_file.name}\n")
                            dst.write(src.read())
                    
                    rule_count += 1
                    print(f"Processed rule: {dest_file.name}")
                    
                except Exception as e:
                    print(f"Error processing rule {yara_file}: {str(e)}")
        
        print(f"Successfully processed {rule_count} rules from repositories")
        
        # Always create missing basic rules as fallback
        if rule_count == 0:
            self.create_missing_rules()
        
        return rule_count > 0
    def create_missing_rules(self):
        """Create YARA rules for categories that are missing them"""
        print("Creating rules for missing categories...")
        
        # Define the categories to check
        categories = ['injection_rules', 'malware_rules', 'custom_rules']
        
        # Basic rule templates for each category
        templates = {
            'injection_rules': """
    rule injection_basic_detection {
        meta:
            description = "Basic injection detection rule"
            author = "YaraRuleManager"
        strings:
            $api1 = "CreateRemoteThread" nocase
            $api2 = "VirtualAllocEx" nocase
            $api3 = "WriteProcessMemory" nocase
            $hex1 = { 68 ?? ?? ?? ?? }  // PUSH instruction
        condition:
            any of them
    }
    """,
            'malware_rules': """
    rule malware_basic_detection {
        meta:
            description = "Basic malware detection rule"
            author = "YaraRuleManager"
        strings:
            $mz = { 4D 5A }  // PE file header
            $str1 = "cmd.exe /c" nocase
            $str2 = "powershell -e" nocase
        condition:
            any of them
    }
    """,
            'custom_rules': """
    rule custom_basic_detection {
        meta:
            description = "Basic custom detection rule"
            author = "YaraRuleManager"
        strings:
            $str1 = "suspicious" nocase
            $str2 = "backdoor" nocase
            $hex1 = { 00 01 02 03 04 }
        condition:
            any of them
    }
    """,
            'otx_rules': """
    rule otx_basic_detection {
        meta:
            description = "Basic OTX detection rule"
            author = "YaraRuleManager"
        strings:
            $str1 = "otx" nocase
        condition:
            $str1
    }
    """,
            'neo23x0_rules': """
    rule neo23x0_basic_detection {
        meta:
            description = "Basic neo23x0 detection rule"
            author = "YaraRuleManager"
        strings:
            $str1 = "neo23x0" nocase
        condition:
            $str1
    }
    """,
            'fireeye_rules': """
    rule fireeye_basic_detection {
        meta:
            description = "Basic fireeye detection rule"
            author = "YaraRuleManager"
        strings:
            $str1 = "fireeye" nocase
        condition:
            $str1
    }
    """,
            'cape_rules': """
    rule cape_basic_detection {
        meta:
            description = "Basic CAPEv2 detection rule"
            author = "YaraRuleManager"
        strings:
            $str1 = "cape" nocase
        condition:
            $str1
    }
    """,
            'awesome_rules': """
    rule awesome_basic_detection {
        meta:
            description = "Basic awesome-yara detection rule"
            author = "YaraRuleManager"
        strings:
            $str1 = "awesome" nocase
        condition:
            $str1
    }
    """,
        }
        # Check each category and create rule if missing
        for category in categories:
            category_dir = self.rules_dir / category
            rule_files = list(category_dir.glob('*.yar*'))
            
            # If no rules found in this category
            if not rule_files:
                print(f"No rules found in {category} - creating basic rule")
                rule_file = category_dir / "basic_detection.yar"
                try:
                    with open(rule_file, 'w') as f:
                        f.write(templates[category])
                    print(f"Created rule file: {rule_file}")
                except Exception as e:
                    print(f"Error creating rule file {rule_file}: {str(e)}")
        
        print("Missing rules creation complete!")
        return True
    def _create_default_rules(self):
        """Create default YARA rules if no rules were found or processed"""
        logging.info("Creating default YARA rules...")
        
        default_rules = {
            'memory_rules': """
    rule default_memory_detection {
        meta:
            description = "Default rule for memory scanning"
            author = "YaraRuleManager"
        strings:
            $shellcode_pattern = { 55 8B EC }
            $process_injection = "VirtualAlloc"
        condition:
            any of them
    }
    """,
            'shellcode_rules': """
    rule default_shellcode_detection {
        meta:
            description = "Default rule for shellcode detection"
            author = "YaraRuleManager"
        strings:
            $nop_sled = { 90 90 90 90 90 }
            $shellcode = { 55 8B EC }
        condition:
            any of them
    }
    """,
            'injection_rules': """
    rule default_injection_detection {
        meta:
            description = "Default rule for code injection detection"
            author = "YaraRuleManager"
        strings:
            $api1 = "CreateRemoteThread" nocase
            $api2 = "VirtualAllocEx" nocase
            $api3 = "WriteProcessMemory" nocase
        condition:
            any of them
    }
    """,
            'malware_rules': """
    rule default_malware_detection {
        meta:
            description = "Default rule for basic malware detection"
            author = "YaraRuleManager"
        strings:
            $suspicious1 = "cmd.exe /c " nocase
            $suspicious2 = "powershell -e" nocase
            $suspicious3 = { 4D 5A }  // PE file header
        condition:
            any of them
    }
    """,
            'custom_rules': """
    rule default_custom_detection {
        meta:
            description = "Default custom rule"
            author = "YaraRuleManager"
        strings:
            $s1 = "suspicious" nocase
        condition:
            $s1
    }
    """
        }
        
        # Create default rules in each category
        for category, rule_content in default_rules.items():
            category_dir = self.rules_dir / category
            default_file = category_dir / "default_rule.yar"
            
            # Only create if directory is empty
            if not any(category_dir.glob('*.yar*')):
                try:
                    with open(default_file, 'w') as f:
                        f.write(rule_content)
                    logging.info(f"Created default rule in {category}")
                except Exception as e:
                    logging.error(f"Error creating default rule in {category}: {str(e)}")
    def create_repo_directories(self):
        """Explicitly create all repository directories with verbose logging"""
        print("=== Creating Repository Directories ===")
        self.rules_dir = getattr(self, 'rules_dir', Path('yara_rules'))
        # Make sure we're using a Path object
        if isinstance(self.rules_dir, str):
            self.rules_dir = Path(self.rules_dir)
        
        print(f"Base rules directory: {self.rules_dir}")
        
        # Create base directory
        try:
            os.makedirs(self.rules_dir, exist_ok=True)
            print(f"✓ Created base directory: {self.rules_dir}")
        except Exception as e:
            print(f"✗ Error creating base directory: {str(e)}")
        
        # Define repository sources if not already defined
        if not hasattr(self, 'repo_sources') or not self.repo_sources:
            self.repo_sources = {
                "awesome-yara": "https://github.com/InQuest/awesome-yara",
                "cape-sandbox": "https://github.com/kevoreilly/CAPEv2",
                "fireeye": "https://github.com/mandiant/red_team_tool_countermeasures",
                "otx": "https://github.com/xosski/OTX-Python-SDK",
                "neo23x0": "https://github.com/Neo23x0/signature-base"
            }
        
        # Create category directories
        for category in ['memory_rules', 'shellcode_rules', 'injection_rules', 'malware_rules', 'custom_rules']:
            category_dir = self.rules_dir / category
            try:
                os.makedirs(category_dir, exist_ok=True)
                print(f"✓ Created category directory: {category_dir}")
            except Exception as e:
                print(f"✗ Error creating category directory {category}: {str(e)}")
        
        # Create repository directories
        for repo_name, repo_url in self.repo_sources.items():
            repo_dir = self.rules_dir / repo_name
            try:
                os.makedirs(repo_dir, exist_ok=True)
                print(f"✓ Created repository directory: {repo_dir}")
                
                # Verify the directory exists
                if repo_dir.exists():
                    print(f"  ✓ Verified directory exists: {repo_dir}")
                else:
                    print(f"  ✗ Directory creation failed, path doesn't exist: {repo_dir}")
            except Exception as e:
                print(f"✗ Error creating repository directory {repo_name}: {str(e)}")
        
        print("=== Repository Directory Creation Complete ===")
        return True
    def create_basic_rules(self):
        """Create basic, guaranteed-to-compile YARA rules in all category directories"""
        print("Creating basic YARA rules for all categories...")
        
        # Basic template for valid YARA rules
        basic_rule_template = """
    rule {category}_basic_detection {{
        meta:
            description = "Basic detection rule for {category}"
            author = "YaraRuleManager"
            created = "{date}"
        
        strings:
            $str1 = "{pattern1}" nocase
            $str2 = "{pattern2}" nocase
            $hex1 = {{ {hex_pattern} }}
        
        condition:
            any of them
    }}
    """

        # Category-specific detection patterns
        patterns = {
            "memory_rules": {
                "pattern1": "VirtualAlloc", 
                "pattern2": "MemoryBasicInformation",
                "hex_pattern": "90 90 90 90 90" # NOP sled
            },
            "shellcode_rules": {
                "pattern1": "shellcode", 
                "pattern2": "payload",
                "hex_pattern": "55 8B EC" # Common x86 prologue
            },
            "injection_rules": {
                "pattern1": "CreateRemoteThread", 
                "pattern2": "WriteProcessMemory",
                "hex_pattern": "68 ?? ?? ?? ??" # PUSH instruction
            },
            "malware_rules": {
                "pattern1": "malware", 
                "pattern2": "trojan",
                "hex_pattern": "4D 5A 90 00" # PE header start
            },
            "custom_rules": {
                "pattern1": "suspicious", 
                "pattern2": "detection",
                "hex_pattern": "00 01 02 03 04" # Simple byte sequence
            }
        }
        
        current_date = datetime.now().strftime("%Y-%m-%d")
        
        # Create rules for each category
        for category, patterns_dict in patterns.items():
            # Ensure the directory exists
            category_dir = self.rules_dir / category
            os.makedirs(category_dir, exist_ok=True)
            
            # Generate rule content
            rule_content = basic_rule_template.format(
                category=category.replace("_rules", ""),
                date=current_date,
                pattern1=patterns_dict["pattern1"],
                pattern2=patterns_dict["pattern2"],
                hex_pattern=patterns_dict["hex_pattern"]
            )
            
            # Write to file
            rule_file = category_dir / "basic_detection.yar"
            try:
                with open(rule_file, "w") as f:
                    f.write(rule_content)
                print(f"Created rule file: {rule_file}")
            except Exception as e:
                print(f"Error creating rule file {rule_file}: {str(e)}")
                
        print("Basic rules creation complete!")
        return True

    def fetch_all_rules(self):
        """Fetch and load all YARA rules."""
        try:
            rules_directory = getattr(self, 'rules_directory', None)
            if not rules_directory:
                rules_directory = getattr(self, 'rules_dir', None)
            
            if not rules_directory:
                rules_directory = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'yara_rules')
                self.rules_directory = rules_directory
                self.rules_dir = rules_directory
            
            # Create necessary subdirectories using os.path.join
            for subdir in ['memory_rules', 'shellcode_rules', 'injection_rules', 'malware_rules', 'custom_rules']:
                subdir_path = os.path.join(rules_directory, subdir)
                if not os.path.exists(subdir_path):
                    os.makedirs(subdir_path)
            
            # Search for existing rules
            rule_count = 0
            for subdir in ['memory_rules', 'shellcode_rules', 'injection_rules', 'malware_rules', 'custom_rules']:
                pattern = os.path.join(rules_directory, subdir, '*.yar')
                matched_files = glob.glob(pattern)
                rule_count += len(matched_files)
            
            # Create default rules if needed
            if rule_count == 0:
                # Create some default rules
                for subdir in ['memory_rules', 'shellcode_rules']:
                    subdir_path = os.path.join(rules_directory, subdir)
                    default_rule_path = os.path.join(subdir_path, 'default_rule.yar')
                    with open(default_rule_path, 'w') as f:
                        f.write("""
                        rule basic_shellcode_detection {
                            strings:
                                $nop_sled = { 90 90 90 90 90 }
                                $shellcode = { 55 8B EC }
                            condition:
                                any of them
                        }
                        """)
            self._rules_loaded = True
            return True
        except Exception as e:
            logging.error(f"Error fetching YARA rules: {str(e)}")
            self._rules_loaded = False
            return False
    def compile_combined_rules(self):
        """Compile all YARA rules from different categories into a single ruleset"""
        print("Compiling combined rules...")
        
        # Create a dictionary for different rule categories
        rule_categories = {
            "memory": os.path.join(self.rules_dir, "memory_rules"),
            "shellcode": os.path.join(self.rules_dir, "shellcode_rules"),
            "injection": os.path.join(self.rules_dir, "injection_rules"),
            "malware": os.path.join(self.rules_dir, "malware_rules"),
            "custom": os.path.join(self.rules_dir, "custom_rules")
        }
        
        # Dictionary to hold filepaths with their namespaces
        filepaths = {}
        total_rules = 0
        
        # Collect rule files from each category
        for category, directory in rule_categories.items():
            if not os.path.exists(directory):
                print(f"Rules directory not found: {directory}")
                continue
                
            print(f"Looking for {category} rules at {directory}/*.yar")
            rule_files = [f for f in glob.glob(os.path.join(directory, "*.yar")) if os.path.isfile(f)]
            
            if rule_files:
                print(f"Found {len(rule_files)} rules in category '{category}'")
                # Add each file with the category as namespace
                for rule_file in rule_files:
                    filename = os.path.basename(rule_file)
                    # Use category_filename as the namespace
                    namespace = f"{category}_{os.path.splitext(filename)[0]}"
                    filepaths[namespace] = rule_file
                    total_rules += 1
            else:
                print(f"No rules found in category '{category}'")
        
        # Compile rules with proper external variables
        if filepaths:
            print(f"\nCompiling {total_rules} YARA rules...")
            
            # Let's identify any external variables in the YARA rules first
            external_vars = set()
            for rule_path in filepaths.values():
                try:
                    with open(rule_path, 'r') as f:
                        content = f.read()
                        # Simple regex to find external variable declarations
                        for match in re.finditer(r'external\s+(\w+)', content):
                            external_vars.add(match.group(1))
                except Exception as e:
                    self.logger.error(f"Error reading rule file {rule_path}: {str(e)}")
            
            if external_vars:
                print(f"Found these external variables in rules: {', '.join(external_vars)}")
            
            try:
                # Define external variables with correct types
                # Include ALL found external variables with appropriate types
                externals = {}
                
                # Common external variables
                common_externals = {
                    'filename': '',      # string
                    'filepath': '',      # string
                    'extension': '',     # string
                    'filesize': 0,       # integer
                    'filepath_1': '',    # string
                    'filepath_2': '',    # string
                    'fullpath': '',      # string
                    'md5': '',           # string
                    'sha1': '',          # string
                    'sha256': '',        # string
                    'env': '',           # string
                    'filetype': '',      # string
                    'mime_type': '',     # string
                    'count': 0,          # integer
                    'offset': 0,         # integer
                    'is_executable': False, # boolean
                    'is_dll': False,     # boolean
                    'is_64bit': False,   # boolean
                    'timestamp': 0.0,    # float
                }
                
                # Add any found external variables to our externals dictionary
                for var in external_vars:
                    if var in common_externals:
                        externals[var] = common_externals[var]
                    else:
                        # Default to empty string for unknown variables
                        externals[var] = ''
                        print(f"Warning: Unknown external variable '{var}' found in rules, defaulting to string type")
                
                # Only include common variables that weren't already added
                for var, value in common_externals.items():
                    if var not in externals:
                        externals[var] = value
                
                # Debug: print all external variables we're using
                print(f"Using these external variables: {externals}")
                
                # Correct syntax for yara.compile with filepaths
                compiled_rules = yara.compile(filepaths=filepaths, externals=externals)
                print("YARA rules compiled successfully!")
                return compiled_rules
                
            except yara.Error as e:
                error_msg = f"Failed to compile YARA rules: {str(e)}"
                print(error_msg)
                self.logger.error(error_msg)
                
                # Try compiling each file individually to find problematic rules
                print("\nTrying to identify problematic rules:")
                for namespace, rule_path in filepaths.items():
                    print(f"Testing rule file: {namespace} ({rule_path})")
                    try:
                        rule_content = ""
                        with open(rule_path, 'r') as f:
                            rule_content = f.read()
                            
                        # Look for external declarations
                        file_externals = set()
                        for match in re.finditer(r'external\s+(\w+)', rule_content):
                            file_externals.add(match.group(1))
                        
                        if file_externals:
                            print(f"  - Contains external variables: {', '.join(file_externals)}")
                        
                        # Try to compile just this rule
                        yara.compile(filepath=rule_path, externals=externals)
                        print(f"  - Rule compiles successfully")
                    except Exception as e:
                        print(f"  - ERROR in rule: {str(e)}")
                        self.logger.error(f"Error in rule file '{namespace}' at {rule_path}: {str(e)}")
                
                return None
        else:
            print("No rules found to compile")
            return None

    def load_yara_rules(self):
        try:
            if isinstance(self.rules_dir, str):
                # Use os.path.join for strings
                rule_paths = {
                    'memory': os.path.join(self.rules_dir, 'memory_rules'),
                    'shellcode': os.path.join(self.rules_dir, 'shellcode_rules'),
                    'injection': os.path.join(self.rules_dir, 'injection_rules'),
                    'malware': os.path.join(self.rules_dir, 'malware_rules'),
                    'custom': os.path.join(self.rules_dir, 'custom_rules')
                }
            else:
                # Use / operator for Path objects
                rule_paths = {
                    'memory': str(self.rules_dir / 'memory_rules'),
                    'shellcode': str(self.rules_dir / 'shellcode_rules'),
                    'injection': str(self.rules_dir / 'injection_rules'),
                    'malware': str(self.rules_dir / 'malware_rules'),
                    'custom': str(self.rules_dir / 'custom_rules')
                }
            
            
        except Exception as e:
            self.logger.error(f"Error loading YARA rules: {str(e)}")
            print(f"Error loading YARA rules: {str(e)}")
        
        return self.compile_combined_rules()
    def are_rules_loaded(self):
        """Check if YARA rules are actually loaded"""
        if not hasattr(self, 'rules_dir'):
            return False
        
        # Check all category directories for rule files
        rule_count = 0
        for category in ['memory_rules', 'shellcode_rules', 'injection_rules', 'malware_rules', 'custom_rules']:
            category_dir = self.rules_dir / category
            if category_dir.exists():
                rule_files = list(category_dir.glob('*.yar')) + list(category_dir.glob('*.yara'))
                rule_count += len(rule_files)
        
        # Also check if compiled rules exist
        has_compiled = hasattr(self, 'combined_rules') and self.combined_rules is not None
        
        # Set and return the loading status
        self._rules_loaded = rule_count > 0 and has_compiled
        return self._rules_loaded
    def generate_runtime_key(self):
        # Generate puzzle components first
        puzzle_key = self.generate_puzzle_components()
        
        # Enhanced base components with biblical reference
        base_parts = [
            bytes([ord(c) ^ 0x42]) for c in [
                chr(x ^ 0x37) for x in [74, 101, 115, 117, 115, 32, 67, 104, 114, 105, 115, 116]
            ]
        ]
        
        static_parts = [
            int(self.static_hash[i:i+8], 16) ^ 0xF0F0F0F0
            for i in range(0, len(self.static_hash), 8)
        ]
        
        # Incorporate puzzle solution into runtime assembly
        time_seed = sum(map(int, datetime.now().strftime("%H%M%S")))
        runtime_key = sum(static_parts) ^ time_seed ^ int(puzzle_key[:16], 16)
        
        assembled = bytes(x ^ y for x, y in zip(
            b''.join(base_parts),
            runtime_key.to_bytes(32, 'big')
        ))
        
        # Include puzzle verification in final hash
        return hashlib.sha512(assembled + puzzle_key.encode()).hexdigest()
    def fetch_otx_rules(self):
        otx_dir = self.rules_dir / "otx"
        otx_dir.mkdir(exist_ok=True)
        if not (otx_dir / ".git").exists():
            self.repo_sources['otx-rules'] = 'https://github.com/xosski/OTX-Python-SDK'
            subprocess.run([
                'git', 'clone',
                '--depth', '1',
                self.repo_sources['otx-rules'],
                str(otx_dir)
            ])
        else:
            # Optionally update existing repository
            try:
                subprocess.run(['git', 'pull'], cwd=str(otx_dir), check=False)
            except Exception as e:
                logging.warning(f"Failed to update OTX rules: {str(e)}")
        
         # Process YARA files only once
        if not hasattr(self, '_rules_processed'):
            for yara_file in otx_dir.glob('**/*.yar*'):
                try:
                    yara.compile(str(yara_file))
                    logging.info(f"Loaded YARA rule: {yara_file.name}")
                except Exception as e:
                    logging.debug(f"Skipping invalid rule file {yara_file}: {str(e)}")
            self._rules_processed = True
        
        # Load local threat indicators
        indicators_file = self.rules_dir / "threat_indicators.json"
        if indicators_file.exists():
            with open(indicators_file) as f:
                data = json.load(f)
                for indicator in data:
                    self.analyze_threat_indicators(indicator)
        if hasattr(self, '_otx_fetched') and self._otx_fetched:
            return
        # Use API for real-time threat detection
        threat_url = "https://otx.alienvault.com/api/v1/pulses/6733cb23929b42dfad4f5712"
        headers = {
            'X-OTX-API-KEY': 'Insert API Key',
            'Accept': 'application/json'
        }
        
        # Query for recent threats
        threat_url = f"{threat_url}/indicators"
        response = requests.get(threat_url, headers=headers)
        
        if response.status_code == 200:
            data = response.json()
            for activity in data.get('results', []):
                if activity.get('indicators'):
                    self.analyze_threat_indicators(activity)
        self._otx_fetched = True
    def verify_rules_loaded(self):
        """Verify YARA rules are properly loaded and return detailed status"""
        report = {
            "directories_exist": True,
            "rule_files_exist": False,
            "rule_files_count": 0,
            "compilation_success": False,
            "error_message": None
        }
        
        try:
            # Check directories
            for category in ['memory_rules', 'shellcode_rules', 'injection_rules', 'malware_rules', 'custom_rules']:
                category_dir = self.rules_dir / category
                if not category_dir.exists():
                    report["directories_exist"] = False
                    report["error_message"] = f"Directory missing: {category_dir}"
                    return report
            
            # Check for rule files
            rule_count = 0
            for category in ['memory_rules', 'shellcode_rules', 'injection_rules', 'malware_rules', 'custom_rules']:
                category_dir = self.rules_dir / category
                rule_files = list(category_dir.glob('*.yar')) + list(category_dir.glob('*.yara'))
                rule_count += len(rule_files)
            
            report["rule_files_count"] = rule_count
            report["rule_files_exist"] = rule_count > 0
            
            if rule_count == 0:
                report["error_message"] = "No rule files found in any category"
                return report
            
            # Check compilation
            try:
                self.combined_rules = self.compile_combined_rules()
                report["compilation_success"] = self.combined_rules is not None
                
                if not report["compilation_success"]:
                    report["error_message"] = "Rules compilation failed"
            except Exception as e:
                report["compilation_success"] = False
                report["error_message"] = f"Error during compilation: {str(e)}"
            
            return report
        
        except Exception as e:
            report["error_message"] = f"Error during verification: {str(e)}"
            return report
    def generate_puzzle_components(self):
        # Biblical reference encoded in hex pairs
        biblical_hex = bytes([
            0x4a, 0x6f, 0x68, 0x6e, 0x33, 0x3a, 0x31, 0x36,
            0x52, 0x65, 0x76, 0x32, 0x31, 0x3a, 0x36
        ])
        
        # Mathematical sequence with significance
        sequence = [7, 12, 19, 23, 42, 77, 144, 365]
        
        # Encoded coordinates pointing to meaningful location
        coordinates = [31.7767, 35.2345]
        
        # Time-based rotation using significant dates
        rotation_key = sum(map(int, datetime.now().strftime("%d%m")))
        
        return self.encode_challenge(biblical_hex, sequence, coordinates, rotation_key)

    def encode_challenge(self, biblical, sequence, coords, rotation):
        # Layer 1: Biblical cipher
        layer1 = bytes([b ^ (rotation % 256) for b in biblical])
        
        # Layer 2: Mathematical progression with proper byte range
        layer2 = bytes([
            ((s * rotation) ^ (i * 0x42)) % 256
            for i, s in enumerate(sequence)
        ])
        
        # Layer 3: Geographic coordinates
        layer3 = struct.pack('dd', *coords)
        
        combined = hashlib.sha512(layer1 + layer2 + layer3).digest()
        
        key_parts = []
        for i in range(8):
            part = hashlib.sha256(combined[i*8:(i+1)*8]).hexdigest()[:8]
            key_parts.append(part)
        
        return ''.join(key_parts)

    def verify_solution(attempt, challenge):
        # Verification steps for each layer
        verification = hashlib.sha512(attempt.encode()).hexdigest()
        if verification.startswith(challenge[:32]):
            # Generate API key from verified solution
            key_base = hashlib.sha512(verification.encode()).digest()
            return base64.b85encode(key_base).decode()[:64]
        return None
    def test_otx_connection(self):
        try:
            headers = {
                'X-OTX-API-KEY': 'Insert API Key',
                'Accept': 'application/json'
            }
            threat_url = "https://otx.alienvault.com/api/v1/pulses/6733cb23929b42dfad4f5712"
            
            logging.debug("Testing OTX API connection with correct endpoint...")
            response = requests.get(threat_url,headers=headers)
            
            if response.status_code == 200:
                logging.debug("OTX API connection successful with valid response")
                return True
            else:
                logging.debug(f"OTX API connection failed - Status: {response.status_code}")
                logging.debug(f"Response content: {response.text}")
                return False
        except Exception as e:
            logging.debug(f"OTX API connection error: {str(e)}")
            return False
    
    def analyze_threat_indicators(self, activity):
        """Process threat indicators from OTX activity data"""
        indicators_dir = self.rules_dir / "threat_indicators"
        indicators_dir.mkdir(exist_ok=True)
        
        threat_types = {
            'FileHash-MD5': 'hashes',
            'FileHash-SHA1': 'hashes',
            'FileHash-SHA256': 'hashes',
            'URL': 'urls',
            'Domain': 'domains',
            'IPv4': 'ips',
            'IPv6': 'ips',
            'YARA': 'yara'
        }
        
        for indicator in activity.get('indicators', []):
            indicator_type = indicator.get('type')
            if indicator_type in threat_types:
                category = threat_types[indicator_type]
                indicator_file = indicators_dir / f"{category}.txt"
                
                with open(indicator_file, 'a') as f:
                    if category == 'yara':
                        f.write(f"# {activity['name']}\n{indicator['content']}\n\n")
                    else:
                        f.write(f"{indicator['indicator']}\n")
                
                print(f"Added {indicator_type} indicator from: {activity['name']}")
    
            
class MalwareScanner:
    
    def __init__(self):
        self.signature_db = set()
        self.quarantine_dir = Path("quarantine")
    
        self.yara_manager = YaraRuleManager()
        self.scanner = MalwareScanner()
        self.logger = self._setup_logging()
        self.dos_header = self.Image_Dos_Header()
        self.yara_manager.combined_rules = self.yara_manager.compile_combined_rules()
        self.executable_found = False
    def _setup_logging(self) -> logging.Logger:
        logging.basicConfig(
            filename='scanner.log',
            level=logging.info,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )
        return logging.getLogger('MalwareScanner')
    class Image_Dos_Header(ctypes.Structure):
                _fields_ = [
                    ("e_magic", ctypes.c_ushort),
                    ("e_cblp", ctypes.c_ushort),
                    ("e_cp", ctypes.c_ushort),
                    ("e_crlc", ctypes.c_ushort),
                    ("e_cparhdr", ctypes.c_ushort),
                    ("e_minalloc", ctypes.c_ushort),
                    ("e_maxalloc", ctypes.c_ushort),
                    ("e_ss", ctypes.c_ushort),
                    ("e_sp", ctypes.c_ushort),
                    ("e_csum", ctypes.c_ushort),
                    ("e_ip", ctypes.c_ushort),
                    ("e_cs", ctypes.c_ushort),
                    ("e_lfarlc", ctypes.c_ushort),
                    ("e_ovno", ctypes.c_ushort),
                    ("e_res", ctypes.c_ushort * 4),
                    ("e_oemid", ctypes.c_ushort),
                    ("e_oeminfo", ctypes.c_ushort),
                    ("e_res2", ctypes.c_ushort * 10),
                    ("e_lfanew", ctypes.c_long)
                ]
    def load_signatures(self, signature_file=None):
        if signature_file is None:
            # Use a default path or skip loading signatures
            logging.warning("No signature file provided, skipping signature loading")
            self.signature_db = set()  # Initialize with empty set
            return False
        
        if not os.path.exists(signature_file):
            logging.warning(f"Signature file not found: {signature_file}")
            self.signature_db = set()
            return False
        
        with open(signature_file, 'r') as f:
            self.signature_db = set(line.strip() for line in f)
        return True
    def detect_shellcode(self, memory_content, base_address=0):
        """
        Detect shellcode patterns and suspicious code characteristics
        Returns detailed analysis of potential shellcode
        """
        shellcode_indicators = {
            'found': False,
            'patterns': [],
            'characteristics': [],
            'risk_level': 0,
            'location': hex(base_address)
        }
        
        # Common shellcode patterns
        PATTERNS = {
            'egg_hunter': rb'\x66\x81\xca\xff\x0f\x42\x52\x6a\x02',
            'api_hashing': rb'\x74\x0c\x75\x14\xb8[\x00-\xff]{4}',
            'stack_alignment': rb'\x83\xec[\x00-\xff]\x83\xe4\xf0',
            'syscall_stub': rb'\x0f\x34|\x0f\x05|\xcd\x80',
            'null_free': rb'[\x01-\xff]{20,}',  # 20+ bytes without nulls
            'function_prolog': rb'\x55\x8b\xec|\x48\x89\x5c',
            'register_setup': rb'\x33\xc0|\x31\xc0|\x48\x31'
        }
        
        # Check for common patterns
        for name, pattern in PATTERNS.items():
            matches = re.finditer(pattern, memory_content)
            for match in matches:
                shellcode_indicators['patterns'].append({
                    'type': name,
                    'offset': match.start(),
                    'bytes': memory_content[match.start():match.start()+16].hex()
                })
                shellcode_indicators['risk_level'] += 1
        
        # Analyze characteristics
        characteristics = []
        
        # Check for position-independent code
        if b'\xff\x34\x24' in memory_content:  # Push/Pop patterns
            characteristics.append('position_independent')
            shellcode_indicators['risk_level'] += 2
            
        # Check for encoded/encrypted segments
        entropy = self._calculate_entropy(memory_content)
        if entropy > 7.0:
            characteristics.append('high_entropy')
            shellcode_indicators['risk_level'] += 2
            
        # Check for small code blocks
        if len(memory_content) < 4096:
            characteristics.append('small_code_block')
            shellcode_indicators['risk_level'] += 1
            
        # Check for stack/heap operations
        if b'\x89\xe5' in memory_content or b'\x8b\xe5' in memory_content:
            characteristics.append('stack_manipulation')
            shellcode_indicators['risk_level'] += 1
        
        shellcode_indicators['characteristics'] = characteristics
        shellcode_indicators['found'] = shellcode_indicators['risk_level'] > 2
        
        return shellcode_indicators

    def _calculate_entropy(self, data):
        """Calculate Shannon entropy of data"""
        if not data:
            return 0
        entropy = 0
        for x in range(256):
            p_x = float(data.count(x))/len(data)
            if p_x > 0:
                entropy += - p_x * math.log(p_x, 2)
        return entropy
    def calculate_file_hash(self, filepath):
        if not filepath or not os.path.exists(filepath):
            return None
            
        sha256_hash = hashlib.sha256()
        try:
            with open(filepath, "rb") as f:
                for byte_block in iter(lambda: f.read(4096), b""):
                    sha256_hash.update(byte_block)
            return sha256_hash.hexdigest()
        except Exception as e:
            logging.debug(f"Hash calculation skipped for {filepath}: {str(e)}")
            return None
    def scan_file(self, filepath: str) -> bool:
        self.compiled_rules = self.yara_manager.compile_combined_rules()
        try:
            matches = self.compiled_rules.match(filepath, timeout=60)
            return matches
        except Exception as e:
            logger.error(f"Error scanning file {filepath}: {str(e)}")
            return []
    def scan_directory(self, directory: str) -> List[str]:
        infected_files = []
        for root, _, files in os.walk(directory):
            for file in files:
                full_path = os.path.join(root, file)
                if self.scan_file(full_path):
                    infected_files.append(full_path)
                    logging.warning(f"Malware detected: {full_path}")
        return infected_files

    def quarantine_file(self, filepath: str) -> bool:
        try:
            self.quarantine_dir.mkdir(exist_ok=True)
            filename = Path(filepath).name
            quarantine_path = self.quarantine_dir / f"{filename}.quarantine"
            shutil.move(filepath, quarantine_path)
            logging.info(f"Quarantined {filepath} to {quarantine_path}")
            return True
        except Exception as e:
            logging.error(f"Quarantine failed for {filepath}: {str(e)}")
            return False
    def remove_file(self, filepath: str) -> bool:
        try:
            os.remove(filepath)
            logging.info(f"Removed infected file: {filepath}")
            return True
        except Exception as e:
            logging.error(f"Removal failed for {filepath}: {str(e)}")
            return False
class MemoryScanner:
    _instance = None
    _initialized = True
    kernel32 = ctypes.windll.kernel32
    kernel32: ctypes.WinDLL = ctypes.WinDLL('kernel32')
    VirtualQueryEx = kernel32.VirtualQueryEx
    VirtualQueryEx.argtypes = [
        wintypes.HANDLE,  # hProcess
        wintypes.LPCVOID, # lpAddress
        ctypes.POINTER(MEMORY_BASIC_INFORMATION), # lpBuffer
        ctypes.c_size_t   # dwLength
    ]
    MEM_COMMIT = 0x1000
    MEM_RESERVE = 0x2000
    MEM_RELEASE = 0x8000
    PAGE_NOACCESS = 0x01
    PAGE_READONLY = 0x02
    PAGE_READWRITE = 0x04
    PAGE_WRITECOPY = 0x08
    PAGE_EXECUTE = 0x10
    PAGE_EXECUTE_READ = 0x20
    PAGE_EXECUTE_READWRITE = 0x40
    PAGE_EXECUTE_WRITECOPY = 0x80
    PAGE_GUARD = 0x100
    PAGE_NOCACHE = 0x200
    PAGE_WRITECOMBINE = 0x400
    DEFAULT_PAGE_SIZE = 4096
    TH32CS_SNAPTHREAD = 0x00000002
    pmmap_ext_size = ()
    SystemProcessInformation = 5
    SystemModuleInformation = 11
    STATUS_INFO_LENGTH_MISMATCH = 0xC0000004
    @classmethod
    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._initialized = False
        return cls._instance
    def __init__(self, root=None):
        self.root = None
        self.enable_debug_privilege()
        
        if not MemoryScanner._initialized:
            self.gui = ScannerGui
            self.yara_manager = YaraRuleManager()
            MemoryScanner._initialized = True
            self.enable_debug_privilege()
            logging.info("MemoryScanner")
        self._initialized = True
        self.executable_found = False
        self.logger = logging.getLogger(__name__)
        self.logger.info("MemoryScanner")
        self.scanner = None
        self.detection_methods = []
        # Initialize YaraRuleManager directly
        self.yara_manager = YaraRuleManager()
        self.yara_manager.fetch_all_rules()
        self.logger = logging.getLogger(__name__)
        self.logging = self.setup_scanner_logging()
        self.gui = ScannerGui
        self._process_hollowing_stack = set()
        self.disasembler = CodeDisassembler()
        
        logging.debug("MemoryScanner Initialization ===")
        logging.info("MemoryScanner")
        if not self.yara_manager:
            logging.debug("Initializing YaraRuleManager")
        try:
            # Call compile_combined_rules() directly on yara_manager, not through another attribute
            self.combined_rules = self.yara_manager.compile_combined_rules()
        except Exception as e:
            self.logger.error(f"Error loading YARA rules: {str(e)}")
            print(f"Error loading YARA rules: {str(e)}")
            self.combined_rules = None
        self.memory_info_dict = {
            "BaseAddress": 0,
            "AllocationBase": 0,
            "AllocationProtect": 0,
            "RegionSize": 0,
            "State": 0,
            "Protect": 0,
            "Type": 0
        }
        self.quarantine_enabled = False  # Start disabled by default
        self.quarantine_threshold = 75
        
        # Set up quarantine directory
        try:
            self.quarantine_dir = os.path.join(os.path.expanduser("~"), "scanner_quarantine")
            if not os.path.exists(self.quarantine_dir):
                os.makedirs(self.quarantine_dir)
        except Exception as e:
            logging.error(f"Failed to initialize quarantine directory: {str(e)}")
            self.quarantine_dir = None
            self.quarantine_enabled = False  # Disable if dir creation fails
        
        # Set up logger
        self.logger = logging.getLogger(__name__)
        self.quarantine = ThreatQuarantine()
        PROTECTED_PROCESSES = [
        "Registry",  # Registry process
        "smss.exe",  # Session Manager Subsystem
        "csrss.exe",  # Client Server Runtime Process
        "wininit.exe",  # Windows Initialization Process
        "services.exe",  # Services Control Manager
        "lsass.exe",  # Local Security Authority Subsystem Service
        "winlogon.exe",  # Windows Logon Process
        "System",  # Windows System Process (PID 4)
        "System Idle Process"  # System Idle Process (PID 0)
        ]
        
        self.signature_db = set()
        logging.debug("YaraRuleManager instance attached")
        # Log memory constants
        logging.debug("Memory Protection Constants:")
        logging.debug(f"MEM_COMMIT: {self.MEM_COMMIT}")
        logging.debug(f"PAGE_EXECUTE_READWRITE: {self.PAGE_EXECUTE_READWRITE}")
        self.injection_patterns = {
            'shellcode': rb'\x55\x8B\xEC|\x90{4,}',
            'script_injection': rb'(eval|exec|system|subprocess.run)',
            'memory_manipulation': rb'(VirtualAlloc|WriteProcessMemory)',
            'dll_injection': rb'(LoadLibrary|GetProcAddress)',
            'code_execution': rb'(WScript.Shell|cmd.exe|powershell.exe)',
            'encoded_commands': rb'([A-Za-z0-9+/]{40,}={0,2})'
        }
         # Define memory quarantine structure
        self.memory_quarantine = {
            'active': {},  # Currently quarantined processes
            'history': {},  # Historical quarantine records
            'metadata': {}  # Additional quarantine information
        }
        self.kernel32 = ctypes.windll.kernel32
        VirtualQueryEx = self.kernel32.VirtualQueryEx
        VirtualQueryEx.argtypes = [
            wintypes.HANDLE,  # hProcess
            wintypes.LPCVOID, # lpAddress
            ctypes.POINTER(MEMORY_BASIC_INFORMATION), # lpBuffer
            ctypes.c_size_t   # dwLength
        ]
        VirtualQueryEx.restype = ctypes.c_size_t
        # Log injection patterns
        logging.debug("Initialized Injection Patterns:")
        for pattern_name in self.injection_patterns.keys():
            logging.debug(f"- {pattern_name}")
        self.quarantine_dir = Path("memory_quarantine")
        self.quarantine_dir.mkdir(exist_ok=True)
        # Log scanner setup
       
        logging.debug("MemoryScanner Components:")
        logging.debug(f"Quarantine Directory: {self.quarantine_dir}")
        logging.debug(f"Rules Loaded: {bool(self.load_local_rules())}")
        logging.debug(f"Signature DB Size: {len(self.signature_db)}")
        
        logging.debug("MemoryScanner Initialization Complete ===\n")
        self.root = root
        
        self.rules = self.load_local_rules()
        self.quarantine_dir = Path("memory_quarantine")
        self.quarantine_dir.mkdir(exist_ok=True)
        self.verify_system_modules = True
        self.yara_manager.load_yara_rules()
        logging.debug("YaraRuleManager instance attached")
    def enable_debug_privilege(self):
        """Enable SeDebugPrivilege to access more processes"""
        try:
            import win32security
            import win32api
            import ntsecuritycon
            
            logging.debug("Attempting to enable SeDebugPrivilege")
            
            # Get the process token
            hToken = win32security.OpenProcessToken(
                win32api.GetCurrentProcess(),
                win32security.TOKEN_ADJUST_PRIVILEGES | win32security.TOKEN_QUERY
            )
            
            # Enable SeDebugPrivilege
            privilege_id = win32security.LookupPrivilegeValue(
                None, ntsecuritycon.SE_DEBUG_NAME
            )
            
            win32security.AdjustTokenPrivileges(
                hToken, 0, [(privilege_id, win32security.SE_PRIVILEGE_ENABLED)]
            )
            
            win32api.CloseHandle(hToken)
            logging.info("SeDebugPrivilege enabled successfully")
        except Exception as e:
            logging.error(f"Failed to enable SeDebugPrivilege: {str(e)}")
    def initialize_ntdll_database(self):
        """
        Initializes a database of original bytes for NTDLL functions from the current system.
        This should be run on a clean system to create a baseline for comparison.
        """
        try:
            self.ntdll_original_bytes = {}
            
            # Open ntdll.dll from the system directory
            ntdll_path = os.path.join(os.environ.get('SystemRoot', 'C:\\Windows'), 'System32\\ntdll.dll')
            if not os.path.exists(ntdll_path):
                logging.error(f"NTDLL not found at {ntdll_path}")
                return
                
            # Load the DLL for parsing
            ntdll_handle = win32api.LoadLibrary(ntdll_path)
            
            # Functions to catalog
            functions_to_check = [
                "NtCreateProcess", "NtCreateThread", "NtAllocateVirtualMemory",
                "NtWriteVirtualMemory", "NtProtectVirtualMemory", "NtQueueApcThread",
                "NtCreateSection", "NtMapViewOfSection"
            ]
            
            # Get function addresses and record the first bytes
            for func_name in functions_to_check:
                try:
                    # Get function address
                    func_addr = win32api.GetProcAddress(ntdll_handle, func_name)
                    if func_addr:
                        # Create a memory view to read the first bytes (we need to use ctypes for this)
                        buf = (ctypes.c_ubyte * 10)()
                        ctypes.memmove(buf, func_addr, 10)
                        
                        # Convert to bytes and store
                        self.ntdll_original_bytes[func_name] = bytes(buf)
                        logging.debug(f"Recorded original bytes for {func_name}")
                    else:
                        logging.debug(f"Could not find address for {func_name}")
                except Exception as func_err:
                    logging.debug(f"Error recording bytes for {func_name}: {str(func_err)}")
                    
            # Free the library
            win32api.FreeLibrary(ntdll_handle)
            
            logging.info(f"Initialized NTDLL database with {len(self.ntdll_original_bytes)} functions")
            
        except Exception as e:
            logging.error(f"Error initializing NTDLL database: {str(e)}")
    def _suspend_process(self, process_handle):
        """Suspend a process using NtSuspendProcess from ntdll.dll"""
        try:
            ntdll = ctypes.windll.ntdll
            NtSuspendProcess = ntdll.NtSuspendProcess
            NtSuspendProcess(process_handle)
            return True
        except Exception as e:
            if hasattr(self, 'logger'):
                self.logger.error(f"Failed to suspend process: {str(e)}")
            else:
                logging.error(f"Failed to suspend process: {str(e)}")
            return False
    def setup_scanner_logging(self):
        """Set up enhanced logging for the scanner"""
        import logging
        from pathlib import Path
        
        # Create logs directory if it doesn't exist
        log_dir = Path('logs')
        log_dir.mkdir(exist_ok=True)
        
        # Get logger
        logger = logging.getLogger('ScannerLogger')
        
        # Only set up handlers if they don't exist already
        if not logger.handlers:
            logger.setLevel(logging.DEBUG)  # Set logger level
            
            # File handler for detailed logging
            file_path = log_dir / 'scanner_debug.log'
            file_handler = logging.FileHandler(str(file_path))
            file_handler.setLevel(logging.DEBUG)
            
            # Console handler for info messages
            console_handler = logging.StreamHandler()
            console_handler.setLevel(logging.INFO)
            
            # Create formatters
            detailed_fmt = '%(asctime)s - %(levelname)s - %(filename)s:%(lineno)d - %(message)s'
            simple_fmt = '%(levelname)s: %(message)s'
            
            file_handler.setFormatter(logging.Formatter(detailed_fmt))
            console_handler.setFormatter(logging.Formatter(simple_fmt))
            
            # Add handlers to logger
            logger.addHandler(file_handler)
            logger.addHandler(console_handler)
            
            # Log that we've set up logging
            logger.info("Scanner logging initialized")
            logger.debug("Detailed logging enabled")
        
        return logger
    def _get_default_system_info(cls):
        """Return default system information when actual retrieval fails"""
        return {
            'system_info': None,
            'processor_architecture': 0x0,
            'page_size': 0x1000,  # Standard page size
            'min_address': 0x0,
            'max_address': 0x7FFFFFFF0000,  # Default max user-mode address
            'processor_count': 0x1,
            'processor_type': 0x0,
            'allocation_granularity': 0x10000,  # Default allocation granularity
            'processor_level': 0x0,
            'processor_revision': 0x0,
            'active_processor_mask': 0x0,
            'processor_features': [],
            'system_firmware_table': None,
            'system_flags': 0x0,
            'error': 'Using default values'
        }
    def load_signatures(self, signature_file=None):
        if signature_file is None:
            # Use a default path or skip loading signatures
            logging.warning("No signature file provided, skipping signature loading")
            self.signature_db = set()  # Initialize with empty set
            return False
        
        if not os.path.exists(signature_file):
            logging.warning(f"Signature file not found: {signature_file}")
            self.signature_db = set()
            return False
        
        with open(signature_file, 'r') as f:
            self.signature_db = set(line.strip() for line in f)
        return True
    def _setup_logging(self) -> logging.Logger:
        logging.basicConfig(
            filename='memory_scanner.log',
            level=logging.info,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )
        return logging.getLogger('memory_scanner')
    def load_local_rules(self):
        # Load built-in detection patterns
        self.injection_patterns = {
            'shellcode': rb'\x55\x8B\xEC|\x90{4,}',
            'script_injection': rb'(eval|exec|system|subprocess.run)',
            'memory_manipulation': rb'(VirtualAlloc|WriteProcessMemory)',
            'dll_injection': rb'(LoadLibrary|GetProcAddress)',
            'code_execution': rb'(WScript.Shell|cmd.exe|powershell.exe)',
            'encoded_commands': rb'([A-Za-z0-9+/]{40,}={0,2})'
        }
        
        # Compile rules without external dependencies
        rule_string = """
        rule suspicious_memory {
            strings:
                $shellcode = /\x55\x8B\xEC|\x90{4,}/
                $injection = /(VirtualAlloc|WriteProcessMemory)/
            condition:
                any of them
        }
        """
        return yara.compile(source=rule_string)
    
    def detect_shellcode_patterns(self, memory_content: bytes) -> Dict[str, any]:
        shellcode_indicators = {
            'nop_sled': rb'\x90{5,}',  # NOP sleds
            'function_prolog': rb'\x55\x8B\xEC',  # Push EBP, MOV EBP, ESP
            'api_hashing': rb'\x74\x0C\x75',  # Common API hashing patterns
            'stack_strings': rb'([A-Za-z0-9]{8,})\x00',  # Stack-based strings
            'syscall_patterns': rb'\xCD\x80|\x0F\x34|\x0F\x05',  # Various syscall instructions
            'heap_spray': rb'\u9090' * 10,  # Heap spray patterns
            'rop_gadgets': rb'\xC3|\xCB|\xC2[\x00-\xFF]{2}',  # Return instructions
            'shellcode_encoders': rb'\xEB\x02[\x00-\xFF]{2}\xEB'  # JMP patterns
        }
        
        findings = {}
        for indicator_name, pattern in shellcode_indicators.items():
            matches = list(re.finditer(pattern, memory_content))
            if matches:
                findings[indicator_name] = {
                    'count': len(matches),
                    'offsets': [hex(match.start()) for match in matches],
                    'context': [memory_content[max(0, match.start()-16):match.end()+16].hex() for match in matches]
                }
        
        return findings
    

    def _calculate_entropy(self, data):
        """Calculate Shannon entropy of data"""
        if not data:
            return 0
        entropy = 0
        for x in range(256):
            p_x = float(data.count(x))/len(data)
            if p_x > 0:
                entropy += - p_x * math.log(p_x, 2)
        return entropy
    def safe_pid(self, pid_value):
        """
        Safely validate a process ID
        
        Args:
            pid_value: Integer, dictionary, or object containing PID information
            
        Returns:
            int: Valid PID or 0 if invalid
        """
        try:
            # Handle different input types
            if pid_value is None:
                return 0
                
            # If pid_value is a dictionary
            if isinstance(pid_value, dict):
                pid = pid_value.get('pid', 0)
            # If pid_value is already an integer
            elif isinstance(pid_value, int):
                pid = pid_value
            # If pid_value is a string that can be converted to int
            elif isinstance(pid_value, str) and pid_value.isdigit():
                pid = int(pid_value)
            # If pid_value is an object with a pid attribute
            elif hasattr(pid_value, 'pid'):
                pid = pid_value.pid
            else:
                return 0
                
            # Validate PID exists
            if pid > 0:
                try:
                    proc = psutil.Process(pid)
                    if not proc.is_running():
                        return 0
                    return pid  # Valid PID
                except psutil.NoSuchProcess:
                    return 0
            return 0  # Invalid PID
        except Exception as e:
            logging.error(f"Error validating PID: {str(e)}")
            return 0
    def safe_int_conversion(self, value, default=0, base=10):
        """Safely convert a value to integer with detailed error handling.
        
        Args:
            value: The value to convert to integer
            default: Default value to return if conversion fails (default: 0)
            base: Base for conversion (default: 10)
            
        Returns:
            Converted integer or default value if conversion fails
        """
        try:
            if isinstance(value, int):
                return value
            elif isinstance(value, str):
                # Handle hex values with '0x' prefix
                if value.lower().startswith('0x'):
                    return int(value, 16)
                # Handle memory ranges like "7FF1234-7FF5678"
                elif '-' in value:
                    start_addr = value.split('-')[0].strip()
                    return int(start_addr, 16) if '0x' in start_addr.lower() or all(c in '0123456789abcdefABCDEF' for c in start_addr) else int(start_addr)
                else:
                    return int(value, base)
            else:
                logging.debug(f"Unexpected type for integer conversion: {type(value)}")
                return default
        except ValueError as e:
            # Log the actual value and error
            logging.debug(f"Invalid literal for int(): '{value}' (type: {type(value)}, repr: {repr(value)})")
            logging.debug(f"Error details: {str(e)}")
            
            # Try to detect and handle common pattern issues
            if isinstance(value, str):
                # Try to handle values with unexpected characters
                clean_value = ''.join(c for c in value if c.isdigit())
                if clean_value:
                    logging.debug(f"Attempting conversion of cleaned value: {clean_value}")
                    try:
                        return int(clean_value)
                    except ValueError:
                        logging.debug("Conversion of cleaned value also failed")
                        
                # Try hex conversion if it looks like a hex value
                if any(c.lower() in 'abcdef' for c in value):
                    try:
                        clean_hex = ''.join(c for c in value if c.lower() in '0123456789abcdef')
                        logging.debug(f"Attempting hex conversion of: {clean_hex}")
                        return int(clean_hex, 16)
                    except ValueError:
                        logging.debug("Hex conversion also failed")
            
            return default
    # Helper function to add to your class
    def safe_int_from_handle(self, handle_obj):
        """Safely convert a handle object to integer"""
        if handle_obj is None:
            return 0
        
        try:
            # First try direct int conversion
            return int(handle_obj)
        except (TypeError, ValueError):
            # If that fails, try accessing the handle value
            if hasattr(handle_obj, 'handle'):
                return int(handle_obj.handle)
            # For PyHANDLE objects
            elif hasattr(handle_obj, '_handle'):
                return int(handle_obj._handle)
            # For memory addresses as pointers
            elif hasattr(handle_obj, 'value'):
                return int(handle_obj.value)
            # Last resort - convert address to int
            else:
                try:
                    return ctypes.addressof(handle_obj)
                except:
                    return id(handle_obj)  # Use object ID as fallback
    def detect_injection_techniques(self, process_handle, pid):
        """
        Detects various process injection techniques.
        
        Args:
            process_handle: Windows handle to the process
            pid: Process ID
            
        Returns:
            List of dictionaries containing injection findings
        """
        logging.debug(f"Checking for injection techniques in PID {pid}")
        findings = []
        
        try:
            # 1. Check for hollowed processes (compare file on disk vs memory)
            proc = psutil.Process(pid)
            process_path = proc.exe()
            
            if process_path and os.path.exists(process_path):
                # Get section headers from file
                try:
                    with open(process_path, 'rb') as f:
                        file_data = f.read(8192)  # Read header portion
                    
                    # Compare with in-memory PE header
                    base_addr = self.get_process_base_address(process_handle)
                    if base_addr:
                        try:
                            mem_data = win32process.ReadProcessMemory(process_handle, base_addr, 8192)
                            
                            # Check for differences in PE header
                            if file_data and mem_data and len(file_data) > 256 and len(mem_data) > 256:
                                # Compare DOS header and PE signature
                                if file_data[0:64] != mem_data[0:64]:
                                    findings.append({
                                        "technique": "Process Hollowing",
                                        "details": f"PE header modifications detected in {proc.name()}"
                                    })
                        except Exception as e:
                            logging.debug(f"Error reading process memory: {str(e)}")
                except Exception as e:
                    logging.debug(f"Error reading process file: {str(e)}")
            
            # 2. Check for NTDLL hooks (common in injection techniques)
            try:
                modules = self.list_process_modules(process_handle)
                for module in modules:
                    if module.get('name', '').lower() == 'ntdll.dll':
                        base = module.get('base')
                        # Check for hooks on critical functions
                        hooked_functions = self.check_ntdll_hooks(process_handle, base)
                        if hooked_functions:
                            findings.append({
                                "technique": "API Hooking",
                                "details": f"Hooked NTDLL functions: {', '.join(hooked_functions)}"
                            })
            except Exception as e:
                logging.debug(f"Error checking NTDLL hooks: {str(e)}")
            
            # 3. Check for APC injection (look for registered APCs)
            try:
                threads = self.list_process_threads(pid)
                for thread in threads:
                    if thread.get('apc_count', 0) > 0:
                        findings.append({
                            "technique": "APC Injection",
                            "details": f"Thread {thread.get('tid')} has {thread.get('apc_count')} APCs queued"
                        })
            except Exception as e:
                logging.debug(f"Error checking APCs: {str(e)}")
                
        except Exception as e:
            logging.error(f"Error in detect_injection_techniques: {str(e)}")
        
        return findings

    def inspect_threads(self, pid):
        """
        Inspects threads for suspicious characteristics.
        
        Args:
            pid: Process ID
            
        Returns:
            List of dictionaries containing thread findings
        """
        logging.debug(f"Inspecting threads for PID {pid}")
        findings = []
        
        try:
            # Get all threads for the process
            threads = self.list_process_threads(pid)
            
            for thread in threads:
                tid = thread.get('tid')
                # Skip if no thread ID
                if not tid:
                    continue
                    
                try:
                    # 1. Check for threads created from remote processes
                    creator_pid = thread.get('creator_pid')
                    if creator_pid and creator_pid != pid:
                        findings.append({
                            "tid": tid,
                            "details": f"Created by external process PID {creator_pid}",
                            "severity": "Critical"
                        })
                    
                    # 2. Check thread start address
                    start_addr = thread.get('start_address')
                    if start_addr:
                        # Check if start address is outside of loaded modules
                        if not self.is_address_in_module(pid, start_addr):
                            findings.append({
                                "tid": tid,
                                "details": f"Thread starting at non-module address {hex(start_addr)}",
                                "severity": "High"
                            })
                    
                    # 3. Check thread priority (extremely high priority can be suspicious)
                    priority = thread.get('priority')
                    if priority and priority > 15:  # THREAD_PRIORITY_TIME_CRITICAL is 15
                        findings.append({
                            "tid": tid,
                            "details": f"Thread with abnormally high priority {priority}",
                            "severity": "Medium"
                        })
                    
                    # 4. Check for hidden/suspended threads
                    state = thread.get('state')
                    if state == 'Initialized' or state == 'Suspended':
                        findings.append({
                            "tid": tid,
                            "details": f"Thread in {state} state",
                            "severity": "Medium"
                        })
                        
                except Exception as e:
                    logging.debug(f"Error inspecting thread {tid}: {str(e)}")
                    
        except Exception as e:
            logging.error(f"Error in inspect_threads: {str(e)}")
        
        return findings
    def list_process_threads(process_id):
        """Lists all threads for a given process ID"""
        try:
            process_handle = win32api.OpenProcess(win32con.PROCESS_ALL_ACCESS, False, process_id)
            snapshot = win32process.CreateToolhelp32Snapshot(win32con.TH32CS_SNAPTHREAD, 0)
            thread_entry = win32process.Thread32First(snapshot)
            threads = []
            
            while thread_entry:
                if thread_entry.th32OwnerProcessID == process_id:
                    threads.append({
                        'ThreadId': thread_entry.th32ThreadID,
                        'BasePri': thread_entry.tpBasePri,
                        'DeltaPri': thread_entry.tpDeltaPri
                    })
                thread_entry = win32process.Thread32Next(snapshot)
            
            win32api.CloseHandle(snapshot)
            win32api.CloseHandle(process_handle)
            return threads
            
        except Exception as e:
            logging.debug(f"Error listing process threads: {str(e)}")
            return []
    def is_address_in_module(address, module):
        """
        Checks if a memory address falls within a module's address range
        
        Args:
            address: Memory address to check
            module: Module object containing BaseAddress and Size
        
        Returns:
            bool: True if address is within module range, False otherwise
        """
        module_start = module.BaseAddress
        module_end = module.BaseAddress + module.Size
        return module_start <= address <= module_end
    def check_network_connections(self, pid):
        """
        Checks for suspicious network connections.
        
        Args:
            pid: Process ID
            
        Returns:
            List of dictionaries containing connection information
        """
        logging.debug(f"Checking network connections for PID {pid}")
        suspicious_connections = []
        
        try:
            # Get all connections for this process
            connections = psutil.Process(pid).net_connections()
            
            # List of known malicious/suspicious ports
            suspicious_ports = [4444, 31337, 1080, 8080, 9001, 9002]
            
            # Common C2 ports and ranges
            c2_port_ranges = [(1024, 1050), (50000, 60000)]
            
            # Known malicious IPs (example)
            suspicious_ips = [
                '127.0.0.1',  # For testing only
                # Add your suspicious IPs here
            ]
            
            for conn in connections:
                is_suspicious = False
                reason = []
                
                # Skip if no remote address
                if not hasattr(conn, 'raddr') or not conn.raddr:
                    continue
                    
                remote_ip = conn.raddr.ip
                remote_port = conn.raddr.port
                status = conn.status
                
                # Check for connections to suspicious IPs
                if remote_ip in suspicious_ips:
                    is_suspicious = True
                    reason.append(f"Connection to suspicious IP {remote_ip}")
                
                # Check for suspicious ports
                if remote_port in suspicious_ports:
                    is_suspicious = True
                    reason.append(f"Connection to suspicious port {remote_port}")
                
                # Check port ranges
                for port_range in c2_port_ranges:
                    if port_range[0] <= remote_port <= port_range[1]:
                        is_suspicious = True
                        reason.append(f"Connection to suspicious port range {port_range[0]}-{port_range[1]}")
                
                # Check connection status (waiting connections can be suspicious)
                if status in ['LISTEN', 'NONE']:
                    reason.append(f"Connection in {status} state")
                    
                # Add the connection to results
                connection_info = {
                    'pid': pid,
                    'local_addr': f"{conn.laddr.ip}:{conn.laddr.port}" if hasattr(conn, 'laddr') else "Unknown",
                    'remote_addr': remote_ip,
                    'remote_port': remote_port,
                    'status': status,
                    'suspicious': is_suspicious,
                    'reason': ", ".join(reason) if reason else ""
                }
                
                suspicious_connections.append(connection_info)
                
        except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess) as e:
            logging.debug(f"Error accessing process connections: {str(e)}")
        except Exception as e:
            logging.error(f"Error in check_network_connections: {str(e)}")
        
        return suspicious_connections

    def verify_registry(self, pid):
        """
        Verifies registry for signs of persistence or malicious configuration.
        
        Args:
            pid: Process ID
            
        Returns:
            List of dictionaries containing registry findings
        """
        logging.debug(f"Verifying registry for PID {pid}")
        findings = []
        
        try:
            # Get process details
            proc = psutil.Process(pid)
            process_name = proc.name().lower()
            process_path = proc.exe()
            
            # Key registry locations to check
            registry_keys = [
                r"SOFTWARE\Microsoft\Windows\CurrentVersion\Run",
                r"SOFTWARE\Microsoft\Windows\CurrentVersion\RunOnce",
                r"SOFTWARE\Wow6432Node\Microsoft\Windows\CurrentVersion\Run",
                r"SOFTWARE\Microsoft\Windows\CurrentVersion\Explorer\StartupApproved\Run",
                r"SOFTWARE\Microsoft\Windows\CurrentVersion\Explorer\StartupApproved\RunOnce",
                r"SOFTWARE\Microsoft\Windows NT\CurrentVersion\Winlogon\Userinit",
                r"SOFTWARE\Microsoft\Windows NT\CurrentVersion\Winlogon\Shell",
                r"SOFTWARE\Microsoft\Windows NT\CurrentVersion\Image File Execution Options"
            ]
            
            # Check if this process is registered in autorun locations
            for key_path in registry_keys:
                try:
                    # Check in HKLM
                    key = winreg.OpenKey(winreg.HKEY_LOCAL_MACHINE, key_path, 0, winreg.KEY_READ)
                    i = 0
                    
                    while True:
                        try:
                            name, value, _ = winreg.EnumValue(key, i)
                            
                            # Check if this process is mentioned in registry
                            if process_name in value.lower() or (process_path and process_path.lower() in value.lower()):
                                findings.append({
                                    "type": "Persistence Registry Entry",
                                    "details": f"Found in HKLM\\{key_path}\\{name} = {value}"
                                })
                                
                            # Check for suspicious command-line parameters
                            suspicious_params = ["-e ", "/c ", "powershell", "cmd.exe", "rundll32", "regsvr32", 
                                                "javascript:", "vbscript:", "-encodedcommand", "-enc", 
                                                "-decode", "base64"]
                                                
                            for param in suspicious_params:
                                if param in value.lower():
                                    findings.append({
                                        "type": "Suspicious Registry Command",
                                        "details": f"Found in HKLM\\{key_path}\\{name} = {value}"
                                    })
                                    break
                                    
                            i += 1
                        except WindowsError:
                            break
                        
                    winreg.CloseKey(key)
                    
                    # Also check HKCU
                    key = winreg.OpenKey(winreg.HKEY_CURRENT_USER, key_path, 0, winreg.KEY_READ)
                    i = 0
                    
                    while True:
                        try:
                            name, value, _ = winreg.EnumValue(key, i)
                            
                            # Check if this process is mentioned in registry
                            if process_name in value.lower() or (process_path and process_path.lower() in value.lower()):
                                findings.append({
                                    "type": "Persistence Registry Entry",
                                    "details": f"Found in HKCU\\{key_path}\\{name} = {value}"
                                })
                                
                            # Check for suspicious command-line parameters
                            suspicious_params = ["-e ", "/c ", "powershell", "cmd.exe", "rundll32", "regsvr32", 
                                                "javascript:", "vbscript:", "-encodedcommand", "-enc", 
                                                "-decode", "base64"]
                                                
                            for param in suspicious_params:
                                if param in value.lower():
                                    findings.append({
                                        "type": "Suspicious Registry Command",
                                        "details": f"Found in HKCU\\{key_path}\\{name} = {value}"
                                    })
                                    break
                                    
                            i += 1
                        except WindowsError:
                            break
                        
                    winreg.CloseKey(key)
                    
                except WindowsError:
                    # Key doesn't exist or access denied
                    pass
                    
            # Check for debugger hijacking in Image File Execution Options
            if process_name.endswith('.exe'):
                try:
                    key_path = f"SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Image File Execution Options\\{process_name}"
                    key = winreg.OpenKey(winreg.HKEY_LOCAL_MACHINE, key_path, 0, winreg.KEY_READ)
                    
                    try:
                        debugger, _ = winreg.QueryValueEx(key, "Debugger")
                        findings.append({
                            "type": "Debugger Hijacking",
                            "details": f"Process has debugger set in IFEO: {debugger}"
                        })
                    except WindowsError:
                        pass
                        
                    winreg.CloseKey(key)
                except WindowsError:
                    pass
                    
        except Exception as e:
            logging.error(f"Error in verify_registry: {str(e)}")
        
        return findings
    def verify_modules(self, process_handle, pid):
        """
        Verifies loaded modules for suspicious characteristics.
        
        Args:
            process_handle: Windows handle to the process
            pid: Process ID
            
        Returns:
            List of dictionaries containing module findings
        """
        logging.debug(f"Verifying modules for PID {pid}")
        findings = []
        
        try:
            # List all modules loaded in the process
            modules = self.list_process_modules(process_handle)
            
            for module in modules:
                module_name = module.get('name', '').lower()
                module_path = module.get('path', '')
                
                if not module_name or not module_path:
                    continue
                    
                # 1. Check for unsigned modules
                if not self.is_file_signed(module_path):
                    findings.append({
                        "type": "Unsigned Module",
                        "path": module_path,
                        "address": hex(module.get('base', 0)),
                        "details": f"Module is not digitally signed"
                    })
                
                # 2. Check for modules in suspicious locations
                suspicious_locations = [
                    os.path.join(os.environ.get('TEMP', ''), ''),
                    os.path.join(os.environ.get('TMP', ''), ''),
                    os.path.expandvars('%APPDATA%\\Local\\Temp'),
                    os.path.expandvars('%USERPROFILE%\\Downloads'),
                    os.path.expandvars('%PUBLIC%')
                ]
                
                for location in suspicious_locations:
                    if location and module_path.lower().startswith(location.lower()):
                        findings.append({
                            "type": "Suspicious Module Location",
                            "path": module_path,
                            "address": hex(module.get('base', 0)),
                            "details": f"Module loaded from temporary or download directory"
                        })
                
                # 3. Check for DLL hijacking - unexpected DLL locations
                system_dlls = ['kernel32.dll', 'user32.dll', 'gdi32.dll', 'advapi32.dll', 
                            'shell32.dll', 'ole32.dll', 'oleaut32.dll', 'ntdll.dll']
                
                if module_name in system_dlls:
                    expected_path = os.path.join(os.environ.get('SystemRoot', 'C:\\Windows'), 'System32')
                    if not module_path.lower().startswith(expected_path.lower()):
                        findings.append({
                            "type": "Potential DLL Hijacking",
                            "path": module_path,
                            "address": hex(module.get('base', 0)),
                            "details": f"System DLL loaded from unexpected location (not System32)"
                        })
                
                # 4. Check for known malicious module names (you can expand this list)
                malicious_names = ['nethelper.dll', 'wshelper.dll', 'cryptbase32.dll', 'secur32x.dll']
                
                for mal_name in malicious_names:
                    if module_name == mal_name:
                        findings.append({
                            "type": "Known Malicious Module",
                            "path": module_path,
                            "address": hex(module.get('base', 0)),
                            "details": f"Known malicious module name detected"
                        })
                
                # 5. Check file attributes and timestamps
                try:
                    if os.path.exists(module_path):
                        # Check for unusual file timestamps
                        file_stats = os.stat(module_path)
                        
                        # Convert timestamps to datetime objects
                        create_time = datetime.datetime.fromtimestamp(file_stats.st_ctime)
                        modify_time = datetime.datetime.fromtimestamp(file_stats.st_mtime)
                        
                        # Check for very recent creation (could be suspicious)
                        now = datetime.datetime.now()
                        if (now - create_time).days < 1:
                            findings.append({
                                "type": "Recently Created Module",
                                "path": module_path,
                                "address": hex(module.get('base', 0)),
                                "details": f"Module created within the last 24 hours"
                            })
                        
                        # Check for time stomping (modification time before creation time)
                        if modify_time < create_time:
                            findings.append({
                                "type": "Timestomp Detected",
                                "path": module_path,
                                "address": hex(module.get('base', 0)),
                                "details": f"Module has modification time before creation time"
                            })
                        
                        # Check for hidden file attribute
                        if file_stats.st_file_attributes & 0x2:  # Hidden attribute
                            findings.append({
                                "type": "Hidden Module",
                                "path": module_path,
                                "address": hex(module.get('base', 0)),
                                "details": f"Module has hidden file attribute"
                            })
                except Exception as attr_err:
                    logging.debug(f"Error checking file attributes for {module_path}: {str(attr_err)}")
                
                # 6. Check for module hash against known bad
                try:
                    if os.path.exists(module_path) and hasattr(self, 'hash_database'):
                        file_hash = self.calculate_file_hash(module_path)
                        self.hash_database = {
                            'malicious': [],
                            'clean': [],
                            'suspicious': []
                        }
                        if file_hash in self.hash_database.get('malicious', []):
                            findings.append({
                                "type": "Known Bad Hash",
                                "path": module_path,
                                "address": hex(module.get('base', 0)),
                                "details": f"Module hash matches known malicious file: {file_hash}"
                            })
                except Exception as hash_err:
                    logging.debug(f"Error checking file hash for {module_path}: {str(hash_err)}")
                
                # 7. Check for memory vs disk differences (if PE header was modified in memory)
                try:
                    if os.path.exists(module_path):
                        # Compare file on disk with memory version (first 1024 bytes should be enough for PE header)
                        with open(module_path, 'rb') as f:
                            disk_data = f.read(1024)
                        
                        base_addr = module.get('base', 0)
                        if base_addr:
                            memory_data = win32process.ReadProcessMemory(process_handle, base_addr, 1024)
                            
                            # Compare the headers
                            if disk_data and memory_data and disk_data != memory_data:
                                findings.append({
                                    "type": "Memory Modification",
                                    "path": module_path,
                                    "address": hex(base_addr),
                                    "details": f"Module PE header modified in memory (different from disk)"
                                })
                except Exception as comp_err:
                    logging.debug(f"Error comparing module versions for {module_path}: {str(comp_err)}")
                
        except Exception as e:
            logging.error(f"Error in verify_modules: {str(e)}")
        
        return findings

    def is_file_signed(self, file_path):
        """
        Checks if a file is digitally signed with a valid signature.
        
        Args:
            file_path: Path to the file to check
            
        Returns:
            Boolean indicating if file has valid signature
        """
        try:
            if not os.path.exists(file_path):
                return False
                
            # Use PowerShell to check the signature
            command = f'powershell -command "Get-AuthenticodeSignature \'{file_path}\' | Select-Object -ExpandProperty Status"'
            process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)
            stdout, stderr = process.communicate()
            
            if stderr:
                logging.debug(f"Signature check produced error: {stderr.decode()}")
                
            # Valid status will be "Valid" if properly signed
            return b"Valid" in stdout
            
        except Exception as e:
            logging.debug(f"Error checking file signature for {file_path}: {str(e)}")
            return False

    def list_process_modules(self, process_handle):
        """
        Lists all modules loaded in a process.
        
        Args:
            process_handle: Handle to the process
            
        Returns:
            List of dictionaries containing module information
        """
        modules = []
        
        try:
            # Use EnumProcessModulesEx to get all modules
            module_handles = (ctypes.c_void_p * 1024)()
            
            # Try using psapi.dll for module enumeration
            hProcess = ctypes.c_void_p(int(process_handle))
            cbNeeded = ctypes.c_ulong()
            
            # Load psapi and enum modules
            psapi = ctypes.WinDLL('psapi.dll')
            if psapi.EnumProcessModulesEx(hProcess, ctypes.byref(module_handles),
                                        ctypes.sizeof(module_handles), ctypes.byref(cbNeeded),
                                        0x03):  # LIST_MODULES_ALL
                
                count = cbNeeded.value // ctypes.sizeof(ctypes.c_void_p)
                for i in range(count):
                    module_info = {
                        'base': ctypes.addressof(module_handles[i].contents),
                        'name': '',
                        'path': ''
                    }
                    
                    # Get module name
                    name_buffer = (ctypes.c_char * 256)()
                    if psapi.GetModuleBaseNameA(hProcess, module_handles[i], name_buffer, ctypes.sizeof(name_buffer)):
                        module_info['name'] = name_buffer.value.decode('utf-8', errors='ignore')
                    
                    # Get module path
                    path_buffer = (ctypes.c_char * 1024)()
                    if psapi.GetModuleFileNameExA(hProcess, module_handles[i], path_buffer, ctypes.sizeof(path_buffer)):
                        module_info['path'] = path_buffer.value.decode('utf-8', errors='ignore')
                    
                    modules.append(module_info)
        except Exception as e:
            logging.error(f"Error listing modules: {str(e)}")
        
        return modules

    def calculate_file_hash(self, file_path, algorithm='sha256'):
        """
        Calculates the hash of a file.
        
        Args:
            file_path: Path to the file
            algorithm: Hash algorithm to use (md5, sha1, sha256)
            
        Returns:
            Hexadecimal hash string
        """
        try:
            hash_obj = None
            if algorithm == 'md5':
                hash_obj = hashlib.md5()
            elif algorithm == 'sha1':
                hash_obj = hashlib.sha1()
            else:
                hash_obj = hashlib.sha256()
                
            with open(file_path, 'rb') as f:
                for chunk in iter(lambda: f.read(4096), b''):
                    hash_obj.update(chunk)
            
            return hash_obj.hexdigest()
        except Exception as e:
            logging.debug(f"Error calculating file hash: {str(e)}")
            return None

    def get_process_base_address(self, process_handle):
        """
        Gets the base address of a process.
        
        Args:
            process_handle: Handle to the process
            
        Returns:
            Base address as an integer
        """
        try:
            # Get the first module which is typically the main executable
            modules = self.list_process_modules(process_handle)
            if modules:
                return modules[0].get('base', 0)
        except Exception as e:
            logging.debug(f"Error getting process base address: {str(e)}")
        
        return 0

    def check_ntdll_hooks(self, process_handle, ntdll_base):
        """
        Checks for hooks in critical NTDLL functions.
        
        Args:
            process_handle: Handle to the process
            ntdll_base: Base address of ntdll.dll
            
        Returns:
            List of hooked function names
        """
        hooked_functions = []
        
        try:
            # Critical functions to check
            functions_to_check = [
                "NtCreateProcess", "NtCreateThread", "NtAllocateVirtualMemory",
                "NtWriteVirtualMemory", "NtProtectVirtualMemory", "NtQueueApcThread",
                "NtCreateSection", "NtMapViewOfSection"
            ]
            
            # Read the first bytes of each function to detect hooks
            for func_name in functions_to_check:
                try:
                    # Get function address using our new parser
                    func_offset = self.get_function_offset(process_handle, ntdll_base, func_name)
                    if func_offset is None:
                        logging.debug(f"Could not find offset for {func_name}")
                        continue
                    
                    func_addr = ntdll_base + func_offset
                    
                    # Read the first bytes of the function
                    bytes_data = win32process.ReadProcessMemory(process_handle, func_addr, 10)
                    
                    # Check for common hook patterns (JMP, CALL, etc.)
                    if bytes_data:
                        # JMP instruction (E9)
                        if bytes_data[0] == 0xE9:
                            hooked_functions.append(func_name)
                            
                        # CALL instruction (E8)
                        elif bytes_data[0] == 0xE8:
                            hooked_functions.append(func_name)
                            
                        # JMP/CALL indirect (FF 15, FF 25)
                        elif bytes_data[0] == 0xFF and len(bytes_data) > 1 and bytes_data[1] in (0x15, 0x25):
                            hooked_functions.append(func_name)
                            
                        # MOV EAX, imm32 followed by JMP EAX (common in hooks)
                        elif bytes_data[0] == 0xB8 and len(bytes_data) > 5 and bytes_data[5] == 0xFF and bytes_data[6] == 0xE0:
                            hooked_functions.append(func_name)
                        
                        # Check for other suspicious patterns
                        # Many hooks start with PUSH instruction followed by MOV
                        elif bytes_data[0] == 0x68 and len(bytes_data) > 5 and bytes_data[5] in (0x89, 0x8B):
                            hooked_functions.append(func_name)
                            
                except Exception as func_err:
                    logging.debug(f"Error checking {func_name}: {str(func_err)}")
        except Exception as e:
            logging.debug(f"Error checking NTDLL hooks: {str(e)}")
        return hooked_functions
    def get_function_offset(self, process_handle, module_base, function_name):
        """
        Gets the offset of a function within a module by parsing its export table.
        
        Args:
            process_handle: Handle to the process
            module_base: Base address of the module
            function_name: Name of the function to locate
            
        Returns:
            Offset from module base or None if not found
        """
        try:
            # Read PE headers
            dos_header = self.read_structure(process_handle, module_base, IMAGE_DOS_HEADER)
            if not dos_header or dos_header.e_magic != 0x5A4D:  # "MZ" signature
                logging.debug(f"Invalid DOS header for module at {hex(module_base)}")
                return None
                
            # Get PE header
            pe_header_offset = module_base + dos_header.e_lfanew
            pe_header = self.read_structure(process_handle, pe_header_offset, IMAGE_NT_HEADERS)
            if not pe_header or pe_header.Signature != 0x4550:  # "PE" signature
                logging.debug(f"Invalid PE header for module at {hex(module_base)}")
                return None
                
            # Get export directory
            export_dir_rva = pe_header.OptionalHeader.DataDirectory[0].VirtualAddress
            if not export_dir_rva:
                logging.debug(f"No export directory found for module at {hex(module_base)}")
                return None
                
            export_dir = self.read_structure(process_handle, module_base + export_dir_rva, IMAGE_EXPORT_DIRECTORY)
            if not export_dir:
                logging.debug(f"Failed to read export directory at {hex(module_base + export_dir_rva)}")
                return None
                
            # Read export names, functions, and ordinals
            name_rvas = self.read_array(process_handle, module_base + export_dir.AddressOfNames, 
                                        export_dir.NumberOfNames, ctypes.c_uint32)
            ordinals = self.read_array(process_handle, module_base + export_dir.AddressOfNameOrdinals, 
                                    export_dir.NumberOfNames, ctypes.c_uint16)
            function_rvas = self.read_array(process_handle, module_base + export_dir.AddressOfFunctions, 
                                            export_dir.NumberOfFunctions, ctypes.c_uint32)
            
            if not name_rvas or not ordinals or not function_rvas:
                logging.debug("Failed to read export tables")
                return None
                
            # Find function by name
            function_name_bytes = function_name.encode('ascii')
            for i in range(export_dir.NumberOfNames):
                name_addr = module_base + name_rvas[i]
                name = self.read_string(process_handle, name_addr)
                
                if name == function_name_bytes:
                    ordinal = ordinals[i]
                    if ordinal < export_dir.NumberOfFunctions:
                        return function_rvas[ordinal]  # Return the RVA (Relative Virtual Address)
                        
            logging.debug(f"Function {function_name} not found in export table")
            return None
            
        except Exception as e:
            logging.error(f"Error parsing export table: {str(e)}")
            return None

    def read_structure(self, process_handle, address, struct_type):
        """
        Reads a C structure from process memory.
        
        Args:
            process_handle: Handle to the process
            address: Memory address to read from
            struct_type: ctypes Structure class
            
        Returns:
            Instance of the structure or None on failure
        """
        try:
            buffer_size = ctypes.sizeof(struct_type)
            buffer = win32process.ReadProcessMemory(process_handle, address, buffer_size)
            
            if not buffer or len(buffer) != buffer_size:
                return None
                
            result = struct_type()
            ctypes.memmove(ctypes.byref(result), buffer, buffer_size)
            return result
        except Exception as e:
            logging.debug(f"Error reading structure at {hex(address)}: {str(e)}")
            return None

    def read_array(self, process_handle, address, count, item_type):
        """
        Reads an array of items from process memory.
        
        Args:
            process_handle: Handle to the process
            address: Memory address to read from
            count: Number of items to read
            item_type: ctypes type of each item
            
        Returns:
            List of items or None on failure
        """
        try:
            item_size = ctypes.sizeof(item_type)
            buffer_size = item_size * count
            buffer = win32process.ReadProcessMemory(process_handle, address, buffer_size)
            
            if not buffer or len(buffer) != buffer_size:
                return None
                
            result = []
            for i in range(count):
                item = item_type()
                offset = i * item_size
                ctypes.memmove(ctypes.byref(item), buffer[offset:offset+item_size], item_size)
                result.append(item.value)
                
            return result
        except Exception as e:
            logging.debug(f"Error reading array at {hex(address)}: {str(e)}")
            return None

    def read_string(self, process_handle, address, max_length=256):
        """
        Reads a null-terminated string from process memory.
        
        Args:
            process_handle: Handle to the process
            address: Memory address to read from
            max_length: Maximum string length to read
            
        Returns:
            String as bytes or None on failure
        """
        try:
            result = bytearray()
            for i in range(max_length):
                char = win32process.ReadProcessMemory(process_handle, address + i, 1)
                if not char or char[0] == 0:
                    break
                result.append(char[0])
            return bytes(result)
        except Exception as e:
            logging.debug(f"Error reading string at {hex(address)}: {str(e)}")
            return None
    def should_scan_region(self, region):
        """Determine if a memory region should be scanned based on its properties. Args:region: Memory region dictionary with State, Protect, RegionSize, etc.Returns:bool: True if region should be scanned, False otherwise"""
        # Skip non-committed memory
        PAGE_EXECUTE = 0x10
        PAGE_EXECUTE_READ = 0x20
        PAGE_EXECUTE_READWRITE = 0x40
        PAGE_NOACCESS = 0x01
        PAGE_READWRITE = 0x04
        PAGE_TARGETS_INVALID = 0x40000000
        PAGE_EXECUTE_WRITECOPY = 0x80
        PAGE_WRITECOPY = 0x08
        if not (region['State'] & self.MEM_COMMIT):
            return False
            
        # Skip small regions (less than 4KB)
        if region['RegionSize'] < 4096:
            return False
            
        # Always scan executable regions
        if (region['Protect'] & (PAGE_EXECUTE | PAGE_EXECUTE_READ |
                                PAGE_EXECUTE_READWRITE | PAGE_EXECUTE_WRITECOPY)):
            return True
            
        # Scan writable regions that are an unusual size (potentially shellcode)
        if (region['Protect'] & (PAGE_READWRITE | PAGE_WRITECOPY)) and \
            (region['RegionSize'] % 4096 != 0 or region['RegionSize'] < 8192):
            return True
            
        # Scan regions with suspicious protection
        if region['Protect'] & PAGE_TARGETS_INVALID:
            return True
            
        # Scan regions with NOACCESS if they're in a suspicious part of memory
        if (region['Protect'] & PAGE_NOACCESS) and \
        (region['Type'] == 0x1000000):  # MEM_IMAGE type
            return True
            
        # Skip most non-executable, standard memory regions for performance
        return False
    def get_system_info(self):
        kernel32 = ctypes.windll.kernel32
        _fields_ = [
                ("wProcessorArchitecture", ctypes.c_ushort),
                ("wReserved", ctypes.c_ushort),
                ("dwPageSize", ctypes.c_ulong),
                ("lpMinimumApplicationAddress", ctypes.c_void_p),
                ("lpMaximumApplicationAddress", ctypes.c_void_p),
                ("dwActiveProcessorMask", ctypes.c_ulong),
                ("dwNumberOfProcessors", ctypes.c_ulong),
                ("dwProcessorType", ctypes.c_ulong),
                ("dwAllocationGranularity", ctypes.c_ulong),
                ("wProcessorLevel", ctypes.c_ushort),
                ("wProcessorRevision", ctypes.c_ushort)
            ]
        
        system_info = self._get_default_system_info()
        kernel32.GetSystemInfo(ctypes.byref(system_info))
        return system_info
    def set_alert_callback(self, callback):
        self.alert_callback = callback    
    def process_executable(self, process_name):
        try:
            # Initialize process_handle with a default value
            process_handle = None
            
            # Get the process ID from the process name (OpenProcess requires a PID, not a name)
            pid = self._get_parent_process_info_winapi(process_name)  # You need to implement this function
            
            if not pid:
                logging.debug(f"Could not find PID for {process_name}")
                return
            
            # Attempt to open the process using the PID
            process_handle = win32api.OpenProcess(
                win32con.PROCESS_QUERY_INFORMATION | win32con.PROCESS_VM_READ, 
                False, 
                pid
            )
            
            # Only proceed if we successfully got a handle
            if process_handle:
                try:
                    if self.detect_process_hollowing(process_name, process_handle):
                        self.executable_found.append(process_name)
                except Exception as e:
                    logging.debug(f"Error processing {process_name}: {str(e)}")
            else:
                logging.debug(f"Could not obtain handle for {process_name}")
                
        except Exception as e:
            logging.debug(f"Error processing {process_name}: {str(e)}")
        finally:
            # Make sure to close the handle if it exists and is valid
            if process_handle:
                try:
                    win32api.CloseHandle(process_handle)
                except Exception as e:
                    logging.debug(f"Error closing handle for {process_name}: {str(e)}")
    def get_process_name_with_fallbacks(self, pid):
        """Get process name using multiple methods to handle access denied"""
        # Try multiple methods to get the process name
        try:
            # Method 1: Using WMI (works even with some access restrictions)
            import wmi
            c = wmi.WMI()
            for process in c.win32_process(ProcessId=pid):
                return process.Name
        except:
            pass
            
        try:
            # Method 2: Using psutil (different access method)
            
            process = psutil.Process(pid)
            return process.name()
        except:
            pass
            
        try:
            # Method 3: Using Windows API via toolhelp32 snapshot
            hProcessSnap = win32process.CreateToolhelp32Snapshot(win32con.TH32CS_SNAPPROCESS, 0)
            pe32 = PROCESSENTRY32()
            pe32.dwSize = win32process.sizeof(pe32)
            
            if win32process.Process32First(hProcessSnap, pe32):
                while True:
                    if pe32.th32ProcessID == pid:
                        win32api.CloseHandle(hProcessSnap)
                        return pe32.szExeFile
                    if not win32process.Process32Next(hProcessSnap, pe32):
                        break
            win32api.CloseHandle(hProcessSnap)
        except:
            pass
            
        return "Unknown"
    def detect_suspicious_access_denial(self, pid):
        """Flag processes that deny access but aren't Windows system processes"""
        try:
            # Get process name
            process_name = self.get_process_name_with_fallbacks(pid)
            
            # List of common system processes that might legitimately deny access
            system_processes = {
                "system", "smss.exe", "csrss.exe", "wininit.exe", "services.exe",
                "lsass.exe", "winlogon.exe", "svchost.exe", "audiodg.exe"
            }
            
            # If it's not a known system process but denies access, that's suspicious
            if process_name.lower() not in system_processes:
                # Get additional context about the process
                creation_time = self._get_process_info_winapi(pid).get('creation_time')
                command_line = self._get_process_cmdline_winapi(pid)
                modules = self.get_module_info(pid)
                
                logging.warning(f"Suspicious: Non-system process {process_name} (PID {pid}) is denying access")
                
                return {
                    'suspicious': True,
                    'reason': 'non_system_process_denying_access',
                    'process_name': process_name,
                    'pid': pid,
                    'creation_time': creation_time,
                    'command_line': command_line,
                    'modules': modules
                }
                
            return {'suspicious': False}
        except Exception as e:
            logging.debug(f"Error in suspicious access detection: {str(e)}")
            return {'suspicious': False}
    def get_process_handle(self, pid):
        # Ensure pid is an integer
        try:
            pid = int(pid) if not isinstance(pid, int) else pid
        except (ValueError, TypeError):
            raise TypeError(f"Invalid process ID type: {type(pid)}")
        
        try:
            # Open process with appropriate permissions
            handle = win32api.OpenProcess(
                win32con.PROCESS_QUERY_INFORMATION | 
                win32con.PROCESS_VM_READ | 
                win32con.PROCESS_VM_OPERATION,
                False,  # Don't inherit handle
                pid
            )
            return handle
            
        except pywintypes.error as e:
            # Handle Windows-specific errors appropriately
            if e.winerror == 5:  # ERROR_ACCESS_DENIED
                raise PermissionError(f"Access denied to process {pid}")
            elif e.winerror == 87:  # ERROR_INVALID_PARAMETER
                raise ValueError(f"Invalid parameter when accessing process {pid}")
            else:
                raise RuntimeError(f"Windows error when accessing process {pid}: {str(e)}")
                
        except Exception as e:
            # Preserve the original error type
            raise
       
    def scan_process(self, process, pid=None):
        """
        Scan a process for malicious activity with improved error handling
        and protected process awareness
        """
        process_handle = None
        self.executable_found = []
        process_name = "Unknown"
        hollowing_results = None
        
        try:
            # Validate the PID first
            validated_pid = self.safe_process_validation(pid)
            
            # Extract process info based on what we received
            if isinstance(process, dict):
                pid = process.get('pid', validated_pid)
                process_name = process.get('name', 'Unknown')
            elif hasattr(process, 'pid'):
                # This is likely a psutil.Process object
                pid = process.pid
                try:
                    process_name = process.name()
                except:
                    process_name = f"PID-{pid}"
            else:
                # Assume it's a PID
                pid = validated_pid if validated_pid else process
                process_name = f"Process_{pid}" if pid else "Unknown"
            
            # Final PID validation before operations
            if not self.validate_pid(pid):
                logging.debug(f"Invalid PID {pid}, skipping scan")
                return False
            
            # Check if this is a protected system process
            if self._is_protected_process(pid):
                logging.debug(f"Skipping scan of protected process {process_name} (PID: {pid})")
                return None
                
            # Get process name for better logging
            try:
                process_name = self.get_process_name(pid) or f"PID-{pid}"
            except Exception:
                process_name = f"PID-{pid}"
            
            # Try Yara scanning first - it's more likely to succeed
            try:
                self.compiled_rules = self.yara_manager.compile_combined_rules()
                matches = self.compiled_rules.match(pid=pid, timeout=60)
                if matches:
                    logging.info(f"Yara matches found in process {process_name} (PID: {pid})")
                    return matches
            except Exception as e:
                # Don't exit on Yara failure, continue with other scanning methods
                logging.error(f"Error in Yara scan for process {process_name}: {str(e)}")
            
            # Ensure we have a process object
            process_obj = None
            try:
                if not isinstance(process, psutil.Process):
                    process_obj = psutil.Process(pid)
                else:
                    process_obj = process
            except psutil.NoSuchProcess:
                logging.warning(f"Process {pid} no longer exists")
                return None
            except psutil.AccessDenied:
                # Check if this is a protected process
                if self._is_protected_process(pid):
                    logging.debug(f"Access denied to protected process {process_name} (PID: {pid}), skipping")
                    return None
                else:
                    logging.warning(f"Access denied to process {process_name} (PID: {pid})")
                    return None
            
            # Try to get process handle
            try:
                process_handle = win32api.OpenProcess(
                    win32con.PROCESS_QUERY_INFORMATION | win32con.PROCESS_VM_READ,
                    False,
                    pid
                )
                
                # Check if handle is valid before proceeding
                if not process_handle:
                    error_code = ctypes.get_last_error()
                    if error_code == 5:  # ACCESS_DENIED
                        # Check if this is a protected process
                        if self._is_protected_process(pid):
                            logging.debug(f"Access denied to protected process {process_name} (PID: {pid}), skipping")
                        else:
                            logging.debug(f"Access denied to process {process_name} (PID: {pid}), skipping")
                        return None
                    else:
                        logging.debug(f"Could not obtain handle for process {process_name} (PID: {pid}), error: {error_code}")
                        return None
                        
            except Exception as e:
                logging.debug(f"Error opening process {process_name}: {str(e)}")
                return None
            
            # Track if any malicious activity is found
            malicious_activity_found = False
            detection_info = {
                'pid': pid,
                'process': process_name,
                'detections': []
            }
            
            # Check for process hollowing - use the pid directly
            hollowing_results = self.detect_process_hollowing(pid)
            
            # Check if hollowing results is a list with items or a dictionary with indicators
            if hollowing_results:
                if isinstance(hollowing_results, list) and len(hollowing_results) > 0:
                    malicious_activity_found = True
                    detection_info['detections'].append({
                        'type': 'process_hollowing',
                        'details': hollowing_results
                    })
                elif isinstance(hollowing_results, dict) and any(hollowing_results.values()):
                    malicious_activity_found = True
                    detection_info['detections'].append({
                        'type': 'process_hollowing',
                        'details': hollowing_results
                    })
            
            # Continue with memory scanning
            try:
                memory_regions = process_obj.memory_maps()
                for region in memory_regions:
                    # Read memory INSIDE the loop
                    try:
                        mem = self.memory_region_raw(region)
                        
                        # Scan with YARA rules
                        matches = self.yara_manager.combined_rules.match(data=mem)
                        
                        if matches:
                            malicious_activity_found = True
                            detection_info['detections'].append({
                                'type': 'yara_match',
                                'region': region.addr,
                                'matches': [match.rule for match in matches]
                            })
                    except Exception as e:
                        logging.debug(f"Error reading memory region {getattr(region, 'addr', 'unknown')}: {str(e)}")
            except Exception as e:
                logging.debug(f"Error accessing memory maps for {process_name}: {str(e)}")
            
            # If we found any malicious activity, collect extended information
            if malicious_activity_found:
                # Collect extended information for comprehensive analysis
                extended_info = self.get_extended_process_info(process_handle)
                detection_info['extended_info'] = extended_info
                
                # Add timestamp
                detection_info['timestamp'] = datetime.datetime.now().isoformat()
                
                # Log the detection
                logging.warning(f"Detected malicious activity in process {process_name} (PID {pid}): {detection_info}")
                
                # Trigger alert callback with the comprehensive information
                if self.alert_callback:
                    self.alert_callback(detection_info)
            
            # Update class properties based on hollowing results
            if isinstance(hollowing_results, dict):
                if 'executable_found' in hollowing_results:
                    self.executable_found = hollowing_results['executable_found']
                    
                # Log hollowing indicators
                for indicator, details in hollowing_results.items():
                    if indicator != 'executable_found':  # Skip the flag itself
                        # Properly handle different detail types
                        if isinstance(details, dict):
                            logging.warning(f"Process hollowing indicator found: {indicator} - {details}")
                        elif isinstance(details, list):
                            logging.warning(f"Process hollowing indicator found: {indicator} - {', '.join(map(str, details))}")
                        else:
                            logging.warning(f"Process hollowing indicator found: {indicator} - {details}")
                        
                        # Add these details to hollowing_detections
                        if not hasattr(self, 'hollowing_detections'):
                            self.hollowing_detections = {}
                        
                        if pid not in self.hollowing_detections:
                            self.hollowing_detections[pid] = {}
                        
                        self.hollowing_detections[pid][indicator] = details
            
            return detection_info if malicious_activity_found else None
            
        except Exception as e:
            logging.debug(f"Error scanning process {process_name}: {str(e)}")
            return None
        finally:
            # Always close the handle if it was opened - only once
            if process_handle is not None:
                try:
                    win32api.CloseHandle(process_handle)
                except Exception as e:
                    logging.debug(f"Error closing handle for {process_name}: {str(e)}")
    def scan_all_processes(self):
        """Scan all running processes with proper error handling"""
        processes = self.get_process_list()
        scanned_count = 0
        skipped_count = 0
        detected_count = 0
        
         # Log the actual processes for debugging
        logging.debug(f"Found {len(processes)} processes to scan")
        
        for i, process in enumerate(processes):
            if process is None:
                logging.debug(f"Skipping None process at index {i}")
                continue
                
            # Get PID from process object
            if isinstance(process, dict):
                pid = process.get('pid')
            else:
                pid = process
                
            # Only call scan_process if PID is valid
            if self.validate_pid(pid):
                self.scan_process(process)
        
        logging.info(f"Process scan complete: {scanned_count} processes scanned, {skipped_count} processes skipped, {detected_count} threats detected")
        return {
            'scanned': scanned_count,
            'skipped': skipped_count,
            'detected': detected_count
        }
    def scan_system_for_threats(self):
        """Comprehensive system threat detection with proper GUI integration and detection logging"""
        
        findings = {}
        detections = []  # List to store formatted detections for GUI
        process_count = 0
        threat_count = 0
        start_time = time.time()
        
        logging.info("Beginning comprehensive system security scan")
        
        # 1. Process scanning with detection formatting
        try:
            processes = self.enumerate_processes()
            process_count = len(processes)
            logging.info(f"Scanning {process_count} active processes")
            
            for pid in processes:
                try:
                    # Skip protected processes with expected access denial
                    process_info = self._get_process_info_winapi(pid)
                    if not hasattr(self._get_process_info_winapi, '_get_process_info_winapi'):
                        logging.error(f"self._get_process_info_winapi is not a scanner object! Type: {type(self._get_process_info_winapi)}, Value: {self._get_process_info_winapi}")
                        continue
                    if process_info and process_info.get('access_denied_expected', False):
                        logging.debug(f"Skipping protected process {pid} ({process_info.get('name', 'Unknown')})")
                        continue
                    
                    # Memory scanning with detection formatting
                    memory_scan_results = self.scan_process_memory(pid)
                    if memory_scan_results:
                        findings[f"process_{pid}_memory"] = memory_scan_results
                        
                        # Format for GUI and detection logging
                        for key, result in memory_scan_results.items():
                            detection = {
                                'id': f"MEM-{uuid.uuid4().hex[:8]}",
                                'type': 'MEMORY_PATTERN',
                                'severity': 'HIGH' if result.get('type') == 'yara_match' else 'MEDIUM',
                                'process_id': pid,
                                'process_name': process_info.get('name', 'Unknown'),
                                'details': result,
                                'timestamp': time.time(),
                                'description': f"Suspicious memory pattern in process {process_info.get('name', 'Unknown')} (PID: {pid})"
                            }
                            detections.append(detection)
                            
                            # Log individual detection
                            self.log_detection(detection)
                        
                        threat_count += len(memory_scan_results)
                    
                    # Process hollowing detection
                    hollowing_results = self.detect_process_hollowing(pid)
                    if hollowing_results:
                        findings[f"process_{pid}_hollowing"] = hollowing_results
                        
                        # Format hollowing detection for GUI
                        detection = {
                            'id': f"HOLLOW-{uuid.uuid4().hex[:8]}",
                            'type': 'PROCESS_HOLLOWING',
                            'severity': 'CRITICAL',
                            'process_id': pid,
                            'process_name': process_info.get('name', 'Unknown'),
                            'details': hollowing_results,
                            'timestamp': time.time(),
                            'description': f"Process hollowing detected in {process_info.get('name', 'Unknown')} (PID: {pid})"
                        }
                        detections.append(detection)
                        self.log_detection(detection)
                        threat_count += 1
                    
                    # Other detection types with similar formatting...
                    
                except Exception as e:
                    logging.debug(f"Error scanning process {pid}: {str(e)}")
        except Exception as e:
            logging.error(f"Error during process scanning: {str(e)}")
        
        # 2. Registry scanning with detection formatting
        try:
            logging.info("Checking registry for suspicious modifications")
            
            if hasattr(self, 'scan_registry_keys'):
                registry_findings = self.scan_registry_keys()
            else:
                registry_findings = self.check_registry_integrity()
                
            if registry_findings:
                findings["registry_modifications"] = registry_findings
                
                # Format registry detections for GUI
                for key, result in registry_findings.items():
                    detection = {
                        'id': f"REG-{uuid.uuid4().hex[:8]}",
                        'type': 'REGISTRY_MODIFICATION',
                        'severity': 'HIGH',
                        'registry_key': key,
                        'details': result,
                        'timestamp': time.time(),
                        'description': f"Suspicious registry modification in {key}"
                    }
                    detections.append(detection)
                    self.log_detection(detection)
                    
                threat_count += len(registry_findings)
        except Exception as e:
            logging.error(f"Error during registry scanning: {str(e)}")
        
        # Add more scanners with similar detection formatting...
        
        # Add scan summary
        scan_time = time.time() - start_time
        scan_summary = {
            "timestamp": time.time(),
            "processes_scanned": process_count,
            "threats_found": threat_count,
            "scan_duration_seconds": scan_time
        }
        findings["scan_summary"] = scan_summary
        
        # Update GUI with all detections
        if hasattr(self, 'update_gui_detections'):
            self.gui.update_gui_detections(detections)
        
        # Final detection summary logging
        if threat_count > 0:
            logging.warning(f"SECURITY ALERT: Scan completed in {scan_time:.2f} seconds. Found {threat_count} potential threats.")
        else:
            logging.info(f"Scan completed in {scan_time:.2f} seconds. No threats detected.")
        
        return {
            'findings': findings,
            'detections': detections,
            'summary': scan_summary
        }
    def scan_registry_keys(self):
        """Scan registry for suspicious modifications or malware persistence mechanisms"""
        suspicious_findings = {}
        
        # Define suspicious registry locations to check
        suspicious_locations = [
            # Autorun keys (persistence)
            {"hive": winreg.HKEY_LOCAL_MACHINE, "path": r"SOFTWARE\Microsoft\Windows\CurrentVersion\Run"},
            {"hive": winreg.HKEY_LOCAL_MACHINE, "path": r"SOFTWARE\Microsoft\Windows\CurrentVersion\RunOnce"},
            {"hive": winreg.HKEY_CURRENT_USER, "path": r"SOFTWARE\Microsoft\Windows\CurrentVersion\Run"},
            {"hive": winreg.HKEY_CURRENT_USER, "path": r"SOFTWARE\Microsoft\Windows\CurrentVersion\RunOnce"},
            
            # Services
            {"hive": winreg.HKEY_LOCAL_MACHINE, "path": r"SYSTEM\CurrentControlSet\Services"},
            
            # Known malware locations
            {"hive": winreg.HKEY_LOCAL_MACHINE, "path": r"SOFTWARE\Classes\exefile\shell\open\command"},
            {"hive": winreg.HKEY_LOCAL_MACHINE, "path": r"SOFTWARE\Classes\htmlfile\shell\open\command"},
            
            # Boot execute
            {"hive": winreg.HKEY_LOCAL_MACHINE, "path": r"SYSTEM\CurrentControlSet\Control\Session Manager"},
            
            # Browser Helper Objects
            {"hive": winreg.HKEY_LOCAL_MACHINE, "path": r"SOFTWARE\Microsoft\Windows\CurrentVersion\Explorer\Browser Helper Objects"}
        ]
        
        # Patterns that might indicate suspicious values
        suspicious_patterns = [
            r"powershell -e",
            r"cmd \/c",
            r"rundll32.exe.*,",
            r"regsvr32 \/s",
            r"certutil -decode",
            r"AppData\Local\Temp",
            r"mshta.exe"
        ]
        
        # Check each registry location
        for location in suspicious_locations:
            try:
                registry_key = winreg.OpenKey(location["hive"], location["path"], 0, winreg.KEY_READ)
                
                # First enumerate subkeys if needed
                if location["path"].endswith("Services"):
                    # For services, we need to check each service
                    i = 0
                    while True:
                        try:
                            subkey_name = winreg.EnumKey(registry_key, i)
                            subkey_path = f"{location['path']}\\{subkey_name}"
                            
                            # Check each service's ImagePath
                            try:
                                service_key = winreg.OpenKey(location["hive"], subkey_path, 0, winreg.KEY_READ)
                                try:
                                    image_path, _ = winreg.QueryValueEx(service_key, "ImagePath")
                                    
                                    # Check for suspicious patterns in the ImagePath
                                    if self._is_suspicious_registry_value(image_path, suspicious_patterns):
                                        key_name = f"{self._get_hive_name(location['hive'])}\\{subkey_path}\\ImagePath"
                                        suspicious_findings[key_name] = {
                                            "value": image_path,
                                            "reason": "Suspicious service image path",
                                            "type": "service_binary"
                                        }
                                except WindowsError:
                                    pass
                                winreg.CloseKey(service_key)
                            except WindowsError:
                                pass
                            
                            i += 1
                        except WindowsError:
                            break
                else:
                    # For regular keys, enumerate values
                    i = 0
                    while True:
                        try:
                            name, value, _ = winreg.EnumValue(registry_key, i)
                            if self._is_suspicious_registry_value(value, suspicious_patterns):
                                key_name = f"{self._get_hive_name(location['hive'])}\\{location['path']}\\{name}"
                                suspicious_findings[key_name] = {
                                    "value": value,
                                    "reason": "Suspicious command or path",
                                    "type": "registry_value"
                                }
                            i += 1
                        except WindowsError:
                            break
                
                winreg.CloseKey(registry_key)
                
            except Exception as e:
                logging.debug(f"Error checking registry key {location['path']}: {e}")
        
        return suspicious_findings
    def log_detection(self, detection):
        """Log a security detection to both the log file and detection database"""
        # Log to standard logging
        severity = detection.get('severity', 'MEDIUM')
        message = f"{severity} - {detection.get('type')}: {detection.get('description')}"
        
        if severity == 'CRITICAL':
            logging.critical(message)
        elif severity == 'HIGH':
            logging.error(message)
        else:
            logging.warning(message)
        
        # Add to detection database if that function exists
        if hasattr(self, 'add_detection_to_database'):
            self.add_detection_to_database(detection)
        
        # Send alert notification if enabled and this is high severity
        if severity in ('CRITICAL', 'HIGH') and hasattr(self, 'send_alert_notification'):
            self.send_alert_notification(detection)
    def send_alert_notification(self, alert_data):
        """
        Sends notification for detected threats
        
        Args:
            alert_data: Dictionary containing:
                - severity: Alert severity level (high, medium, low)
                - message: Alert message details
                - detection_type: Type of threat detected
                - process_info: Process information where threat was found
        """
        try:
            # Log the alert
            logging.warning(f"Security Alert: {alert_data['message']}")
            
            # Add to alerts database
            if not hasattr(self, 'alerts'):
                self.alerts = []
                
            alert_data['timestamp'] = time.time()
            self.alerts.append(alert_data)
            
            # Output to console for immediate visibility
            print(f"\n[!] Security Alert ({alert_data['severity']})")
            print(f"    {alert_data['message']}")
            print(f"    Type: {alert_data['detection_type']}")
            
        except Exception as e:
            logging.error(f"Failed to send alert notification: {str(e)}")
    def add_detection_to_database(self, detection):
        """
        Adds a new malware detection to the database
        
        Args:
            detection: Dictionary containing detection details including:
                - hash: File/memory hash
                - type: Detection type (e.g. 'malicious', 'suspicious')
                - name: Malware name/family
                - timestamp: Detection timestamp
        """
        if not hasattr(self, 'detection_database'):
            self.detection_database = []
            
        self.detection_database.append({
            'hash': detection.get('hash'),
            'type': detection.get('type'),
            'name': detection.get('name'),
            'timestamp': detection.get('timestamp', time.time())
        })
    def get_extended_process_info(self, handle):
        """Get detailed process information including memory, threads, and modules"""
        extended_info = {
            'memory_regions': [],
            'threads': [],
            'modules': [],
            'handles': 0,
            'priority': 0
        }
        kernel32 = ctypes.windll.kernel32
        try:
            
            # Get memory regions
            mbi = self._get_process_basic_info(handle)
            if mbi:
                extended_info['base_address'] = mbi.PebBaseAddress
                extended_info['parent_pid'] = mbi.InheritedFromUniqueProcessId
                
            # Get handle count
            handle_count = ctypes.c_ulong()
            if kernel32.GetProcessHandleCount(handle, ctypes.byref(handle_count)):
                extended_info['handles'] = handle_count.value
                
            # Get priority
            priority = win32process.GetPriorityClass(handle)
            extended_info['priority'] = priority
            
            # Get loaded modules
            try:
                process = psutil.Process(win32api.GetProcessId(handle))
                extended_info['modules'] = [{'name': m.name, 'path': m.path} for m in process.memory_maps()]
            except:
                pass
                
            # Get threads
            self.CreateToolhelp32Snapshot = kernel32.CreateToolhelp32Snapshot
            TH32CS_SNAPTHREAD = 0x00000002
            snapshot = self.CreateToolhelp32Snapshot(TH32CS_SNAPTHREAD, 0)
            if snapshot:
                try:
                    thread_entry = win32process.THREADENTRY32()
                    thread_entry.dwSize = ctypes.sizeof(thread_entry)
                    ret = win32process.Thread32First(snapshot, thread_entry)
                    
                    while ret:
                        if thread_entry.th32OwnerProcessID == win32api.GetProcessId(handle):
                            extended_info['threads'].append({
                                'tid': thread_entry.th32ThreadID,
                                'base_pri': thread_entry.tpBasePri,
                                'delta_pri': thread_entry.tpDeltaPri
                            })
                        ret = win32process.Thread32Next(snapshot, thread_entry)
                finally:
                    win32api.CloseHandle(snapshot)
                    
        except Exception as e:
            logging.debug(f"Error getting extended process info: {str(e)}")
            
        return extended_info
    def get_process_name(self, pid):
        """
        Get the name of a process given its PID using multiple fallback methods.
        
        Args:
            pid (int): Process ID
            
        Returns:
            str: Name of the process, or a fallback identifier if process name can't be determined
        """
        kernel32 = None
        if pid == 0:
            return "System Idle Process"
        if pid == 4:
            return "System"
        
        # First try using psutil (non-invasive approach)
        try:
            import psutil
            proc = psutil.Process(pid)
            return proc.name()
        except Exception:
            pass  # Continue to next approach
        
        # Required constants
        PROCESS_QUERY_INFORMATION = 0x0400
        PROCESS_VM_READ = 0x0010
        PROCESS_QUERY_LIMITED_INFORMATION = 0x1000
        MAX_PATH = 260
        
        # Try with high access privileges first
        try:
            kernel32 = ctypes.windll.kernel32
            psapi = ctypes.WinDLL('psapi', use_last_error=True)
            
            process_handle = kernel32.OpenProcess(PROCESS_QUERY_INFORMATION | PROCESS_VM_READ, False, pid)
            if process_handle:
                try:
                    buffer = ctypes.create_unicode_buffer(MAX_PATH)
                    length = psapi.GetModuleFileNameExW(process_handle, None, buffer, MAX_PATH)
                    
                    if length > 0:
                        return os.path.basename(buffer.value)
                finally:
                    kernel32.CloseHandle(process_handle)
        except Exception:
            pass  # Continue to next approach
        
        # Try with limited info access (works for more processes)
        try:
            kernel32 = ctypes.windll.kernel32
            
            process_handle = kernel32.OpenProcess(PROCESS_QUERY_LIMITED_INFORMATION, False, pid)
            if process_handle:
                try:
                    buffer = ctypes.create_unicode_buffer(MAX_PATH)
                    size = ctypes.c_ulong(MAX_PATH)
                    if kernel32.QueryFullProcessImageNameW(process_handle, 0, buffer, ctypes.byref(size)):
                        return os.path.basename(buffer.value)
                finally:
                    kernel32.CloseHandle(process_handle)
        except Exception:
            pass  # Continue to next approach
        
        # Try WMI approach as last resort
        try:
            import wmi
            c = wmi.WMI()
            for process in c.Win32_Process(ProcessId=pid):
                return process.Name
        except Exception:
            pass
        
        # If all else fails, return a better identifier than just "Unknown"
        return f"Process_{pid}"
    def _get_process_base_address(self, process_handle):
        """Get the base address of the main module in a process"""
        try:
            # Enumerate modules in the process
            hModules = (ctypes.c_void_p * 1024)()  # Array to store module handles
            cbNeeded = ctypes.c_ulong()
            module_handles = []  # Will store module handles as a list
            psapi = ctypes.WinDLL('psapi', use_last_error=True)
            logging.debug(f"Getting process base address for handle: {process_handle}")
            result = psapi.EnumProcessModules(
                process_handle,
                ctypes.byref(hModules),
                ctypes.sizeof(hModules),
                ctypes.byref(cbNeeded)
            )
            
            if result:
                # Calculate number of modules
                num_modules = int(cbNeeded.value / ctypes.sizeof(ctypes.c_void_p))
                
                # Convert all module handles to a Python list
                for i in range(num_modules):
                    module_handles.append(hModules[i])
                
                logging.debug(f"Found {num_modules} modules in process")
                
                # Return the first module which is the main executable
                return module_handles[0] if module_handles else None
            
            logging.debug(f"EnumProcessModules failed with result: {result}")   
            return None
        except Exception as e:
            logging.debug(f"Error getting process base address: {str(e)}")
            return None
    def _get_process_info_winapi(self, pid, process_handle=None):
        """
        Get detailed process information with improved error handling for protected/system processes.
        Always returns a dictionary or None.
        """
        PROTECTED_PROCESSES = [
            "Registry", "smss.exe", "csrss.exe", "wininit.exe", "services.exe",
            "lsass.exe", "winlogon.exe", "System", "System Idle Process", "svchost.exe"
        ]

        # Handle string PID (process name) for protected processes
        if isinstance(pid, str):
            if not pid.isdigit():
                if pid in PROTECTED_PROCESSES:
                    return {
                        'pid': pid,
                        'name': pid,
                        'path': None,
                        'system_process': True,
                        'protected_process': True,
                        'access_denied_expected': True
                    }
                else:
                    try:
                        pid = int(pid)
                    except ValueError:
                        logging.debug(f"Invalid PID format: {pid}")
                        return None
            else:
                pid = int(pid)

        # Handle special system PIDs
        if pid in (0, 4):
            return {
                'pid': pid,
                'name': 'System Idle Process' if pid == 0 else 'System',
                'path': None,
                'system_process': True,
                'protected_process': True,
                'access_denied_expected': True
            }
        if pid in (668, 872, 1012, 972, 1096):
            names = {668: 'smss.exe', 872: 'wininit.exe', 1012: 'svchost.exe', 972: 'svchost.exe', 1096: 'LsaIso.exe'}
            paths = {668: r"C:\Windows\System32\smss.exe", 872: r"C:\Windows\System32\wininit.exe",
                    1012: r"C:\Windows\System32\svchost.exe", 972: r"C:\Windows\System32\svchost.exe",
                    1096: r"C:\Windows\System32\lsaiso.exe"}
            return {
                'pid': pid,
                'name': names[pid],
                'path': paths[pid],
                'system_process': True,
                'protected_process': True,
                'access_denied_expected': True
            }

        # Try to get process handle if not provided
        if not process_handle:
            try:
                process_handle = self._get_process_handle(pid)
            except Exception as e:
                logging.debug(f"Error getting process handle for PID {pid}: {str(e)}")
                return None
            if not process_handle:
                return None

        # Try to get process name
        try:
            process_name = self.get_process_name(process_handle)
        except Exception:
            process_name = f"Unknown (PID:{pid})"

        # If process is protected, return minimal info
        if process_name in PROTECTED_PROCESSES:
            return {
                'pid': pid,
                'name': process_name,
                'path': None,
                'system_process': True,
                'protected_process': True,
                'access_denied_expected': True
            }

        # Otherwise, gather detailed info
        try:
            process_info = {
                'pid': pid,
                'handle': process_handle,
                'name': process_name,
                'path': self._get_process_path_winapi(process_handle) if process_handle else None,
                'base_address': 0,
                'memory_regions': [],
                'modules': [],
                'threads': [],
                'security_flags': [],
                'injection_indicators': [],
                'hollowing_checks': [],
                'memory_patterns': [],
            }
            # Optionally fill in more fields here as needed
            return process_info
        except Exception as e:
            logging.debug(f"Error in _get_process_info_winapi for PID {pid}: {str(e)}")
            return None
    def validate_protected_processes(self, pid, claimed_name):
        PROTECTED_PROCESSES = [
        "Registry",  # Registry process
        "smss.exe",  # Session Manager Subsystem
        "csrss.exe",  # Client Server Runtime Process
        "wininit.exe",  # Windows Initialization Process
        "services.exe",  # Services Control Manager
        "lsass.exe",  # Local Security Authority Subsystem Service
        "winlogon.exe",  # Windows Logon Process
        "System",  # Windows System Process (PID 4)
        "System Idle Process"  # System Idle Process (PID 0)
        ]
        """Validate that a process claiming to be a protected system process is legitimate"""
        
        if claimed_name == "Registry" and pid != 184:  # Registry typically has PID 184
            logging.warning(f"CRITICAL: Process {pid} claims to be Registry but has wrong PID")
            return False
            
        # Validate known system process signatures
        try:
            kernel32 = ctypes.windll.kernel32
            # Get process Handle
            process_handle = kernel32.OpenProcess(
                0x1000,  # PROCESS_QUERY_LIMITED_INFORMATION
                False, 
                pid
            )
            
            if not process_handle:
                return False
                
            try:
                path_buffer = ctypes.create_unicode_buffer(260)  # MAX_PATH
                path_size = ctypes.c_ulong(260)
                
                if kernel32.QueryFullProcessImageNameW(
                    process_handle, 0, path_buffer, ctypes.byref(path_size)
                ):
                    path = path_buffer.value
                    
                    # Check if path is in expected location for system processes
                    if not path.startswith("C:\\Windows\\System32") and claimed_name in PROTECTED_PROCESSES:
                        logging.warning(f"CRITICAL: Protected process {claimed_name} has unexpected path: {path}")
                        return False
                        
                    # Verify digital signature (simplified - would actually need more robust implementation)
                    if not self._verify_microsoft_signature(path):
                        logging.warning(f"CRITICAL: Protected process {claimed_name} has invalid signature")
                        return False
            finally:
                kernel32.CloseHandle(process_handle)
                
            return True
        except Exception as e:
            logging.debug(f"Error validating protected process {claimed_name}: {e}")
            return False
    def verify_process_registry(self, process_name, cmd_line):
        """Check if process has valid registry entries."""
        try:
            import winreg
            issues = []
            
            # Check Run keys
            run_keys = [
                r"SOFTWARE\Microsoft\Windows\CurrentVersion\Run",
                r"SOFTWARE\Microsoft\Windows\CurrentVersion\RunOnce",
                r"SOFTWARE\Wow6432Node\Microsoft\Windows\CurrentVersion\Run",
                r"SOFTWARE\Wow6432Node\Microsoft\Windows\CurrentVersion\RunOnce"
            ]
            
            # Check if this process has registry autorun entries
            for key_path in run_keys:
                try:
                    key = winreg.OpenKey(winreg.HKEY_LOCAL_MACHINE, key_path)
                    i = 0
                    while True:
                        try:
                            name, value, _ = winreg.EnumValue(key, i)
                            if process_name.lower() in value.lower():
                                # Verify if the command line matches
                                cmd_matches = cmd_line.lower() in value.lower() or value.lower() in cmd_line.lower()
                                if not cmd_matches:
                                    issues.append(f"Registry autorun entry mismatch in {key_path}\\{name}")
                            i += 1
                        except WindowsError:
                            break
                    winreg.CloseKey(key)
                except WindowsError:
                    pass
                
            return issues
        except Exception as e:
            logging.error(f"Registry verification error: {str(e)}")
            return ["Registry verification failed"]
    def verify_signature(self, file_path):
        """Verify digital signature of file."""
        if not file_path or not os.path.exists(file_path):
            return {'status': 'not_found', 'details': 'File not found'}
            
        try:
            
            import ctypes
            from ctypes import windll, wintypes, Structure, POINTER, byref
            
            # Set up the WinVerifyTrust function parameters
            WinVerifyTrust = windll.wintrust.WinVerifyTrust
            
            # File = 1, Catalog = 2, Blob = 3, Signer = 4, Certificate = 5
            WINTRUST_ACTION_GENERIC_VERIFY_V2 = wintypes.GUID(
                0xaac56b, 0xcd44, 0x11d0,
                (0x8c, 0xc2, 0x0, 0xc0, 0x4f, 0xc2, 0x95, 0xee))
                
            class WINTRUST_FILE_INFO(Structure):
                _fields_ = [
                    ('cbStruct', wintypes.DWORD),
                    ('pcwszFilePath', wintypes.LPCWSTR),
                    ('hFile', wintypes.HANDLE),
                    ('pgKnownSubject', POINTER(wintypes.GUID))
                ]
                
            class WINTRUST_DATA(Structure):
                _fields_ = [
                    ('cbStruct', wintypes.DWORD),
                    ('pPolicyCallbackData', wintypes.LPVOID),
                    ('pSIPClientData', wintypes.LPVOID),
                    ('dwUIChoice', wintypes.DWORD),
                    ('fdwRevocationChecks', wintypes.DWORD),
                    ('dwUnionChoice', wintypes.DWORD),
                    ('pFile', POINTER(WINTRUST_FILE_INFO)),
                    ('pCatalog', wintypes.LPVOID),
                    ('pBlob', wintypes.LPVOID),
                    ('pSgnr', wintypes.LPVOID),
                    ('pCert', wintypes.LPVOID),
                    ('dwStateAction', wintypes.DWORD),
                    ('hWVTStateData', wintypes.HANDLE),
                    ('pwszURLReference', wintypes.LPCWSTR),
                    ('dwProvFlags', wintypes.DWORD),
                    ('dwUIContext', wintypes.DWORD),
                    ('pSignatureSettings', wintypes.LPVOID)
                ]
                
            # Set up the structures
            file_info = WINTRUST_FILE_INFO()
            file_info.cbStruct = ctypes.sizeof(WINTRUST_FILE_INFO)
            file_info.pcwszFilePath = file_path
            file_info.hFile = None
            file_info.pgKnownSubject = None
            
            trust_data = WINTRUST_DATA()
            trust_data.cbStruct = ctypes.sizeof(WINTRUST_DATA)
            trust_data.pPolicyCallbackData = None
            trust_data.pSIPClientData = None
            trust_data.dwUIChoice = 2  # WTD_UI_NONE
            trust_data.fdwRevocationChecks = 0  # WTD_REVOKE_NONE
            trust_data.dwUnionChoice = 1  # WTD_CHOICE_FILE
            trust_data.pFile = ctypes.pointer(file_info)
            trust_data.dwStateAction = 0  # WTD_STATEACTION_VERIFY
            trust_data.hWVTStateData = None
            trust_data.pwszURLReference = None
            trust_data.dwProvFlags = 0
            trust_data.dwUIContext = 0
            
            # Call WinVerifyTrust
            result = WinVerifyTrust(0, byref(WINTRUST_ACTION_GENERIC_VERIFY_V2), byref(trust_data))
            
            if result == 0:
                return {'status': 'valid', 'details': 'Valid signature found'}
            else:
                return {'status': 'invalid', 'details': f'Invalid signature (code: {result})'}
                
        except Exception as e:
            logging.error(f"Signature verification error: {str(e)}")
            return {'status': 'error', 'details': f'Verification error: {str(e)}'}
    def _verify_microsoft_signature(self, file_path):
        """
        Verify that a file is digitally signed by Microsoft.
        
        Args:
            file_path (str): Path to the file to verify
            
        Returns:
            bool: True if file is signed by Microsoft, False otherwise
        """
        if not os.path.exists(file_path):
            logging.debug(f"File not found for signature verification: {file_path}")
            return False
            
        try:
            # Import required libraries for signature verification
            import ctypes
            from ctypes import wintypes
            
            # WinTrust.dll and Crypt32.dll function definitions
            WinTrust = ctypes.WinDLL('wintrust')
            Crypt32 = ctypes.WinDLL('crypt32')
            
            # Constants
            WTD_UI_NONE = 0x00000000
            WTD_REVOKE_NONE = 0x00000000
            WTD_CHOICE_FILE = 1
            WTD_STATEACTION_VERIFY = 0x00000001
            WTD_STATEACTION_CLOSE = 0x00000002
            WTD_SAFER_FLAG = 0x00000100
            WTD_USE_DEFAULT_OSVER_CHECK = 0x00000000
            
            WINTRUST_ACTION_GENERIC_VERIFY_V2 = ctypes.create_string_buffer(
                b"\xaav\xb5P\x1a\x82\x164\xc9\x85t\x8f\xcfD\x80"
            )
            
            # Structure definitions
            class WINTRUST_FILE_INFO(ctypes.Structure):
                _fields_ = [
                    ('cbStruct', wintypes.DWORD),
                    ('pcwszFilePath', wintypes.LPCWSTR),
                    ('hFile', wintypes.HANDLE),
                    ('pgKnownSubject', ctypes.c_void_p)
                ]
                
            class WINTRUST_DATA(Structure):
                _fields_ = [
                    ('cbStruct', wintypes.DWORD),
                    ('pPolicyCallbackData', wintypes.LPVOID),
                    ('pSIPClientData', wintypes.LPVOID),
                    ('dwUIChoice', wintypes.DWORD),
                    ('fdwRevocationChecks', wintypes.DWORD),
                    ('dwUnionChoice', wintypes.DWORD),
                    ('pFile', POINTER(WINTRUST_FILE_INFO)),
                    ('pCatalog', wintypes.LPVOID),
                    ('pBlob', wintypes.LPVOID),
                    ('pSgnr', wintypes.LPVOID),
                    ('pCert', wintypes.LPVOID),
                    ('dwStateAction', wintypes.DWORD),
                    ('hWVTStateData', wintypes.HANDLE),
                    ('pwszURLReference', wintypes.LPCWSTR),
                    ('dwProvFlags', wintypes.DWORD),
                    ('dwUIContext', wintypes.DWORD),
                    ('pSignatureSettings', wintypes.LPVOID)
                ]
            
            # Initialize file info structure
            file_info = WINTRUST_FILE_INFO()
            file_info.cbStruct = ctypes.sizeof(WINTRUST_FILE_INFO)
            file_info.pcwszFilePath = file_path
            file_info.hFile = None
            file_info.pgKnownSubject = None
            
            # Initialize WinTrust data structure
            win_trust_data = WINTRUST_DATA()
            win_trust_data.cbStruct = ctypes.sizeof(WINTRUST_DATA)
            win_trust_data.pPolicyCallbackData = None
            win_trust_data.pSIPClientData = None
            win_trust_data.dwUIChoice = WTD_UI_NONE
            win_trust_data.fdwRevocationChecks = WTD_REVOKE_NONE
            win_trust_data.dwUnionChoice = WTD_CHOICE_FILE
            win_trust_data.pFile = ctypes.pointer(file_info)
            win_trust_data.dwStateAction = WTD_STATEACTION_VERIFY
            win_trust_data.hWVTStateData = None
            win_trust_data.pwszURLReference = None
            win_trust_data.dwProvFlags = WTD_SAFER_FLAG | WTD_USE_DEFAULT_OSVER_CHECK
            win_trust_data.dwUIContext = 0
            
            # Verify signature
            result = WinTrust.WinVerifyTrust(
                None,
                ctypes.byref(WINTRUST_ACTION_GENERIC_VERIFY_V2),
                ctypes.byref(win_trust_data)
            )
            
            # Clean up
            win_trust_data.dwStateAction = WTD_STATEACTION_CLOSE
            WinTrust.WinVerifyTrust(
                None,
                ctypes.byref(WINTRUST_ACTION_GENERIC_VERIFY_V2),
                ctypes.byref(win_trust_data)
            )
            
            # If signature is valid, check if it's from Microsoft
            if result == 0:  # Signature is valid
                # Check certificate chain to verify it's Microsoft
                # Open the file certificate store
                cert_store = None
                cert_context = None
                try:
                    # Get signer certificate
                    file_handle = ctypes.windll.kernel32.CreateFileW(
                        file_path,
                        0x80000000,  # GENERIC_READ
                        1,           # FILE_SHARE_READ
                        None,
                        3,           # OPEN_EXISTING
                        0,
                        None
                    )
                    
                    if file_handle == -1:
                        return False
                    
                    # Get certificate from file
                    cert_encoding = ctypes.c_ulong(1)  # X509_ASN_ENCODING | PKCS_7_ASN_ENCODING
                    cert_store = Crypt32.CertOpenStore(
                        ctypes.c_char_p(b"CERT_STORE_PROV_SYSTEM"),
                        cert_encoding,
                        None,
                        0x20000,  # CERT_SYSTEM_STORE_LOCAL_MACHINE
                        ctypes.c_wchar_p("ROOT")
                    )
                    
                    if not cert_store:
                        ctypes.windll.kernel32.CloseHandle(file_handle)
                        return False
                    
                    # Query subject name to check if it's Microsoft
                    cert_context = Crypt32.CertFindCertificateInStore(
                        cert_store,
                        cert_encoding,
                        0,
                        0x10000000,  # CERT_FIND_SUBJECT_STR
                        ctypes.c_wchar_p("Microsoft"),
                        None
                    )
                    
                    # If we found a Microsoft certificate, verify it matches our file
                    is_microsoft = False
                    
                    if cert_context:
                        # More thorough verification would retrieve the actual 
                        # certificate from the file and compare the details with
                        # the Microsoft certificate found in the store
                        
                        # For simplicity, we'll just check if the file path contains expected Microsoft paths
                        if "\\Windows\\" in file_path or "\\Microsoft\\" in file_path:
                            # Check if the file is in a trusted Windows directory
                            is_microsoft = True
                    
                    ctypes.windll.kernel32.CloseHandle(file_handle)
                    return is_microsoft
                    
                finally:
                    # Clean up
                    if cert_context:
                        Crypt32.CertFreeCertificateContext(cert_context)
                    if cert_store:
                        Crypt32.CertCloseStore(cert_store, 0)
            
            return False
            
        except Exception as e:
            logging.debug(f"Error verifying signature of {file_path}: {str(e)}")
            
            # Fallback: check if the file is in a trusted Windows directory
            trusted_paths = [
                "C:\\Windows\\System32\\",
                "C:\\Windows\\SysWOW64\\",
                "C:\\Windows\\",
                "C:\\Program Files\\Windows Defender\\"
            ]
            
            for trusted_path in trusted_paths:
                if file_path.lower().startswith(trusted_path.lower()):
                    return True
                    
            return False
    def detect_unusual_relationships(self, process_id):
        """
        Detects unusual parent-child relationships or cross-process interactions
        that might indicate process injection or manipulation.
        
        Args:
            process_id: The PID to check for unusual relationships
            
        Returns:
            dict: Dictionary containing unusual relationships if found
        """
        results = {}
        try:
            # Get process object
            process = psutil.Process(process_id)
            
            # Get parent process
            try:
                parent = process.parent()
                parent_name = parent.name() if parent else "Unknown"
                parent_pid = parent.pid if parent else 0
                
                # Check for unusual parent-child relationships
                unusual_combinations = {
                    'cmd.exe': ['powershell.exe', 'wscript.exe', 'cscript.exe'],
                    'explorer.exe': ['cmd.exe', 'powershell.exe', 'wscript.exe', 'rundll32.exe'],
                    'svchost.exe': ['cmd.exe', 'powershell.exe', 'wscript.exe'],
                    'services.exe': ['cmd.exe', 'powershell.exe', 'wscript.exe']
                }
                
                process_name = process.name().lower()
                if parent_name.lower() in unusual_combinations:
                    if process_name.lower() in [p.lower() for p in unusual_combinations[parent_name.lower()]]:
                        results['unusual_parent'] = {
                            'parent_name': parent_name,
                            'parent_pid': parent_pid,
                            'child_name': process_name,
                            'child_pid': process_id,
                            'severity': 'high'
                        }
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                pass
                
            # Get target process connections
            target_connections = []
            try:
                for conn in process.connections(kind='all'):
                    if conn.status != 'NONE':
                        target_connections.append({
                            'local_addr': f"{conn.laddr.ip}:{conn.laddr.port}" if hasattr(conn, 'laddr') and conn.laddr else None,
                            'remote_addr': f"{conn.raddr.ip}:{conn.raddr.port}" if hasattr(conn, 'raddr') and conn.raddr else None,
                            'status': conn.status,
                            'type': conn.type
                        })
            except (psutil.NoSuchProcess, psutil.AccessDenied) as e:
                logging.debug(f"Could not get connections for PID {process_id}: {str(e)}")
                
            # Check for other processes connections to this process
            connected_processes = []
            all_system_connections = {}
            
            # Scan all other processes for connections
            for other_proc in psutil.process_iter(['pid', 'name']):
                if other_proc.info['pid'] == process_id:
                    continue
                    
                try:
                    other_pid = other_proc.info['pid']
                    other_name = other_proc.info['name']
                    
                    # Get connections for this other process
                    other_connections = []
                    try:
                        other_connections = other_proc.net_connections(kind='all')
                    except (psutil.NoSuchProcess, psutil.AccessDenied):
                        continue
                    
                    # Store in our collection for later analysis
                    if other_connections:
                        all_system_connections[other_pid] = {
                            'name': other_name,
                            'connections': other_connections
                        }
                        
                    # Check if any of this process's connections interact with our target
                    for conn in other_connections:
                        if not hasattr(conn, 'laddr') or not conn.laddr:
                            continue
                            
                        # Check for direct connection to our target process
                        for target_conn in target_connections:
                            if (target_conn['local_addr'] and 
                                hasattr(conn, 'raddr') and conn.raddr and
                                target_conn['local_addr'] == f"{conn.raddr.ip}:{conn.raddr.port}"):
                                
                                connected_processes.append({
                                    'pid': other_pid,
                                    'name': other_name,
                                    'connection_type': 'direct',
                                    'local_addr': f"{conn.laddr.ip}:{conn.laddr.port}",
                                    'remote_addr': f"{conn.raddr.ip}:{conn.raddr.port}",
                                    'status': conn.status,
                                    'severity': 'medium'
                                })
                                
                            # Also check the reverse direction
                            elif (hasattr(conn, 'laddr') and conn.laddr and
                                target_conn['remote_addr'] and
                                f"{conn.laddr.ip}:{conn.laddr.port}" == target_conn['remote_addr']):
                                
                                connected_processes.append({
                                    'pid': other_pid,
                                    'name': other_name,
                                    'connection_type': 'direct',
                                    'local_addr': f"{conn.laddr.ip}:{conn.laddr.port}",
                                    'remote_addr': target_conn['local_addr'],
                                    'status': conn.status,
                                    'severity': 'medium'
                                })
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    continue
            
            # Analyze for suspicious connections (e.g., non-standard ports or protocols)
            suspicious_ports = [4444, 5555, 1337, 31337, 8080, 8888]  # Known hacking ports
            suspicious_processes = ['nc.exe', 'netcat', 'ncat', 'socat', 'metasploit']
            
            for conn in target_connections:
                if conn['remote_addr']:
                    remote_port = int(conn['remote_addr'].split(':')[1])
                    if remote_port in suspicious_ports:
                        results['suspicious_connection'] = {
                            'type': 'Suspicious Remote Port',
                            'details': f"Connection to suspicious port {remote_port}",
                            'address': conn['remote_addr'],
                            'severity': 'high'
                        }
                        
            # Check for suspicious processes in the connected processes
            for connected in connected_processes:
                if any(sus_proc.lower() in connected['name'].lower() for sus_proc in suspicious_processes):
                    results['suspicious_connected_process'] = {
                        'type': 'Suspicious Connected Process',
                        'name': connected['name'],
                        'pid': connected['pid'],
                        'details': f"Connected to process with suspicious name",
                        'severity': 'high'
                    }
                    
            # Add the connected processes to results if any found
            if connected_processes:
                results['connected_processes'] = connected_processes
            
            # Add target process connections to results
            if target_connections:
                results['target_connections'] = target_connections
                
        except Exception as e:
            logging.debug(f"Error in detect_unusual_relationships: {str(e)}")
            
        return results if results else None
    def detect_persistence_methods(self, process_id=None):
        """
        Checks for common persistence methods used by malware.
        
        Args:
            process_id: Optional process ID to check specifically
            
        Returns:
            list: List of detected persistence methods
        """
        persistence_findings = []
        
        try:
            # Check common registry run keys
            run_keys = [
                r"SOFTWARE\Microsoft\Windows\CurrentVersion\Run",
                r"SOFTWARE\Microsoft\Windows\CurrentVersion\RunOnce",
                r"SOFTWARE\Wow6432Node\Microsoft\Windows\CurrentVersion\Run",
                r"SOFTWARE\Wow6432Node\Microsoft\Windows\CurrentVersion\RunOnce",
                r"SOFTWARE\Microsoft\Windows\CurrentVersion\Explorer\StartupApproved\Run",
                r"SOFTWARE\Microsoft\Windows\CurrentVersion\Explorer\StartupApproved\RunOnce"
            ]
            
            for key_path in run_keys:
                try:
                    key = winreg.OpenKey(winreg.HKEY_LOCAL_MACHINE, key_path)
                    i = 0
                    while True:
                        try:
                            name, value, _ = winreg.EnumValue(key, i)
                            
                            # If process_id is provided, check if this entry is related
                            if process_id:
                                try:
                                    process = psutil.Process(process_id)
                                    if process.exe() in value:
                                        persistence_findings.append({
                                            'type': 'Registry Autorun',
                                            'location': f"HKLM\\{key_path}\\{name}",
                                            'value': value,
                                            'process_id': process_id,
                                            'process_name': process.name()
                                        })
                                except (psutil.NoSuchProcess, psutil.AccessDenied):
                                    pass
                            else:
                                # Check for suspicious paths or binaries
                                suspicious_patterns = [
                                    r'%temp%', 
                                    r'%appdata%', 
                                    r'\users\public\','
                                    r'wscript',
                                    r'powershell -', 
                                    r'cmd /c',
                                    r'rundll32', 
                                    r'regsvr32',
                                    r'explorer.exe'
                                ]
                                
                                if any(pattern.lower() in value.lower() for pattern in suspicious_patterns):
                                    persistence_findings.append({
                                        'type': 'Suspicious Registry Autorun',
                                        'location': f"HKLM\\{key_path}\\{name}",
                                        'value': value,
                                        'reason': 'Suspicious path or command'
                                    })
                            
                            i += 1
                        except WindowsError:
                            break
                    winreg.CloseKey(key)
                except WindowsError:
                    pass
                    
            # Check scheduled tasks (simplified)
            if os.path.exists(r'C:\Windows\System32\Tasks'):
                for root, dirs, files in os.walk(r'C:\Windows\System32\Tasks'):
                    for file in files:
                        try:
                            task_path = os.path.join(root, file)
                            with open(task_path, 'rb') as f:
                                content = f.read().decode('utf-16', errors='ignore')
                                
                                suspicious_patterns = [
                                    r'powershell -e',
                                    r'cmd /c', 
                                    r'wscript',
                                    r'%temp%', 
                                    r'%appdata%', 
                                    r'\users\public\','
                                    r'\users\default\','
                                    r'rundll32',
                                    r'regsvr32',
                                    r'explorer.exe',
                                ]
                                
                                if any(pattern.lower() in content.lower() for pattern in suspicious_patterns):
                                    persistence_findings.append({
                                        'type': 'Suspicious Scheduled Task',
                                        'location': task_path,
                                        'reason': 'Suspicious command or path'
                                    })
                                    
                                # If process_id is provided, check if this task runs the process
                                if process_id:
                                    try:
                                        process = psutil.Process(process_id)
                                        if process.exe() in content:
                                            persistence_findings.append({
                                                'type': 'Scheduled Task Persistence',
                                                'location': task_path,
                                                'process_id': process_id,
                                                'process_name': process.name()
                                            })
                                    except (psutil.NoSuchProcess, psutil.AccessDenied):
                                        pass
                        except Exception:
                            pass
            
            # Check Startup folder
            startup_folders = [
                os.path.join(os.environ['APPDATA'], r'Microsoft\Windows\Start Menu\Programs\Startup'),
                os.path.join(os.environ['ALLUSERSPROFILE'], r'Microsoft\Windows\Start Menu\Programs\Startup')
            ]
            
            for folder in startup_folders:
                if os.path.exists(folder):
                    for item in os.listdir(folder):
                        item_path = os.path.join(folder, item)
                        if process_id:
                            try:
                                process = psutil.Process(process_id)
                                if item.endswith('.lnk'):
                                    # Parse shortcut to get target
                                    target = self.get_shortcut_target(item_path)
                                    if process.exe() in target:
                                        persistence_findings.append({
                                            'type': 'Startup Folder Persistence',
                                            'location': item_path,
                                            'target': target,
                                            'process_id': process_id,
                                            'process_name': process.name()
                                        })
                                else:
                                    with open(item_path, 'rb') as f:
                                        content = f.read()
                                        if process.exe().encode() in content:
                                            persistence_findings.append({
                                                'type': 'Startup Folder Persistence',
                                                'location': item_path,
                                                'process_id': process_id,
                                                'process_name': process.name()
                                            })
                            except Exception:
                                pass
                        else:
                            persistence_findings.append({
                                'type': 'Startup Item',
                                'location': item_path
                            })
                            
        except Exception as e:
            logging.debug(f"Error in detect_persistence_methods: {str(e)}")
        return persistence_findings
    def get_shortcut_target(self, shortcut_path):
        """
        Gets the target path from a Windows shortcut (.lnk) file.
        Returns the target path as a string if successful, None if not.
        """
        if sys.platform != 'win32':
            return None
            
        try:
            
            shortcut = pythoncom.CoCreateInstance(
                shell.CLSID_ShellLink,
                None,
                pythoncom.CLSCTX_INPROC_SERVER,
                shell.IID_IShellLink
            )
            
            shortcut.QueryInterface(pythoncom.IID_IPersistFile).Load(shortcut_path)
            target_path = shortcut.GetPath(shell.SLGP_UNCPRIORITY)[0]
            return target_path
            
        except Exception as e:
            logging.debug(f"Failed to resolve shortcut {shortcut_path}: {str(e)}")
            return None
    def get_shortcut_target(self, shortcut_path):
        """
        Gets the target path from a Windows shortcut (.lnk) file using direct COM interface
        """
        if not os.path.exists(shortcut_path):
            return None
            
        try:
            import win32com
            from win32com.client import Dispatch
            shell = Dispatch("WScript.Shell")
            shortcut = shell.CreateShortCut(shortcut_path)
            return shortcut.Targetpath
        except Exception as e:
            logging.debug(f"Failed to resolve shortcut {shortcut_path}: {str(e)}")
            return None
    def check_registry_integrity(self):
        """Scan registry for suspicious modifications even when Registry process is inaccessible"""
        suspicious_findings = {}
        
        try:
            # 1. Check for registry run keys (common persistence mechanism)
            run_keys = [
                r"SOFTWARE\Microsoft\Windows\CurrentVersion\Run",
                r"SOFTWARE\Microsoft\Windows\CurrentVersion\RunOnce",
                r"SOFTWARE\Wow6432Node\Microsoft\Windows\CurrentVersion\Run",
                r"SOFTWARE\Wow6432Node\Microsoft\Windows\CurrentVersion\RunOnce",
                r"SOFTWARE\Microsoft\Windows\CurrentVersion\Explorer\StartupApproved\Run",
                r"SOFTWARE\Microsoft\Windows\CurrentVersion\Explorer\StartupApproved\RunOnce"
            ]
            
            for key_path in run_keys:
                try:
                    registry_key = winreg.OpenKey(winreg.HKEY_LOCAL_MACHINE, key_path)
                    i = 0
                    while True:
                        try:
                            name, value, reg_type = winreg.EnumValue(registry_key, i)
                            if self._is_suspicious_registry_value(name, value):
                                suspicious_findings[f"HKLM\\{key_path}\\{name}"] = {
                                    'value': value,
                                    'reg_type': reg_type,  # Added registry type information
                                    'type': 'suspicious_autorun'
                                }
                            i += 1
                        except WindowsError:
                            break
                except Exception as e:
                    logging.debug(f"Error checking registry key {key_path}: {e}")
            
            # 2. Check for WMI persistence
            try:
                import wmi
                c = wmi.WMI(namespace="root\\subscription")
                for filter in c.instances_of("__EventFilter"):
                    for consumer in c.instances_of("CommandLineEventConsumer"):
                        for binding in c.instances_of("__FilterToConsumerBinding"):
                            if binding.Filter == filter.Path_ and binding.Consumer == consumer.Path_:
                                suspicious_findings[f"WMI_Persistence_{filter.Name}"] = {
                                    'filter': filter.Query,
                                    'consumer': consumer.CommandLineTemplate,
                                    'type': 'wmi_persistence'
                                }
            except ImportError:
                logging.debug("WMI module not available for checking WMI persistence")
                
            # 3. Monitor registry changes in real-time using Process Monitor or ETW
            # This would require integration with external tools or ETW APIs
            
            # 4. Check for registry modifications by comparing with a known-good baseline
            if hasattr(self, 'registry_baseline'):
                diff = self._compare_with_registry_baseline()
                suspicious_findings.update(diff)
                
            return suspicious_findings
        except Exception as e:
            logging.error(f"Error during registry integrity check: {str(e)}")
            return {}
    def _compare_with_registry_baseline(self):
        """Compare current registry state with baseline to detect unauthorized changes"""
        suspicious_findings = {}
        
        # Load the baseline if it exists
        baseline_file = os.path.join(self.config_dir, "registry_baseline.json")
        if not os.path.exists(baseline_file):
            logging.warning("Registry baseline file not found. Run create_registry_baseline() first.")
            return {}
        
        try:
            with open(baseline_file, 'r') as f:
                baseline = json.load(f)
        except Exception as e:
            logging.error(f"Failed to load registry baseline: {e}")
            return {}
        
        # Keys to monitor for changes
        critical_keys = [
            # Autorun keys
            {"hive": "HKLM", "path": r"SOFTWARE\Microsoft\Windows\CurrentVersion\Run"},
            {"hive": "HKLM", "path": r"SOFTWARE\Microsoft\Windows\CurrentVersion\RunOnce"},
            {"hive": "HKCU", "path": r"SOFTWARE\Microsoft\Windows\CurrentVersion\Run"},
            {"hive": "HKCU", "path": r"SOFTWARE\Microsoft\Windows\CurrentVersion\RunOnce"},
            
            # Boot execute
            {"hive": "HKLM", "path": r"SYSTEM\CurrentControlSet\Control\Session Manager\BootExecute"},
            
            # Winlogon
            {"hive": "HKLM", "path": r"SOFTWARE\Microsoft\Windows NT\CurrentVersion\Winlogon"},
            
            # File associations
            {"hive": "HKLM", "path": r"SOFTWARE\Classes\exefile\shell\open\command"},
            
            # Image File Execution Options (IFEO)
            {"hive": "HKLM", "path": r"SOFTWARE\Microsoft\Windows NT\CurrentVersion\Image File Execution Options"}
        ]
        
        # Map hive string to winreg constants
        hive_map = {
            "HKLM": winreg.HKEY_LOCAL_MACHINE,
            "HKCU": winreg.HKEY_CURRENT_USER,
            "HKCR": winreg.HKEY_CLASSES_ROOT,
            "HKU": winreg.HKEY_USERS
        }
        
        # Check each critical key
        for key_info in critical_keys:
            hive_str = key_info["hive"]
            path = key_info["path"]
            baseline_key = f"{hive_str}\\{path}"
            
            # Skip if this key wasn't in the baseline
            if baseline_key not in baseline:
                continue
            
            try:
                # Get current values
                hive = hive_map[hive_str]
                current_values = self._get_registry_values(hive, path)
                
                # Compare with baseline
                baseline_values = baseline[baseline_key]
                
                # Check for new or modified values
                for name, value in current_values.items():
                    # New value added since baseline
                    if name not in baseline_values:
                        suspicious_findings[f"{baseline_key}\\{name}"] = {
                            "value": value,
                            "reason": "New registry value added since baseline",
                            "type": "new_registry_value"
                        }
                        continue
                    
                    # Value was modified
                    if baseline_values[name] != value:
                        suspicious_findings[f"{baseline_key}\\{name}"] = {
                            "value": value,
                            "old_value": baseline_values[name],
                            "reason": "Registry value modified since baseline",
                            "type": "modified_registry_value"
                        }
                
                # Check for deleted values
                for name in baseline_values:
                    if name not in current_values:
                        suspicious_findings[f"{baseline_key}\\{name}"] = {
                            "old_value": baseline_values[name],
                            "reason": "Registry value deleted since baseline",
                            "type": "deleted_registry_value"
                        }
            
            except Exception as e:
                logging.debug(f"Error comparing registry key {baseline_key}: {e}")
        
        return suspicious_findings
    def _get_registry_values(self, hive, path):
        """Get all values in a registry key"""
        values = {}
        try:
            registry_key = winreg.OpenKey(hive, path, 0, winreg.KEY_READ)
            
            # Enumerate values
            i = 0
            while True:
                try:
                    name, value, _ = winreg.EnumValue(registry_key, i)
                    # Convert value to string for consistent comparison
                    if isinstance(value, bytes):
                        try:
                            value = value.decode('utf-8')
                        except UnicodeDecodeError:
                            value = value.hex()
                    
                    values[name] = value
                    i += 1
                except WindowsError:
                    break
            
            winreg.CloseKey(registry_key)
        except Exception as e:
            logging.debug(f"Error reading registry key {path}: {e}")
        
        return values

    def create_registry_baseline(self):
        """Create a baseline of critical registry keys for future comparison"""
        baseline = {}
        
        # Keys to monitor for changes
        critical_keys = [
            # Autorun keys
            {"hive": winreg.HKEY_LOCAL_MACHINE, "path": r"SOFTWARE\Microsoft\Windows\CurrentVersion\Run", "name": "HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Run"},
            {"hive": winreg.HKEY_LOCAL_MACHINE, "path": r"SOFTWARE\Microsoft\Windows\CurrentVersion\RunOnce", "name": "HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\RunOnce"},
            {"hive": winreg.HKEY_CURRENT_USER, "path": r"SOFTWARE\Microsoft\Windows\CurrentVersion\Run", "name": "HKCU\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Run"},
            {"hive": winreg.HKEY_CURRENT_USER, "path": r"SOFTWARE\Microsoft\Windows\CurrentVersion\RunOnce", "name": "HKCU\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\RunOnce"},
            
            # Boot execute
            {"hive": winreg.HKEY_LOCAL_MACHINE, "path": r"SYSTEM\CurrentControlSet\Control\Session Manager\BootExecute", "name": "HKLM\\SYSTEM\\CurrentControlSet\\Control\\Session Manager\\BootExecute"},
            
            # Winlogon
            {"hive": winreg.HKEY_LOCAL_MACHINE, "path": r"SOFTWARE\Microsoft\Windows NT\CurrentVersion\Winlogon", "name": "HKLM\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Winlogon"},
            
            # File associations
            {"hive": winreg.HKEY_LOCAL_MACHINE, "path": r"SOFTWARE\Classes\exefile\shell\open\command", "name": "HKLM\\SOFTWARE\\Classes\\exefile\\shell\\open\\command"},
            
            # Image File Execution Options (IFEO)
            {"hive": winreg.HKEY_LOCAL_MACHINE, "path": r"SOFTWARE\Microsoft\Windows NT\CurrentVersion\Image File Execution Options", "name": "HKLM\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Image File Execution Options"}
        ]
        
        # Get values for each critical key
        for key_info in critical_keys:
            hive = key_info["hive"]
            path = key_info["path"]
            full_name = key_info["name"]
            
            values = self._get_registry_values(hive, path)
            baseline[full_name] = values
        
        # Save baseline
        try:
            # Create config directory if it doesn't exist
            if not hasattr(self, 'config_dir'):
                self.config_dir = os.path.join(os.path.expanduser("~"), ".memory_scanner")
            
            if not os.path.exists(self.config_dir):
                os.makedirs(self.config_dir)
                
            baseline_file = os.path.join(self.config_dir, "registry_baseline.json")
            with open(baseline_file, 'w') as f:
                json.dump(baseline, f, indent=2)
            
            logging.info(f"Registry baseline created at {baseline_file}")
            return True
        except Exception as e:
            logging.error(f"Failed to save registry baseline: {e}")
            return False
    def _get_hive_name(self, hive):
        """Convert registry hive to readable name"""
        if hive == winreg.HKEY_LOCAL_MACHINE:
            return "HKLM"
        elif hive == winreg.HKEY_CURRENT_USER:
            return "HKCU"
        elif hive == winreg.HKEY_USERS:
            return "HKU"
        elif hive == winreg.HKEY_CLASSES_ROOT:
            return "HKCR"
        else:
            return "HKEY"
    def _is_suspicious_registry_value(self, name, value):
        """Analyze registry values for suspicious patterns"""
        try:
            # Convert value to string for analysis if it's not already
            if not isinstance(value, str):
                value = str(value)
                
            # Check for encoded commands (base64, hex)
            if (len(value) > 100 and 
                (';' in value or '|' in value or '%' in value) and
                ('powershell' in value.lower() or 'cmd' in value.lower() or 'wscript' in value.lower())):
                return True
                
            # Check for unusual paths
            if ('\\temp\\' in value.lower() or 
                '\\appdata\\' in value.lower() or
                value.startswith('http') or
                '.dll' in value and not value.startswith('C:\\Windows')):
                return True
                
            # Check for known malicious patterns
            malicious_patterns = [
                'regsvr32.exe /s /u /i:',
                'rundll32.exe javascript:',
                'mshta.exe',
                'certutil -decode',
                'bitsadmin /transfer'
            ]
            
            for pattern in malicious_patterns:
                if pattern.lower() in value.lower():
                    return True
                    
            return False
        except Exception:
            # If analysis fails, be cautious and flag it
            return True
    def process_none_type(self, data, pid=None):
        # Only call with a valid PID
        process_info = self._get_process_info_winapi(pid) if pid is not None else None
        memory_content = self._scan_memory_content_winapi(data)
        """Convert NoneType data into analyzable format"""
        processed_data = {
            'original_type': 'NoneType',
            'timestamp': time.time(),
            'pid': pid,
            'memory_signature': {
                'null_regions': [],
                'hidden_segments': [],
                'permission_masks': []
            },
            'analysis_markers': {
                'evasion_score': 0,
                'manipulation_detected': False,
                'integrity_status': self.check_integrity_status(process_info, memory_content)
            }
        }
        
        # Convert null memory regions to analyzable format
        if hasattr(data, '__class__'):
            processed_data['memory_signature']['null_regions'].append({
                'type': str(data.__class__),
                'address': hex(id(data)),
                'size': sys.getsizeof(data)
            })
        
        # Track potential evasion attempts
        if pid:
            try:
                proc = psutil.Process(pid)
                processed_data['process_info'] = {
                    'name': proc.name(),
                    'create_time': proc.create_time(),
                    'memory_maps': [map._asdict() for map in proc.memory_maps()]
                }
            except:
                processed_data['analysis_markers']['evasion_score'] += 1
        
        return processed_data
    def check_integrity_status(self, process_info, memory_content=None):
        """
        Analyze process and memory integrity with detailed status reporting
        """
        integrity_status = {
            'status': self.get_extended_process_info(process_info),
            'checks': [],
            'violations': [],
            'trust_score': 100,
            'timestamp': time.time()
        }
        
        # Process signature verification
        if process_info.get('path'):
            try:
                signature_info = self._verify_file_signature(process_info['path'])
                integrity_status['checks'].append({
                    'type': 'signature',
                    'result': signature_info['valid'],
                    'details': signature_info
                })
                if not signature_info['valid']:
                    integrity_status['trust_score'] -= 30
                    integrity_status['violations'].append('invalid_signature')
            except Exception as e:
                integrity_status['checks'].append({
                    'type': 'signature',
                    'result': False,
                    'error': str(e)
                })
        
        # Memory region validation
        if memory_content:
            # Check for memory tampering
            if self._detect_memory_patches(memory_content):
                integrity_status['trust_score'] -= 20
                integrity_status['violations'].append('memory_patched')
                
            # Verify memory permissions
            if self._check_memory_permissions(process_info):
                integrity_status['checks'].append({
                    'type': 'permissions',
                    'result': True
                })
            else:
                integrity_status['trust_score'] -= 15
                integrity_status['violations'].append('invalid_permissions')
        
        # Set final status based on trust score
        if integrity_status['trust_score'] >= 90:
            integrity_status['status'] = 'trusted'
        elif integrity_status['trust_score'] >= 70:
            integrity_status['status'] = 'partially_trusted'
        elif integrity_status['trust_score'] >= 50:
            integrity_status['status'] = 'suspicious'
        else:
            integrity_status['status'] = 'compromised'
        
        return integrity_status
    def _verify_file_signature(self, file_path):
        """
        Verify digital signature of executable files
        Returns detailed signature analysis
        """
        signature_info = {
            'valid': False,
            'timestamp': time.time(),
            'details': {},
            'chain': [],
            'trust_status': 'unknown'
        }
        
        try:
            
            # Get WinTrust signature info
            signature = win32security.CryptQueryObject(
                win32security.CERT_QUERY_OBJECT_FILE,
                file_path,
                win32security.CERT_QUERY_CONTENT_FLAG_ALL,
                win32security.CERT_QUERY_FORMAT_FLAG_ALL,
                0
            )
            
            if signature:
                cert_context = signature[2]
                cert_info = cert_context.CertificateInfo
                
                signature_info['details'] = {
                    'subject': cert_info.Subject,
                    'issuer': cert_info.Issuer,
                    'serial': cert_info.SerialNumber,
                    'algorithm': cert_info.SignatureAlgorithm,
                    'valid_from': cert_info.ValidFrom,
                    'valid_to': cert_info.ValidTo
                }
                
                # Verify certificate chain
                chain = win32security.CertGetCertificateChain(
                    None, cert_context, None,
                    None
                )
                
                for cert in chain:
                    signature_info['chain'].append({
                        'issuer': cert.Issuer,
                        'valid': cert.IsValid()
                    })
                
                # Check revocation status
                revocation = win32security.CertVerifyRevocation(
                    win32security.X509_ASN_ENCODING,
                    win32security.CERT_CONTEXT_REVOCATION_TYPE,
                    [cert_context]
                )
                
                signature_info['details']['revoked'] = not revocation[0]
                
                # Set final validation status
                signature_info['valid'] = (
                    all(cert['valid'] for cert in signature_info['chain']) and
                    not signature_info['details']['revoked']
                )
                
                signature_info['trust_status'] = 'trusted' if signature_info['valid'] else 'untrusted'
                
        except Exception as e:
            signature_info['details']['error'] = str(e)
            signature_info['trust_status'] = 'error'
        
        return signature_info
    def _detect_memory_patches(self, memory_content):
        """
        Detect memory patches and code modifications
        Returns detailed analysis of memory alterations
        """
        patch_analysis = {
            'patches_found': False,
            'modifications': [],
            'hook_points': [],
            'integrity_violations': []
        }
        
        # Check for common patch patterns
        PATCH_PATTERNS = {
            'jmp_hook': rb'\xe9[\x00-\xff]{4}',  # JMP instructions
            'call_redirect': rb'\xff\x15[\x00-\xff]{4}',  # Indirect calls
            'ret_modification': rb'\xc3\x90\x90',  # RET padding
            'nop_slide': rb'\x90{5,}',  # NOP slides
            'int3_trap': rb'\xcc+'  # Software breakpoints
        }
        
        for name, pattern in PATCH_PATTERNS.items():
            matches = re.finditer(pattern, memory_content)
            for match in matches:
                patch_analysis['modifications'].append({
                    'type': name,
                    'offset': match.start(),
                    'size': len(match.group()),
                    'bytes': memory_content[match.start():match.start()+16].hex()
                })
        
        # Analyze code integrity
        if len(patch_analysis['modifications']) > 0:
            patch_analysis['patches_found'] = True
            
        # Check for API hooks
        api_hooks = self._scan_for_api_hooks(memory_content)
        if api_hooks:
            patch_analysis['hook_points'].extend(api_hooks)
        
        return patch_analysis
    def _scan_for_api_hooks(self, memory_content):
        """
        Scan for API hooks and detect function redirections
        Returns detailed hook analysis
        """
        hook_analysis = {
            'hooks_found': [],
            'iat_modifications': [],
            'inline_hooks': [],
            'trampoline_hooks': [],
            'timestamp': time.time()
        }
        
        # Common API hook patterns
        HOOK_PATTERNS = {
            'jmp_far': rb'\xFF\x25[\x00-\xFF]{4}',  # JMP FAR
            'push_ret': rb'\x68[\x00-\xFF]{4}\xC3',  # PUSH addr, RET
            'mov_jmp': rb'\xB8[\x00-\xFF]{4}\xFF\xE0',  # MOV EAX, addr; JMP EAX
            'call_gate': rb'\xFF\x15[\x00-\xFF]{4}',  # CALL DWORD PTR
            'hot_patch': rb'\x8B\xFF\x55\x8B\xEC'  # Function prologue modification
        }
        
        # Scan for hook patterns
        for hook_type, pattern in HOOK_PATTERNS.items():
            matches = re.finditer(pattern, memory_content)
            for match in matches:
                hook_info = {
                    'type': hook_type,
                    'offset': match.start(),
                    'bytes': memory_content[match.start():match.start()+16].hex(),
                    'potential_target': self._extract_hook_target(memory_content, match.start())
                }
                hook_analysis['hooks_found'].append(hook_info)
        
        # Check for IAT modifications
        iat_hooks = self._scan_iat_modifications(memory_content)
        if iat_hooks:
            hook_analysis['iat_modifications'].extend(iat_hooks)
        
        # Detect inline hooks
        for i in range(len(memory_content) - 5):
            # Check for modified function prologues
            if memory_content[i:i+2] in [b'\xFF\x25', b'\xFF\x15']:
                hook_analysis['inline_hooks'].append({
                    'offset': i,
                    'type': 'api_redirect',
                    'bytes': memory_content[i:i+6].hex()
                })
        
        # Detect trampoline hooks
        trampoline_patterns = self._find_trampoline_patterns(memory_content)
        hook_analysis['trampoline_hooks'].extend(trampoline_patterns)
        
        return hook_analysis
    def _scan_iat_modifications(self, memory_content):
        """
        Scan Import Address Table for modifications and hooks
        Returns detailed analysis of IAT alterations
        """
        iat_analysis = {
            'modifications': [],
            'suspicious_imports': [],
            'redirections': [],
            'timestamp': time.time()
        }
        
        # IAT modification patterns
        IAT_PATTERNS = {
            'direct_jump': rb'\xFF\x25([\x00-\xFF]{4})',  # JMP DWORD PTR
            'indirect_call': rb'\xFF\x15([\x00-\xFF]{4})',  # CALL DWORD PTR
            'push_ret_hook': rb'\x68([\x00-\xFF]{4})\xC3',  # PUSH addr; RET
        }
        
        # Scan for modifications
        for pattern_type, pattern in IAT_PATTERNS.items():
            matches = re.finditer(pattern, memory_content)
            for match in matches:
                target_addr = int.from_bytes(match.group(1), byteorder='little')
                
                modification = {
                    'type': pattern_type,
                    'offset': match.start(),
                    'target': hex(target_addr),
                    'original_bytes': memory_content[match.start():match.start()+6].hex()
                }
                
                # Check if target is within valid range
                if target_addr > 0x70000000:
                    modification['suspicious'] = True
                    iat_analysis['suspicious_imports'].append(modification)
                
                iat_analysis['modifications'].append(modification)
        
        # Check for API forwarding
        forwarding_patterns = self._check_api_forwarding(memory_content)
        if forwarding_patterns:
            iat_analysis['redirections'].extend(forwarding_patterns)
        
        return iat_analysis
    def _check_api_forwarding(self, memory_content):
        """
        Detect and analyze API forwarding patterns and redirections
        """
        forwarding_analysis = {
            'forwards': [],
            'chains': [],
            'suspicious_forwards': [],
            'timestamp': time.time()
        }
        
        # Known API forwarding patterns
        FORWARD_PATTERNS = {
            'standard_forward': rb'.*\.(dll|DLL|exe|EXE)\..*',
            'ordinal_forward': rb'#\d+',
            'api_ms_forward': rb'API-MS-Win-.*',
            'ext_ms_forward': rb'EXT-MS-.*'
        }
        
        # Track forwarding chains
        forwarding_chain = {}
        
        # Analyze potential forwarding entries
        for i in range(len(memory_content) - 8):
            # Check for DLL references
            if memory_content[i:i+4] in [b'.dll', b'.DLL']:
                # Extract potential forward
                forward_start = max(0, i-64)
                forward_end = min(len(memory_content), i+64)
                potential_forward = memory_content[forward_start:forward_end]
                
                for name, pattern in FORWARD_PATTERNS.items():
                    matches = re.finditer(pattern, potential_forward)
                    for match in matches:
                        forward_info = {
                            'type': name,
                            'offset': forward_start + match.start(),
                            'target': potential_forward[match.start():match.end()].decode('ascii'),
                            'bytes': potential_forward[match.start():match.end()].hex()
                        }
                        logging.debug(f"Potential API forward: {forward_info}")
                        # Check for suspicious characteristics
                        if self._is_suspicious_forward(forward_info['target']):
                            forward_info['suspicious'] = True
                            forwarding_analysis['suspicious_forwards'].append(forward_info)
                        
                        forwarding_analysis['forwards'].append(forward_info)
                        logging.debug(f"Potential API forward: {forward_info}")
                        # Track forwarding chain
                        if forward_info['target'] in forwarding_chain:
                            chain = [forward_info['target']]
                            next_forward = forwarding_chain[forward_info['target']]
                            while next_forward and next_forward not in chain:
                                chain.append(next_forward)
                                next_forward = forwarding_chain.get(next_forward)
                            
                            if len(chain) > 1:
                                forwarding_analysis['chains'].append({
                                    'start': forward_info['target'],
                                    'chain': chain,
                                    'length': len(chain)
                                })
        logging.debug(f"Forwarding analysis: {forwarding_analysis}")   
        return forwarding_analysis

    def _is_suspicious_forward(self, forward_target):
        """
        Check if API forward target is suspicious
        """
        SUSPICIOUS_INDICATORS = [
            r'\\\\',  # Double backslashes
            r'\.\.',  # Parent directory reference
            r'temp',  # Temporary directory
            r'%\w+%',  # Environment variables
            r'http[s]?://',  # URLs
            r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}'  # IP addresses
        ]
        
        return any(re.search(pattern, forward_target, re.IGNORECASE) 
                for pattern in SUSPICIOUS_INDICATORS)
    def _extract_hook_target(self, memory_content, offset):
        """Extract target address from hook instruction"""
        try:
            # Extract 4 bytes after hook instruction
            target_bytes = memory_content[offset+2:offset+6]
            target_address = int.from_bytes(target_bytes, byteorder='little')
            return hex(target_address)
        except:
            return None

    def _find_trampoline_patterns(self, memory_content):
        """Detect trampoline hook patterns"""
        trampolines = []
        
        # Common trampoline patterns
        TRAMPOLINE_SIGNATURES = [
            (rb'\xFF\x25[\x00-\xFF]{4}\x90\x90', 'jump_trampoline'),
            (rb'\x68[\x00-\xFF]{4}\x9C\x60', 'push_context_save'),
            (rb'\x60\x9C\xFF\x25', 'context_save_jump')
        ]
        
        for pattern, hook_type in TRAMPOLINE_SIGNATURES:
            matches = re.finditer(pattern, memory_content)
            for match in matches:
                trampolines.append({
                    'type': hook_type,
                    'offset': match.start(),
                    'size': len(match.group()),
                    'bytes': memory_content[match.start():match.start()+16].hex()
                })
        
        return trampolines

    def _check_memory_permissions(self, process_info):
        """
        Verify memory permissions and detect suspicious configurations
        """
        permission_check = {
            'valid': True,
            'violations': [],
            'suspicious_regions': [],
            'protection_analysis': {}
        }
        
        # Memory protection constants
        PAGE_EXECUTE = 0x10
        PAGE_EXECUTE_READ = 0x20
        PAGE_EXECUTE_READWRITE = 0x40
        PAGE_EXECUTE_WRITECOPY = 0x80
        
        try:
            # Analyze each memory region
            for region in process_info.get('memory_regions', []):
                protection = region.get('Protect', 0)
                base_addr = region.get('BaseAddress', 0)
                
                # Check for suspicious combinations
                if protection & PAGE_EXECUTE_READWRITE:
                    permission_check['violations'].append({
                        'type': 'rwx_memory',
                        'address': hex(base_addr),
                        'size': region.get('RegionSize', 0)
                    })
                    permission_check['valid'] = False
                
                # Track executable regions
                if protection & (PAGE_EXECUTE | PAGE_EXECUTE_READ):
                    permission_check['protection_analysis'][hex(base_addr)] = {
                        'executable': True,
                        'writable': bool(protection & PAGE_EXECUTE_READWRITE),
                        'size': region.get('RegionSize', 0)
                    }
                
                # Check for suspicious locations
                if base_addr > 0x70000000 and (protection & PAGE_EXECUTE):
                    permission_check['suspicious_regions'].append({
                        'type': 'high_memory_executable',
                        'address': hex(base_addr),
                        'protection': hex(protection)
                    })
                if protection & (PAGE_EXECUTE_WRITECOPY):
                    permission_check['suspicious_regions'].append({
                        'type': 'write_copy_executable',
                        'address': hex(base_addr),
                        'protection': hex(protection)
                    })
        except Exception as e:
            permission_check['valid'] = False
            permission_check['violations'].append({
                'type': 'check_error',
                'error': str(e)
            })
        
        return permission_check
    def _capture_memory_state(self, pid):
        """Capture memory state for evasion analysis"""
        memory_state = {
            'timestamp': time.time(),
            'regions': [],
            'permissions': [],
            'mapped_files': []
        }
        
        try:
            process = psutil.Process(pid)
            memory_maps = process.memory_maps()
            for mmap in memory_maps:
                memory_state['regions'].append({
                    'addr': mmap.addr,
                    'perms': mmap.perms,
                    'path': mmap.path,
                    'rss': mmap.rss,
                    'size': mmap.size
                })
        except Exception as e:
            logging.debug(f"Memory state capture failed: {str(e)}")
            
        return memory_state
    def _is_protected_process(self, pid):
        PROTECTED_PROCESSES = [
        "Registry",  # Registry process
        "smss.exe",  # Session Manager Subsystem
        "csrss.exe",  # Client Server Runtime Process
        "wininit.exe",  # Windows Initialization Process
        "services.exe",  # Services Control Manager
        "lsass.exe",  # Local Security Authority Subsystem Service
        "winlogon.exe",  # Windows Logon Process
        "System",  # Windows System Process (PID 4)
        "System Idle Process"  # System Idle Process (PID 0)
        ]
        """Check if a process is a protected Windows system process"""
        # Special system PIDs
        if pid in [0, 4, 184]:  # System Idle, System, Registry
            return True
            
        # Known protected process PIDs (add others as needed)
        if pid in [668]:  # smss.exe is typically PID 668
            return True
            
        # Check process name against protected list
        try:
            import psutil
            process_name = psutil.Process(pid).name()
            return process_name in PROTECTED_PROCESSES
        except:
            # If we can't access the process, check PID range for common system processes
            # System processes are often in lower PID ranges
            return pid < 1000 and pid % 4 == 0  # Heuristic for likely system processes
    def _verify_process_tree(self, pid):
        PROTECTED_PROCESSES = [
        "Registry",  # Registry process
        "smss.exe",  # Session Manager Subsystem
        "csrss.exe",  # Client Server Runtime Process
        "wininit.exe",  # Windows Initialization Process
        "services.exe",  # Services Control Manager
        "lsass.exe",  # Local Security Authority Subsystem Service
        "winlogon.exe",  # Windows Logon Process
        "System",  # Windows System Process (PID 4)
        "System Idle Process"  # System Idle Process (PID 0)
        ]
        """Verify process relationships for evasion detection with improved system process awareness"""
        tree_info = {
            'parent': None,
            'children': [],
            'creation_time': None,
            'suspicious_relations': [],
            'is_system_process': False,
            'legitimate_relationship': True,  # Default to true unless proven otherwise
            'suspicious': False  # Final determination
        }
        
        try:
            # Check if this is a special protected process
            if pid in [0, 4]:  # System Idle Process or System
                tree_info['is_system_process'] = True
                return tree_info
                
            # For specific processes like Registry that might not be accessible via psutil
            try:
                process_info = self._get_process_info_winapi(pid)
                if not hasattr(self._get_process_info_winapi, '_get_process_info_winapi'):
                    logging.error(f"self._get_process_info_winapi is not a scanner object! Type: {type(self._get_process_info_winapi)}, Value: {self._get_process_info_winapi}")
                if process_info and process_info.get('name') in PROTECTED_PROCESSES:
                    tree_info['is_system_process'] = True
                    # Still try to get relationships with psutil, but don't mark as suspicious if it fails
            except Exception:
                pass
            
            # Get process info using psutil
            try:
                process = psutil.Process(pid)
                tree_info['creation_time'] = process.create_time()
                process_name = process.name()
                
                # Get parent info
                try:
                    parent = process.parent()
                    if parent:
                        tree_info['parent'] = {
                            'pid': parent.pid,
                            'name': parent.name(),
                            'create_time': parent.create_time()
                        }
                        
                        # Check if the parent-child relationship is legitimate for system processes
                        # Define legitimate parent-child relationships
                        legitimate_relationships = {
                            "smss.exe": [4, "System"],  # smss.exe is started by System (PID 4)
                            "csrss.exe": ["smss.exe", "wininit.exe"],
                            "wininit.exe": ["smss.exe"],
                            "services.exe": ["wininit.exe"],
                            "lsass.exe": ["wininit.exe"],
                            "winlogon.exe": ["smss.exe"],
                            "svchost.exe": ["services.exe"],
                        }
                        
                        # Check if process is a known system process with defined relationships
                        if process_name.lower() in [k.lower() for k in legitimate_relationships.keys()]:
                            legitimate_parents = legitimate_relationships[process_name]
                            parent_name = parent.name()
                            
                            # Check if parent is in the legitimate list (by PID or name)
                            if parent.pid in legitimate_parents or parent_name in legitimate_parents:
                                logging.debug(f"Legitimate parent-child relationship: {parent_name} ({parent.pid}) -> {process_name} ({pid})")
                            else:
                                logging.warning(f"Suspicious: Process {process_name} (PID {pid}) has unexpected parent {parent_name} (PID {parent.pid})")
                                tree_info['legitimate_relationship'] = False
                                tree_info['suspicious'] = True
                        
                        # Special case for processes with System as parent
                        elif parent.pid == 4 and process_name in PROTECTED_PROCESSES:
                            logging.debug(f"System process {process_name} with System parent (PID 4) - this is legitimate")
                        elif parent.pid == 4:
                            logging.info(f"Process {process_name} (PID {pid}) has system parent {parent.pid}")
                            # This is unusual but not always malicious
                except psutil.NoSuchProcess:
                    parent_info = self._get_parent_process_info_winapi(pid)
                    tree_info['suspicious_relations'].append(parent_info)
                    
                    if parent_info:
                        tree_info['parent'] = {
                            'pid': parent_info.get('pid'),
                            'name': parent_info.get('name', 'Unknown'),
                            'create_time': parent_info.get('create_time', 0)
                        }
                
                # Get children info
                for child in process.children():
                    try:
                        tree_info['children'].append({
                            'pid': child.pid,
                            'name': child.name(),
                            'create_time': child.create_time()
                        })
                    except psutil.NoSuchProcess:
                        child_info = self._get_child_processes_winapi(pid)
                        if child_info:
                            tree_info['suspicious_relations'].extend(child_info)
                            for c in child_info:
                                tree_info['children'].append({
                                    'pid': c.get('pid'),
                                    'name': c.get('name', 'Unknown'),
                                    'create_time': c.get('create_time', 0)
                                })
                
                # Detect evasion techniques
                if process.name() in PROTECTED_PROCESSES and not tree_info['is_system_process']:
                    logging.warning(f"Possible masquerading: Process {pid} claims to be {process.name()} but isn't a verified system process")
                    tree_info['suspicious'] = True
                    
            except psutil.NoSuchProcess:
                logging.debug(f"Process {pid} no longer exists")
                
            except psutil.AccessDenied:
                logging.debug(f"Access denied to process {pid}")
                # Fall back to WinAPI for protected processes
                process_info = self._get_process_info_winapi(pid)
                if not hasattr(self._get_process_info_winapi, '_get_process_info_winapi'):
                    logging.error(f"self._get_process_info_winapi is not a scanner object! Type: {type(self._get_process_info_winapi)}, Value: {self._get_process_info_winapi}")
                if process_info:
                    # Use available info without marking as suspicious if it's a protected process
                    if process_info.get('access_denied_expected', False):
                        tree_info['is_system_process'] = True
            
        except Exception as e:
            logging.debug(f"Process tree verification failed: {str(e)}")
        
        # Mark as suspicious if any suspicious relations were found
        if tree_info['suspicious_relations'] and not tree_info['is_system_process']:
            tree_info['suspicious'] = True
        
        return tree_info

    def _standard_process_info_gathering(self, process_handle, pid):
        """Standard process information gathering with security checks"""
        process_info = {
            'pid': pid,
            'handle': process_handle,
            'base_info': {},
            'security_info': {},
            'memory_info': {},
            'module_info': {}
        }
        
        try:
            # Basic process information
            process = psutil.Process(pid)
            process_info['base_info'] = {
                'name': process.name(),
                'exe': process.exe(),
                'cmdline': process.cmdline(),
                'create_time': process.create_time(),
                'status': process.status()
            }
            
            # Security information
            process_info['security_info'] = {
                'username': process.username(),
                'cwd': process.cwd(),
                'nice': process.nice(),
                'num_threads': process.num_threads(),
                'cpu_percent': process.cpu_percent(),
                'memory_percent': process.memory_percent()
            }
            
            # Memory information
            memory_info = process.memory_info()
            process_info['memory_info'] = {
                'rss': memory_info.rss,
                'vms': memory_info.vms,
                'shared': memory_info.shared if hasattr(memory_info, 'shared') else None,
                'text': memory_info.text if hasattr(memory_info, 'text') else None,
                'data': memory_info.data if hasattr(memory_info, 'data') else None
            }
            
            # Module information
            try:
                modules = win32process.EnumProcessModules(process_handle)
                process_info['module_info'] = {
                    'modules': [win32process.GetModuleFileNameEx(process_handle, mod) for mod in modules],
                    'base_module': win32process.GetModuleFileNameEx(process_handle, modules[0]) if modules else None
                }
            except Exception as e:
                process_info['module_info'] = {'error': str(e)}
                
        except Exception as e:
            logging.debug(f"Process info gathering failed: {str(e)}")
            process_info['error'] = str(e)
            
        return process_info
    def _get_process_threads(self, handle):
        """Get process threads information"""
        threads = []
        snapshot = self.CreateToolhelp32Snapshot(self.TH32CS_SNAPTHREAD, win32api.GetProcessId(handle))
        if snapshot:
            try:
                thread_entry = THREADENTRY32()
                thread_entry.dwSize = ctypes.sizeof(thread_entry)
                have_more = self.Thread32First(snapshot, thread_entry)
                while have_more:
                    if thread_entry.th32OwnerProcessID == win32api.GetProcessId(handle):
                        threads.append({
                            'tid': thread_entry.th32ThreadID,
                            'priority': thread_entry.tpBasePri
                        })
                    have_more = win32process.Thread32Next(snapshot, thread_entry)
            finally:
                win32api.CloseHandle(snapshot)
        return threads

    def _check_security_flags(self, handle):
        """Check process security flags"""
        flags = []
        try:
            if win32security.IsProcessRestricted(handle):
                flags.append('RESTRICTED')
            if win32security.GetTokenInformation(handle, win32security.TokenElevation):
                flags.append('ELEVATED')
        except:
            flags.append('ACCESS_DENIED')
        return flags

    def _detect_injection_patterns(self, handle):
        """Detect common injection patterns"""
        patterns = []
        regions = self.scan_memory_regions(handle)
        for region in regions:
            if region['protection'] & win32con.PAGE_EXECUTE_READWRITE:
                patterns.append('RWX_MEMORY')
            if region['type'] == win32con.MEM_PRIVATE and region['protection'] & win32con.PAGE_EXECUTE:
                patterns.append('PRIVATE_EXECUTABLE')
        return patterns
    def _scan_suspicious_patterns(self, process_handle):
        PROTECTED_PROCESSES = [
        "Registry",  # Registry process
        "smss.exe",  # Session Manager Subsystem
        "csrss.exe",  # Client Server Runtime Process
        "wininit.exe",  # Windows Initialization Process
        "services.exe",  # Services Control Manager
        "lsass.exe",  # Local Security Authority Subsystem Service
        "winlogon.exe",  # Windows Logon Process
        "System",  # Windows System Process (PID 4)
        "System Idle Process"  # System Idle Process (PID 0)
        ]
        """Safely scan process for suspicious memory patterns with proper protected process handling"""
        suspicious_patterns = []
        
        try:
            # First check if this is a protected process that should be skipped
            process_name = self.get_process_name(process_handle)
            if process_name in PROTECTED_PROCESSES:
                logging.debug(f"Skipping suspicious pattern scan for protected process: {process_name}")
                return []  # Return empty list instead of attempting to scan
                
            # Get process ID for reference
            pid = ctypes.windll.kernel32.GetProcessId(process_handle)
            
            # Get process info
            process_info = self._get_process_info_winapi(pid, process_handle)
            if not process_info or process_info.get('access_denied_expected', False):
                return []
                
            # Enumerate memory regions
            memory_regions = self._enumerate_memory_regions_winapi(process_handle)
            
            # Define suspicious patterns to search for
            patterns = [
                # Shellcode patterns
                b"\x55\x8B\xEC\x83\xEC",  # Common function prologue
                b"\x33\xC0\x40\xC3",       # xor eax, eax; inc eax; ret
                b"\x31\xC0\x40\xC3",       # xor eax, eax; inc eax; ret
                
                # PowerShell encoded commands
                b"powershell -e",
                b"powershell.exe -e",
                
                # Other suspicious patterns
                b"CreateRemoteThread",
                b"VirtualAllocEx",
                b"WriteProcessMemory"
            ]
            
            # Scan each memory region
            for region in memory_regions:
                # Skip non-readable regions
                if not region.get('readable', False):
                    continue
                    
                # Now correctly pass all required arguments
                region_results = self._scan_memory_content_winapi(process_handle, region, process_info, patterns)
                if region_results:
                    suspicious_patterns.extend(region_results)
                    
            return suspicious_patterns
            
        except Exception as e:
            logging.debug(f"Error in _scan_suspicious_patterns: {str(e)}")
            return []
    def analyze_system_handles(log_results=True):
        """Safely analyze system handles without modifying them"""
        
        
        # Results collection
        results = {
            'total_handles': 0,
            'handle_types': defaultdict(int),
            'suspicious_handles': [],
            'processes_with_handles': defaultdict(int)
        }
        
        try:
            # Get handle information using NtQuerySystemInformation
            ntdll = ctypes.WinDLL('ntdll.dll')
            
            # SystemHandleInformation = 16
            SystemHandleInformation = 16
            
            # Initial buffer size
            buffer_size = 0x10000
            handle_info = ctypes.create_string_buffer(buffer_size)
            
            # Structure for system handle info
            class SYSTEM_HANDLE_TABLE_ENTRY_INFO(ctypes.Structure):
                _fields_ = [
                    ("ProcessId", ctypes.c_ushort),
                    ("CreatorBackTraceIndex", ctypes.c_ushort),
                    ("ObjectTypeIndex", ctypes.c_ubyte),
                    ("HandleAttributes", ctypes.c_ubyte),
                    ("HandleValue", ctypes.c_ushort),
                    ("Object", ctypes.c_void_p),
                    ("GrantedAccess", ctypes.c_ulong),
                ]
            
            # Get required size first
            size_needed = ctypes.c_ulong(0)
            status = ntdll.NtQuerySystemInformation(
                SystemHandleInformation,
                handle_info,
                buffer_size,
                ctypes.byref(size_needed)
            )
            
            # If buffer too small, resize
            if size_needed.value > buffer_size:
                buffer_size = size_needed.value + 0x1000
                handle_info = ctypes.create_string_buffer(buffer_size)
                status = ntdll.NtQuerySystemInformation(
                    SystemHandleInformation,
                    handle_info,
                    buffer_size,
                    ctypes.byref(size_needed)
                )
            
            # Check if we got the handle information
            if status >= 0:
                # Parse the handle information
                handle_count = ctypes.cast(handle_info, ctypes.POINTER(ctypes.c_ulong))[0]
                results['total_handles'] = handle_count
                
                # Process each handle
                handle_array = ctypes.cast(
                    ctypes.addressof(handle_info) + ctypes.sizeof(ctypes.c_ulong),
                    ctypes.POINTER(SYSTEM_HANDLE_TABLE_ENTRY_INFO)
                )
                
                for i in range(handle_count):
                    handle_entry = handle_array[i]
                    results['handle_types'][handle_entry.ObjectTypeIndex] += 1
                    results['processes_with_handles'][handle_entry.ProcessId] += 1
                    
                    # Check for potential suspicious handles
                    if handle_entry.HandleAttributes & 0x01:  # HANDLE_FLAG_INHERIT
                        if handle_entry.GrantedAccess & 0xF0000:  # High-privilege access
                            results['suspicious_handles'].append({
                                'pid': handle_entry.ProcessId,
                                'handle_value': handle_entry.HandleValue,
                                'type_index': handle_entry.ObjectTypeIndex,
                                'granted_access': hex(handle_entry.GrantedAccess)
                            })
            
            # Log the results if requested
            if log_results:
                logging.info(f"Total system handles: {results['total_handles']}")
                logging.info(f"Processes with handles: {len(results['processes_with_handles'])}")
                logging.info(f"Suspicious handles found: {len(results['suspicious_handles'])}")
                
                for suspicious in results['suspicious_handles']:
                    logging.warning(f"Suspicious handle: PID {suspicious['pid']}, " +
                                f"Value {suspicious['handle_value']}, " +
                                f"Access {suspicious['granted_access']}")
            
            return results
        
        except Exception as e:
            logging.error(f"Error analyzing system handles: {str(e)}")
            return {'error': str(e)}    
    def audit_process_handles(self, target_pid=None):
        """Perform a security audit of process handles without modifying them"""

        kernel32 = None
        results = {
            'anomalies': [],
            'process_info': {},
            'handle_stats': {}
        }

        # --- FIX: Always extract integer PID if target_pid is a dict ---
        if target_pid is not None:
            if isinstance(target_pid, dict):
                target_pid = target_pid.get('pid', 0)
            elif hasattr(target_pid, 'pid'):
                target_pid = target_pid.pid
            try:
                target_pid = int(target_pid)
            except Exception:
                logging.error(f"Invalid target_pid: {target_pid}")
                return {'error': 'Invalid PID'}

        # Get process list
        processes = self.get_process_list()
        if target_pid:
            try:
                process = win32api.OpenProcess(
                    win32con.PROCESS_QUERY_INFORMATION | win32con.PROCESS_VM_READ,
                    False, target_pid
                )
                processes = [(target_pid, process)]
            except Exception as e:
                logging.error(f"Could not open process {target_pid}: {str(e)}")
                return {'error': str(e)}
        else:
            # Get all processes
            import psutil
            for proc in psutil.process_iter(['pid', 'name']):
                try:
                    pid = proc.info['pid']
                    if not isinstance(pid, int):
                        continue
                    process = win32api.OpenProcess(
                        win32con.PROCESS_QUERY_INFORMATION | win32con.PROCESS_VM_READ,
                        False, pid
                    )
                    processes.append((pid, process))
                except Exception as e:
                    logging.error(f"Could not open process {proc.info}: {str(e)}")
                    continue
        
        # Define structures for handle information
        class UNICODE_STRING(ctypes.Structure):
            _fields_ = [
                ("Length", ctypes.c_ushort),
                ("MaximumLength", ctypes.c_ushort),
                ("Buffer", ctypes.c_void_p)
            ]
        
        class OBJECT_BASIC_INFORMATION(ctypes.Structure):
            _fields_ = [
                ("Attributes", ctypes.c_ulong),
                ("GrantedAccess", ctypes.c_ulong),
                ("HandleCount", ctypes.c_ulong),
                ("PointerCount", ctypes.c_ulong),
                ("PagedPoolCharge", ctypes.c_ulong),
                ("NonPagedPoolCharge", ctypes.c_ulong),
                ("Reserved", ctypes.c_ulong * 3),
                ("NameInfoSize", ctypes.c_ulong),
                ("TypeInfoSize", ctypes.c_ulong),
                ("SecurityDescriptorSize", ctypes.c_ulong),
                ("CreationTime", ctypes.c_int64)
            ]
        
        class OBJECT_NAME_INFORMATION(ctypes.Structure):
            _fields_ = [("Name", UNICODE_STRING)]
        
        # Check each process
        for pid, process_handle in processes:
            try:
                # Get process name and path
                process_path = win32process.GetModuleFileNameEx(process_handle, 0)
                process_name = process_path.split('\\')[-1]
                
                # Store basic process info
                results['process_info'][pid] = {
                    'name': process_name,
                    'path': process_path,
                    'handle_count': 0,
                    'suspicious_handles': [],
                    'handle_types': {}  # Track handle types
                }
                
                # Get handle information for the process
                kernel32 = ctypes.windll.kernel32
                ntdll = ctypes.windll.ntdll
                NtQueryObject = ntdll.NtQueryObject
                
                # Define constants for NtQueryObject
                ObjectBasicInformation = 0
                ObjectNameInformation = 1
                ObjectTypeInformation = 2
                
                try:
                    # Check for suspicious handle characteristics
                    handle_info_class = ObjectBasicInformation
                    handle_info = ctypes.create_string_buffer(0x10000)
                    
                    for handle_value in range(0, 0x1000):  # Check first 4096 handles
                        try:
                            # Try to duplicate the handle for inspection
                            dup_handle = ctypes.c_void_p()
                            
                            success = kernel32.DuplicateHandle(
                                process_handle.handle,
                                handle_value,
                                kernel32.GetCurrentProcess(),
                                ctypes.byref(dup_handle),
                                0,
                                False,
                                win32con.DUPLICATE_SAME_ACCESS
                            )
                            
                            if success:
                                # We got the handle, now check its basic information
                                results['process_info'][pid]['handle_count'] += 1
                                
                                # Get basic handle information
                                basic_info = OBJECT_BASIC_INFORMATION()
                                status = NtQueryObject(
                                    dup_handle,
                                    handle_info_class,  # Now we're using handle_info_class
                                    ctypes.byref(basic_info),
                                    ctypes.sizeof(basic_info),
                                    None
                                )
                                
                                # Try to get the object name
                                name_info_buffer = ctypes.create_string_buffer(0x1000)
                                length = ctypes.c_ulong(0)
                                
                                name_status = NtQueryObject(
                                    dup_handle,
                                    ObjectNameInformation,
                                    name_info_buffer,
                                    ctypes.sizeof(name_info_buffer),
                                    ctypes.byref(length)
                                )
                                
                                # Try to get object type information
                                type_info_buffer = handle_info  # Now we're using handle_info buffer
                                type_length = ctypes.c_ulong(0)
                                
                                type_status = NtQueryObject(
                                    dup_handle,
                                    ObjectTypeInformation,
                                    type_info_buffer,
                                    ctypes.sizeof(type_info_buffer),
                                    ctypes.byref(type_length)
                                )
                                
                                # Extract handle information
                                handle_data = {
                                    'handle_value': handle_value,
                                    'has_name': name_status >= 0 and length.value > 0,
                                    'basic_info': {}
                                }
                                
                                # Add basic info if available
                                if status >= 0:
                                    handle_data['basic_info'] = {
                                        'handle_count': basic_info.HandleCount,
                                        'pointer_count': basic_info.PointerCount,
                                        'granted_access': basic_info.GrantedAccess
                                    }
                                
                                # Extract type information if available
                                if type_status >= 0 and type_length.value > 0:
                                    # This requires more code to properly extract the type name
                                    # For simplicity, just note that we have type info
                                    handle_data['has_type_info'] = True
                                    
                                    # Track handle types in statistics
                                    handle_type = "Unknown"  # You'd extract the actual type here
                                    if handle_type not in results['process_info'][pid]['handle_types']:
                                        results['process_info'][pid]['handle_types'][handle_type] = 0
                                    results['process_info'][pid]['handle_types'][handle_type] += 1
                                
                                # Check for suspicious properties
                                is_suspicious = False
                                if handle_data['has_name'] and status >= 0:
                                    # Add your suspicion criteria here
                                    if basic_info.HandleCount > 100 or basic_info.PointerCount > 100:
                                        is_suspicious = True
                                
                                if is_suspicious:
                                    results['process_info'][pid]['suspicious_handles'].append(handle_data)
                                
                                # Close the duplicated handle
                                kernel32.CloseHandle(dup_handle)
                        except Exception as e:
                            # Log specific handle errors if needed
                            pass
                except Exception as e:
                    results['anomalies'].append(f"Error scanning handles for PID {pid}: {str(e)}")
                
                # Close the process handle
                win32api.CloseHandle(process_handle)
                
            except Exception as e:
                results['anomalies'].append(f"Error processing PID {pid}: {str(e)}")
                try:
                    win32api.CloseHandle(process_handle)
                except:
                    pass
        # Log results
        logging.info(f"Audited {len(processes)} processes")
        for pid, info in results['process_info'].items():
            logging.info(f"PID {pid} ({info['name']}): {info['handle_count']} handles")
            if info['suspicious_handles']:
                logging.warning(f"  Found {len(info['suspicious_handles'])} suspicious handles")
            if info['handle_types']:
                logging.info(f"  Handle types: {info['handle_types']}")
        
        # Generate handle stats
        results['handle_stats'] = {
            'total_processes': len(processes),
            'total_handles': sum(info['handle_count'] for info in results['process_info'].values()),
            'suspicious_handles': sum(len(info['suspicious_handles']) for info in results['process_info'].values())
        }
        
        return results

    def _get_process_run_keys(self, process):
        """Check if the process is referenced in Run keys (autostart)"""
        try:
            import winreg
            run_locations = []
            
            # Define registry run key locations to check
            run_keys = [
                (winreg.HKEY_CURRENT_USER, r"Software\Microsoft\Windows\CurrentVersion\Run"),
                (winreg.HKEY_CURRENT_USER, r"Software\Microsoft\Windows\CurrentVersion\RunOnce"),
                (winreg.HKEY_LOCAL_MACHINE, r"SOFTWARE\Microsoft\Windows\CurrentVersion\Run"),
                (winreg.HKEY_LOCAL_MACHINE, r"SOFTWARE\Microsoft\Windows\CurrentVersion\RunOnce"),
                (winreg.HKEY_LOCAL_MACHINE, r"SOFTWARE\WOW6432Node\Microsoft\Windows\CurrentVersion\Run")
            ]
            
            process_path = process.exe() if hasattr(process, 'exe') else None
            if not process_path:
                return []
                
            process_name = process.name().lower()
            
            for hkey, key_path in run_keys:
                try:
                    with winreg.OpenKey(hkey, key_path, 0, winreg.KEY_READ) as key:
                        # Enumerate all values in the key
                        i = 0
                        while True:
                            try:
                                name, value, _ = winreg.EnumValue(key, i)
                                
                                # Check if this process is mentioned in any run keys
                                if process_path.lower() in value.lower() or process_name in value.lower():
                                    run_locations.append({
                                        'hive': 'HKCU' if hkey == winreg.HKEY_CURRENT_USER else 'HKLM',
                                        'key': key_path,
                                        'name': name,
                                        'value': value
                                    })
                                i += 1
                            except WindowsError:
                                break
                except WindowsError:
                    continue
                    
            return run_locations
        except Exception as e:
            logging.debug(f"Error getting registry run keys: {str(e)}")
            return []

    def _get_process_image_registry(self, process):
        """Get registry information about the process executable"""
        try:
            import winreg
            
            # Get process path
            process_path = process.exe() if hasattr(process, 'exe') else None
            if not process_path:
                return {}
                
            # Check for Uninstall information
            uninstall_info = {}
            try:
                uninstall_key = r"SOFTWARE\Microsoft\Windows\CurrentVersion\Uninstall"
                with winreg.OpenKey(winreg.HKEY_LOCAL_MACHINE, uninstall_key, 0, winreg.KEY_READ) as key:
                    i = 0
                    while True:
                        try:
                            subkey_name = winreg.EnumKey(key, i)
                            with winreg.OpenKey(key, subkey_name) as subkey:
                                try:
                                    install_location = winreg.QueryValueEx(subkey, "InstallLocation")[0]
                                    display_name = winreg.QueryValueEx(subkey, "DisplayName")[0]
                                    
                                    # Check if process is from this install location
                                    if install_location and process_path.lower().startswith(install_location.lower()):
                                        uninstall_info = {
                                            'display_name': display_name,
                                            'install_location': install_location,
                                            'uninstall_key': f"{uninstall_key}\\{subkey_name}"
                                        }
                                        break
                                except (WindowsError, IndexError):
                                    pass
                            i += 1
                        except WindowsError:
                            break
            except WindowsError:
                pass
                
            # Check for App Paths
            app_paths_info = {}
            try:
                process_name = process.name()
                app_paths_key = r"SOFTWARE\Microsoft\Windows\CurrentVersion\App Paths"
                
                try:
                    with winreg.OpenKey(winreg.HKEY_LOCAL_MACHINE, f"{app_paths_key}\\{process_name}", 0, winreg.KEY_READ) as key:
                        app_paths_info = {
                            'default': winreg.QueryValueEx(key, "")[0],
                            'path': winreg.QueryValueEx(key, "Path")[0] if winreg.QueryValueEx(key, "Path") else None
                        }
                except WindowsError:
                    pass
            except Exception:
                pass
                
            return {
                'uninstall_info': uninstall_info,
                'app_paths': app_paths_info
            }
        except Exception as e:
            logging.debug(f"Error getting registry image info: {str(e)}")
            return {}

    def _get_process_registry_associations(self, process):
        """Get file and protocol associations for this process"""
        try:
            import winreg
            
            # Get process executable
            process_path = process.exe() if hasattr(process, 'exe') else None
            if not process_path:
                return []
                
            associations = []
            
            # Check file extensions associations
            try:
                with winreg.OpenKey(winreg.HKEY_CLASSES_ROOT, "", 0, winreg.KEY_READ) as root_key:
                    # Enumerate file extensions
                    i = 0
                    while True:
                        try:
                            ext = winreg.EnumKey(root_key, i)
                            # Look for file extensions (starting with dot)
                            if ext.startswith('.'):
                                try:
                                    with winreg.OpenKey(root_key, ext) as ext_key:
                                        # Get file type
                                        file_type = winreg.QueryValueEx(ext_key, "")[0]
                                        
                                        # Check the command for this file type
                                        try:
                                            with winreg.OpenKey(root_key, f"{file_type}\\shell\\open\\command") as cmd_key:
                                                cmd = winreg.QueryValueEx(cmd_key, "")[0]
                                                
                                                # Check if our process is used to open this file type
                                                if process_path.lower() in cmd.lower():
                                                    associations.append({
                                                        'type': 'file_extension',
                                                        'extension': ext,
                                                        'file_type': file_type,
                                                        'command': cmd
                                                    })
                                        except WindowsError:
                                            pass
                                except WindowsError:
                                    pass
                            i += 1
                        except WindowsError:
                            break
            except WindowsError:
                pass
                
            return associations
        except Exception as e:
            logging.debug(f"Error getting registry associations: {str(e)}")
            return []
    
                
    def validate_string(s, default="", encoding=None, process_handle=None):
        if s is None:
            return default
        if encoding:
            try:
                return s.decode(encoding)
            except (UnicodeDecodeError, AttributeError):
                return default
        return s
    def get_process_information(self, process_handle):
        """Collect comprehensive information about a process using its handle"""
        try:
            kernel32 = ctypes.windll.kernel32
            ntdll = ctypes.windll.ntdll
            
            # Create a separate bounds validation function
            def validate_bounds(value, default=0, max_value=None):
                if value is None:
                    return default
                try:
                    value = int(value)
                    if value < 0:
                        return default
                    if max_value is not None and value > max_value:
                        return max_value
                    return value
                except (ValueError, TypeError):
                    return default
            
            # Get process ID with validation
            pid = validate_bounds(kernel32.GetProcessId(process_handle), 0, 0xFFFFFFFF)     
            process_info = {
                'basic': {
                    'pid': pid,
                    'name': self.validate_string(self._get_process_name_winapi(process_handle)),
                    'exe': self.validate_string(self._get_process_path_winapi(process_handle)),
                    'cmdline': self.validate_string(self._get_process_cmdline_winapi(process_handle)) or [],
                    'cwd': self.validate_string(self._get_process_cwd_winapi(process_handle)),
                    'status': self.validate_string(self._get_process_status_winapi(process_handle)),
                    'username': self.validate_string(self._get_process_username_winapi(process_handle)),
                    'created_time': self.validate_string(self._get_process_creation_time_winapi(process_handle), 0),
                    'handles': self.validate_string(self._get_process_handle_count_winapi(process_handle), 0, 0xFFFF),
                    'threads': self.validate_string(self._get_process_thread_count_winapi(process_handle), 0, 0xFFFF),
                    'objects': self.validate_string(self._get_process_object_count_winapi(process_handle), 0, 0xFFFF),
                    'suspicious_values': [],
                    'evasion_detected': False
                },
                'resources': {
                    'cpu_percent': self.validate_string(self._get_process_cpu_usage_winapi(process_handle), 0, 100),
                    'memory_info': self._sanitize_memory_info(self._get_process_memory_info_winapi(process_handle)),
                    'num_threads': self.validate_string(self._get_process_thread_count_winapi(process_handle), 0, 0xFFFF),
                    'num_handles': self.validate_string(self._get_process_handle_count_winapi(process_handle), 0, 0xFFFF)
                },
                'integrity': {
                    'valid_pid': pid > 0 and pid < 0xFFFFFFFF,
                    'valid_handle': bool(process_handle),
                    'suspicious_values': [],
                    'evasion_detected': False
                }
            }
            
            # Additional security checks and validations for each component
            process_info['network'] = self._validate_network_info(
                self._get_process_network_info_winapi(process_handle)
            )
            
            process_info['modules'] = self._validate_modules_info(
                self._get_process_modules_winapi(process_handle)
            )
            
            process_info['parent'] = self._validate_parent_info(
                self._get_parent_process_info_winapi(pid)
            )
            
            process_info['children'] = self._validate_children_info(
                self._get_child_processes_winapi(pid)
            )
            
            # Add integrity and validation flags
            process_info['integrity'] = {
                'valid_pid': pid > 0 and pid < 0xFFFFFFFF,
                'valid_handle': bool(process_handle),
                'suspicious_values': [],
                'evasion_detected': False
            }
            
            return process_info
            
        except Exception as e:
            logging.debug(f"Error in process information collection: {str(e)}")
            return self._get_safe_default_info()
    def _get_process_handle(self, pid):
        try:
            # Try to get process handle
            process_handle = self.kernel32.OpenProcess(
                win32con.PROCESS_ALL_ACCESS, False, pid)
            
            if not process_handle:
                error = ctypes.get_last_error()
                if error == 5:  # ERROR_ACCESS_DENIED
                    logging.debug(f"Access denied to process {pid}. Try running as administrator.")
                else:
                    logging.debug(f"Error getting process handle for PID {pid}: {error}")
                return None
                
            return process_handle
        except Exception as e:
            logging.debug(f"Error getting process handle for PID {pid}: {e}")
            return None    
    def _get_process_object_count_winapi(self, process_handle):
        """Get the count of objects used by a process using Windows API Args: process_handle: Handle to the processReturns: dict: Object count information including total, by type, and suspicious objects"""
        if not process_handle:
            return {'total': 0, 'by_type': {}, 'suspicious': 0}
        kernel32 = None
        try:
            # Define necessary structures and constants
            kernel32 = ctypes.windll.kernel32
            ntdll = ctypes.windll.ntdll
            
            # Get process ID
            pid = kernel32.GetProcessId(process_handle)
            if not pid:
                return {'total': 0, 'by_type': {}, 'suspicious': 0}
            
            # Use NtQuerySystemInformation to get system handle information
            SystemHandleInformation = 16
            
            class SYSTEM_HANDLE_TABLE_ENTRY_INFO(ctypes.Structure):
                _fields_ = [
                    ("UniqueProcessId", ctypes.c_ushort),
                    ("CreatorBackTraceIndex", ctypes.c_ushort),
                    ("ObjectTypeIndex", ctypes.c_ubyte),
                    ("HandleAttributes", ctypes.c_ubyte),
                    ("HandleValue", ctypes.c_ushort),
                    ("Object", ctypes.c_void_p),
                    ("GrantedAccess", ctypes.c_ulong)
                ]
                
            class SYSTEM_HANDLE_INFORMATION(ctypes.Structure):
                _fields_ = [
                    ("NumberOfHandles", ctypes.c_ulong),
                    ("Handles", SYSTEM_HANDLE_TABLE_ENTRY_INFO * 1)
                ]
            
            # Set up NtQuerySystemInformation function
            NtQuerySystemInformation = ntdll.NtQuerySystemInformation
            NtQuerySystemInformation.argtypes = [
                ctypes.c_ulong,
                ctypes.c_void_p,
                ctypes.c_ulong,
                ctypes.POINTER(ctypes.c_ulong)
            ]
            NtQuerySystemInformation.restype = ctypes.c_ulong
            
            # First get the size needed
            return_length = ctypes.c_ulong(0)
            status = NtQuerySystemInformation(SystemHandleInformation, None, 0, ctypes.byref(return_length))
            
            # Allocate buffer with the returned size (plus some extra to be safe)
            buffer_size = return_length.value + 4096
            handle_info_buffer = ctypes.create_string_buffer(buffer_size)
            
            # Get the handle information
            status = NtQuerySystemInformation(
                SystemHandleInformation, 
                handle_info_buffer, 
                buffer_size, 
                ctypes.byref(return_length)
            )
            
            if status != 0:  # STATUS_SUCCESS
                return {'total': 0, 'by_type': {}, 'suspicious': 0}
                
            # Parse the handle information
            handle_info = ctypes.cast(handle_info_buffer, ctypes.POINTER(SYSTEM_HANDLE_INFORMATION)).contents
            
            # Dictionary to store handle types (using ObjectTypeIndex as key)
            type_indices = {}
            object_counts = {'total': 0, 'by_type': {}, 'suspicious': 0}
            
            # Process each handle that belongs to our target process
            for i in range(handle_info.NumberOfHandles):
                handle_entry = handle_info.Handles[i]
                
                # Only count handles belonging to our target process
                if handle_entry.UniqueProcessId != pid:
                    continue
                    
                object_counts['total'] += 1
                
                # Try to get the object type from our cached types, or get it if not available
                type_index = handle_entry.ObjectTypeIndex
                object_type = "Unknown"
                
                if type_index in type_indices:
                    object_type = type_indices[type_index]
                else:
                    # Try to duplicate the handle to get its type
                    try:
                        target_handle = ctypes.c_void_p(0)
                        result = kernel32.DuplicateHandle(
                            process_handle,
                            handle_entry.HandleValue,
                            kernel32.GetCurrentProcess(),
                            ctypes.byref(target_handle),
                            0,
                            False,
                            2  # DUPLICATE_SAME_ACCESS
                        )
                        
                        if result and target_handle.value:
                            # Get the type using NtQueryObject
                            ObjectTypeInformation = 2
                            
                            class UNICODE_STRING(ctypes.Structure):
                                _fields_ = [
                                    ("Length", ctypes.c_ushort),
                                    ("MaximumLength", ctypes.c_ushort),
                                    ("Buffer", ctypes.c_void_p)
                                ]
                                
                            class OBJECT_TYPE_INFORMATION(ctypes.Structure):
                                _fields_ = [
                                    ("TypeName", UNICODE_STRING),
                                    ("TotalNumberOfObjects", ctypes.c_ulong),
                                    ("TotalNumberOfHandles", ctypes.c_ulong),
                                    # Other fields omitted for brevity
                                ]
                            
                            # Query the object type
                            NtQueryObject = ntdll.NtQueryObject
                            NtQueryObject.argtypes = [
                                ctypes.c_void_p,
                                ctypes.c_ulong,
                                ctypes.c_void_p,
                                ctypes.c_ulong,
                                ctypes.POINTER(ctypes.c_ulong)
                            ]
                            NtQueryObject.restype = ctypes.c_ulong
                            
                            type_info_buffer = ctypes.create_string_buffer(4096)
                            status = NtQueryObject(
                                target_handle,
                                ObjectTypeInformation,
                                type_info_buffer,
                                4096,
                                None
                            )
                            
                            if status == 0:  # STATUS_SUCCESS
                                type_info = ctypes.cast(type_info_buffer, ctypes.POINTER(OBJECT_TYPE_INFORMATION)).contents
                                # Extract the type name from the UNICODE_STRING
                                if type_info.TypeName.Length > 0:
                                    buffer = ctypes.create_string_buffer(type_info.TypeName.Length + 2)
                                    ctypes.memmove(buffer, type_info.TypeName.Buffer, type_info.TypeName.Length)
                                    object_type = buffer.raw.decode('utf-16-le').rstrip('\0')
                                    
                                    # Cache this type index for future references
                                    type_indices[type_index] = object_type
                                    
                            # Close the duplicated handle
                            kernel32.CloseHandle(target_handle)
                    except:
                        # If we can't get the type, just use Unknown
                        pass
                
                # Update the count for this object type
                if object_type in object_counts['by_type']:
                    object_counts['by_type'][object_type] += 1
                else:
                    object_counts['by_type'][object_type] = 1
                    
                # Check for suspicious handles
                access = handle_entry.GrantedAccess
                
                # Identify potentially suspicious access patterns
                if (object_type == 'Process' and (access & 0x1FFFFF == 0x1FFFFF)) or \
                (object_type == 'Thread' and (access & 0x1F03FF == 0x1F03FF)) or \
                (object_type == 'Section' and (access & 0x6 == 0x6)):  # SECTION_MAP_WRITE | SECTION_MAP_EXECUTE
                    object_counts['suspicious'] += 1
            
            return object_counts
            
        except Exception as e:
            logging.debug(f"Error getting process object count: {str(e)}")
            return {'total': 0, 'by_type': {}, 'suspicious': 0}
        
    def _get_process_objects_info_winapi(self, process_handle):
        """
        Use NtQueryObject to gather information about objects used by the process
        """
        if not process_handle:
            return []
        
        object_info = []
        kernel32 = None
        ntdll = None
        try:
            # Define necessary structures and constants
            ULONG_PTR = ctypes.c_ulonglong if ctypes.sizeof(ctypes.c_void_p) == 8 else ctypes.c_ulong
            
            class UNICODE_STRING(ctypes.Structure):
                _fields_ = [
                    ("Length", ctypes.c_ushort),
                    ("MaximumLength", ctypes.c_ushort),
                    ("Buffer", ctypes.c_void_p)
                ]
                
            class OBJECT_BASIC_INFORMATION(ctypes.Structure):
                _fields_ = [
                    ("Attributes", ctypes.c_ulong),
                    ("GrantedAccess", ctypes.c_ulong),
                    ("HandleCount", ctypes.c_ulong),
                    ("PointerCount", ctypes.c_ulong),
                    ("PagedPoolCharge", ctypes.c_ulong),
                    ("NonPagedPoolCharge", ctypes.c_ulong),
                    ("Reserved", ctypes.c_ulong * 3),
                    ("NameInfoSize", ctypes.c_ulong),
                    ("TypeInfoSize", ctypes.c_ulong),
                    ("SecurityDescriptorSize", ctypes.c_ulong),
                    ("CreationTime", ctypes.c_int64)
                ]
                
            class OBJECT_TYPE_INFORMATION(ctypes.Structure):
                _fields_ = [
                    ("TypeName", UNICODE_STRING),
                    ("TotalNumberOfObjects", ctypes.c_ulong),
                    ("TotalNumberOfHandles", ctypes.c_ulong),
                    ("TotalPagedPoolUsage", ctypes.c_ulong),
                    ("TotalNonPagedPoolUsage", ctypes.c_ulong),
                    ("TotalNamePoolUsage", ctypes.c_ulong),
                    ("TotalHandleTableUsage", ctypes.c_ulong),
                    ("HighWaterNumberOfObjects", ctypes.c_ulong),
                    ("HighWaterNumberOfHandles", ctypes.c_ulong),
                    ("HighWaterPagedPoolUsage", ctypes.c_ulong),
                    ("HighWaterNonPagedPoolUsage", ctypes.c_ulong),
                    ("HighWaterNamePoolUsage", ctypes.c_ulong),
                    ("HighWaterHandleTableUsage", ctypes.c_ulong),
                    ("InvalidAttributes", ctypes.c_ulong),
                    ("GenericMapping", ctypes.c_ulong * 4),
                    ("ValidAccessMask", ctypes.c_ulong),
                    ("SecurityRequired", ctypes.c_ubyte),
                    ("MaintainHandleCount", ctypes.c_ubyte),
                    ("TypeIndex", ctypes.c_ubyte),
                    ("ReservedByte", ctypes.c_ubyte),
                    ("PoolType", ctypes.c_ulong),
                    ("DefaultPagedPoolCharge", ctypes.c_ulong),
                    ("DefaultNonPagedPoolCharge", ctypes.c_ulong)
                ]
                
            class OBJECT_NAME_INFORMATION(ctypes.Structure):
                _fields_ = [("Name", UNICODE_STRING)]
                
            # Object information class constants
            ObjectBasicInformation = 0
            ObjectNameInformation = 1
            ObjectTypeInformation = 2
            
            # Set up NtQueryObject function
            ntdll = ctypes.WinDLL('ntdll', use_last_error=True)
            NtQueryObject = ntdll.NtQueryObject
            NtQueryObject.argtypes = [
                ctypes.c_void_p,
                ctypes.c_ulong,
                ctypes.c_void_p,
                ctypes.c_ulong,
                ctypes.POINTER(ctypes.c_ulong)
            ]
            NtQueryObject.restype = ctypes.c_ulong
            
            # Get handle information from process
            kernel32 = ctypes.windll.kernel32
            
            # Use NtQuerySystemInformation to get process handles
            SystemHandleInformation = 16
            
            # Define NtQuerySystemInformation
            NtQuerySystemInformation = ntdll.NtQuerySystemInformation
            NtQuerySystemInformation.argtypes = [
                ctypes.c_ulong,
                ctypes.c_void_p,
                ctypes.c_ulong,
                ctypes.POINTER(ctypes.c_ulong)
            ]
            NtQuerySystemInformation.restype = ctypes.c_ulong
            
            class SYSTEM_HANDLE_TABLE_ENTRY_INFO(ctypes.Structure):
                _fields_ = [
                    ("UniqueProcessId", ctypes.c_ushort),
                    ("CreatorBackTraceIndex", ctypes.c_ushort),
                    ("ObjectTypeIndex", ctypes.c_ubyte),
                    ("HandleAttributes", ctypes.c_ubyte),
                    ("HandleValue", ctypes.c_ushort),
                    ("Object", ctypes.c_void_p),
                    ("GrantedAccess", ctypes.c_ulong)
                ]
                
            class SYSTEM_HANDLE_INFORMATION(ctypes.Structure):
                _fields_ = [
                    ("NumberOfHandles", ctypes.c_ulong),
                    ("Handles", SYSTEM_HANDLE_TABLE_ENTRY_INFO * 1)
                ]
            
            # Get the process ID from the handle
            pid = kernel32.GetProcessId(process_handle)
            if not pid:
                return []
                
            # First get the size needed
            return_length = ctypes.c_ulong(0)
            status = NtQuerySystemInformation(SystemHandleInformation, None, 0, ctypes.byref(return_length))
            
            # Allocate buffer with the returned size (plus some extra to be safe)
            buffer_size = return_length.value + 4096
            handle_info_buffer = ctypes.create_string_buffer(buffer_size)
            
            # Get the handle information
            status = NtQuerySystemInformation(
                SystemHandleInformation,
                handle_info_buffer,
                buffer_size,
                ctypes.byref(return_length)
            )
            
            if status != 0:  # STATUS_SUCCESS
                return []
                
            # Parse the handle information
            handle_info = ctypes.cast(handle_info_buffer, ctypes.POINTER(SYSTEM_HANDLE_INFORMATION)).contents
            
            # Process each handle that belongs to our target process
            pid = kernel32.GetCurrentProcessId()
            
            for i in range(handle_info.NumberOfHandles):
                handle_entry = handle_info.Handles[i]
                
                # Only process handles belonging to our target process
                if handle_entry.UniqueProcessId != pid:
                    continue
                    
                # Skip handles we can't access or duplicate
                try:
                    # Duplicate the handle to our process to query it
                    target_handle = ctypes.c_void_p(0)
                    result = kernel32.DuplicateHandle(
                        process_handle,                      # Source process
                        handle_entry.HandleValue,            # Source handle
                        kernel32.GetCurrentProcess(),        # Target process
                        ctypes.byref(target_handle),         # Target handle
                        0,                                   # Access - 0 means same as source
                        False,                               # Inherit handle
                        2                                    # DUPLICATE_SAME_ACCESS
                    )
                    
                    if not result or not target_handle.value:
                        continue
                    
                    handle_obj = {
                        'handle_value': handle_entry.HandleValue,
                        'access': handle_entry.GrantedAccess,
                        'attributes': handle_entry.HandleAttributes,
                        'type': "",
                        'name': "",
                        'basic_info': {}
                    }
                    
                    # Get basic information
                    basic_info_buffer = ctypes.create_string_buffer(ctypes.sizeof(OBJECT_BASIC_INFORMATION))
                    status = NtQueryObject(
                        target_handle,
                        ObjectBasicInformation,
                        basic_info_buffer,
                        ctypes.sizeof(OBJECT_BASIC_INFORMATION),
                        None
                    )
                    
                    if status == 0:  # STATUS_SUCCESS
                        basic_info = ctypes.cast(basic_info_buffer, ctypes.POINTER(OBJECT_BASIC_INFORMATION)).contents
                        handle_obj['basic_info'] = {
                            'attributes': basic_info.Attributes,
                            'granted_access': basic_info.GrantedAccess,
                            'handle_count': basic_info.HandleCount,
                            'pointer_count': basic_info.PointerCount,
                            'paged_pool_charge': basic_info.PagedPoolCharge,
                            'non_paged_pool_charge': basic_info.NonPagedPoolCharge,
                            'creation_time': basic_info.CreationTime
                        }
                    
                    # Get handle type information
                    type_info_buffer = ctypes.create_string_buffer(4096)  # Usually enough for type info
                    status = NtQueryObject(
                        target_handle,
                        ObjectTypeInformation,
                        type_info_buffer,
                        4096,
                        None
                    )
                    
                    if status == 0:  # STATUS_SUCCESS
                        type_info = ctypes.cast(type_info_buffer, ctypes.POINTER(OBJECT_TYPE_INFORMATION)).contents
                        handle_obj['type'] = self._extract_unicode_string(type_info.TypeName)
                        
                        # Get object name if possible
                        # Some object types cause hanging when querying name, skip these
                        if handle_obj['type'] not in ["Thread", "TpWorkerFactory", "IoCompletion", "WaitCompletionPacket"]:
                            name_info_buffer = ctypes.create_string_buffer(4096)
                            status = NtQueryObject(
                                target_handle,
                                ObjectNameInformation,
                                name_info_buffer,
                                4096,
                                None
                            )
                            
                            if status == 0:  # STATUS_SUCCESS
                                name_info = ctypes.cast(name_info_buffer, ctypes.POINTER(OBJECT_NAME_INFORMATION)).contents
                                handle_obj['name'] = self._extract_unicode_string(name_info.Name)
                    
                    # Analyze the handle for suspicious traits
                    handle_obj['is_suspicious'] = self._analyze_handle_for_suspicion(handle_obj)
                    
                    # Add this handle to our collection
                    object_info.append(handle_obj)
                    
                    # Clean up our duplicated handle
                    kernel32.CloseHandle(target_handle)
                    
                except Exception as e:
                    # Skip this handle if there's any error
                    logging.debug(f"Error inspecting handle: {str(e)}")
                    if 'target_handle' in locals() and target_handle.value:
                        kernel32.CloseHandle(target_handle)
            
            return object_info
            
        except Exception as e:
            logging.debug(f"Error gathering process object information: {str(e)}")
            return []
    def _analyze_handle_for_suspicion(self, handle_obj):
        """Analyze a handle for suspicious attributes"""
        if not handle_obj:
            return False
            
        # Initialize suspicion flags
        suspicious = False
        reasons = []
        
        # Check object type
        obj_type = handle_obj.get('type', '')
        access = handle_obj.get('access', 0)
        name = handle_obj.get('name', '')
        basic_info = handle_obj.get('basic_info', {})
        
        # Check for suspicious process access
        if obj_type == 'Process':
            # Check for full control (almost all access rights)
            if access & 0x1FFFFF == 0x1FFFFF:
                suspicious = True
                reasons.append("Full control access to another process")
                
            # Check for memory write access
            if access & 0x0038 == 0x0038:  # PROCESS_VM_WRITE | PROCESS_VM_READ | PROCESS_VM_OPERATION
                suspicious = True
                reasons.append("Memory write access to another process")
        
        # Check for suspicious section objects (often used in injection)
        elif obj_type == 'Section':
            if 'Anonymous' in name:
                suspicious = True
                reasons.append("Anonymous memory section")
                
            # Check for executable and writable memory sections
            if access & 0x4 and access & 0x2:  # SECTION_MAP_EXECUTE and SECTION_MAP_WRITE
                suspicious = True
                reasons.append("Executable and writable memory section")
        
        # Check for thread creation/manipulation capabilities
        elif obj_type == 'Thread':
            # Check for thread control/execution capabilities
            if access & 0x0020:  # THREAD_SUSPEND_RESUME
                suspicious = True
                reasons.append("Thread execution control")
        
        # Check pointer count vs handle count (high disparity can indicate hidden resources)
        if basic_info:
            handle_count = basic_info.get('handle_count', 0)
            pointer_count = basic_info.get('pointer_count', 0)
            
            if pointer_count > handle_count * 3 and pointer_count > 10:
                suspicious = True
                reasons.append(f"Abnormal pointer count ({pointer_count}) vs handle count ({handle_count})")
        
        # Add suspicion details to handle object
        if suspicious:
            handle_obj['suspicious'] = True
            handle_obj['suspicion_reasons'] = reasons
        
        return suspicious

    def _extract_unicode_string(self, unicode_str):
        """Helper to extract string from UNICODE_STRING structure"""
        if not unicode_str.Length:
            return ""
        
        try:
            buffer = ctypes.create_string_buffer(unicode_str.Length + 2)
            ctypes.memmove(buffer, unicode_str.Buffer, unicode_str.Length)
            return buffer.raw.decode('utf-16-le').rstrip('\0')
        except:
            return ""

    def _validate_children_info(self, children_info):
        """Validate children process information"""
        if not isinstance(children_info, list):
            return []
        
        valid_children = []
        for child in children_info:
            if isinstance(child, dict) and 'pid' in child and 'name' in child:
                valid_children.append({
                    'pid': int(child['pid']),
                    'name': str(child['name']),
                    'path': str(child.get('path', '')),
                    'threads': int(child.get('threads', 0))
                })
        return valid_children

    def _validate_parent_info(self, parent_info):
        """Validate parent process information"""
        if not isinstance(parent_info, dict):
            return {'pid': 0, 'name': 'Unknown'}
        
        return {
            'pid': int(parent_info.get('pid', 0)),
            'name': str(parent_info.get('name', 'Unknown'))
        }

    def _validate_modules_info(self, modules):
        """Validate loaded modules information"""
        if not isinstance(modules, list):
            return []
        
        valid_modules = []
        for module in modules:
            if isinstance(module, dict):
                valid_modules.append({
                    'name': str(module.get('name', 'Unknown')),
                    'path': str(module.get('path', '')),
                    'base': int(module.get('base', 0)),
                    'size': int(module.get('size', 0))
                })
        return valid_modules
    def _sanitize_memory_info(self, memory_info):
        """Sanitize memory information values"""
        safe_memory = {}
        max_memory = 0x7FFFFFFFFFFFFFFF  # Max theoretical memory
        
        for key, value in (memory_info or {}).items():
            safe_memory[key] = min(
                max(0, int(str(value).strip(), 16) if isinstance(value, str) else int(value)),
                max_memory
            )
        
        return safe_memory
    def _get_process_name_winapi(self, handle):
        """Get process name using WinAPI"""
        name_buffer = ctypes.create_unicode_buffer(260)
        psapi = ctypes.WinDLL('psapi', use_last_error=True)
        if psapi.GetProcessImageFileNameW(handle, name_buffer, 260):
            return os.path.basename(name_buffer.value)
        return "Unknown"

    def _get_process_path_winapi(self, handle):
        """Get full process path using WinAPI"""
        path_buffer = ctypes.create_unicode_buffer(260)
        kernel32 = ctypes.windll.kernel32
        if kernel32.QueryFullProcessImageNameW(handle, 0, path_buffer, ctypes.byref(ctypes.c_ulong(260))):
            return path_buffer.value
        return "Unknown"

    def _get_process_cmdline_winapi(self, handle):
        """Get process command line using WinAPI"""
        try:
            pbi = self._get_process_basic_info(handle)
            if pbi and pbi.PebBaseAddress:
                return self._read_process_memory_string(handle, pbi.PebBaseAddress + 0x20)
        except:
            pass
        return []
    def _get_process_basic_info(self, handle):
        
        """Get basic process information using Windows API"""
        class PROCESS_BASIC_INFORMATION(ctypes.Structure):
            _fields_ = [
                ("ExitStatus", ctypes.c_ulong),
                ("PebBaseAddress", ctypes.c_void_p),
                ("AffinityMask", ctypes.c_void_p),
                ("BasePriority", ctypes.c_long),
                ("UniqueProcessId", ctypes.c_void_p),
                ("InheritedFromUniqueProcessId", ctypes.c_void_p)
            ]
        
        pbi = PROCESS_BASIC_INFORMATION()
        size = ctypes.sizeof(pbi)
        status = ctypes.windll.ntdll.NtQueryInformationProcess(
            handle, 0, ctypes.byref(pbi), size, None)
        
        return pbi if status == 0 else None

    def _read_process_memory_string(self, handle, address, max_size=1024):
        """Read string from process memory with safety checks"""
        try:
            buffer = win32process.ReadProcessMemory(handle, address, max_size)
            null_pos = buffer.find(b'\x00')
            if null_pos != -1:
                buffer = buffer[:null_pos]
            return buffer.decode('utf-8', errors='ignore')
        except:
            return ""
    def _get_process_cwd_winapi(self, handle):
        """Get process working directory using WinAPI"""
        buffer = ctypes.create_unicode_buffer(260)
        kernel32 = ctypes.windll.kernel32
        if kernel32.GetCurrentDirectoryW(260, buffer):
            return buffer.value
        return "Unknown"

    def _get_process_status_winapi(self, handle):
        """Get process status using WinAPI"""
        status = "Unknown"
        kernel32 = None
        try:
            exit_code = ctypes.c_ulong()
            kernel32 = ctypes.windll.kernel32
            if kernel32.GetExitCodeProcess(handle, ctypes.byref(exit_code)):
                status = "Running" if exit_code.value == 259 else "Terminated"
        except:
            pass
        return status

    def _get_process_username_winapi(self, handle):
        """Get process username using WinAPI"""
        
        try:
            token = ctypes.c_void_p()
            kernel32 = ctypes.windll.kernel32
            advapi32 = ctypes.windll.advapi32
            
            if kernel32.OpenProcessToken(handle, 0x8, ctypes.byref(token)):
                try:
                    size = ctypes.c_ulong()
                    win32security.GetTokenInformation(token, 20, None, 0, ctypes.byref(size))
                    buffer = ctypes.create_string_buffer(size.value)
                    if win32security.GetTokenInformation(token, 20, buffer, size, ctypes.byref(size)):
                        return self._sid_to_username(buffer)
                finally:
                    kernel32.CloseHandle(token)
        except Exception as e:
            logging.debug(f"Error getting process username: {e}")
        return "Unknown"

    def _sid_to_username(self, sid):
        """Convert Windows Security Identifier (SID) to username"""
        try:
            from win32security import LookupAccountSid
            name, domain, sid_type = LookupAccountSid(None, sid)
            
            # Use the SID type information
            type_info = {
                1: "User",
                2: "Group", 
                3: "Domain",
                4: "Alias",
                5: "WellKnownGroup",
                6: "DeletedAccount",
                7: "Invalid",
                8: "Unknown",
                9: "Computer"
            }
            
            return {
                'full_name': f"{domain}\\{name}",
                'domain': domain,
                'name': name,
                'type': type_info.get(sid_type, "Unknown")
            }
        except:
            return str(sid)
    def _get_safe_default_info(self):
        pid = win32process.GetCurrentProcessId()
        process = win32api.OpenProcess(
            win32con.PROCESS_QUERY_INFORMATION | win32con.PROCESS_VM_READ,
            False, pid
        )
        """Return safe default process information"""
        return {
            'pid': 0,
            'name': self.get_process_name(process),
            'exe': None,
            'path': None,
            'cmdline': [],
            'username': None,
            'create_time': 0,
            'memory_info': {},
            'num_threads': 0,
            'cpu_percent': 0,
            'status': self.check_integrity_status(process),
            'network': [],
        }
    def _get_process_creation_time_winapi(self, handle):
        """Get process creation time using WinAPI"""
        creation_time = ctypes.c_ulonglong()
        exit_time = ctypes.c_ulonglong()
        kernel_time = ctypes.c_ulonglong()
        user_time = ctypes.c_ulonglong()
        kernel32 = ctypes.windll.kernel32
        
        if kernel32.GetProcessTimes(
            handle,
            ctypes.byref(creation_time),
            ctypes.byref(exit_time),
            ctypes.byref(kernel_time),
            ctypes.byref(user_time)
        ):
            return creation_time.value
        return 0

    def _get_process_cpu_usage_winapi(self, handle):
        """Get process CPU usage using WinAPI"""
        kernel32 = None
        try:
            creation_time = ctypes.c_ulonglong()
            exit_time = ctypes.c_ulonglong()
            kernel_time = ctypes.c_ulonglong()
            user_time = ctypes.c_ulonglong()
            kernel32 = ctypes.windll.kernel32
            
            if kernel32.GetProcessTimes(
                handle,
                ctypes.byref(creation_time),
                ctypes.byref(exit_time),
                ctypes.byref(kernel_time),
                ctypes.byref(user_time)
            ):
                return (kernel_time.value + user_time.value) / 10000000  # Convert to seconds
        except:
            pass
        return 0

    def _get_process_memory_info_winapi(self, handle):
        """Get process memory information using WinAPI"""
        class PROCESS_MEMORY_COUNTERS(ctypes.Structure):
            _fields_ = [
                ("cb", ctypes.c_ulong),
                ("PageFaultCount", ctypes.c_ulong),
                ("PeakWorkingSetSize", ctypes.c_size_t),
                ("WorkingSetSize", ctypes.c_size_t),
                ("QuotaPeakPagedPoolUsage", ctypes.c_size_t),
                ("QuotaPagedPoolUsage", ctypes.c_size_t),
                ("QuotaPeakNonPagedPoolUsage", ctypes.c_size_t),
                ("QuotaNonPagedPoolUsage", ctypes.c_size_t),
                ("PagefileUsage", ctypes.c_size_t),
                ("PeakPagefileUsage", ctypes.c_size_t)
            ]
        
        pmc = PROCESS_MEMORY_COUNTERS()
        psapi = ctypes.WinDLL('psapi', use_last_error=True)
        if psapi.GetProcessMemoryInfo(handle, ctypes.byref(pmc), ctypes.sizeof(pmc)):
            return {field[0]: getattr(pmc, field[0]) for field in pmc._fields_}
        return {}

    def _get_process_thread_count_winapi(self, handle):
        """Get process thread count using WinAPI"""
        class SYSTEM_PROCESS_INFORMATION(ctypes.Structure):
            _fields_ = [
                ("NextEntryOffset", ctypes.c_ulong),
                ("NumberOfThreads", ctypes.c_ulong),
                ("Reserved1", ctypes.c_byte * 48),
                ("Reserved2", ctypes.c_byte * 3),
                ("UniqueProcessId", ctypes.c_void_p),
                ("Reserved3", ctypes.c_void_p),
                ("HandleCount", ctypes.c_ulong),
                ("Reserved4", ctypes.c_byte * 4),
                ("Reserved5", ctypes.c_void_p * 11)
            ]
        
        process_info = SYSTEM_PROCESS_INFORMATION()
        ntdll = ctypes.WinDLL('ntdll', use_last_error=True)
        status = ntdll.NtQuerySystemInformation(5, ctypes.byref(process_info), ctypes.sizeof(process_info), None)
        
        if status == 0:
            return process_info.NumberOfThreads
        return 0

    def _get_process_handle_count_winapi(self, handle):
        """Get process handle count using WinAPI"""
        kernel32 = None
        try:
            handle_count = ctypes.c_ulong()
            kernel32 = ctypes.windll.kernel32
            if kernel32.GetProcessHandleCount(handle, ctypes.byref(handle_count)):
                return handle_count.value
        except Exception as e:
            logging.debug(f"Error getting process handle count: {e}")
        return 0

    def _validate_network_info(self, network_info):
        """Validate network connection information"""
        valid_connections = []
        
        CONNECTION_STATES = {
            1: 'ESTABLISHED',
            2: 'LISTENING',
            3: 'SYN_SENT',
            4: 'SYN_RECEIVED',
            5: 'FIN_WAIT1',
            6: 'FIN_WAIT2',
            7: 'CLOSE_WAIT',
            8: 'CLOSING',
            9: 'LAST_ACK',
            10: 'TIME_WAIT',
            11: 'DELETE_TCB'
        }
        
        CONNECTION_TYPES = {
            1: 'TCP',
            2: 'UDP',
            3: 'RAW',
            4: 'ICMP',
            5: 'UDP_LITE'
        }

        for conn in (network_info or []):
            if isinstance(conn, dict):
                status_code = conn.get('status_code', 0)
                type_code = conn.get('type_code', 0)
                
                valid_connections.append({
                    'local_addr': self._validate_address(conn.get('local_addr')),
                    'remote_addr': self._validate_address(conn.get('remote_addr')),
                    'status': CONNECTION_STATES.get(status_code, 'UNKNOWN'),
                    'type': CONNECTION_TYPES.get(type_code, 'UNKNOWN'),
                    'pid': conn.get('pid'),
                    'created': conn.get('created_timestamp')
                })

        return valid_connections
    def _validate_address(self, address):
        """Validate memory address ranges and permissions"""
        if not isinstance(address, (int, ctypes.c_void_p)):
            return False
            
        # Convert to integer if needed
        addr_int = address if isinstance(address, int) else ctypes.cast(address, ctypes.c_void_p).value
        
        # Get system info for valid address range
        system_info = self._get_system_info_winapi()
        min_addr = system_info['min_address']
        max_addr = system_info['max_address']
        
        # Check address is within valid range
        if addr_int < min_addr or addr_int > max_addr:
            return False
            
        # Check alignment
        if addr_int % system_info['allocation_granularity'] != 0:
            return False
            
        return True
    def _get_process_network_info_winapi(self, handle):
        """Get process network connections using WinAPI"""
        class MIB_TCPROW_OWNER_PID(ctypes.Structure):
            _fields_ = [
                ("dwState", ctypes.c_uint),
                ("dwLocalAddr", ctypes.c_uint),
                ("dwLocalPort", ctypes.c_uint),
                ("dwRemoteAddr", ctypes.c_uint),
                ("dwRemotePort", ctypes.c_uint),
                ("dwOwningPid", ctypes.c_uint)
            ]

        connections = []
        kernel32 = None
        
        try:
            # First load the libraries properly
            kernel32 = ctypes.windll.kernel32
            iphlpapi = ctypes.windll.iphlpapi
            
            # Then use them
            pid = kernel32.GetProcessId(handle)
            
            size = ctypes.c_ulong(0)
            iphlpapi.GetExtendedTcpTable(None, ctypes.byref(size), True, 2, 5, 0)
            table = ctypes.create_string_buffer(size.value)
            
            if iphlpapi.GetExtendedTcpTable(table, ctypes.byref(size), True, 2, 5, 0) == 0:
                entries = ctypes.cast(table, ctypes.POINTER(ctypes.c_uint)).contents.value
                for i in range(entries):
                    row = ctypes.cast(
                        table[ctypes.sizeof(ctypes.c_uint) + i * ctypes.sizeof(MIB_TCPROW_OWNER_PID)],
                        ctypes.POINTER(MIB_TCPROW_OWNER_PID)
                    ).contents
                    
                    if row.dwOwningPid == pid:
                        connections.append({
                            'local_addr': f"{self._int_to_ip(row.dwLocalAddr)}:{row.dwLocalPort}",
                            'remote_addr': f"{self._int_to_ip(row.dwRemoteAddr)}:{row.dwRemotePort}",
                            'status': self._tcp_state_to_string(row.dwState),
                            'type': 'TCP'
                        })
        except Exception as e:
            logging.debug(f"Error getting TCP connections: {e}")
        
        return connections

    def _int_to_ip(self, ip):
        """Convert integer to IP address string"""
        return '.'.join([str(ip >> (i * 8) & 0xff) for i in range(4)][::-1])
    def _tcp_state_to_string(self, state):
        """Convert TCP state to string representation"""
        states = {
            1: "CLOSED",
            2: "LISTENING",
            3: "SYN_SENT",
            4: "SYN_RECEIVED",
            5: "ESTABLISHED",
            6: "FIN_WAIT1",
            7: "FIN_WAIT2",
            8: "CLOSE_WAIT",
            9: "CLOSING",
            10: "LAST_ACK",
            11: "TIME_WAIT",
            12: "DELETE_TCB"
        }
        return states.get(state, "UNKNOWN")
    def _get_process_modules_winapi(self, process_handle):
        """Enhanced process module enumeration with proper handle validation and error handling"""
        
        if not process_handle or process_handle == 0 or process_handle == -1:
            logging.debug(f"Invalid process handle provided to module enumeration")
            return []
        
        # Verify handle is still valid
        try:
            kernel32 = ctypes.windll.kernel32
            # Quick test to see if handle is valid - GetExitCodeProcess should work on valid handles
            exit_code = ctypes.c_ulong(0)
            if not kernel32.GetExitCodeProcess(process_handle, ctypes.byref(exit_code)): 
                error_code = kernel32.GetLastError()
                logging.debug(f"Invalid process handle detected during module enumeration. Error: {error_code}")
                return []
                
            # If process has exited, handle is invalid for module enumeration
            if exit_code.value != 259:  # STILL_ACTIVE = 259
                logging.debug(f"Process has exited, cannot enumerate modules")
                return []
        except Exception as e:
            logging.debug(f"Error validating process handle: {str(e)}")
            return []
        
        modules = []
        try:
            # Ensure handle has required access rights for module enumeration
            # We need PROCESS_QUERY_INFORMATION and PROCESS_VM_READ
            required_access = 0x0400 | 0x0010  # PROCESS_QUERY_INFORMATION | PROCESS_VM_READ
            
            # Get proper handle with required access if needed
            current_pid = ctypes.c_ulong(0)
            if kernel32.GetProcessId(process_handle) > 0:
                current_pid.value = kernel32.GetProcessId(process_handle)
                
                # Only try to get a new handle if we can get the PID
                if current_pid.value > 0:
                    new_handle = kernel32.OpenProcess(
                        required_access,
                        False,
                        current_pid.value
                    )
                    
                    if new_handle:
                        # Use the new handle with appropriate access rights
                        # Don't close the original handle as it might be used elsewhere
                        process_handle = new_handle
            
            # Use psapi.dll to enumerate modules
            h_modules = (ctypes.c_void_p * 1024)()
            cb_needed = ctypes.c_ulong()
            
            if not kernel32.EnumProcessModules(
                process_handle,
                ctypes.byref(h_modules),
                ctypes.sizeof(h_modules),
                ctypes.byref(cb_needed)
            ):
                error_code = kernel32.GetLastError()
                if error_code == 6:  # ERROR_INVALID_HANDLE
                    logging.debug(f"Failed to enumerate process modules. Error: 6 (Invalid Handle)")
                else:
                    logging.debug(f"Failed to enumerate process modules. Error: {error_code}")
                return []
            
            # Calculate number of modules
            count = min(cb_needed.value // ctypes.sizeof(ctypes.c_void_p), 1024)
            
            # Get module information
            for i in range(count):
                module_name = ctypes.create_unicode_buffer(260)  # MAX_PATH
                module_path = ctypes.create_unicode_buffer(260)  # MAX_PATH
                
                if kernel32.GetModuleBaseNameW(
                    process_handle, h_modules[i], module_name, ctypes.sizeof(module_name)
                ):
                    # Get full path
                    if kernel32.GetModuleFileNameExW(
                        process_handle, h_modules[i], module_path, ctypes.sizeof(module_path)
                    ):
                        mod_info = ctypes.wintypes.MODULEINFO()
                        if kernel32.GetModuleInformation( 
                                process_handle,
                                h_modules[i],
                                ctypes.byref(mod_info),
                                ctypes.sizeof(mod_info)
                            ):
                            modules.append({
                                'name': module_name.value,
                                'path': module_path.value,
                                'base': mod_info.lpBaseOfDll,
                                'size': mod_info.SizeOfImage
                            })
            # Clean up if we created a new handle
            if 'new_handle' in locals() and new_handle:
                ctypes.windll.kernel32.CloseHandle(new_handle)
                
            return modules
        
        except Exception as e:
            logging.debug(f"Exception during module enumeration: {str(e)}")
            
    def get_module_info(self, process_handle):
            pid = self.get_process_name(process_handle)
            self.process_info = self._get_process_info_winapi(process_handle, pid)
            # Initialize variables with safe defaults
            base_address = 0
            entry_point = 0
            module_name = "Unknown"
            size = 0
            psapi = ctypes.WinDLL('psapi', use_last_error=True)
            try:
                # Skip if handle is invalid
                if not process_handle or process_handle == 0:
                    logging.debug("Invalid process handle")
                    return None
                    
                # Get the first module (main executable)
                modules = (ctypes.wintypes.HMODULE * 1)()
                needed = ctypes.wintypes.DWORD()
                
                # Try to enumerate modules
                if not psapi.EnumProcessModules(
                    process_handle,
                    ctypes.byref(modules),
                    ctypes.sizeof(modules),
                    ctypes.byref(needed)
                ):
                    error_code = ctypes.get_last_error()
                    logging.debug(f"Failed to enumerate process modules. Error: {error_code}")
                    return None
                
                
                
                # Get module information
                module_info = self.get_system_info()  # Initialize here
                if not psapi.GetModuleInformation(
                    process_handle,
                    module_handle,
                    ctypes.byref(module_info),
                    ctypes.sizeof(module_info)
                ):
                    error_code = ctypes.get_last_error()
                    logging.debug(f"Failed to get module information. Error: {error_code}")
                    return None
                # Get the first module's handle
                module_handle = modules[0]
                # Get module name - safely
                local_module_name_buffer = ctypes.create_unicode_buffer(260)  # MAX_PATH
                if psapi.GetModuleFileNameExW(
                    process_handle,
                    module_handle,
                    local_module_name_buffer,
                    260
                ) > 0:  # Check return value properly
                    module_name = local_module_name_buffer.value
                
                # Safely get base address
                if hasattr(module_info, 'lpBaseOfDll') and module_info.lpBaseOfDll:
                    try:
                        base_address = int(ctypes.cast(module_info.lpBaseOfDll, ctypes.c_void_p).value)
                    except (OverflowError, TypeError) as e:
                        logging.debug(f"Error converting base address: {str(e)}")
                
                # Safely get entry point
                if hasattr(module_info, 'EntryPoint') and module_info.EntryPoint:
                    try:
                        entry_point = int(ctypes.cast(module_info.EntryPoint, ctypes.c_void_p).value)
                    except (OverflowError, TypeError) as e:
                        logging.debug(f"Error converting entry point: {str(e)}")
                
                # Safely get size
                if hasattr(module_info, 'SizeOfImage'):
                    size = module_info.SizeOfImage
                
                return {
                    'base_address': base_address,
                    'size': size,
                    'entry_point': entry_point,
                    'name': module_name
                }
                
            except Exception as ex:
                logging.debug(f"Exception in get_module_info: {str(ex)}")
                return None
    def _get_parent_process_info_winapi(self, pid):
        """Get parent process information using WinAPI"""
        ntdll = ctypes.WinDLL('ntdll', use_last_error=True)
        kernel32= None
        
        try:
            kernel32 = ctypes.windll.kernel32
            handle = kernel32.OpenProcess(0x1000, False, pid)
            if handle:
                try:
                    pbi = self._get_process_basic_info(handle)
                    if pbi and pbi.InheritedFromUniqueProcessId:
                        parent_pid = pbi.InheritedFromUniqueProcessId
                        parent_handle = kernel32.OpenProcess(0x1000, False, parent_pid)
                        
                        if parent_handle:
                            try:
                                return {
                                    'pid': parent_pid,
                                    'name': self._get_process_name_winapi(parent_handle),
                                    'path': self._get_process_path_winapi(parent_handle),
                                    'creation_time': self._get_process_creation_time_winapi(parent_handle)
                                }
                            finally:
                                kernel32.CloseHandle(parent_handle)
                finally:
                    kernel32.CloseHandle(handle)
        except Exception as e:
            logging.debug(f"Error getting parent process info: {e}")
        
        return None

    def _get_child_processes_winapi(self, pid):
        """Get child processes using WinAPI"""
        children = []
        
        # Initialize kernel32 properly at the beginning
        kernel32 = ctypes.windll.kernel32
        CreateToolhelp32Snapshot = kernel32.CreateToolhelp32Snapshot
        snapshot = CreateToolhelp32Snapshot(0x2, 0)  # TH32CS_SNAPPROCESS
        if snapshot != -1:
            try:
                class PROCESSENTRY32W(ctypes.Structure):
                    _fields_ = [
                        ("dwSize", ctypes.c_ulong),
                        ("cntUsage", ctypes.c_ulong),
                        ("th32ProcessID", ctypes.c_ulong),
                        ("th32DefaultHeapID", ctypes.c_void_p),
                        ("th32ModuleID", ctypes.c_ulong),
                        ("cntThreads", ctypes.c_ulong),
                        ("th32ParentProcessID", ctypes.c_ulong),
                        ("pcPriClassBase", ctypes.c_long),
                        ("dwFlags", ctypes.c_ulong),
                        ("szExeFile", ctypes.c_wchar * 260)
                    ]
                
                pe = PROCESSENTRY32W()
                pe.dwSize = ctypes.sizeof(pe)
                
                # Remove this line - no need to set to None after already initializing
                # kernel32 = None
                
                if kernel32.Process32FirstW(snapshot, ctypes.byref(pe)):
                    while True:
                        if pe.th32ParentProcessID == pid:
                            handle = kernel32.OpenProcess(0x1000, False, pe.th32ProcessID)
                            if handle:
                                try:
                                    children.append({
                                        'pid': pe.th32ProcessID,
                                        'name': pe.szExeFile,
                                        'path': self._get_process_path_winapi(handle),
                                        'threads': pe.cntThreads
                                    })
                                finally:
                                    kernel32.CloseHandle(handle)
                        
                        if not kernel32.Process32NextW(snapshot, ctypes.byref(pe)):
                            break
            finally:
                kernel32.CloseHandle(snapshot)
        
        return children

    def trace_attribute_error(self, error=None):
        """Set up a custom exception hook to trace PyHANDLE attribute errors"""
        import sys, traceback
        
        def custom_excepthook(exc_type, exc_value, exc_traceback):
            if exc_type is AttributeError and "'PyHANDLE' object has no attribute" in str(exc_value):
                # Get detailed traceback info
                tb_lines = traceback.format_exception(exc_type, exc_value, exc_traceback)
                
                # Log to file and console
                error_msg = "="*80 + "\n"
                error_msg += f"FOUND THE ERROR: {str(exc_value)}\n"
                error_msg += "="*80 + "\n"
                error_msg += "Traceback:\n"
                error_msg += "".join(tb_lines)
                error_msg += "\nLocal variables at each level:\n"
                
                logging.error(error_msg)
                
        sys.excepthook = custom_excepthook

        # Call this at the beginning of your program
    trace_attribute_error("pyhandle_error_trace.log")        
    def get_memory_info(self, pid: int) -> list:
        """Gathers memory region details for the specified process. Returns a list of dictionaries, each describing a memory region."""
        region_details = []

        try:
            process = psutil.Process(pid)
            if not process.is_running():
                logging.warning(f"Process with PID {pid} is not running.")
                return region_details

            process_handle = win32api.OpenProcess(
                win32con.PROCESS_QUERY_INFORMATION | win32con.PROCESS_VM_READ,
                False,
                pid
            )

            for mbi in self._enumerate_memory_regions_winapi(process_handle):
                # Build a dictionary describing this region
                region_info = {
                    "BaseAddress": mbi.BaseAddress,
                    "AllocationBase": mbi.AllocationBase,
                    "AllocationProtect": mbi.AllocationProtect,
                    "RegionSize": mbi.RegionSize,
                    "State": mbi.State,
                    "Protect": mbi.Protect,
                    "Type": mbi.Type
                }
                region_details.append(region_info)

            win32api.CloseHandle(process_handle)

        except psutil.NoSuchProcess:
            logging.error(f"No such process with PID {pid}")
        except Exception as e:
            logging.error(f"Failed to get memory info for PID {pid}: {str(e)}")

        return region_details
    
    def analyze_memory_region(self, pid, process_handle, process_name, region, base_addr_int, region_size):
        """
        Comprehensive analysis of a memory region, integrating all detection methods
        """
        protection = region.get('Protect', region.Protect if hasattr(region, 'Protect') else 0)
        
        # Track various types of suspicious memory regions
        detection_results = []
        
        # 1. Check for suspicious memory protections
        protection_result = self.analyze_memory_protection(pid, process_name, protection, base_addr_int, region_size)
        if protection_result:
            detection_results.append(protection_result)
        
        # 2. Check if region is executable
        is_executable = bool(protection & (self.PAGE_EXECUTE | self.PAGE_EXECUTE_READ | 
                                        self.PAGE_EXECUTE_READWRITE | self.PAGE_EXECUTE_WRITECOPY))
        
        if is_executable:
            try:
                # Read memory content
                memory_content = self._read_memory_in_chunks_winapi(
                    process_handle,
                    base_addr_int,
                    region_size
                )
                
                if not memory_content or len(memory_content) < 64:
                    return detection_results
                self.Detector = ShellcodeDetector()
                # 3. Check for shellcode patterns
                shellcode_findings = self.Detector.detect_shellcode(memory_content)
                if shellcode_findings:
                    for pattern_name, offset in shellcode_findings:
                        detection_results.append({
                            'pid': pid,
                            'process': process_name,
                            'type': 'Shellcode Pattern',
                            'details': f'{pattern_name} at offset {offset} from {hex(base_addr_int)}',
                            'location': f'Memory region at {hex(base_addr_int)}, size: {region_size}'
                        })
                
                # 4. Check for injection patterns using scan_bytes
                scan_results = self.scan_bytes(memory_content)
                if scan_results:
                    for result in scan_results:
                        detection_results.append({
                            'pid': pid,
                            'process': process_name,
                            'type': result.get('type', 'Code Injection'),
                            'details': result.get('details', f'Found at {hex(base_addr_int)}'),
                            'location': f'Memory region at {hex(base_addr_int)}, size: {region_size}'
                        })
                
                # 5. Check for specific injection patterns
                for pattern_name, pattern in self.injection_patterns.items():
                    try:
                        if isinstance(pattern, bytes):
                            if pattern in memory_content:
                                detection_results.append({
                                    'pid': pid,
                                    'process': process_name,
                                    'type': f'Injection Pattern: {pattern_name}',
                                    'details': f'Found at {hex(base_addr_int)}',
                                    'location': f'Memory region at {hex(base_addr_int)}, size: {region_size}'
                                })
                        elif hasattr(pattern, 'search'):  # Compiled regex
                            if pattern.search(memory_content):
                                detection_results.append({
                                    'pid': pid,
                                    'process': process_name,
                                    'type': f'Injection Pattern: {pattern_name}',
                                    'details': f'Found at {hex(base_addr_int)}',
                                    'location': f'Memory region at {hex(base_addr_int)}, size: {region_size}'
                                })
                        elif isinstance(pattern, str):  # String pattern, needs compilation
                            compiled_pattern = re.compile(pattern.encode(), re.DOTALL)
                            if compiled_pattern.search(memory_content):
                                detection_results.append({
                                    'pid': pid,
                                    'process': process_name,
                                    'type': f'Injection Pattern: {pattern_name}',
                                    'details': f'Found at {hex(base_addr_int)}',
                                    'location': f'Memory region at {hex(base_addr_int)}, size: {region_size}'
                                })
                    except Exception as e:
                        logging.debug(f"Error scanning for {pattern_name}: {str(e)}")
                
                # 6. Scan with YARA rules
                if hasattr(self, 'combined_rules') and self.combined_rules:
                    try:
                        matches = self.combined_rules.match(data=memory_content)
                        if matches:
                            for match in matches:
                                extended_info = None
                                if hasattr(self.scanner, 'get_extended_process_info'):
                                    try:
                                        extended_info = self.get_extended_process_info(pid)
                                    except Exception as e:
                                        logging.debug(f"Failed to get extended info: {str(e)}")
                                
                                detection_results.append({
                                    'pid': pid,
                                    'process': process_name,
                                    'type': f'YARA Rule: {match.rule}',
                                    'location': f'Memory region at {hex(base_addr_int)}',
                                    'extended_info': extended_info
                                })
                    except Exception as yara_error:
                        logging.debug(f"YARA scanning error: {str(yara_error)}")
                
                # 7. Analyze for specific shellcode techniques
                techniques_result = self.analyze_shellcode_techniques(memory_content, pid, process_name, base_addr_int, region_size)
                if techniques_result:
                    detection_results.extend(techniques_result)
                    
            except Exception as region_error:
                logging.debug(f"Error scanning region in {process_name}: {str(region_error)}")
        
        return detection_results
    def analyze_memory_protection(self, pid, process_name, protection, base_addr_int, region_size):
        """
        Analyzes memory protection settings for suspicious configurations
        """
        self.PAGE_TARGETS_NO_UPDATE = 0x40000000
        self.PAGE_TARGETS_INVALID = 0x40000000
        # Check for NOACCESS memory
        if protection & self.PAGE_NOACCESS:
            if process_name.lower() in ['svchost.exe', 'lsass.exe', 'csrss.exe', 'services.exe']:
                return {
                    'pid': pid,
                    'process': process_name,
                    'type': 'Suspicious Memory Protection',
                    'details': 'NOACCESS Memory in System Process (Potential Hidden Code)',
                    'location': f'Memory region at {hex(base_addr_int)}, size: {region_size}'
                }
        
        # Check for WRITECOPY with executable permissions
        if protection & self.PAGE_WRITECOPY:
            if protection & (self.PAGE_EXECUTE | self.PAGE_EXECUTE_READ | self.PAGE_EXECUTE_WRITECOPY):
                return {
                    'pid': pid,
                    'process': process_name,
                    'type': 'Suspicious Memory Protection',
                    'details': 'Executable WRITECOPY Memory (Unusual, Potential Code Injection)',
                    'location': f'Memory region at {hex(base_addr_int)}, size: {region_size}'
                }
        
        # Check for CFG bypass (PAGE_TARGETS_INVALID)
        if protection & self.PAGE_TARGETS_INVALID:
            return {
                'pid': pid,
                'process': process_name,
                'type': 'Security Protection Bypass',
                'details': 'Control Flow Guard disabled (PAGE_TARGETS_INVALID)',
                'location': f'Memory region at {hex(base_addr_int)}, size: {region_size}'
            }
        
        # Check for PAGE_TARGETS_NO_UPDATE
        if protection & self.PAGE_TARGETS_NO_UPDATE:
            if process_name.lower() in ['svchost.exe', 'lsass.exe', 'csrss.exe', 'winlogon.exe']:
                return {
                    'pid': pid,
                    'process': process_name,
                    'type': 'Control Flow Guard Bypass',
                    'details': f'PAGE_TARGETS_NO_UPDATE detected at {hex(base_addr_int)}',
                    'location': f'Memory region at {hex(base_addr_int)}, size: {region_size}'
                }
        
        # Check for RWX memory
        if protection & self.PAGE_EXECUTE_READWRITE:
            return {
                'pid': pid,
                'process': process_name,
                'type': 'Suspicious Memory Protection',
                'details': 'RWX Memory (Read-Write-Execute)',
                'location': f'Memory region at {hex(base_addr_int)}, size: {region_size}'
            }
        
        # Check for WX memory (Write+Execute without Read)
        if (protection & self.PAGE_EXECUTE) and (protection & self.PAGE_READWRITE) and not (protection & self.PAGE_READONLY):
            return {
                'pid': pid,
                'process': process_name,
                'type': 'High Risk Memory Protection',
                'details': 'Write+Execute Memory (No Read Permission)',
                'location': f'Memory region at {hex(base_addr_int)}, size: {region_size}'
            }
        
        return None
    def analyze_shellcode_techniques(self, memory_content, pid, process_name, base_addr_int, region_size):
        """
        Analyzes memory content for specific shellcode techniques
        """
        results = []
        
        # 1. Analyze for API hashing techniques
        api_hash_patterns = [
            rb'\x74\x0c\x81\xec[\x00-\xff]{2}\x00\x00\xe8[\x00-\xff]{3}\x00\x00',  # Common API hash calculation
            rb'\x33\xC0\x68.*?\x00\x50\x68.*?\x00\x50',  # Common API resolver pattern
            rb'\x8B\x3C\x24\x0F\xB7.*?\x01\xC7',  # API name hashing loop
        ]
        
        for pattern in api_hash_patterns:
            if re.search(pattern, memory_content, re.DOTALL):
                results.append({
                    'pid': pid,
                    'process': process_name,
                    'type': 'API Hashing Technique',
                    'details': 'API resolution through hashing (common in shellcode)',
                    'location': f'Memory region at {hex(base_addr_int)}, size: {region_size}'
                })
                break
        
        # 2. Analyze for egg hunting techniques
        egg_hunt_patterns = [
            rb'\x66\x81\xCA\xFF\x0F\x42\x52\x6A\x02\x58\xCD\x2E\x3C\x05\x5A\x74\xEF\xB8',  # Common egg hunter
            rb'\xEB\x24\x5A\x45\x52\xE8\xFF\xFF\xFF\xFF\xC2\x5A\x45\x52',  # Backward search egg hunter
        ]
        
        for pattern in egg_hunt_patterns:
            if re.search(pattern, memory_content, re.DOTALL):
                results.append({
                    'pid': pid,
                    'process': process_name,
                    'type': 'Egg Hunter Technique',
                    'details': 'Memory searching shellcode to locate second-stage payload',
                    'location': f'Memory region at {hex(base_addr_int)}, size: {region_size}'
                })
                break
        
        # 3. Analyze for process injection code
        injection_patterns = [
            rb'\x68.{4}\x68.{4}\xE8.{4}\x89',  # VirtualAllocEx + WriteProcessMemory pattern
            rb'\x68.{4}\x68.{4}\x68.{4}\xFF\x15',  # Common injection API call sequence
            rb'\x68.{4}\x68.{4}\x68.{4}\xE8.{4}\x68.{4}\xE8',  # Multi-API call sequence
        ]
        
        for pattern in injection_patterns:
            if re.search(pattern, memory_content, re.DOTALL):
                results.append({
                    'pid': pid,
                    'process': process_name,
                    'type': 'Process Injection Shellcode',
                    'details': 'Memory contains code for injecting into other processes',
                    'location': f'Memory region at {hex(base_addr_int)}, size: {region_size}'
                })
                break
        
        # 4. Analyze for XOR encoding/decoding loops
        xor_patterns = [
            rb'\x8B\xF.\xB9.{4}\x80\x3E.{1}\x74.\x80\xF6.{1}\x46\xE2',  # Common XOR loop
            rb'\xAC\x34.{1}\xAA\xE2\xFA',  # Simple XOR loop
            rb'\x31.{1}[\x40\x41\x42\x43\x44\x45\x46\x47][\xEB\xE9\xE2].{1}',  # XOR with loop
        ]
        
        for pattern in xor_patterns:
            if re.search(pattern, memory_content, re.DOTALL):
                results.append({
                    'pid': pid,
                    'process': process_name,
                    'type': 'XOR Encoding/Decoding',
                    'details': 'Self-decoding/decrypting code (common in shellcode)',
                    'location': f'Memory region at {hex(base_addr_int)}, size: {region_size}'
                })
                break
        
        # 5. Analyze for stack strings
        stack_string_patterns = [
            rb'(\x68.{4}){3,}',  # Multiple consecutive push operations
            rb'(\xC6\x45.{2}){4,}',  # Multiple byte assignments to local variables
            rb'(\x88.{2}){4,}',  # Multiple byte stores
        ]
        
        for pattern in stack_string_patterns:
            if re.search(pattern, memory_content, re.DOTALL):
                results.append({
                    'pid': pid,
                    'process': process_name,
                    'type': 'Stack String Construction',
                    'details': 'Dynamic string building on stack (obfuscation technique)',
                    'location': f'Memory region at {hex(base_addr_int)}, size: {region_size}'
                })
                break
        
        # 6. Analyze for PEB access (common in shellcode for finding DLLs)
        peb_patterns = [
            rb'\x64\xA1\x30\x00\x00\x00',  # mov eax, fs:[30h]
            rb'\x64\x8B\x1D\x30\x00\x00\x00',  # mov ebx, fs:[30h]
            rb'\x64\x8B\x0D\x30\x00\x00\x00',  # mov ecx, fs:[30h]
            rb'\x64\x8B\x15\x30\x00\x00\x00',  # mov edx, fs:[30h]
            rb'\x31\xC0\x64\x8B\x40\x30',  # xor eax,eax / mov eax, fs:[eax+30h]
        ]
        
        for pattern in peb_patterns:
            if re.search(pattern, memory_content, re.DOTALL):
                results.append({
                    'pid': pid,
                    'process': process_name,
                    'type': 'PEB Access',
                    'details': 'Process Environment Block access for DLL discovery',
                    'location': f'Memory region at {hex(base_addr_int)}, size: {region_size}'
                })
                break
        
        # 7. Analyze for reflective loading
        reflective_patterns = [
            rb'\x4D\x5A.{128,256}\x50\x45\x00\x00',  # PE header in memory
            rb'\xE8\x00\x00\x00\x00\x58\x83\xE8\x05',  # GetPC technique + adjustment
            rb'\x8B\x45.{1}\x89\x45.{1}\x8B\x4D.{1}\x89\x4D',  # Multiple register preservation
        ]
        
        for pattern in reflective_patterns:
            if re.search(pattern, memory_content, re.DOTALL):
                results.append({
                    'pid': pid,
                    'process': process_name,
                    'type': 'Reflective Loading',
                    'details': 'Self-loading executable code without standard loader',
                    'location': f'Memory region at {hex(base_addr_int)}, size: {region_size}'
                })
                break
        
        # 8. Analyze for ROP-like gadget chains
        rop_patterns = [
            rb'(\xC3.{0,16}\xC3.{0,16}\xC3.{0,16}\xC3){3,}',  # Multiple close RET instructions
            rb'(\x5F|\x5E|\x5D|\x5B|\x5A|\x59|\x58).{0,2}\xC3',  # POP reg / RET combinations
        ]
        
        for pattern in rop_patterns:
            if re.search(pattern, memory_content, re.DOTALL):
                results.append({
                    'pid': pid,
                    'process': process_name,
                    'type': 'ROP Chain',
                    'details': 'Return-Oriented Programming technique detected',
                    'location': f'Memory region at {hex(base_addr_int)}, size: {region_size}'
                })
                break
        
        return results
    def scan_process_memory(self, pid):
        """Enhanced process memory scanning with improved error handling and PID type flexibility"""
        
        # Define necessary constants
        PROCESS_QUERY_INFORMATION = 0x0400
        PROCESS_VM_READ = 0x0010
        MEM_COMMIT = 0x1000
        suspicious_regions = 0
        regions_with_suspicious_content = 0
        suspicious_patterns = []
        threat_score = 0
        process_handle = None
        PROTECTED_PROCESSES = [
        "Registry",  # Registry process
        "smss.exe",  # Session Manager Subsystem
        "csrss.exe",  # Client Server Runtime Process
        "wininit.exe",  # Windows Initialization Process
        "services.exe",  # Services Control Manager
        "lsass.exe",  # Local Security Authority Subsystem Service
        "winlogon.exe",  # Windows Logon Process
        "System",  # Windows System Process (PID 4)
        "System Idle Process"  # System Idle Process (PID 0)
        ]
        try:
             # Check if this is a protected process first
            if self._is_protected_process(pid):
                process_name = self.get_process_name(pid)
                logging.debug(f"Skipping scan of protected process {process_name} (PID: {pid})")
                return {}
            
            # Handle string PIDs (like "Registry")
            if isinstance(pid, str):
                if not pid.isdigit():
                    logging.debug(f"Processing special named process: {pid}")
                    # Check if this is a protected process by name
                    if pid in PROTECTED_PROCESSES:
                        logging.debug(f"Skipping scan of protected process {pid}")
                        return {}
                        
                    # Get specialized process info for named processes
                    process_info = self._get_process_info_winapi(pid)
                    return process_info.get('memory_patterns', {})
                else:
                    # Convert numeric string to int
                    pid = int(pid)
            
            # Try to open the process using win32api instead of kernel32 directly
            try:
                process_handle = win32api.OpenProcess(
                    win32con.PROCESS_QUERY_INFORMATION | win32con.PROCESS_VM_READ,
                    False, pid
                )
            except Exception as e:
                error_message = str(e)
                
                # Check if this is a protected process
                if self._is_protected_process(pid):
                    process_name = self.get_process_name(pid)
                    logging.info(f"Access denied to protected system process {process_name} (PID: {pid}) - This is expected")
                elif "Access is denied" in error_message:
                    logging.warning(f"Suspicious: Process {pid} is denying access despite admin rights")
                else:
                    logging.warning(f"Failed to open process with PID {pid}. Error: {error_message}")
                return {}
            # Handle string PIDs (like "Registry")
            if isinstance(pid, str):
                if not pid.isdigit():
                    logging.debug(f"Processing special named process: {pid}")
                    # Get specialized process info for named processes
                    process_info = self._get_process_info_winapi(pid)
                    return process_info.get('memory_patterns', {})
                else:
                    # Convert numeric string to int
                    pid = int(pid)
            
            # Open process with required access rights
            process_handle = ctypes.windll.kernel32.OpenProcess(
                PROCESS_QUERY_INFORMATION | PROCESS_VM_READ,
                False,
                pid
            )
            
            if not process_handle:
                error_code = ctypes.windll.kernel32.GetLastError()
                
                # Check if this is an expected protected process
                process_info = self._get_process_info_winapi(pid)
                if process_info and process_info.get('access_denied_expected', False):
                    logging.info(f"Access denied to protected system process {pid} ({process_info['name']}) - This is expected")
                elif error_code == 5:  # Access Denied
                    logging.warning(f"Suspicious: Process {pid} is denying access despite admin rights (Error 5)")
                else:
                    logging.warning(f"Failed to open process with PID {pid}. Error: {error_code}")
                return {}
            
            # Get process information for reporting (corrected argument order)
            process_info = self._get_process_info_winapi(pid, process_handle)
            
            if not process_info:
                logging.debug(f"Unable to get process info for PID {pid}")
                return {}
            
            regions_scanned = 0
            regions_with_suspicious_content = 0
            
            # Enumerate and scan memory regions
            memory_regions = self._enumerate_memory_regions_winapi(process_handle)
            if not memory_regions:
                logging.debug(f"No memory regions found for process {pid}")
                return {}
                
            for region in memory_regions:
                # Skip non-committed memory
                if not (region['State'] & MEM_COMMIT):
                    continue
                
                # Skip regions that are too small
                if region['RegionSize'] < 1024:
                    continue
                
                regions_scanned += 1
                
                try:
                    memory_content = self._read_memory_in_chunks_winapi(
                        process_handle,
                        region['BaseAddress'],
                        region['RegionSize']
                    )
                    
                    if memory_content and len(memory_content) > 0:
                        # Scan the memory content and capture the returned suspicious patterns
                        results = self._scan_memory_content_winapi(region, process_info, suspicious_patterns)
                        
                        # Update our suspicious_patterns with the results
                        if results and len(results) > len(suspicious_patterns):  # Fixed comparison
                            regions_with_suspicious_content += 1
                            suspicious_patterns = results
                            
                except MemoryError:
                    logging.debug(f"Memory allocation error scanning region at {hex(region['BaseAddress'])}")
                    continue
                except Exception as e:
                    logging.debug(f"Error scanning memory at {hex(region['BaseAddress'])}: {str(e)}")
                    continue
            
            logging.debug(f"Scanned {regions_scanned} memory regions in process {pid}, found suspicious content in {regions_with_suspicious_content} regions")
            
            return suspicious_patterns
        except Exception as e:
            logging.debug(f"Error scanning process {pid}: {str(e)}")
            
        if regions_with_suspicious_content > 0:
                # Calculate threat score based on suspicious findings
                threat_score = self._calculate_threat_score(suspicious_patterns, regions_with_suspicious_content)
                
                # If score exceeds threshold, quarantine
                if self.quarantine_enabled and threat_score >= self.quarantine_threshold:
                    threat_details = {
                        "suspicious_patterns": suspicious_patterns,
                        "suspicious_regions": regions_with_suspicious_content,
                        "threat_score": threat_score
                    }
                    quarantined = self.quarantine.quarantine_process(pid, process_info, threat_details)
                    if quarantined:
                        logging.warning(f"Quarantined malicious process {pid} ({process_info.get('Name', 'Unknown')}) - Threat score: {threat_score}")
                    else:
                        logging.error(f"Failed to quarantine process {pid} despite high threat score: {threat_score}")
        # Ensure process handle is closed even if an exception occurs
        if process_handle:
            ctypes.windll.kernel32.CloseHandle(process_handle)
        return {
            "suspicious_regions": suspicious_regions,
            "regions_with_suspicious_content": regions_with_suspicious_content,
            "suspicious_patterns": suspicious_patterns,
            "threat_score": threat_score,
            "quarantined": threat_score >= self.quarantine_threshold and self.quarantine_enabled
        }
    def _calculate_threat_score(self, suspicious_patterns, suspicious_regions_count):
        """Calculate a threat score based on suspicious findings"""
        score = 0
        
        # Base score on number of suspicious regions
        score += suspicious_regions_count * 5
        
        # Add points for each suspicious pattern based on severity
        for pattern in suspicious_patterns:
            if "severity" in pattern:
                score += pattern["severity"] * 10
            else:
                score += 10  # Default severity score
                
        return score
    
    def analyze_handle_objects(process_handle, pid, process_name, detailed=True):
        """
        Analyzes process handles to detect potential malicious behavior.
        
        Args:
            process_handle: Handle to the process being analyzed
            pid: Process ID
            process_name: Name of the process
            detailed: Whether to perform detailed analysis of handle permissions
            
        Returns:
            Dictionary containing handle analysis results and threat assessment
        """
        
        
        # Constants for object types
        OBJECT_TYPES = {
            "File": 0x1,
            "Port": 0x2,
            "Directory": 0x3,
            "SymbolicLink": 0x4,
            "Token": 0x5,
            "Job": 0x6,
            "Process": 0x7,
            "Thread": 0x8,
            "UserAPC": 0x9,
            "IoCompletionReserve": 0xA,
            "Event": 0xB,
            "EventPair": 0xC,
            "Mutant": 0xD, # Mutex
            "Callback": 0xE,
            "Semaphore": 0xF,
            "Timer": 0x10,
            "IRTimer": 0x11,
            "Profile": 0x12,
            "KeyedEvent": 0x13,
            "WindowStation": 0x14,
            "Desktop": 0x15,
            "Section": 0x16, # Memory Section
            "Key": 0x17,     # Registry Key
            "ALPC Port": 0x18,
            "PowerRequest": 0x19,
            "WmiGuid": 0x1A,
            "EtwRegistration": 0x1B,
            "EtwConsumer": 0x1C,
            "DmaAdapter": 0x1D,
            "DmaDomain": 0x1E,
            "PcwObject": 0x1F,
            "FilterConnectionPort": 0x20,
            "FilterCommunicationPort": 0x21,
        }
        
        # Known malicious handle patterns - expanded for better detection
        SUSPICIOUS_HANDLE_PATTERNS = {
            "process_hollowing": [
                "\\Device\\HarddiskVolume", 
                "\\Windows\\System32\\", 
                "\\KnownDlls\\"
            ],
            "token_manipulation": [
                "\\Device\\NamedPipe\\lsass", 
                "\\Sessions\\", 
                "\\BaseNamedObjects\\"
            ],
            "code_injection": [
                "\\Device\\NTFS", 
                "\\Device\\Tcp", 
                "\\Device\\Afd", 
                "\\Device\\RawIp"
            ],
            "registry_persistence": [
                "\\REGISTRY\\MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Run",
                "\\REGISTRY\\MACHINE\\SYSTEM\\CurrentControlSet\\Services",
                "\\REGISTRY\\MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Explorer\\ShellServiceObjects",
                "\\REGISTRY\\MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\ShellServiceObjectDelayLoad"
            ],
            "credential_access": [
                "\\Device\\NamedPipe\\protected_storage",
                "\\Device\\NamedPipe\\lsass",
                "\\Device\\KsecDD"
            ],
            "defense_evasion": [
                "\\REGISTRY\\MACHINE\\SYSTEM\\CurrentControlSet\\Services\\WinDefend",
                "\\REGISTRY\\MACHINE\\SOFTWARE\\Microsoft\\Windows Defender",
                "\\REGISTRY\\MACHINE\\SOFTWARE\\Policies\\Microsoft\\Windows Defender"
            ]
        }
        
        # Malware-specific mutex patterns
        MALWARE_MUTEX_PATTERNS = [
            "Global\\MsWinZonesCacheCounterMutexA",  # Used by some trojans
            "Global\\AC_", # Used by Qakbot
            "Global\\I30Comp",  # Generic malware mutex
            "_AVIRA_",  # Anti-AV mutex
            "Ransomware_",  # Generic ransomware
            "Global\\8758",  # Used by TrickBot
            "Global\\CTF",  # Used by several malware families
            "AhnLab",  # Anti-AV evasion
            "AVG_",  # Anti-AV evasion
            "Kaspersky_",  # Anti-AV evasion 
        ]
        
        # Initialize results
        results = {
            'handles': [],
            'statistics': {
                'type_counts': {},
                'access_rights': {},
                'hidden_objects': 0,
                'suspicious_objects': 0
            },
            'anomalies': [],
            'malware_indicators': [],  # New section for specific malware indicators
            'timestamp': datetime.now().isoformat()
        }
        
        # Load Windows API functions
        kernel32 = ctypes.windll.kernel32
        ntdll = ctypes.windll.ntdll
        
        # Define function prototypes with proper return types
        NtQueryObject = ntdll.NtQueryObject
        NtQueryObject.restype = ctypes.c_ulong
        
        # Define object information classes
        ObjectBasicInformation = 0
        ObjectNameInformation = 1
        ObjectTypeInformation = 2
        ObjectAllTypesInformation = 3
        ObjectHandleInformation = 4
        
        # Create buffer for handle information
        handle_info = ctypes.create_string_buffer(0x10000)
        
        # Define structures for parsing object information
        class UNICODE_STRING(ctypes.Structure):
            _fields_ = [
                ("Length", ctypes.c_ushort),
                ("MaximumLength", ctypes.c_ushort),
                ("Buffer", ctypes.c_void_p)
            ]
        # Use ObjectBasicInformation for basic handle info
        basic_info_status = NtQueryObject(
            dup_handle,
            ObjectBasicInformation,  # Using the constant
            handle_info,  # Using the buffer
            ctypes.sizeof(handle_info),
            ctypes.byref(length)
        )

        # Use ObjectAllTypesInformation for system-wide type information
        all_types_status = NtQueryObject(
            None,
            ObjectAllTypesInformation,  # Using the constant
            handle_info,
            ctypes.sizeof(handle_info),
            ctypes.byref(length)
        )

        # Use ObjectHandleInformation for handle-specific flags
        handle_info_status = NtQueryObject(
            dup_handle,
            ObjectHandleInformation,  # Using the constant
            handle_info,
            ctypes.sizeof(handle_info),
            ctypes.byref(length)
        )

        # Use OBJECT_TYPE_INFORMATION structure for parsing type info
        type_info = ctypes.cast(handle_info, ctypes.POINTER(OBJECT_TYPE_INFORMATION)).contents
        class OBJECT_TYPE_INFORMATION(ctypes.Structure):
            _fields_ = [
                ("Name", UNICODE_STRING),
                ("ObjectCount", ctypes.c_ulong),
                ("HandleCount", ctypes.c_ulong),
                ("Reserved1", ctypes.c_ulong * 4),
                ("PeakObjectCount", ctypes.c_ulong),
                ("PeakHandleCount", ctypes.c_ulong),
                ("Reserved2", ctypes.c_ulong * 4),
                ("InvalidAttributes", ctypes.c_ulong),
                ("GenericMapping", ctypes.c_ulong * 4),
                ("ValidAccessMask", ctypes.c_ulong),
                ("SecurityRequired", ctypes.c_ubyte),
                ("MaintainHandleCount", ctypes.c_ubyte),
                ("TypeIndex", ctypes.c_ushort),
                ("ReservedByte", ctypes.c_ubyte),
                ("PoolType", ctypes.c_ulong),
                ("DefaultPagedPoolCharge", ctypes.c_ulong),
                ("DefaultNonPagedPoolCharge", ctypes.c_ulong)
            ]
        
        # Analyze each handle in the process
        suspicious_count = 0
        hidden_count = 0
        
        # Dictionary to track malware families based on indicators
        malware_family_indicators = {
            'process_injection': 0,
            'ransomware': 0,
            'infostealer': 0,
            'rootkit': 0,
            'backdoor': 0,
            'trojan': 0,
            'keylogger': 0
        }
        
        for handle_value in range(0, 0x1000):  # Check first 4096 handles
            try:
                # Duplicate the handle for inspection
                dup_handle = ctypes.c_void_p()
                
                success = kernel32.DuplicateHandle(
                    process_handle.handle,
                    handle_value,
                    kernel32.GetCurrentProcess(),
                    ctypes.byref(dup_handle),
                    0,
                    False,
                    win32con.DUPLICATE_SAME_ACCESS
                )
                
                if not success:
                    continue
                    
                # Initialize handle data
                handle_data = {
                    'handle_value': handle_value,
                    'object_name': None,
                    'object_type': None,
                    'access_rights': None,
                    'flags': [],
                    'protection_level': 'Unknown',
                    'suspicious_rating': 0,  # 0-10 rating
                    'analysis': [],
                    'malware_techniques': []  # New field for MITRE ATT&CK-like technique references
                }
                
                # --- Get object type information ---
                type_info = ctypes.create_string_buffer(0x1000)
                length = ctypes.c_ulong(0)
                
                status = NtQueryObject(
                    dup_handle,
                    ObjectTypeInformation,
                    type_info,
                    ctypes.sizeof(type_info),
                    ctypes.byref(length)
                )
                
                if status >= 0 and length.value > 0:
                    try:
                        # Parse the type information (this is a simplified approach)
                        # In production, you'd want to properly parse the OBJECT_TYPE_INFORMATION structure
                        type_info_str = type_info.raw[:length.value].decode('utf-16le', errors='ignore')
                        for obj_type, _ in OBJECT_TYPES.items():
                            if obj_type in type_info_str:
                                handle_data['object_type'] = obj_type
                                # Update statistics
                                results['statistics']['type_counts'][obj_type] = results['statistics']['type_counts'].get(obj_type, 0) + 1
                                break
                    except:
                        pass
                
                # --- Get object name information ---
                name_info = ctypes.create_string_buffer(0x10000)  # Larger buffer for paths
                length = ctypes.c_ulong(0)
                
                status = NtQueryObject(
                    dup_handle,
                    ObjectNameInformation,
                    name_info,
                    ctypes.sizeof(name_info),
                    ctypes.byref(length)
                )
                
                if status >= 0 and length.value > 0:
                    try:
                        # The first UNICODE_STRING structure contains the name
                        # Skip the Length and MaximumLength fields (2 USHORTs = 4 bytes)
                        # and read the pointer value
                        buffer_ptr = struct.unpack_from("<L", name_info, 8)[0]
                        
                        # If buffer_ptr is non-zero, there's a name
                        if buffer_ptr:
                            # For simplicity, we're going to scan the whole buffer for a UTF-16LE string
                            obj_name = name_info.raw[16:length.value].decode('utf-16le', errors='ignore').strip('\x00')
                            if obj_name:
                                handle_data['object_name'] = obj_name
                    except:
                        pass
                
                # --- Get handle security information ---
                if detailed and handle_data['object_type']:
                    try:
                        # Try to get security information
                        security_info = win32security.GetSecurityInfo(
                            dup_handle.value,
                            win32security.SE_KERNEL_OBJECT,
                            win32security.OWNER_SECURITY_INFORMATION |
                            win32security.GROUP_SECURITY_INFORMATION |
                            win32security.DACL_SECURITY_INFORMATION
                        )
                        
                        # Extract the DACL
                        dacl = security_info.GetSecurityDescriptorDacl()
                        if dacl:
                            # Analyze permissions
                            handle_data['access_rights'] = []
                            for i in range(dacl.GetAceCount()):
                                ace = dacl.GetAce(i)
                                handle_data['access_rights'].append({
                                    'type': ace[0][0],  # ACE type
                                    'flags': ace[0][1],  # ACE flags
                                    'mask': ace[1],      # Access mask
                                    'trustee': str(ace[2])  # SID
                                })
                                
                                # Check for "Everyone" access to sensitive objects
                                if "S-1-1-0" in str(ace[2]):  # Everyone SID
                                    if handle_data['object_type'] in ['Process', 'Thread', 'Token', 'Section']:
                                        handle_data['suspicious_rating'] += 3
                                        handle_data['analysis'].append("Everyone has access to sensitive object")
                                        handle_data['malware_techniques'].append("T1134 - Access Token Manipulation")
                                        suspicious_count += 1
                    except:
                        pass
                
                # --- Analyze the handle based on its characteristics ---
                
                # Check object name against suspicious patterns
                if handle_data['object_name']:
                    for pattern_name, patterns in SUSPICIOUS_HANDLE_PATTERNS.items():
                        for pattern in patterns:
                            if pattern in handle_data['object_name']:
                                handle_data['suspicious_rating'] += 2
                                handle_data['analysis'].append(f"Matched suspicious pattern: {pattern_name}")
                                handle_data['malware_techniques'].append(f"Potential {pattern_name} technique")
                                suspicious_count += 1
                                
                                # Update malware family indicators
                                if pattern_name == "process_hollowing" or pattern_name == "code_injection":
                                    malware_family_indicators['process_injection'] += 1
                                    malware_family_indicators['trojan'] += 1
                                elif pattern_name == "token_manipulation":
                                    malware_family_indicators['rootkit'] += 1
                                elif pattern_name == "registry_persistence":
                                    malware_family_indicators['backdoor'] += 1
                                elif pattern_name == "credential_access":
                                    malware_family_indicators['infostealer'] += 1
                                
                    # Check for specific types of objects
                    if handle_data['object_type'] == 'Process':
                        # Process handles can indicate code injection
                        handle_data['analysis'].append("Process handle could be used for code injection")
                        handle_data['malware_techniques'].append("T1055 - Process Injection")
                        handle_data['suspicious_rating'] += 1
                        malware_family_indicators['process_injection'] += 1
                        
                    elif handle_data['object_type'] == 'Section':
                        # Section objects can be used for sharing memory between processes
                        if 'ALPC' not in handle_data['object_name'] and 'Anonymous' not in handle_data['object_name']:
                            handle_data['analysis'].append("Named section could be used for inter-process communication")
                            handle_data['malware_techniques'].append("T1559 - Inter-Process Communication")
                            handle_data['suspicious_rating'] += 1
                            
                    elif handle_data['object_type'] == 'Token':
                        # Token handles can indicate privilege escalation attempts
                        handle_data['analysis'].append("Token handle could be used for privilege escalation")
                        handle_data['malware_techniques'].append("T1134 - Access Token Manipulation")
                        handle_data['suspicious_rating'] += 2
                        malware_family_indicators['rootkit'] += 1
                    elif handle_data['object_type'] == 'Mutant':  # Mutex
                        # Check for malware-specific mutex patterns
                        if handle_data['object_name']:
                            for mutex_pattern in MALWARE_MUTEX_PATTERNS:
                                if mutex_pattern in handle_data['object_name']:
                                    handle_data['suspicious_rating'] += 5
                                    handle_data['analysis'].append(f"Matched known malware mutex pattern: {mutex_pattern}")
                                    handle_data['malware_techniques'].append("T1056 - Input Capture")
                                    handle_data['flags'].append('KNOWN_MALWARE_MUTEX')
                                    
                                    if "Ransomware_" in mutex_pattern:
                                        malware_family_indicators['ransomware'] += 3
                                        results['malware_indicators'].append({
                                            'type': 'MUTEX',
                                            'indicator': handle_data['object_name'],
                                            'severity': 'HIGH', 
                                            'family': 'Ransomware',
                                            'description': 'Mutex commonly used by ransomware'
                                        })
                                    elif "Global\\AC_" in mutex_pattern:
                                        malware_family_indicators['trojan'] += 3
                                        results['malware_indicators'].append({
                                            'type': 'MUTEX',
                                            'indicator': handle_data['object_name'],
                                            'severity': 'HIGH', 
                                            'family': 'Qakbot',
                                            'description': 'Mutex used by Qakbot banking trojan'
                                        })
                                    elif any(av in mutex_pattern for av in ["_AVIRA_", "AhnLab", "AVG_", "Kaspersky_"]):
                                        malware_family_indicators['trojan'] += 2
                                        results['malware_indicators'].append({
                                            'type': 'MUTEX',
                                            'indicator': handle_data['object_name'],
                                            'severity': 'MEDIUM', 
                                            'family': 'Unknown',
                                            'description': 'Anti-AV mutex indicating AV evasion'
                                        })
                                    else:
                                        malware_family_indicators['trojan'] += 1
                                        results['malware_indicators'].append({
                                            'type': 'MUTEX',
                                            'indicator': handle_data['object_name'],
                                            'severity': 'MEDIUM', 
                                            'family': 'Generic Malware',
                                            'description': 'Suspicious mutex pattern'
                                        })
                    
                    elif handle_data['object_type'] == 'File':
                        # Check for interesting file access patterns
                        if handle_data['object_name']:
                            # System32 access could indicate system tampering
                            if '\\Windows\\System32\\' in handle_data['object_name']:
                                handle_data['analysis'].append("Access to System32 files")
                                
                                # Look for common system files that malware targets
                                critical_system_files = ['ntdll.dll', 'kernel32.dll', 'wininet.dll', 'user32.dll', 'advapi32.dll']
                                for file in critical_system_files:
                                    if file in handle_data['object_name']:
                                        handle_data['suspicious_rating'] += 2
                                        handle_data['malware_techniques'].append("T1574 - Hijack Execution Flow")
                                        malware_family_indicators['rootkit'] += 1
                                        handle_data['analysis'].append(f"Access to critical system file: {file}")
                            
                            # Check for access to user data which might indicate infostealing
                            user_data_paths = ['\\Users\\', '\\Documents', '\\AppData\\', '\\Desktop\\']
                            for path in user_data_paths:
                                if path in handle_data['object_name']:
                                    handle_data['suspicious_rating'] += 1
                                    handle_data['analysis'].append(f"Access to user data: {path}")
                                    handle_data['malware_techniques'].append("T1005 - Data from Local System")
                                    malware_family_indicators['infostealer'] += 1
                            
                            # Look for specific file extensions that might indicate ransomware activity
                            ransomware_targets = ['.doc', '.xls', '.ppt', '.pdf', '.jpg', '.png', '.txt', '.zip']
                            for ext in ransomware_targets:
                                if handle_data['object_name'].lower().endswith(ext):
                                    handle_data['suspicious_rating'] += 1
                                    handle_data['analysis'].append(f"Access to potentially valuable file: {ext}")
                                    malware_family_indicators['ransomware'] += 1
                    
                    elif handle_data['object_type'] == 'Key':  # Registry key
                        # Check for suspicious registry activity
                        if handle_data['object_name']:
                            # Look for autorun registry locations
                            autorun_locations = [
                                'CurrentVersion\\Run', 
                                'CurrentVersion\\RunOnce', 
                                'CurrentControlSet\\Services'
                            ]
                            
                            for location in autorun_locations:
                                if location in handle_data['object_name']:
                                    handle_data['suspicious_rating'] += 3
                                    handle_data['analysis'].append(f"Access to autorun registry location: {location}")
                                    handle_data['malware_techniques'].append("T1547 - Boot or Logon Autostart Execution")
                                    malware_family_indicators['backdoor'] += 2
                                    results['malware_indicators'].append({
                                        'type': 'REGISTRY',
                                        'indicator': handle_data['object_name'],
                                        'severity': 'HIGH', 
                                        'technique': 'Persistence',
                                        'description': 'Registry autorun location accessed'
                                    })
                
                # Update handle data flags based on suspicious rating
                if handle_data['suspicious_rating'] >= 5:
                    handle_data['flags'].append('HIGH_RISK')
                    handle_data['protection_level'] = 'Critical'
                elif handle_data['suspicious_rating'] >= 3:
                    handle_data['flags'].append('MEDIUM_RISK')
                    handle_data['protection_level'] = 'High'
                elif handle_data['suspicious_rating'] >= 1:
                    handle_data['flags'].append('LOW_RISK')
                    handle_data['protection_level'] = 'Medium'
                else:
                    handle_data['protection_level'] = 'Low'
                
                # Add the analyzed handle to the results
                if handle_data['object_type'] is not None:
                    results['handles'].append(handle_data)
                    
                    # Track suspicious objects for statistics
                    if handle_data['suspicious_rating'] > 0:
                        results['statistics']['suspicious_objects'] += 1
                    
                    # If handle is suspicious but has no name, it might be hidden
                    if handle_data['suspicious_rating'] > 0 and handle_data['object_name'] is None:
                        results['statistics']['hidden_objects'] += 1
                        hidden_count += 1
                        handle_data['flags'].append('HIDDEN_OBJECT')
                
                # Clean up by closing duplicated handle
                if dup_handle.value:
                    kernel32.CloseHandle(dup_handle)
            
            except Exception as e:
                # Log the error but continue processing
                logging.error(f"Error analyzing handle {handle_value}: {str(e)}")
                continue
        
        # Add anomalies and threat assessment to results
        if hidden_count > 0:
            results['anomalies'].append({
                'type': 'HIDDEN_OBJECTS',
                'count': hidden_count,
                'description': f'Process has {hidden_count} hidden objects which might indicate intentional obfuscation'
            })
        
        if suspicious_count > 0:
            results['anomalies'].append({
                'type': 'SUSPICIOUS_OBJECTS',
                'count': suspicious_count,
                'description': f'Process has {suspicious_count} suspicious object handles'
            })
        
        # Determine most likely malware family based on indicators
        if any(value > 0 for value in malware_family_indicators.values()):
            # Find the malware family with the highest indicator count
            likely_family = max(malware_family_indicators.items(), key=lambda x: x[1])
            
            if likely_family[1] >= 3:  # Only report if we have a moderate confidence
                severity = "HIGH" if likely_family[1] >= 5 else "MEDIUM"
                results['anomalies'].append({
                    'type': 'POTENTIAL_MALWARE',
                    'family': likely_family[0],
                    'confidence': likely_family[1],
                    'severity': severity,
                    'description': f'Process shows indicators consistent with {likely_family[0]} malware'
                })
        
        # Update final statistics
        results['statistics']['suspicious_objects'] = suspicious_count
        results['statistics']['hidden_objects'] = hidden_count
        results['statistics']['total_handles'] = len(results['handles'])
        results['statistics']['process_id'] = pid
        results['statistics']['process_name'] = process_name
        
        # Generate an overall threat score (0-100)
        results['threat_score'] = min(100, (suspicious_count * 5) + (hidden_count * 10) + 
                                sum(handle['suspicious_rating'] * 2 for handle in results['handles']))
        
        # Determine overall verdict
        if results['threat_score'] >= 70:
            results['verdict'] = "HIGH_RISK"
        elif results['threat_score'] >= 40:
            results['verdict'] = "SUSPICIOUS" 
        elif results['threat_score'] >= 20:
            results['verdict'] = "POTENTIALLY_UNWANTED"
        else:
            results['verdict'] = "CLEAN"
        
        return results
    def enumerate_processes(self):
        """Enumerate all running processes using Windows API"""
        processes = self.get_process_list()
        kernel32 = ctypes.windll.kernel32
        psapi = ctypes.windll.psapi
        
        # Create process snapshot
        snapshot = kernel32.CreateToolhelp32Snapshot(0x2, 0)  # TH32CS_SNAPPROCESS
        
        if snapshot != -1:
            class PROCESSENTRY32W(ctypes.Structure):
                _fields_ = [
                    ("dwSize", ctypes.c_ulong),
                    ("cntUsage", ctypes.c_ulong),
                    ("th32ProcessID", ctypes.c_ulong),
                    ("th32DefaultHeapID", ctypes.c_void_p),
                    ("th32ModuleID", ctypes.c_ulong),
                    ("cntThreads", ctypes.c_ulong),
                    ("th32ParentProcessID", ctypes.c_ulong),
                    ("pcPriClassBase", ctypes.c_long),
                    ("dwFlags", ctypes.c_ulong),
                    ("szExeFile", ctypes.c_wchar * 260)
                ]
            
            process_entry = PROCESSENTRY32W()
            process_entry.dwSize = ctypes.sizeof(process_entry)
            
            # Get first process
            if kernel32.Process32FirstW(snapshot, ctypes.byref(process_entry)):
                while True:
                    try:
                        process_handle = kernel32.OpenProcess(
                            0x1000,  # PROCESS_QUERY_LIMITED_INFORMATION
                            False,
                            process_entry.th32ProcessID
                        )
                        
                        if process_handle:
                            processes.append({
                                'handle': process_handle,
                                'pid': process_entry.th32ProcessID,
                                'name': process_entry.szExeFile,
                                'threads': process_entry.cntThreads,
                                'parent_pid': process_entry.th32ParentProcessID
                            })
                    except:
                        pass
                    
                    if not kernel32.Process32NextW(snapshot, ctypes.byref(process_entry)):
                        break
                        
            kernel32.CloseHandle(snapshot)
        
        return processes
    def get_process_list(self):
        """
        Get a list of all processes in the system using Windows API.
        
        Returns:
            list: A list of process information dictionaries containing:
                - pid: Process ID
                - name: Process name
                - parent_pid: Parent Process ID
                - threads: Number of threads
        """
        # Define constants
        TH32CS_SNAPPROCESS = 0x00000002
        INVALID_HANDLE_VALUE = -1
        
        # Load kernel32.dll
        k32 = ctypes.WinDLL('kernel32', use_last_error=True)
        CreateToolHelp32Snapshot = k32.CreateToolhelp32Snapshot
        # Define required function prototypes
        CreateToolHelp32Snapshot.argtypes = [wintypes.DWORD, wintypes.DWORD]
        CreateToolHelp32Snapshot.restype = wintypes.HANDLE
        
        Process32First = k32.Process32First
        Process32First.argtypes = [wintypes.HANDLE, ctypes.POINTER(PROCESSENTRY32)]
        Process32First.restype = wintypes.BOOL
        
        Process32Next = k32.Process32Next
        Process32Next.argtypes = [wintypes.HANDLE, ctypes.POINTER(PROCESSENTRY32)]
        Process32Next.restype = wintypes.BOOL
        
        CloseHandle = k32.CloseHandle
        CloseHandle.argtypes = [wintypes.HANDLE]
        CloseHandle.restype = wintypes.BOOL
        
        process_list = []
        h_snapshot = INVALID_HANDLE_VALUE
        
        try:
            # Create snapshot of processes
            h_snapshot = CreateToolHelp32Snapshot(TH32CS_SNAPPROCESS, 0)
            if h_snapshot == INVALID_HANDLE_VALUE:
                error = ctypes.get_last_error()
                logging.error(f"Failed to create process snapshot. Error: {error}")
                return []  # Return empty list on failure
            
            # Initialize process entry structure
            process_entry = PROCESSENTRY32()
            process_entry.dwSize = sizeof(PROCESSENTRY32)
            
            # Get first process
            success = Process32First(h_snapshot, byref(process_entry))
            
            while success:
                try:
                    # Extract process information
                    pid = process_entry.th32ProcessID
                    
                    # Skip invalid PIDs (should never happen with API, but being defensive)
                    if pid <= 0:
                        logging.debug(f"Skipping invalid PID: {pid}")
                        success = Process32Next(h_snapshot, byref(process_entry))
                        continue
                        
                    name = process_entry.szExeFile.decode('utf-8', errors='replace')
                    logging.debug(f"Processing process: PID={pid}, Name={name}")
                    # Create process info dictionary
                    process_info = {
                        'pid': pid,
                        'name': name,
                        'parent_pid': process_entry.th32ParentProcessID,
                        'threads': process_entry.cntThreads,
                        # Add memory scanning relevant info
                        'is_critical': self.is_critical_process(name),
                        'scan_priority': self.get_scan_priority(name, pid)
                    }
                    
                    process_list.append(process_info)
                    
                except Exception as e:
                    logging.debug(f"Error processing process entry: {str(e)}")
                
                # Get next process
                success = Process32Next(h_snapshot, byref(process_entry))
                
        except Exception as e:
            logging.error(f"Error enumerating processes: {str(e)}")
        finally:
            # Close the snapshot handle
            if h_snapshot != INVALID_HANDLE_VALUE:
                k32.CloseHandle(h_snapshot)
    def is_critical_process(self, process_name):
        """
        Determine if a process is critical to system operation.
        
        Critical processes usually should be treated carefully during scanning
        as they might be protected or cause system instability if accessed incorrectly.
        
        Args:
            process_name (str): The name of the process executable
            
        Returns:
            bool: True if the process is critical, False otherwise
        """
        # List of known critical system processes
        critical_processes = [
            'System',
            'Registry',
            'smss.exe',
            'csrss.exe',
            'wininit.exe',
            'services.exe',
            'lsass.exe',
            'svchost.exe',
            'winlogon.exe',
            'explorer.exe',
            'dwm.exe',
            'MemCompression',
            'conhost.exe',
            'ntoskrnl.exe',
            'MsMpEng.exe',  # Windows Defender
            'audiodg.exe',
            'spoolsv.exe',
            'TrustedInstaller.exe'
        ]
        
        # Case-insensitive check
        process_name_lower = process_name.lower()
        for critical_process in critical_processes:
            if critical_process.lower() == process_name_lower:
                return True
                
        # Check for common system process patterns
        if process_name_lower.startswith('sys') or 'service' in process_name_lower:
            return True
            
        return False

    def get_scan_priority(self, process_name, pid):
        """
        Determine the scanning priority for a process.
        
        Higher priority processes will be scanned first or more thoroughly.
        
        Args:
            process_name (str): The name of the process executable
            pid (int): The process ID
            
        Returns:
            int: Priority value (higher number = higher priority)
        """
        # Default priority
        priority = 5
        
        # Lower priority for critical processes to avoid system instability
        if self.is_critical_process(process_name):
            return 1
        
        # Higher priority for potentially interesting processes
        high_interest_processes = [
            'chrome.exe',
            'firefox.exe',
            'msedge.exe',
            'iexplore.exe',
            'outlook.exe',
            'thunderbird.exe',
            'excel.exe', 
            'word.exe',
            'powerpnt.exe',
            'powershell.exe',
            'cmd.exe',
            'python.exe',
            'javaw.exe',
            'java.exe',
            'notepad.exe'
        ]
        
        process_name_lower = process_name.lower()
        
        # Check for high interest processes
        for high_interest in high_interest_processes:
            if high_interest.lower() == process_name_lower:
                return 10
        
        # Medium priority for user applications (not system processes)
        if not process_name_lower.endswith('.exe'):
            return 3
        
        # Check for suspicious behavior indicators
        if (process_name_lower.startswith('temp') or 
            'tmp' in process_name_lower or
            '_' in process_name_lower and len(process_name_lower) < 10):
            return 8
        
        # Prioritize non-Windows processes
        windows_path = os.environ.get('WINDIR', 'C:\\Windows').lower()
        try:
            process_path = self.get_process_path(pid)
            if process_path and windows_path not in process_path.lower():
                return 7
        except:
            pass
        
        return priority

    def memory_maps(self):
        memory_regions = []
        try:
            process = psutil.Process(self.pid)
            for mmap in process.memory_maps():
                memory_regions.append(mmap)
        except (psutil.NoSuchProcess, psutil.AccessDenied):
            pass
        return memory_regions
    def scan_memory_regions(self, pid: int) -> dict:
        """Scans all accessible memory regions of a process for suspicious patterns using Windows API"""
        suspicious_patterns = {}
        process_handle = None

        # Define necessary constants
        PROCESS_QUERY_INFORMATION = 0x0400
        PROCESS_VM_READ = 0x0010
        MEM_COMMIT = 0x1000
        PAGE_NOACCESS = 0x01

        # Initialize YARA rules
        self.yara_manager = YaraRuleManager()
        self.yara_manager.fetch_all_rules()
        self.yara_manager.combined_rules = self.yara_manager.compile_combined_rules()
        
        # If no PID is provided, don't try to scan system-wide
        if pid is None:
            logging.debug("Cannot scan memory: No PID provided")
            return None
            
        # Validate PID
        validated_pid = self.safe_process_validation(pid)
        if validated_pid is None:
            return None
        # Add a sanity check to prevent scanning with invalid PID
        if validated_pid <= 0:
            logging.debug(f"Invalid PID for memory scan: {validated_pid}")
            return None
        try:
            # Only open the process handle ONCE
            kernel32 = ctypes.windll.kernel32
            logging.debug("Getting system information using Windows API")
            process_handle = kernel32.OpenProcess(
                PROCESS_QUERY_INFORMATION | PROCESS_VM_READ,
                False,
                validated_pid
            )
            
            if not process_handle:
                error_code = kernel32.GetLastError()
                logging.warning(f"Failed to open process with PID {validated_pid}. Error: {error_code}")
                return suspicious_patterns
                
            # Get process info
            process_info = self._get_process_info_winapi(process_handle, validated_pid)
            
            # Initialize a counter for scanned regions
            scanned_regions = 0
            interesting_regions = 0
            
            # Enumerate all memory regions
            for region in self._enumerate_memory_regions_winapi(process_handle):
                scanned_regions += 1
                
                # Skip non-committed memory
                if not (region['State'] & MEM_COMMIT):
                    continue
                    
                # Skip memory we can't read
                if region['Protect'] & PAGE_NOACCESS:
                    continue
                    
                try:
                    # Read memory content
                    memory_content = self._read_memory_in_chunks_winapi(
                        process_handle,
                        region['BaseAddress'],
                        region['RegionSize']
                    )
                    
                    # Skip empty or too small memory regions
                    if not memory_content or len(memory_content) < 8:
                        continue
                        
                    # Scan this memory region
                    region_results = self._scan_memory_content_winapi(memory_content, region, process_info, suspicious_patterns)
                    if region_results:
                        interesting_regions += 1
                        
                except Exception as e:
                    logging.debug(f"Failed to read memory at {hex(region['BaseAddress'])}: {str(e)}")
            # Log meaningful results
            logging.debug(f"Scanned {scanned_regions} memory regions, found {interesting_regions} interesting regions")
                    
        except Exception as e:
            logging.error(f"Error scanning memory regions for PID {validated_pid}: {str(e)}")
               
         # Handle region dict vs object properly
        if isinstance(region, dict):
            if not (region.get('State', 0) & self.MEM_COMMIT):
                return None
            protection = region.get('Protect', 0)
            base_addr = region.get('BaseAddress', 0)
            region_size = region.get('RegionSize', 0)
        else:
            if not (region.State & self.MEM_COMMIT):
                return None
            protection = region.Protect
            base_addr = region.BaseAddress
            region_size = region.RegionSize
        
        # Convert base address safely
        base_addr_int = self.safe_int_conversion(base_addr)
        
        # Skip tiny regions that are likely not interesting
        if region_size < 256:
            return None
        
        # First check memory protection
        is_executable = bool(protection & (self.PAGE_EXECUTE | self.PAGE_EXECUTE_READ |
                                self.PAGE_EXECUTE_READWRITE | self.PAGE_EXECUTE_WRITECOPY))
        
        # Report suspicious memory protections first
        if protection & self.PAGE_EXECUTE_READWRITE:
            process_name = self._get_process_name_winapi(pid)
            self.shellcode_tome = ShellCodeTome()
            detection = {
                'pid': pid,
                'process': process_name,
                'type': 'RWX Memory',
                'details': 'Read-Write-Execute memory (high-risk permission combination)',
                'location': f'Memory region at {hex(base_addr_int)}, size: {region_size}'
            }
            self.shellcode_tome.add_detection(detection)
            return detection
        
        # We only want to analyze executable memory (with some exceptions)
        if not is_executable and not (protection & self.PAGE_NOACCESS and 
                                    process_name.lower() in ['svchost.exe', 'lsass.exe']):
            return None
        
        try:
            # Read memory content in chunks to handle large regions
            memory_content = self._read_memory_in_chunks_winapi(
                process_handle,
                base_addr_int,
                region_size
            )
            
            if not memory_content:
                return None
            
            # Use ShellCodeTome's integrated analysis
            detections = self.shellcode_tome.analyze_memory_region(
                memory_content, 
                pid, 
                process_name, 
                base_addr_int, 
                region_size
            )
            
            if detections:
                return detections[0]  # Return the first detection for immediate reporting
            return None     
        except Exception as e:
            logging.debug(f"Error scanning memory region at {hex(base_addr_int)}: {str(e)}")
        
                   
        finally:
                # Close the handle only once and only if it exists
                if process_handle:
                    kernel32.CloseHandle(process_handle)
                    
                return suspicious_patterns        

        
    def _read_memory_in_chunks_winapi(self, process_handle, base_address, region_size, chunk_size=4096):
        """Read process memory in chunks using Windows API directly"""
        # Validate inputs
        if base_address is None or region_size is None:
            logging.debug("Cannot read memory: base_address or region_size is None")
            return None
        
        memory_data = bytearray()
        bytes_read = 0
        
        # Ensure base_address and region_size are integers
        try:
            base_address = int(base_address)
            region_size = int(region_size)
        except (TypeError, ValueError) as e:
            logging.debug(f"Type conversion error: {e}")
            return None
        
        # Skip if zero or negative size
        if region_size <= 0:
            return None
        
        while bytes_read < region_size:
            current_chunk_size = min(chunk_size, region_size - bytes_read)
            current_address = base_address + bytes_read
            
            try:
                kernel32 = ctypes.windll.kernel32
                # Prepare buffer and structure for ReadProcessMemory
                buffer = ctypes.create_string_buffer(current_chunk_size)
                bytes_read_chunk = ctypes.c_size_t(0)
                
                success = kernel32.ReadProcessMemory(
                    process_handle,
                    ctypes.c_void_p(current_address),
                    buffer,
                    current_chunk_size,
                    ctypes.byref(bytes_read_chunk)
                )
                
                if success and bytes_read_chunk.value > 0:
                    memory_data.extend(buffer.raw[:bytes_read_chunk.value])
                
                bytes_read += current_chunk_size
                
            except Exception as e:
                # Log error and continue to next chunk
                logging.debug(f"Memory read error at {hex(current_address)}: {e}")
                bytes_read += current_chunk_size
        
            return bytes(memory_data) if memory_data else None
    def is_valid_pid(pid):
        """Validate process ID before attempting operations"""
        if pid is None:
            logging.debug(f"Invalid PID: None")
            return False  # Return False for None PID
        
        try:
            pid_int = int(pid)
            if pid_int <= 0:
                logging.debug(f"Invalid PID: {pid} (non-positive)")
                return False
            return True
        except (ValueError, TypeError):
            logging.debug(f"Invalid PID: {pid} (not convertible to int)")
            return False
    def safe_process_validation(self, pid):
        """Enhanced process validation with proper error handling"""
        # Early return for None cases
        if pid is None:
            logging.debug("Invalid PID: None")
            return False
        
        try:
            # Handle dictionary case
            if isinstance(pid, dict):
                if 'pid' in pid:
                    pid = pid['pid']
                elif 'basic' in pid and 'pid' in pid['basic']:
                    pid = pid['basic']['pid']
                else:
                    # Couldn't find PID in dictionary
                    logging.debug(f"Invalid PID structure: {pid}")
                    return None
            
            # Handle objects with pid attribute
            if hasattr(pid, 'pid'):
                pid = pid.pid
            
            # Convert to int
            try:
                pid_int = int(pid)
                if pid_int <= 0:
                    logging.debug(f"Invalid PID value: {pid_int}")
                    return None
                return pid_int
            except (ValueError, TypeError):
                logging.debug(f"Cannot convert to valid PID: {pid}")
                return None
                
        except Exception as e:
            logging.debug(f"PID validation error: {str(e)}")
            return None

    def open_process_with_privileges(self, pid, desired_access=None):
        """Open a process with the specified access rights, handling errors properly"""
        if not pid or pid is None:
            logging.debug(f"Cannot open process: Invalid PID")
            return None
            
        # Default access rights if none specified
        if desired_access is None:
            desired_access = win32con.PROCESS_QUERY_INFORMATION | win32con.PROCESS_VM_READ
            
        try:
            process_handle = win32api.OpenProcess(desired_access, False, pid)
            if not process_handle:
                error_code = ctypes.get_last_error()
                logging.debug(f"Failed to open process {pid}, error code: {error_code}")
                return None
            return process_handle
        except Exception as e:
            logging.debug(f"Exception opening process {pid}: {str(e)}")
            return None
    def validate_pid(pid):
        """Unified PID validation with consistent return values"""
        # First extract PID value from various possible formats
        if pid is None:
            logging.debug("Invalid PID: None")
            return None
            
        try:
            # Extract PID from dictionaries or objects
            if isinstance(pid, dict):
                pid = pid.get('pid') or (pid.get('basic', {}).get('pid') if 'basic' in pid else None)
            elif hasattr(pid, 'pid'):
                pid = pid.pid
                
            # Validate the extracted value
            if pid is None:
                logging.debug("Invalid PID: None after extraction")
                return None
                
            pid_int = int(pid)
            if pid_int <= 0:
                logging.debug(f"Invalid PID: {pid_int} (non-positive)")
                return None
                
            return pid_int
        except Exception as e:
            logging.debug(f"PID validation error: {str(e)}")
            return None
    def check_for_hollowing(self, pid):
        """Wrapper function to check for process hollowing with better error handling"""
        try:
            # Get a handle to the process
            process_handle = self.audit_process_handles(pid)
            
            # Check if this is a protected process
            if not process_handle:
                process_info = self._get_process_info_winapi(pid)
                if process_info and process_info.get('access_denied_expected', False):
                    process_name = process_info.get('name', f"PID_{pid}")
                    logging.debug(f"Process {process_name} is protected, skipping hollowing check")
                    return []
                
            # Run hollowing detection
            hollowing_indicators = self.detect_process_hollowing(process_handle or pid)
            
            # Ensure hollowing_indicators is always a list
            if hollowing_indicators is None:
                hollowing_indicators = []
            elif isinstance(hollowing_indicators, bool):  # Handle boolean return
                if hollowing_indicators:
                    hollowing_indicators = ["General hollowing indicators detected"]
                else:
                    hollowing_indicators = []
            
            return hollowing_indicators
        
        except Exception as e:
            logging.debug(f"Error in check_for_hollowing for PID {pid}: {str(e)}")
            return []
        finally:
            if process_handle:
                kernel32 = ctypes.windll.kernel32
                kernel32.CloseHandle(process_handle)
    def analyze_process(self, process_name, process_path, pid):
        # Create a risk score rather than binary trusted/untrusted
        risk_score = 0
        process_info = None
        # Check if process appears to be a system process
        known_system_processes = {
            "svchost.exe": r"C:\Windows\System32",
            "WUDFHost.exe": r"C:\Windows\System32",
            "NVDisplay.Container.exe": r"C:\Program Files\NVIDIA Corporation"
        }
        cmd_line = process_info.get('command_line', '')
        modules = process_info.get('modules', [])
        
        # Analyze command line
        cmd_analysis = self.analyze_command_line(cmd_line)
        
        # Analyze modules
        module_analysis = self.analyze_modules(modules)
        if process_name.lower() in cmd_analysis:
            risk_score += 10
        if process_name.lower() in module_analysis:
            risk_score += 10
        # 1. Path verification - Is it running from the expected location?
        if process_name.lower() in known_system_processes:
            expected_path = known_system_processes[process_name.lower()]
            if not process_path.lower().startswith(expected_path.lower()):
                risk_score += 40  # High risk: system process from unexpected location
                logging.warning(f"System process {process_name} running from unexpected location: {process_path}")
        
        # 2. Digital signature verification
        if not self._verify_digital_signature(process_path):
            risk_score += 30
            logging.warning(f"Process {process_name} has invalid or missing digital signature")
        
        # 3. Process behavior analysis (even for "trusted" processes)
        try:
            # Limited access mode - try to scan what we can without full access
            behavioral_indicators = self._scan_process_behavior(pid, limited_access=True)
            if behavioral_indicators:
                risk_score += len(behavioral_indicators) * 10
                logging.warning(f"Process {process_name} exhibits suspicious behaviors: {behavioral_indicators}")
        except psutil.AccessDenied:
            # Log access denied but don't immediately consider suspicious
            logging.info(f"Limited access to process {process_name} (PID {pid}) - performing alternative checks")
            
            # 4. Check loaded modules from outside the process
            try:
                suspicious_modules = self._check_loaded_modules_indirectly(pid)
                if suspicious_modules:
                    risk_score += 25
                    logging.warning(f"Process {process_name} has loaded suspicious modules: {suspicious_modules}")
            except Exception as e:
                logging.debug(f"Error checking modules indirectly: {str(e)}")
        
        # 5. Memory pattern scanning - can be done with limited rights
        try:
            memory_findings = self.scan_process_memory(pid)
            if memory_findings:
                risk_score += 35
                logging.warning(f"Process {process_name} contains suspicious memory patterns")
        except Exception as e:
            logging.debug(f"Error scanning accessible memory: {str(e)}")
        
        # Evaluate final risk score
        if risk_score >= 50:
            logging.warning(f"High risk process detected: {process_name} (PID {pid}), score: {risk_score}")
            return True  # Suspicious
        elif risk_score >= 20:
            logging.info(f"Moderate risk process: {process_name} (PID {pid}), score: {risk_score}")
            return False  # Not immediately suspicious, but worth monitoring
        else:
            logging.debug(f"Low risk process: {process_name} (PID {pid}), score: {risk_score}")
            return False  # Likely benign
    def analyze_command_line(cmd_line):
        """Analyze the command line arguments for suspicious patterns."""
        results = {}
        
        # Check if command line is empty
        if not cmd_line:
            results['status'] = 'unknown'
            return results
        
        # Look for suspicious arguments
        suspicious_args = ['--hidden', '--no-log', '--bypass-security']
        for arg in suspicious_args:
            if arg in cmd_line:
                results.setdefault('suspicious_args', []).append(arg)
        
        # Check for script execution
        if '.py' in cmd_line or '.sh' in cmd_line or '.ps1' in cmd_line:
            results['script_execution'] = True
        
        results['status'] = 'suspicious' if results else 'normal'
        return results

    def analyze_modules(modules):
        """Analyze loaded modules for suspicious or unexpected entries."""
        results = {}
        
        # Check if modules list is empty
        if not modules:
            results['status'] = 'unknown'
            return results
        
        # Known suspicious modules
        suspicious_modules = ['inject.dll', 'keylog.dll', 'hook.dll']
        
        # Check each module
        for module in modules:
            module_name = module.get('name', '')
            module_path = module.get('path', '')
            
            # Check against suspicious list
            if any(sus_mod in module_name.lower() for sus_mod in suspicious_modules):
                results.setdefault('suspicious_modules', []).append({
                    'name': module_name,
                    'path': module_path
                })
            
            # Check for unsigned modules (if signature info is available)
            if module.get('signed') is False:
                results.setdefault('unsigned_modules', []).append({
                    'name': module_name,
                    'path': module_path
                })
        
        results['status'] = 'suspicious' if results.get('suspicious_modules') or results.get('unsigned_modules') else 'normal'
        return results    
    def _verify_digital_signature(self, file_path):
        """
        Verifies the digital signature of a file using Windows Authenticode.
        
        Args:
            file_path: Path to the executable or DLL to verify
            
        Returns:
            bool: True if the file has a valid signature, False otherwise
        """
        WTD_UI_NONE = 2
        WTD_REVOKE_NONE = 0
        WTD_CHOICE_FILE = 1
        WTD_STATEACTION_VERIFY = 1
        WTD_STATEACTION_CLOSE = 2
        WTD_SAFER_FLAG = 0x100
        LPVOID = ctypes.c_void_p
        WTD_E_SECURITY_SETTINGS = 0x80096004
        if not os.path.exists(file_path):
            logging.debug(f"File not found for signature verification: {file_path}")
            return False
        
        try:
            # Initialize structures for WinVerifyTrust
            guid = GUID()
            guid.Data1 = 0xC689AAB8
            guid.Data2 = 0x8E78
            guid.Data3 = 0x11D0
            guid.Data4 = b"\x8C\x47\x00\xC0\x4F\xC2\x95\xEE"
            
            file_info = WINTRUST_FILE_INFO()
            file_info.cbStruct = ctypes.sizeof(WINTRUST_FILE_INFO)
            file_info.pcwszFilePath = file_path
            file_info.hFile = None
            file_info.pgKnownSubject = None
            
            trust_data = WINTRUST_DATA()
            trust_data.cbStruct = ctypes.sizeof(WINTRUST_DATA)
            trust_data.pPolicyCallbackData = None
            trust_data.pSIPClientData = None
            trust_data.dwUIChoice = WTD_UI_NONE
            trust_data.fdwRevocationChecks = WTD_REVOKE_NONE
            trust_data.dwUnionChoice = WTD_CHOICE_FILE
            trust_data.pFile = ctypes.pointer(file_info)
            trust_data.dwStateAction = WTD_STATEACTION_VERIFY
            trust_data.hWVTStateData = None
            trust_data.pwszURLReference = None
            trust_data.dwProvFlags = 0
            trust_data.dwUIContext = 0
            
            # Call WinVerifyTrust
            wintrust_dll = windll.wintrust
            result = wintrust_dll.WinVerifyTrust(
                None,
                ctypes.byref(guid),
                ctypes.byref(trust_data)
            )
            
            # Clean up
            trust_data.dwStateAction = WTD_STATEACTION_CLOSE
            wintrust_dll.WinVerifyTrust(
                None,
                ctypes.byref(guid),
                ctypes.byref(trust_data)
            )
            
            # Result interpretation
            if result == 0:
                # Extract signer information for additional verification if needed
                try:
                    signer_info = win32api.GetSignerInfo(file_path)
                    logging.debug(f"File signed by: {signer_info.get('signer', 'Unknown')}")
                except:
                    pass
                return True
            elif result == WTD_E_SECURITY_SETTINGS:
                logging.debug(f"Security settings prevented signature check: {file_path}")
                return False
            else:
                logging.debug(f"Invalid signature for file: {file_path}, error: {result}")
                return False
                
        except Exception as e:
            logging.debug(f"Exception during signature verification: {str(e)}")
            return False

    def _scan_process_behavior(self, pid, limited_access=False):
        """
        Analyzes process behavior using available means, even with limited access rights.
        
        Args:
            pid: Process ID to analyze
            limited_access: Boolean indicating if we have limited access to the process
            
        Returns:
            list: List of suspicious behavior indicators found
        """
        suspicious_behaviors = []
        
        try:
            # Check process creation time - very new processes may be suspicious
            creation_time = self._get_process_creation_time_indirect(pid)
            if creation_time and (time.time() - creation_time < 60):  # Process is < 60 seconds old
                suspicious_behaviors.append("recently_created")
                
            # Check parent-child relationships that might be suspicious
            parent_info = self._get_parent_process_info_winapi(pid)
            if parent_info:
                parent_name = parent_info.get('name', '').lower()
                process_name = self._get_process_name_indirect(pid).lower()
                
                # Check for suspicious parent-child combinations
                suspicious_pairs = [
                    ('explorer.exe', 'cmd.exe'),
                    ('explorer.exe', 'powershell.exe'),
                    ('svchost.exe', 'cmd.exe'),
                    ('services.exe', 'powershell.exe')
                ]
                
                if any(parent_name == p and process_name == c for p, c in suspicious_pairs):
                    suspicious_behaviors.append(f"suspicious_parent_{parent_name}")
                    
            # Check for network connections even with limited access
            network_info = self._get_process_network_connections_indirect(pid)
            if network_info:
                # Check for suspicious connections (e.g., uncommon ports)
                suspicious_ports = [4444, 5555, 6666, 7777, 8888, 9999]
                suspicious_ips = ['127.0.0.1']  # Example - would be expanded with known C2 IPs
                
                for conn in network_info:
                    remote_port = conn.get('remote_port')
                    remote_ip = conn.get('remote_address')
                    
                    if remote_port in suspicious_ports:
                        suspicious_behaviors.append(f"suspicious_port_{remote_port}")
                    if remote_ip in suspicious_ips:
                        suspicious_behaviors.append(f"suspicious_ip_{remote_ip}")
                        
            # Check command line arguments if available
            cmdline = self._get_process_cmdline_indirect(pid)
            if cmdline:
                suspicious_args = [
                    '-enc', '-encodedcommand', '-w hidden', '-windowstyle hidden',
                    'downloadstring', 'downloadfile', 'bypass', 'hidden', 'vbscript'
                ]
                
                cmdline_lower = cmdline.lower()
                for arg in suspicious_args:
                    if arg in cmdline_lower:
                        suspicious_behaviors.append(f"suspicious_argument_{arg}")
                        
            return suspicious_behaviors
            
        except Exception as e:
            logging.debug(f"Error scanning process behavior: {str(e)}")
            return suspicious_behaviors

    def _check_loaded_modules_indirectly(self, pid):
        """
        Checks loaded modules without requiring full process access by using alternative methods.
        
        Args:
            pid: Process ID to check
            
        Returns:
            list: List of suspicious modules found
        """
        suspicious_modules = []
        
        try:
            # Method 1: Use NtQuerySystemInformation to get loaded modules
            if hasattr(self, '_get_process_modules_using_nt_query'):
                modules = self._get_process_modules_using_nt_query(pid)
            else:
                # Fallback to toolhelp if module enumeration using NtQuerySystemInformation isn't implemented
                modules = self._get_process_modules_toolhelp32(pid)
                
            if not modules:
                return suspicious_modules
                
            # Check for suspicious module locations
            suspicious_paths = [
                r'C:\Users\Public',
                r'C:\Windows\Temp',
                r'C:\Temp',
                r'C:\ProgramData\Microsoft\Windows',
                os.environ.get('TEMP', ''),
                os.path.join(os.environ.get('APPDATA', ''), 'Roaming')
            ]
            
            # Known legitimate modules for common system processes
            known_modules = {
                'svchost.exe': [
                    'ntdll.dll', 'kernel32.dll', 'kernelbase.dll', 'msvcrt.dll',
                    'combase.dll', 'rpcrt4.dll', 'sechost.dll'
                ],
                'WUDFHost.exe': [
                    'ntdll.dll', 'kernel32.dll', 'kernelbase.dll', 'wudfplatform.dll',
                    'msvcrt.dll', 'combase.dll', 'rpcrt4.dll'
                ],
                'NVDisplay.Container.exe': [
                    'ntdll.dll', 'kernel32.dll', 'kernelbase.dll', 'msvcrt.dll',
                    'combase.dll', 'rpcrt4.dll', 'nvapi64.dll'
                ]
            }
            
            process_name = self._get_process_name_indirect(pid).lower()
            expected_modules = known_modules.get(process_name, [])
            
            # Check each module
            for module in modules:
                module_path = module.get('path', '').lower()
                module_name = module.get('name', '').lower()
                
                # Check for modules from suspicious locations
                for sus_path in suspicious_paths:
                    if sus_path.lower() in module_path:
                        suspicious_modules.append({
                            'name': module_name,
                            'path': module_path,
                            'reason': f"loaded_from_suspicious_location_{sus_path}"
                        })
                        break
                        
                # Check for suspicious naming patterns
                if module_name not in expected_modules:
                    suspicious_naming_patterns = [
                        'svchost', 'lsass', 'csrss', 'winlogon',  # System process imposters
                        'svch0st', 'lsa55', 'c5r55', 'win1ogon'   # Typosquatting
                    ]
                    
                    for pattern in suspicious_naming_patterns:
                        if pattern in module_name and not module_path.startswith(r'C:\Windows\System32'):
                            suspicious_modules.append({
                                'name': module_name,
                                'path': module_path,
                                'reason': f"suspicious_naming_pattern_{pattern}"
                            })
                            break
            
            return suspicious_modules
            
        except Exception as e:
            logging.debug(f"Error checking loaded modules indirectly: {str(e)}")
            return suspicious_modules

    # Helper methods for indirect access
    def _get_process_name_indirect(self, pid):
        """Gets process name without requiring a process handle"""
        try:
            import wmi
            c = wmi.WMI()
            for process in c.Win32_Process(ProcessId=pid):
                return process.Name
        except Exception:
            # Fallback to using toolhelp32
            return self._get_process_name_toolhelp32(pid)
        return ""
    def _get_process_name_toolhelp32(pid):
        """
        Get process name using Toolhelp32 snapshot API.
        
        Args:
            pid (int): Process ID
        
        Returns:
            str: Process name or None if not found
        """
        TH32CS_SNAPPROCESS = 0x00000002
        MAX_PATH = 260
        kernel32 = ctypes.windll.kernel32
        
        # Take a snapshot of all processes
        h_snapshot = kernel32.CreateToolhelp32Snapshot(TH32CS_SNAPPROCESS, 0)
        if h_snapshot == -1:  # INVALID_HANDLE_VALUE
            return None
        
        try:
            pe32 = PROCESSENTRY32()
            pe32.dwSize = ctypes.sizeof(PROCESSENTRY32)
            
            # Get first process
            if not kernel32.Process32First(h_snapshot, ctypes.byref(pe32)):
                return None
            
            # Iterate through processes
            while True:
                if pe32.th32ProcessID == pid:
                    # Return the process name if the PID matches
                    return pe32.szExeFile.decode('utf-8', errors='replace')
                
                if not kernel32.Process32Next(h_snapshot, ctypes.byref(pe32)):
                    break
            
            return None
        finally:
            # Close the handle regardless of whether we found the process
            kernel32.CloseHandle(h_snapshot)
    def _get_process_creation_time_indirect(self, pid):
        try:
            # Try using WMI first - this often works with limited privileges
            import wmi
            c = wmi.WMI()
            for process in c.Win32_Process(ProcessId=pid):
                # Convert WMI datetime to timestamp
                creation_date = process.CreationDate
                if creation_date:
                    # WMI time format: yyyymmddHHMMSS.mmmmmm+UUU
                    year = int(creation_date[0:4])
                    month = int(creation_date[4:6])
                    day = int(creation_date[6:8])
                    hour = int(creation_date[8:10])
                    minute = int(creation_date[10:12])
                    second = int(creation_date[12:14])
                    
                    # Convert to timestamp
                    import datetime
                    dt = datetime.datetime(year, month, day, hour, minute, second)
                    return dt.timestamp()
            
            # Fallback method: Try using kernel32.GetProcessTimes with minimal access rights
            kernel32 = ctypes.windll.kernel32
            k32 = ctypes.WinDLL('kernel32')
            LARGE_INTEGER = ctypes.c_longlong
            # Open process with minimal rights required for GetProcessTimes
            h_process = k32.OpenProcess(0x0400, False, pid)  # PROCESS_QUERY_INFORMATION
            if not h_process:
                # Try with even fewer rights
                h_process = k32.OpenProcess(0x1000, False, pid)  # PROCESS_QUERY_LIMITED_INFORMATION
                if not h_process:
                    return None
            
            try:
                creation_time = LARGE_INTEGER()
                exit_time = LARGE_INTEGER()
                kernel_time = LARGE_INTEGER()
                user_time = LARGE_INTEGER()
                
                if k32.GetProcessTimes(h_process, byref(creation_time), byref(exit_time), byref(kernel_time), byref(user_time)):
                    # Convert Windows FILETIME to Unix timestamp
                    # FILETIME is 100ns intervals since Jan 1, 1601 UTC
                    # Need to convert to seconds since Jan 1, 1970 UTC
                    timestamp = (creation_time.value / 10000000) - 11644473600
                    return timestamp
                return None
            finally:
                k32.CloseHandle(h_process)
        
        except Exception as e:
            logging.debug(f"Error getting process creation time: {str(e)}")
            return None

    def _get_process_network_connections_indirect(self, pid):
        """
        Gets network connections for a process without direct process access.
        
        Args:
            pid: Process ID
            
        Returns:
            list: List of network connections for the process
        """
        connections = []
        
        try:
            # Use GetExtendedTcpTable and GetExtendedUdpTable from iphlpapi.dll
            iphlpapi = windll.iphlpapi
            
            # Constants for GetExtendedTcpTable/GetExtendedUdpTable
            TCP_TABLE_OWNER_PID_ALL = 5
            UDP_TABLE_OWNER_PID = 1
            AF_INET = 2
            
            # Get TCP connections
            # First get the size needed
            tcp_size = DWORD(0)
            iphlpapi.GetExtendedTcpTable(None, byref(tcp_size), False, AF_INET, TCP_TABLE_OWNER_PID_ALL, 0)
            
            # Allocate the buffer and get the table
            tcp_buffer = ctypes.create_string_buffer(tcp_size.value)
            if iphlpapi.GetExtendedTcpTable(tcp_buffer, byref(tcp_size), False, AF_INET, TCP_TABLE_OWNER_PID_ALL, 0) == 0:
                # Parse the buffer
                # First DWORD is the number of entries
                entries = struct.unpack('I', tcp_buffer[:4])[0]
                offset = 4
                
                # Each entry is a MIB_TCPROW_OWNER_PID structure
                for i in range(entries):
                    row = MIB_TCPROW_OWNER_PID.from_buffer_copy(tcp_buffer[offset:offset+sizeof(MIB_TCPROW_OWNER_PID)])
                    offset += sizeof(MIB_TCPROW_OWNER_PID)
                    
                    if row.dwOwningPid == pid:
                        # Convert IPs and ports from network to host byte order
                        local_ip = socket.inet_ntoa(struct.pack('L', row.dwLocalAddr))
                        remote_ip = socket.inet_ntoa(struct.pack('L', row.dwRemoteAddr))
                        local_port = socket.ntohs(row.dwLocalPort)
                        remote_port = socket.ntohs(row.dwRemotePort)
                        
                        connections.append({
                            'protocol': 'TCP',
                            'local_address': local_ip,
                            'local_port': local_port,
                            'remote_address': remote_ip,
                            'remote_port': remote_port,
                            'state': row.dwState
                        })
            
            # Get UDP connections
            udp_size = DWORD(0)
            iphlpapi.GetExtendedUdpTable(None, byref(udp_size), False, AF_INET, UDP_TABLE_OWNER_PID, 0)
            
            udp_buffer = ctypes.create_string_buffer(udp_size.value)
            if iphlpapi.GetExtendedUdpTable(udp_buffer, byref(udp_size), False, AF_INET, 
                                            UDP_TABLE_OWNER_PID, 0) == 0:
                entries = struct.unpack('I', udp_buffer[:4])[0]
                offset = 4
                
                for i in range(entries):
                    row = MIB_UDPROW_OWNER_PID.from_buffer_copy(udp_buffer[offset:offset+sizeof(MIB_UDPROW_OWNER_PID)])
                    offset += sizeof(MIB_UDPROW_OWNER_PID)
                    
                    if row.dwOwningPid == pid:
                        local_ip = socket.inet_ntoa(struct.pack('L', row.dwLocalAddr))
                        local_port = socket.ntohs(row.dwLocalPort)
                        
                        connections.append({
                            'protocol': 'UDP',
                            'local_address': local_ip,
                            'local_port': local_port,
                            'remote_address': None,
                            'remote_port': None,
                            'state': None
                        })
                        
            return connections
            
        except Exception as e:
            logging.debug(f"Error getting network connections: {str(e)}")
            return connections

    def _get_process_cmdline_indirect(self, pid):
        """
        Gets command line arguments without requiring full process access.
        
        Args:
            pid: Process ID
            
        Returns:
            str: Command line string or None if not available
        """
        try:
            # Try WMI first - most reliable with limited privileges
            import wmi
            c = wmi.WMI()
            for process in c.Win32_Process(ProcessId=pid):
                return process.CommandLine
            
            # Fallback method: use Windows Management Instrumentation Command-line
            try:
                import subprocess
                output = subprocess.check_output(
                    f'wmic process where ProcessId={pid} get CommandLine /format:list', 
                    shell=True, 
                    text=True
                )
                if output and "CommandLine=" in output:
                    return output.split("CommandLine=", 1)[1].strip()
            except Exception:
                pass
                
            # Another fallback: try through registry for Windows 10+
            # Process CommandLine is stored in Performance data 
            # This requires elevated privileges though
            try:
                import winreg
                with winreg.OpenKey(
                    winreg.HKEY_PERFORMANCE_DATA,
                    r"Process",
                    0,
                    winreg.KEY_READ
                ) as key:
                    # This is very implementation specific and not always reliable
                    # Code would need to parse the performance data
                    pass
            except Exception:
                pass
                
            return None
            
        except Exception as e:
            logging.debug(f"Error getting process cmdline: {str(e)}")
            return None

    def _get_process_modules_using_nt_query(self, pid):
        """
        Uses NtQuerySystemInformation to enumerate loaded modules.
        This can sometimes work when other methods fail.
        
        Args:
            pid: Process ID
            
        Returns:
            list: List of modules loaded in the process
        """
        modules = []
        try:
            # Get a handle to ntdll.dll
            ntdll = windll.ntdll
            
            # Define NtQuerySystemInformation function
            NtQuerySystemInformation = ntdll.NtQuerySystemInformation
            NtQuerySystemInformation.argtypes = [
                wintypes.ULONG,
                LPVOID,
                wintypes.ULONG,
                POINTER(wintypes.ULONG)
            ]
            NtQuerySystemInformation.restype = wintypes.LONG
            
            # Query for module information
            # First, we need to determine the required buffer size
            buffer_size = wintypes.ULONG(0)
            status = NtQuerySystemInformation(
                self.SystemModuleInformation,
                None,
                0,
                byref(buffer_size)
            )
            
            if status != self.STATUS_INFO_LENGTH_MISMATCH:
                return modules
                
            # Allocate buffer of required size
            buffer = (ctypes.c_byte * buffer_size.value)()
            
            # Query again with properly sized buffer
            status = NtQuerySystemInformation(
                self.SystemModuleInformation,
                buffer,
                buffer_size.value,
                byref(buffer_size)
            )
            
            if status != 0:  # STATUS_SUCCESS is 0
                return modules
                
            # Number of modules is the first ULONG in the buffer
            count = ctypes.cast(buffer, POINTER(wintypes.ULONG))[0]
            
            # Process each module entry
            offset = ctypes.sizeof(wintypes.ULONG)  # Skip past count
            module_entry_size = ctypes.sizeof(SYSTEM_MODULE_INFORMATION)
            
            for i in range(count):
                # Extract module information
                module_info = SYSTEM_MODULE_INFORMATION.from_buffer(buffer, offset)
                offset += module_entry_size
                
                # Extract module name - it's in ImageName after ModuleNameOffset
                module_name = ctypes.string_at(
                    ctypes.addressof(module_info.ImageName) + module_info.ModuleNameOffset
                ).decode('utf-8', errors='replace')
                
                # The full path is the entire ImageName
                module_path = ctypes.string_at(
                    ctypes.addressof(module_info.ImageName)
                ).decode('utf-8', errors='replace')
                
                # Get driver/module info from the registry to check if it's loaded in our target process
                # This requires additional checks that would become complex to implement here
                # For simplicity, this function should be combined with other techniques
                
                modules.append({
                    'name': module_name,
                    'path': module_path,
                    'base': module_info.ImageBase,
                    'size': module_info.ImageSize
                })
                
            return modules
            
        except Exception as e:
            logging.debug(f"Error using NtQuerySystemInformation for modules: {str(e)}")
            return modules
    def _get_process_modules_toolhelp32(self, pid):
        """Gets process modules using CreateToolhelp32Snapshot"""
        modules = []
        try:
            import win32api
            import win32process
            import win32con
            CreateToolhelp32Snapshot = win32api.CreateToolhelp32Snapshot
            INVALID_HANDLE_VALUE = win32con.INVALID_HANDLE_VALUE
            TH32CS_SNAPMODULE = 0x00000008
            TH32CS_SNAPMODULE32 = 0x00000010
            # Create snapshot of all modules
            _fields_ = [
                ("dwSize", ctypes.c_ulong),
                ("th32ModuleID", ctypes.c_ulong),
                ("th32ProcessID", ctypes.c_ulong),
                ("GlblcntUsage", ctypes.c_ulong),
                ("ProccntUsage", ctypes.c_ulong),
                ("modBaseAddr", ctypes.POINTER(ctypes.c_byte)),
                ("modBaseSize", ctypes.c_ulong),
                ("hModule", ctypes.c_void_p),
                ("szModule", ctypes.c_char * 256),
                ("szExePath", ctypes.c_char * 260)
            ]
            hModuleSnap = CreateToolhelp32Snapshot(win32con.TH32CS_SNAPMODULE | win32con.TH32CS_SNAPMODULE32, pid)
            if hModuleSnap == INVALID_HANDLE_VALUE:
                return modules
                
            module_entry = win32process.MODULEENTRY32()
            module_entry.dwSize = ctypes.sizeof(win32process.MODULEENTRY32)
            
            # Get first module
            success = win32process.Module32First(hModuleSnap, module_entry)
            while success:
                modules.append({
                    'name': module_entry.szModule,
                    'path': module_entry.szExePath,
                    'base': module_entry.modBaseAddr,
                    'size': module_entry.modBaseSize
                })
                success = win32process.Module32Next(hModuleSnap, module_entry)
                
            win32api.CloseHandle(hModuleSnap)
            return modules
            
        except Exception as e:
            logging.debug(f"Error in toolhelp32 module enumeration: {str(e)}")
            return modules
    def detect_process_hollowing(self, pid):
        """Detect process hollowing by comparing on-disk and in-memory PE headers
        and checking for suspicious memory permissions.
        
        Args:
            pid: Process ID to check
        Returns:
            dict: Dictionary containing hollowing indicators and findings
        """

        
        
        hollowing_indicators = {
            'executable_found': False,
            'process_id': pid
        }
        process_handle = None
        process_name = None
        process_path = None
        process_info = None
        base_address = 0
        entry_point = 0
        dos_header = None
        disk_pe_header = None
        memory_pe_header = None
        # Initialize process_handle to None
        process_handle = None
         # Handle different input formats
        if process_info is None:
            logging.debug(f"Cannot detect hollowing: process_info is None")
            
            # Get process name for better logging
            process_name = self.get_process_name_with_fallbacks(pid)
            logging.debug(f"Process {process_name} (PID {pid}) denied access")
            
            # Check if this is suspicious (non-system process denying access)
            suspicious_check = self.detect_suspicious_access_denial(pid)
            if suspicious_check['suspicious']:
                # Return a hollowing result indicating suspicious access denial
                return {
                    'executable_found': True,
                    'detection_method': 'access_denial_heuristic',
                    'details': f"Suspicious: non-system process {process_name} actively denied access",
                    'process_name': process_name
                }
            
            # Try alternative detection methods
            return self.detect_hollowing_alternative(pid)
            
        # Extract PID from various input formats
        if isinstance(process_info, dict):
            pid = process_info.get('pid')
            if pid is None and 'basic' in process_info:
                pid = process_info['basic'].get('pid')
        else:
            # Assume it's directly a PID value
            pid = process_info
            
        # Validate the extracted PID
        validated_pid = self.safe_process_validation(pid)
        if validated_pid is None:
            logging.debug(f"Invalid PID for hollowing detection: {pid}")
            return hollowing_indicators
        # Check if process_info is valid and is a dictionary
        if not process_info:
            process_name = f"PID_{pid}"
            try:
                process = psutil.Process(pid)
                process_name = process.name()
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                pass
                
            logging.debug(f"Process hollowing check failed for {process_name}: Invalid process info (not a dictionary)")
            return []
            
        # Check if this is a protected process
        if process_info.get('access_denied_expected', False):
            process_name = process_info.get('name', f"PID_{pid}")
            logging.debug(f"Process {process_name} is protected, skipping hollowing check")
            return []
        hollowing_indicators = []
        # Constants
        MEM_COMMIT = 0x1000
        MEM_IMAGE = 0x1000000
        PAGE_EXECUTE_READ = 0x20
        PAGE_EXECUTE_READWRITE = 0x40
        PROCESS_VM_READ = 0x0010
        PROCESS_QUERY_INFORMATION = 0x0400
        
        # Windows API setup
        kernel32 = ctypes.windll.kernel32
        psapi = ctypes.windll.psapi
        
        # Define Windows API functions
        OpenProcess = kernel32.OpenProcess
        OpenProcess.argtypes = [ctypes.wintypes.DWORD, ctypes.wintypes.BOOL, ctypes.wintypes.DWORD]
        OpenProcess.restype = ctypes.wintypes.HANDLE
        
        CloseHandle = kernel32.CloseHandle
        CloseHandle.argtypes = [ctypes.wintypes.HANDLE]
        CloseHandle.restype = ctypes.wintypes.BOOL
        
        ReadProcessMemory = kernel32.ReadProcessMemory
        ReadProcessMemory.argtypes = [
            ctypes.wintypes.HANDLE,
            ctypes.wintypes.LPCVOID,
            ctypes.wintypes.LPVOID,
            ctypes.c_size_t,
            ctypes.POINTER(ctypes.c_size_t)
        ]
        ReadProcessMemory.restype = ctypes.wintypes.BOOL
        
        GetModuleFileNameExW = psapi.GetModuleFileNameExW
        GetModuleFileNameExW.argtypes = [
            ctypes.wintypes.HANDLE,
            ctypes.wintypes.HMODULE,
            ctypes.wintypes.LPWSTR,
            ctypes.wintypes.DWORD
        ]
        GetModuleFileNameExW.restype = ctypes.wintypes.DWORD
            
        # Define structures
        class Image_Dos_Header(ctypes.Structure):
            _fields_ = [
                ("e_magic", ctypes.c_ushort),
                ("e_cblp", ctypes.c_ushort),
                ("e_cp", ctypes.c_ushort),
                ("e_crlc", ctypes.c_ushort),
                ("e_cparhdr", ctypes.c_ushort),
                ("e_minalloc", ctypes.c_ushort),
                ("e_maxalloc", ctypes.c_ushort),
                ("e_ss", ctypes.c_ushort),
                ("e_sp", ctypes.c_ushort),
                ("e_csum", ctypes.c_ushort),
                ("e_ip", ctypes.c_ushort),
                ("e_cs", ctypes.c_ushort),
                ("e_lfarlc", ctypes.c_ushort),
                ("e_ovno", ctypes.c_ushort),
                ("e_res", ctypes.c_ushort * 4),
                ("e_oemid", ctypes.c_ushort),
                ("e_oeminfo", ctypes.c_ushort),
                ("e_res2", ctypes.c_ushort * 10),
                ("e_lfanew", ctypes.c_long)
            ]
            
        class MODULEINFO(ctypes.Structure):
            _fields_ = [
                ("lpBaseOfDll", ctypes.c_void_p),
                ("SizeOfImage", ctypes.wintypes.DWORD),
                ("EntryPoint", ctypes.c_void_p)
            ]
        # First, validate that process_info itself is not None
        if process_info is None:
            logging.debug(f"Cannot detect hollowing: process_info is None")
            
            # Get process name for better logging
            process_name = self.get_process_name_with_fallbacks(pid)
            logging.debug(f"Process {process_name} (PID {pid}) denied access")
            
            # Check if this is suspicious (non-system process denying access)
            suspicious_check = self.detect_suspicious_access_denial(pid)
            if suspicious_check['suspicious']:
                # Return a hollowing result indicating suspicious access denial
                return {
                    'executable_found': True,
                    'detection_method': 'access_denial_heuristic',
                    'details': f"Suspicious: non-system process {process_name} actively denied access",
                    'process_name': process_name
                }
            
            # Try alternative detection methods
            return self.detect_hollowing_alternative(pid)
         
               
        # Helper function to get module info without recursion
        def get_module_info(process_handle):
            self.process_info = self._get_process_info_winapi(process_handle, pid)
            # Initialize variables with safe defaults
            base_address = 0
            entry_point = 0
            module_name = self.get_module_info(module_name)
            size = 0
            
            try:
                # Skip if handle is invalid
                if not process_handle or process_handle == 0:
                    logging.debug("Invalid process handle")
                    return None
                    
                # Get the first module (main executable)
                modules = (ctypes.wintypes.HMODULE * 1)()
                needed = ctypes.wintypes.DWORD()
                
                # Try to enumerate modules
                if not psapi.EnumProcessModules(
                    process_handle,
                    ctypes.byref(modules),
                    ctypes.sizeof(modules),
                    ctypes.byref(needed)
                ):
                    error_code = ctypes.get_last_error()
                    logging.debug(f"Failed to enumerate process modules. Error: {error_code}")
                    return None
                
                
                
                # Get module information
                module_info = MODULEINFO()  # Initialize here
                if not psapi.GetModuleInformation(
                    process_handle,
                    module_handle,
                    ctypes.byref(module_info),
                    ctypes.sizeof(module_info)
                ):
                    error_code = ctypes.get_last_error()
                    logging.debug(f"Failed to get module information. Error: {error_code}")
                    return None
                # Get the first module's handle
                module_handle = modules[0]
                # Get module name - safely
                local_module_name_buffer = ctypes.create_unicode_buffer(260)  # MAX_PATH
                if psapi.GetModuleFileNameExW(
                    process_handle,
                    module_handle,
                    local_module_name_buffer,
                    260
                ) > 0:  # Check return value properly
                    module_name = local_module_name_buffer.value
                
                # Safely get base address
                if hasattr(module_info, 'lpBaseOfDll') and module_info.lpBaseOfDll:
                    try:
                        base_address = int(ctypes.cast(module_info.lpBaseOfDll, ctypes.c_void_p).value)
                    except (OverflowError, TypeError) as e:
                        logging.debug(f"Error converting base address: {str(e)}")
                
                # Safely get entry point
                if hasattr(module_info, 'EntryPoint') and module_info.EntryPoint:
                    try:
                        entry_point = int(ctypes.cast(module_info.EntryPoint, ctypes.c_void_p).value)
                    except (OverflowError, TypeError) as e:
                        logging.debug(f"Error converting entry point: {str(e)}")
                
                # Safely get size
                if hasattr(module_info, 'SizeOfImage'):
                    size = module_info.SizeOfImage
                
                return {
                    'base_address': base_address,
                    'size': size,
                    'entry_point': entry_point,
                    'name': module_name
                }
                
            except Exception as ex:
                logging.debug(f"Exception in get_module_info: {str(ex)}")
                return None
        
        try:
            # Initialize variables
            process_path = None
            base_address = None
            dos_header = None
            disk_pe_header = None
            memory_pe_header = None
            pid = self.safe_process_validation(process_info.get('pid'))
            # Get PID safely
            if isinstance(process_info, dict):
                pid = process_info.get('pid') if 'pid' in process_info else None
                if pid is None and 'basic' in process_info:
                    pid = process_info['basic'].get('pid') if isinstance(process_info['basic'], dict) else None
            elif hasattr(process_info, 'pid'):
                pid = process_info.pid
            else:
                pid = process_info  # Assume it's directly a PID
            
            # Now validate the PID
            validated_pid = self.safe_process_validation(pid)
            if validated_pid is None:
                logging.debug("Skipping process with invalid PID")
                hollowing_indicators['reason'] = 'invalid_pid'
                return hollowing_indicators
            
            # Now we know validated_pid is valid, so continue with it
            process_handle = OpenProcess(
                PROCESS_QUERY_INFORMATION | PROCESS_VM_READ,
                False,
                validated_pid
            )
            
            if not process_handle or process_handle == 0:
                error_code = ctypes.get_last_error()
                if error_code == 5:  # ACCESS_DENIED
                    logging.warning(f"Access denied for process with PID {pid}. Skipping.")
                    hollowing_indicators['reason'] = 'access_denied'
                else:
                    logging.warning(f"Failed to open process with PID {pid}. Error: {error_code}")
                    hollowing_indicators['reason'] = f'open_process_failed_error_{error_code}'
                
                # Ensure process_handle is explicitly set to None
                process_handle = None
            else:
                # Get process path
                try:
                    filename_buffer = ctypes.create_unicode_buffer(260)  # MAX_PATH
                    if GetModuleFileNameExW(process_handle, None, filename_buffer, 260) == 0:
                        error_code = ctypes.get_last_error()
                        logging.error(f"Failed to get process path. Error: {error_code}")
                        hollowing_indicators['reason'] = f'get_process_path_failed_error_{error_code}'
                    else:
                        process_path = filename_buffer.value
                        # Update memory_info_dict with process path
                        if hasattr(self, 'memory_info_dict'):
                            self.memory_info_dict['path'] = process_path
                except Exception as ex:
                    logging.debug(f"Exception getting process path for {pid}: {str(ex)}")
                    hollowing_indicators['reason'] = 'exception_getting_process_path'
                    hollowing_indicators['error'] = str(ex)
                    process_path = None  # Ensure process_path is explicitly set
                
                # Only continue if we have a valid process path
                if process_path:
                    # Get module information
                    try:
                        module_info = get_module_info(process_handle)
                        if module_info is None:
                            hollowing_indicators['reason'] = 'module_info_unavailable'
                            base_address = None
                        else:
                            # Safely get base_address from module_info dictionary
                            base_address = module_info.get('base_address', 0)
                            
                            # Update memory_info_dict with module info data
                            if hasattr(self, 'memory_info_dict'):
                                self.memory_info_dict['base_address'] = base_address
                                self.memory_info_dict['entry_point'] = module_info.get('entry_point', 0)
                                # Only now set the module name from module_info if available
                                if 'name' in module_info:
                                    self.memory_info_dict['name'] = module_info['name']
                    except Exception as ex:
                        logging.debug(f"Exception getting module info for {pid}: {str(ex)}")
                        hollowing_indicators['reason'] = 'exception_getting_module_info'
                        hollowing_indicators['error'] = str(ex)
                        base_address = None
                    
                    # Only continue if we have a valid base address
                    if base_address:
                        # Read memory PE header
                        try:
                            dos_header = Image_Dos_Header()
                            bytes_read = ctypes.c_size_t(0)
                            
                            success = ReadProcessMemory(
                                process_handle,
                                ctypes.c_void_p(base_address),
                                ctypes.byref(dos_header),
                                ctypes.sizeof(dos_header),
                                ctypes.byref(bytes_read)
                            )
                            
                            if not success:
                                error_code = ctypes.get_last_error()
                                logging.error(f"Failed to read process memory for PID {pid}. Error: {error_code}")
                                hollowing_indicators['reason'] = f'read_process_memory_failed_error_{error_code}'
                                dos_header = None
                        except Exception as ex:
                            logging.debug(f"Exception reading memory header for {pid}: {str(ex)}")
                            hollowing_indicators['reason'] = 'exception_reading_memory_header'
                            hollowing_indicators['error'] = str(ex)
                            dos_header = None
                        
                        # Check for valid DOS header
                        if dos_header and dos_header.e_magic == 0x5A4D:  # 'MZ' signature
                            try:
                                # Read the PE header at the offset indicated by e_lfanew
                                pe_offset = dos_header.e_lfanew
                                pe_signature = ctypes.c_uint32()
                                
                                success = ReadProcessMemory(
                                    process_handle,
                                    ctypes.c_void_p(base_address + pe_offset),
                                    ctypes.byref(pe_signature),
                                    ctypes.sizeof(pe_signature),
                                    ctypes.byref(bytes_read)
                                )
                            
                                if success and pe_signature.value == 0x4550:  # 'PE\0\0' signature
                                        hollowing_indicators['executable_found'] = True
                            except Exception as ex:
                                logging.debug(f"Exception reading PE signature for {pid}: {str(ex)}")
                                hollowing_indicators['reason'] = 'exception_reading_pe_signature'
                                hollowing_indicators['error'] = str(ex)
            # IMPORTANT: Check that bytes_read is valid before accessing pe_signature.value
                        if success and bytes_read.value == ctypes.sizeof(pe_signature):
                            try:    
                                if pe_signature.value == 0x4550:  # 'PE\0\0' signature
                                    hollowing_indicators['executable_found'] = True
                            except Exception as ex:
                                logging.debug(f"Exception checking PE header for {pid}: {str(ex)}")
                                hollowing_indicators['reason'] = 'exception_checking_pe_header'
                                hollowing_indicators['error'] = str(ex)
                            
                            # Read the PE header from disk if we have a valid path
                            if process_path and os.path.exists(process_path):
                                try:
                                    with open(process_path, 'rb') as f:
                                        disk_pe_header = f.read(4096)  # Read first 4KB for PE header
                                except Exception as e:
                                    logging.error(f"Cannot read process executable: {str(e)}")
                                    hollowing_indicators['reason'] = 'disk_read_failed'
                                    hollowing_indicators['error'] = str(e)
                            
                            # Prepare buffer to read memory PE header
                            if base_address:
                                try:
                                    memory_buffer = ctypes.create_string_buffer(4096)
                                    success = ReadProcessMemory(
                                        process_handle,
                                        ctypes.c_void_p(base_address),
                                        memory_buffer,
                                        4096,
                                        ctypes.byref(bytes_read)
                                    )
                                    
                                    if success and bytes_read.value > 0:  # Check bytes_read is valid
                                        memory_pe_header = memory_buffer.raw[:bytes_read.value]
                                    else:
                                        error_code = ctypes.get_last_error()
                                        logging.error(f"Failed to read memory PE header for PID {pid}. Error: {error_code}")
                                        hollowing_indicators['reason'] = f'read_pe_header_failed_error_{error_code}'
                                except Exception as ex:
                                    logging.debug(f"Exception reading memory PE header for {pid}: {str(ex)}")
                                    hollowing_indicators['reason'] = 'exception_reading_memory_pe_header'
                                    hollowing_indicators['error'] = str(ex)
                            
                            # Compare disk PE header with memory PE header
                            if disk_pe_header and memory_pe_header:
                                # Check for differences in headers
                                if disk_pe_header != memory_pe_header:
                                    hollowing_indicators['pe_header_mismatch'] = True
                                    
                                    # Compare signature bytes safely
                                    if len(disk_pe_header) >= 2 and len(memory_pe_header) >= 2:
                                        if disk_pe_header[0:2] != memory_pe_header[0:2]:
                                            hollowing_indicators['header_signature_mismatch'] = {
                                                'disk_sig': disk_pe_header[0:2].hex(),
                                                'memory_sig': memory_pe_header[0:2].hex()
                                            }
                                    
                                    # Compare other important header sections if needed
                                    # PE header starts at e_lfanew
                                    if dos_header and dos_header.e_magic == 0x5A4D:
                                        pe_offset = dos_header.e_lfanew
                                        
                                        # Compare sections after PE header with length checks
                                        if (len(disk_pe_header) > pe_offset + 24 and 
                                            len(memory_pe_header) > pe_offset + 24):
                                            disk_sections = disk_pe_header[pe_offset:pe_offset+24]
                                            memory_sections = memory_pe_header[pe_offset:pe_offset+24]
                                            
                                            if disk_sections != memory_sections:
                                                hollowing_indicators['pe_sections_mismatch'] = True

                                # Check for suspicious memory permissions in main image sections
                                if hasattr(self, 'memory_info_dict'):
                                    memory_regions = []
                                    if process_handle and process_handle != 0:
                                        try:
                                            memory_regions = self._enumerate_memory_regions_winapi(process_handle)
                                        except Exception as e:
                                            logging.debug(f"Error enumerating memory regions: {str(e)}")
                                    
                                    # Check for suspicious memory permissions
                                    sections_with_rx = []
                                    sections_with_rwx = []
                                    
                                    for region in memory_regions:
                                        if region.get('Type', 0) & MEM_IMAGE and region.get('State', 0) & MEM_COMMIT:
                                            # Check for RWX sections (highly suspicious)
                                            if region.get('Protect', 0) & PAGE_EXECUTE_READWRITE:
                                                sections_with_rwx.append(hex(region.get('BaseAddress', 0)))
                                            # Check for RX sections (normal for code, but track them)
                                            elif region.get('Protect', 0) & PAGE_EXECUTE_READ:
                                                sections_with_rx.append(hex(region.get('BaseAddress', 0)))
                                    
                                    if sections_with_rwx:
                                        hollowing_indicators['rwx_sections'] = sections_with_rwx
                                        # RWX sections in image memory are highly suspicious
                                    
                                    if sections_with_rx:
                                        hollowing_indicators['rx_sections'] = sections_with_rx
                            try:
                                # Get entry point from module_info
                                if module_info and 'entry_point' in module_info:
                                    memory_entry_point = module_info['entry_point']
                                    
                                    # Store the entry point in indicators
                                    hollowing_indicators['memory_entry_point'] = memory_entry_point
                                    
                                    # Check if entry point is outside the module's memory range
                                    module_end = base_address + module_info.get('size', 0)
                                    if memory_entry_point < base_address or memory_entry_point >= module_end:
                                        hollowing_indicators['suspicious_entry_point'] = True
                                        hollowing_indicators['entry_point_outside_module'] = True
                                        logging.warning(f"Process {pid}: Entry point at {hex(memory_entry_point)} is outside module range {hex(base_address)}-{hex(module_end)}")
                                    
                                    # Read entry point bytes to check for suspicious code
                                    if process_handle:
                                        try:
                                            # Read first 16 bytes at entry point
                                            entry_bytes = ctypes.create_string_buffer(16)
                                            bytes_read = ctypes.c_size_t(0)
                                            
                                            success = ReadProcessMemory(
                                                process_handle,
                                                ctypes.c_void_p(memory_entry_point),
                                                entry_bytes,
                                                16,
                                                ctypes.byref(bytes_read)
                                            )
                                            
                                            if success and bytes_read.value > 0:
                                                # Check for common shellcode patterns at entry point
                                                entry_code = entry_bytes.raw[:bytes_read.value]
                                                
                                                # Common shellcode patterns to look for
                                                shellcode_patterns = {
                                                    'jmp_far': b'\xFF\x25',  # JMP FAR instruction
                                                    'call_far': b'\xFF\x15',  # CALL FAR instruction
                                                    'push_ret': b'\x68....\xC3',  # PUSH addr, RET pattern
                                                    'mov_jmp': b'\xB8....\xFF\xE0'  # MOV EAX, addr; JMP EAX pattern
                                                }
                                                
                                                for pattern_name, pattern in shellcode_patterns.items():
                                                    if re.search(pattern.replace(b'....', b'....'), entry_code, re.DOTALL):
                                                        hollowing_indicators['suspicious_entry_code'] = True
                                                        hollowing_indicators['entry_code_pattern'] = pattern_name
                                                        hollowing_indicators['entry_code_bytes'] = entry_code.hex()
                                                        break
                                        except Exception as ex:
                                            logging.debug(f"Error reading entry point code: {str(ex)}")
                                    
                                    # Extract entry point from disk PE file
                                    if os.path.exists(process_path):
                                        try:
                                            # Parse the PE file to get its expected entry point
                                            # This requires parsing the PE header structure
                                            # For simplicity, we'll use a helper function
                                            disk_entry_point = self.get_disk_entry_point(process_path)
                                            
                                            if disk_entry_point:
                                                hollowing_indicators['disk_entry_point'] = disk_entry_point
                                                
                                                # Compare memory entry point with disk entry point (accounting for ASLR)
                                                # We need to compare relative offsets since base addresses will differ
                                                memory_entry_offset = memory_entry_point - base_address
                                                
                                                # Entry point in PE file is RVA (Relative Virtual Address)
                                                if abs(memory_entry_offset - disk_entry_point) > 16:  # Allow small differences due to optimizations
                                                    hollowing_indicators['entry_point_mismatch'] = True
                                                    hollowing_indicators['entry_point_difference'] = abs(memory_entry_offset - disk_entry_point)
                                                    logging.warning(f"Process {pid}: Entry point mismatch - disk:{hex(disk_entry_point)} vs memory offset:{hex(memory_entry_offset)}")
                                        except Exception as ex:
                                            logging.debug(f"Error comparing entry points: {str(ex)}")
                            except Exception as ex:
                                logging.debug(f"Error analyzing entry point: {str(ex)}")
        except Exception as ex:
           # Make even safer error logging that works regardless of variable state
            logging.error(f"Error checking memory regions in unknown PID: {str(ex)}")
            hollowing_indicators = hollowing_indicators if 'hollowing_indicators' in locals() else {}
            hollowing_indicators['memory_region_error'] = str(ex)
            
        finally:
            # Always clean up resources
            if process_handle is not None and process_handle != 0:
                try:
                    CloseHandle(process_handle)
                except Exception as e:
                    if "(5, 'OpenProcess', 'Access is denied')" in str(e):
                        # FIXED: Check for None before using pid in log message
                        process_name_str = process_name if process_name else "Unknown"
                        pid_str = str(pid) if pid is not None else "Unknown"
                        logging.debug(f"Access denied for protected process {process_name_str} (PID: {pid_str}) - skipping")
                    else:
                        logging.error(f"Error processing {process_name if process_name else 'Unknown'}: {str(e)}")
                        logging.debug(f"Error closing process handle: {str(e)}")
            
            # CRITICAL: Remove PID from stack to prevent memory leaks but check for None
            if pid is not None and pid in self._process_hollowing_stack:
                self._process_hollowing_stack.remove(pid)
            
            return hollowing_indicators
    def detect_hollowing_alternative(self, pid):
        """Detection when direct access is denied"""
        suspicious = False
        
        # Check for suspicious parent-child relationships
        try:
            parent_pid = self.get_parent_pid(pid)
            if self.is_unusual_parent(pid, parent_pid):
                suspicious = True
        except:
            pass
            
        # Check image file path vs actual loaded modules
        try:
            if self.check_path_discrepancy(pid):
                suspicious = True
        except:
            pass
                
        # Check for suspicious handle operations
        if self.check_handle_operations(pid):
            suspicious = True
                
        return suspicious
    def get_parent_pid(self, pid):
        """Get parent PID for a process even with limited access"""
        try:
            # Try using WMI first (works with limited privileges)
            import wmi
            c = wmi.WMI()
            for process in c.Win32_Process(ProcessId=pid):
                return process.ParentProcessId
        except ImportError:
            # Fallback if WMI module is missing
            logging.debug(f"WMI module not available, using alternative method for parent PID")
            return self._get_parent_pid_using_toolhelp(pid)
        except Exception as e:
            logging.debug(f"Error getting parent PID for {pid}: {str(e)}")
            return None
    def _get_parent_pid_using_toolhelp(self, pid):
        """Alternative method to get parent PID using Toolhelp snapshot"""
        TH32CS_SNAPPROCESS = 0x00000002
        kernel32 = ctypes.windll.kernel32
        h_snapshot = kernel32.CreateToolhelp32Snapshot(TH32CS_SNAPPROCESS, 0)
        if h_snapshot == -1:
            return None
            
        process_entry = PROCESSENTRY32()
        process_entry.dwSize = ctypes.sizeof(PROCESSENTRY32)
        
        if not ctypes.windll.Process32First(h_snapshot, ctypes.byref(process_entry)):
            ctypes.windll.CloseHandle(h_snapshot)
            return None
            
        try:
            while ctypes.windll.Process32Next(h_snapshot, ctypes.byref(process_entry)):
                if process_entry.th32ProcessID == pid:
                    parent_pid = process_entry.th32ParentProcessID
                    ctypes.windll.CloseHandle(h_snapshot)
                    return parent_pid
        finally:
            ctypes.windll.CloseHandle(h_snapshot)
            
        return None
    def is_unusual_parent(self, pid, parent_pid):
        """Check if parent-child relationship is suspicious"""
        if parent_pid is None:
            return False
            
        try:
            # Common legitimate parent processes
            system_parents = {4, 0, 8}  # System, Idle, etc.
            
            # Get process names - with proper error handling
            child_info = self._get_process_info_winapi(pid)
            parent_info = self._get_process_info_winapi(parent_pid)
             # Check if non-system process has system parent (potentially suspicious)
            if parent_pid in system_parents:
                child_info = self._get_process_info_winapi(pid)
                if child_info and child_info.get('basic', {}).get('name', '').lower() not in ['smss.exe', 'csrss.exe', 'wininit.exe', 'winlogon.exe']:
                    logging.info(f"Suspicious: Process {pid} has system parent {parent_pid}")
                    return True
            # Check if we got valid info
            if not child_info or not parent_info:
                logging.debug(f"Could not get process info for pid {pid} or parent {parent_pid}")
                return False
                
            # Extract names with safe navigation
            child_name = child_info.get('basic', {}).get('name', 'unknown').lower()
            parent_name = parent_info.get('basic', {}).get('name', 'unknown').lower()
            
            # Known suspicious patterns
            suspicious_patterns = [
                # Rest of your patterns are good
                {'parent': 'explorer.exe', 'child': ['lsass.exe', 'services.exe', 'svchost.exe']},
                {'parent': ['winword.exe', 'excel.exe', 'powerpnt.exe'],
                'child': ['cmd.exe', 'powershell.exe', 'wscript.exe', 'cscript.exe']},
                {'parent': ['chrome.exe', 'firefox.exe', 'iexplore.exe', 'msedge.exe'],
                'child': ['cmd.exe', 'powershell.exe', 'wscript.exe']}
            ]
            
            # Rest of your pattern checking is good
            for pattern in suspicious_patterns:
                parent_match = False
                child_match = False
                
                if isinstance(pattern['parent'], list):
                    parent_match = parent_name in pattern['parent']
                else:
                    parent_match = parent_name == pattern['parent']
                    
                if isinstance(pattern['child'], list):
                    child_match = child_name in pattern['child']
                else:
                    child_match = child_name == pattern['child']
                    
                if parent_match and child_match:
                    logging.info(f"Suspicious parent-child relationship: {parent_name}({parent_pid}) -> {child_name}({pid})")
                    return True
                    
            return False
        except Exception as e:
            logging.debug(f"Error checking parent-child relationship: {str(e)}")
            return False
    def check_handle_operations(self, pid):
        """Look for suspicious handle operations that might indicate process hollowing"""
        try:
            # Check for suspicious handle relationships
            suspicious_handles = self.audit_process_handles(pid)
            if suspicious_handles:
                return True
                
            # Check for memory mapped files that don't match process image
            suspicious_mappings = self.memory_maps(pid)
            if suspicious_mappings:
                return True
                
            return False
        except Exception as e:
            logging.debug(f"Error checking handle operations: {str(e)}")
            return False
    def check_path_discrepancy(self, pid):
        """Check for discrepancy between reported path and actual executable"""
        try:
            # Get reported path from WMI (works with limited access)
            import wmi
            c = wmi.WMI()
            reported_path = None
            executable_path = None
            
            for process in c.Win32_Process(ProcessId=pid):
                reported_path = process.ExecutablePath
                break
                
            if not reported_path:
                return False
                
            # Get actual path from module list (if accessible)
            try:
                import psutil
                process = psutil.Process(pid)
                if hasattr(process, 'exe'):
                    executable_path = process.exe()
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                pass
                
            # If we couldn't get the actual path, try Windows API
            if not executable_path:
                executable_path = self.get_process_path(pid)
                
            # If we still don't have both paths, we can't compare
            if not reported_path or not executable_path:
                return False
                
            # Compare the paths, ignoring case
            if reported_path.lower() != executable_path.lower():
                logging.info(f"Path discrepancy for PID {pid}: Reported={reported_path}, Actual={executable_path}")
                return True
                
            return False
        except Exception as e:
            logging.debug(f"Error checking path discrepancy: {str(e)}")
            return False
    def get_disk_entry_point(self, pe_path):
        """Extract entry point address from disk PE file"""
        try:
            # Use simple file parsing to extract entry point
            with open(pe_path, 'rb') as f:
                # Read DOS header
                dos_header = f.read(64)  # DOS header is 64 bytes
                if len(dos_header) < 64 or dos_header[:2] != b'MZ':
                    return None
                    
                # Get e_lfanew offset
                e_lfanew = int.from_bytes(dos_header[60:64], byteorder='little')
                
                # Go to PE header
                f.seek(e_lfanew)
                signature = f.read(4)
                if signature != b'PE\0\0':
                    return None
                    
                # Skip COFF header (20 bytes)
                f.seek(e_lfanew + 4 + 2 + 2 + 4 + 4 + 4 + 2 + 2)
                
                # Read Optional Header
                # Entry point is at offset 16 in the Optional Header
                f.seek(e_lfanew + 24)  # Skip to OptionalHeader
                entry_point_bytes = f.read(4)
                entry_point = int.from_bytes(entry_point_bytes, byteorder='little')
                
                return entry_point
        except Exception as ex:
            logging.debug(f"Error reading disk entry point: {str(ex)}")
            return None
    def _enumerate_memory_regions_winapi(self, process_handle):
        """Enumerate memory regions using direct Windows API calls"""
        regions = []
        
        class MEMORY_BASIC_INFORMATION(ctypes.Structure):
            _fields_ = [
                ("BaseAddress", ctypes.c_void_p),
                ("AllocationBase", ctypes.c_void_p),
                ("AllocationProtect", ctypes.c_ulong),
                ("RegionSize", ctypes.c_size_t),
                ("State", ctypes.c_ulong),
                ("Protect", ctypes.c_ulong),
                ("Type", ctypes.c_ulong)
            ]
        
        mbi = MEMORY_BASIC_INFORMATION()
        mbi_size = ctypes.sizeof(mbi)
        current_address = 0
        
        system_info = self._get_system_info_winapi()
        max_address = 0x7FFFFFFF0000  # Default for 64-bit systems
        
        if system_info and hasattr(system_info, 'lpMaximumApplicationAddress'):
            try:
                max_address = ctypes.cast(system_info.lpMaximumApplicationAddress, ctypes.c_void_p).value
            except (TypeError, ValueError):
                logging.debug("Using default max address")
        
        max_address = min(max_address, 0x7FFFFFFF0000)
        max_iterations = 100000
        iteration_count = 0
        scanned_regions = 0
        interesting_regions = 0
        while current_address < max_address and iteration_count < max_iterations:
            try:
                process_handle = ctypes.windll.kernel32.GetCurrentProcess()
                
                result = ctypes.windll.kernel32.VirtualQueryEx(
                    process_handle,
                    ctypes.c_void_p(current_address),
                    ctypes.byref(mbi),
                    mbi_size
                )
                
                # Capture the region regardless of result
                regions.append({
                    'BaseAddress': int(mbi.BaseAddress or current_address),
                    'RegionSize': max(mbi.RegionSize, 0x1000),  # Ensure minimum size
                    'State': mbi.State,
                    'Protect': mbi.Protect,
                    'Type': mbi.Type,
                    'QueryResult': result,  # Store the query result for analysis
                    'Suspicious': result == 0 or mbi.RegionSize == 0  # Flag suspicious regions
                })
                
                scanned_regions += 1
                if result != 0:
                    interesting_regions += 1
                    logging.debug(f"Memory region at 0x{current_address:x}: Result={result}")
                
                # Progress to next region while preventing infinite loops
                next_address = current_address + (mbi.RegionSize if mbi.RegionSize > 0 else 0x1000)
                current_address = next_address if next_address > current_address else current_address + 0x1000
                
            except Exception as e:
                # Record the problematic region
                regions.append({
                    'BaseAddress': current_address,
                    'RegionSize': 0x1000,
                    'State': 0,
                    'Protect': 0,
                    'Type': 0,
                    'Error': str(e),
                    'Suspicious': True
                })
                current_address += 0x1000
                
            iteration_count += 1
        
        logging.debug(f"Scanned {scanned_regions} memory regions, found {interesting_regions} interesting regions")
        return regions
    def get_process_path(self, pid):
        """
        Get the full path of a process executable.
        
        Args:
            pid (int): Process ID
            
        Returns:
            str: Full path to the process executable, or empty string if not found
        """
        try:
            import win32api
            import win32process
            import win32con
            
            # Open the process with minimal access rights
            h_process = win32api.OpenProcess(win32con.PROCESS_QUERY_LIMITED_INFORMATION, False, pid)
            if h_process:
                try:
                    # Get the full path
                    return win32process.GetModuleFileNameEx(h_process, 0)
                finally:
                    win32api.CloseHandle(h_process)
        except Exception as e:
            logging.debug(f"Error getting process path for PID {pid}: {str(e)}")
        
        return ""
    @classmethod
    def _get_system_info_winapi(cls):
        """Enhanced system information retrieval using Windows API"""
        logging.debug("Getting system information using Windows API")
        try:
            class SYSTEM_INFO(ctypes.Structure):
                _fields_ = [
                    ("wProcessorArchitecture", ctypes.c_ushort),
                    ("wReserved", ctypes.c_ushort),
                    ("dwPageSize", ctypes.c_ulong),
                    ("lpMinimumApplicationAddress", ctypes.c_void_p),
                    ("lpMaximumApplicationAddress", ctypes.c_void_p),
                    ("dwActiveProcessorMask", ctypes.POINTER(ctypes.c_ulong)),
                    ("dwNumberOfProcessors", ctypes.c_ulong),
                    ("dwProcessorType", ctypes.c_ulong),
                    ("dwAllocationGranularity", ctypes.c_ulong),
                    ("wProcessorLevel", ctypes.c_ushort),
                    ("wProcessorRevision", ctypes.c_ushort),
                ]

            # Create system_info instance OUTSIDE the class definition
            system_info = SYSTEM_INFO()
            kernel32 = ctypes.windll.kernel32
            kernel32.GetSystemInfo(ctypes.byref(system_info))
            
            # Process and return system information
            return {
                'processor_architecture': system_info.wProcessorArchitecture,
                'page_size': system_info.dwPageSize,
                'min_address': int(system_info.lpMinimumApplicationAddress or 0),
                'max_address': int(system_info.lpMaximumApplicationAddress or 0),
                'processor_count': system_info.dwNumberOfProcessors,
                'allocation_granularity': system_info.dwAllocationGranularity
            }
        except Exception as e:
            # Capture and log the stack trace
            stack_trace = traceback.format_exc()
            logging.error(f"Error in _get_system_info_winapi: {str(e)}")
            logging.debug(f"Stack trace: {stack_trace}")
            return cls._get_default_system_info()
    def _get_firmware_table(self):
        """Get system firmware table information"""
        kernel32 = ctypes.windll.kernel32
        buffer_size = kernel32.GetSystemFirmwareTable('RSMB', 0, None, 0)
        if buffer_size:
            buffer = (ctypes.c_char * buffer_size)()
            if kernel32.GetSystemFirmwareTable('RSMB', 0, buffer, buffer_size):
                return bytes(buffer)
        return None
    def _get_processor_features(self):
        """Get processor features using Windows API"""
        features = []
        kernel32 = ctypes.windll.kernel32
        
        for i in range(64):
            if kernel32.IsProcessorFeaturePresent(i):
                features.append(i)
        return features
    def get_system_info_from_handle(self, handle):
        """
        Get system information using a process handle
        
        Args:
            handle: A PyHANDLE object or process handle
            
        Returns:
            Dictionary containing system information
        """
        try:
            # Check if we have a valid handle
            if not handle or not bool(handle):
                logging.debug("Invalid handle provided to get_system_info_from_handle")
                return None
                
            # Get handle value for logging
            if isinstance(handle, dict):
                handle_value = handle.get('value', 0)  # Get the value from dict
            else:
                handle_value = int(handle) if hasattr(handle, '__int__') else 0
            logging.debug(f"Retrieving system info using handle: {handle_value}")
            
            # Initialize kernel32
            kernel32 = ctypes.windll.kernel32
            
            # Define the SYSTEM_INFO structure
            class SYSTEM_INFO(ctypes.Structure):
                _fields_ = [
                    ("wProcessorArchitecture", ctypes.c_ushort),
                    ("wReserved", ctypes.c_ushort),
                    ("dwPageSize", ctypes.c_ulong),
                    ("lpMinimumApplicationAddress", ctypes.c_void_p),
                    ("lpMaximumApplicationAddress", ctypes.c_void_p),
                    ("dwActiveProcessorMask", ctypes.POINTER(ctypes.c_ulong)),
                    ("dwNumberOfProcessors", ctypes.c_ulong),
                    ("dwProcessorType", ctypes.c_ulong),
                    ("dwAllocationGranularity", ctypes.c_ulong),
                    ("wProcessorLevel", ctypes.c_ushort),
                    ("wProcessorRevision", ctypes.c_ushort)
                ]
            
            # Create an instance of SYSTEM_INFO
            system_info = SYSTEM_INFO()
            
            # Call GetSystemInfo
            kernel32.GetSystemInfo(ctypes.byref(system_info))
            
            # Get process information if we have a valid handle
            process_info = {}
            if bool(handle):
                try:
                    # Define the PROCESS_BASIC_INFORMATION structure
                    class PROCESS_BASIC_INFORMATION(ctypes.Structure):
                        _fields_ = [
                            ("Reserved1", ctypes.c_void_p),
                            ("PebBaseAddress", ctypes.c_void_p),
                            ("Reserved2", ctypes.c_void_p * 2),
                            ("UniqueProcessId", ctypes.c_void_p),
                            ("Reserved3", ctypes.c_void_p)
                        ]
                    
                    # Try to get process info using NtQueryInformationProcess
                    ntdll = ctypes.WinDLL('ntdll.dll')
                    NtQueryInformationProcess = ntdll.NtQueryInformationProcess
                    ProcessBasicInformation = 0
                    
                    process_info_struct = PROCESS_BASIC_INFORMATION()
                    return_length = ctypes.c_ulong(0)
                    
                    status = NtQueryInformationProcess(
                        handle,
                        ProcessBasicInformation,
                        ctypes.byref(process_info_struct),
                        ctypes.sizeof(process_info_struct),
                        ctypes.byref(return_length)
                    )
                    
                    if status == 0:  # STATUS_SUCCESS
                        process_info['peb_address'] = process_info_struct.PebBaseAddress
                        process_info['process_id'] = process_info_struct.UniqueProcessId
                except Exception as e:
                    logging.debug(f"Error getting process information: {str(e)}")
            
            # Create a dictionary with system information
            info = {
                'processor_architecture': system_info.wProcessorArchitecture,
                'page_size': system_info.dwPageSize,
                'min_address': system_info.lpMinimumApplicationAddress,
                'max_address': system_info.lpMaximumApplicationAddress,
                'processor_count': system_info.dwNumberOfProcessors,
                'processor_type': system_info.dwProcessorType,
                'allocation_granularity': system_info.dwAllocationGranularity,
                'processor_level': system_info.wProcessorLevel,
                'processor_revision': system_info.wProcessorRevision,
                'handle_value': handle_value,
                'handle_valid': bool(handle),
                **process_info  # Include any process-specific info we gathered
            }
            
            # Print the information for debugging
            print("System Information:")
            for key, value in info.items():
                if isinstance(value, int) and key != 'processor_count':
                    print(f"  {key}: {value} (0x{value:X})")
                else:
                    print(f"  {key}: {value}")
            
            return info
        
        except Exception as e:
            logging.debug(f"Error in get_system_info_from_handle: {str(e)}")
            print(f"Error getting system info: {str(e)}")
            return None
    def scan_suspicious_handle(self, handle, process_id=None):
        """
        Securely analyze a potentially malicious handle/process to detect various evasion techniques
        
        Args:
            handle: The PyHANDLE object that might be malicious
            process_id: Alternative process ID if handle is not reliable
        
        Returns:
            Dictionary containing security analysis results
        """
        results = {
            'scan_time': time.time(),
            'suspicious_indicators': [],
            'evasion_techniques': [],
            'memory_integrity_issues': [],
            'is_potentially_malicious': False,
            'scan_successful': False,
            'system_info': {}
        }
        
        # Initialize Windows API access
        kernel32 = ctypes.windll.kernel32
        ntdll = ctypes.windll.ntdll
        psapi = ctypes.windll.psapi
        
        # Store the original handle value
        original_handle_value = None
        try:
            original_handle_value = int(handle) if hasattr(handle, '__int__') else None
            results['original_handle_value'] = hex(original_handle_value) if original_handle_value else "Unknown"
        except Exception:
            results['original_handle_value'] = "Error - Could not read handle value"
            results['suspicious_indicators'].append("Handle value access blocked")
        
        # Get process ID if not provided
        if not process_id and original_handle_value:
            try:
                GetProcessId = kernel32.GetProcessId
                GetProcessId.argtypes = [ctypes.wintypes.HANDLE]
                GetProcessId.restype = ctypes.wintypes.DWORD
                
                pid = GetProcessId(handle)
                if pid:
                    process_id = pid
                    results['process_id'] = pid
            except Exception as e:
                results['suspicious_indicators'].append(f"GetProcessId error: {str(e)}")
        
        # === Get basic system info ===
        try:
            class SYSTEM_INFO(ctypes.Structure):
                _fields_ = [
                    ("wProcessorArchitecture", ctypes.c_ushort),
                    ("wReserved", ctypes.c_ushort),
                    ("dwPageSize", ctypes.c_ulong),
                    ("lpMinimumApplicationAddress", ctypes.c_void_p),
                    ("lpMaximumApplicationAddress", ctypes.c_void_p),
                    ("dwActiveProcessorMask", ctypes.POINTER(ctypes.c_ulong)),
                    ("dwNumberOfProcessors", ctypes.c_ulong),
                    ("dwProcessorType", ctypes.c_ulong),
                    ("dwAllocationGranularity", ctypes.c_ulong),
                    ("wProcessorLevel", ctypes.c_ushort),
                    ("wProcessorRevision", ctypes.c_ushort)
                ]
            
            system_info = self._get_system_info_winapi()
            kernel32.GetSystemInfo(ctypes.byref(system_info))
            
            results['system_info'] = {
                'processor_architecture': system_info.wProcessorArchitecture,
                'page_size': system_info.dwPageSize,
                'min_address': int(system_info.lpMinimumApplicationAddress or 0),
                'max_address': int(system_info.lpMaximumApplicationAddress or 0),
                'processor_count': system_info.dwNumberOfProcessors
            }
        except Exception as e:
            results['suspicious_indicators'].append(f"Error getting system info: {str(e)}")
        
        # === DETECTION 1: Anti-Debugging Techniques ===
        try:
            # Check if debugger is being detected (PEB.BeingDebugged check)
            class PEB_PARTIAL(ctypes.Structure):
                _fields_ = [
                    ("InheritedAddressSpace", ctypes.c_ubyte),
                    ("ReadImageFileExecOptions", ctypes.c_ubyte),
                    ("BeingDebugged", ctypes.c_ubyte),
                    ("BitField", ctypes.c_ubyte)
                ]
            
            if process_id:
                # Try to read PEB using NtQueryInformationProcess
                PROCESS_BASIC_INFORMATION = 0
                
                class PROCESS_BASIC_INFORMATION_STRUCT(ctypes.Structure):
                    _fields_ = [
                        ("Reserved1", ctypes.c_void_p),
                        ("PebBaseAddress", ctypes.c_void_p),
                        ("Reserved2", ctypes.c_void_p * 2),
                        ("UniqueProcessId", ctypes.c_void_p),
                        ("Reserved3", ctypes.c_void_p)
                    ]
                
                # Open process with query information rights
                PROCESS_QUERY_INFORMATION = 0x0400
                PROCESS_VM_READ = 0x0010
                
                debug_handle = kernel32.OpenProcess(PROCESS_QUERY_INFORMATION | PROCESS_VM_READ, False, process_id)
                if debug_handle:
                    try:
                        # Get process information
                        process_info = PROCESS_BASIC_INFORMATION_STRUCT()
                        return_length = ctypes.c_ulong(0)
                        
                        NtQueryInformationProcess = ntdll.NtQueryInformationProcess
                        NtQueryInformationProcess.argtypes = [
                            ctypes.wintypes.HANDLE,
                            ctypes.c_ulong,
                            ctypes.c_void_p,
                            ctypes.c_ulong,
                            ctypes.POINTER(ctypes.c_ulong)
                        ]
                        
                        status = NtQueryInformationProcess(
                            debug_handle,
                            PROCESS_BASIC_INFORMATION,
                            ctypes.byref(process_info),
                            ctypes.sizeof(process_info),
                            ctypes.byref(return_length)
                        )
                        
                        if status == 0:  # STATUS_SUCCESS
                            # Read the PEB.BeingDebugged field
                            peb = PEB_PARTIAL()
                            bytes_read = ctypes.c_size_t(0)
                            
                            if process_info.PebBaseAddress:
                                success = kernel32.ReadProcessMemory(
                                    debug_handle,
                                    process_info.PebBaseAddress,
                                    ctypes.byref(peb),
                                    ctypes.sizeof(peb),
                                    ctypes.byref(bytes_read)
                                )
                                
                                if success and bytes_read.value >= 3:  # We need at least 3 bytes to get BeingDebugged
                                    results['peb_being_debugged'] = bool(peb.BeingDebugged)
                                    
                                    # Check if anti-debugging is detected
                                    if process_info.PebBaseAddress:
                                        # Try to find code that may be checking PEB.BeingDebugged
                                        anti_debug_patterns = [
                                            b"\x64\xA1\x30\x00\x00\x00",  # mov eax, fs:[30h] (get PEB in x86)
                                            b"\x65\x48\x8B\x04\x25\x30\x00\x00\x00",  # mov rax, gs:[30h] (get PEB in x64)
                                            b"\x80\x78\x02\x00"  # cmp byte ptr [eax+2], 0 (check BeingDebugged)
                                        ]
                                        
                                        class MEMORY_BASIC_INFORMATION(ctypes.Structure):
                                            _fields_ = [
                                                ("BaseAddress", ctypes.c_void_p),
                                                ("AllocationBase", ctypes.c_void_p),
                                                ("AllocationProtect", ctypes.c_ulong),
                                                ("RegionSize", ctypes.SIZE_T),
                                                ("State", ctypes.c_ulong),
                                                ("Protect", ctypes.c_ulong),
                                                ("Type", ctypes.c_ulong)
                                            ]
                                        
                                        # Look for code sections
                                        MEM_COMMIT = 0x1000
                                        PAGE_EXECUTE = 0x10
                                        PAGE_EXECUTE_READ = 0x20
                                        PAGE_EXECUTE_READWRITE = 0x40
                                        
                                        mem_info = MEMORY_BASIC_INFORMATION()
                                        address = 0
                                        found_anti_debug = False
                                        
                                        # Scan for potential anti-debugging code
                                        scan_limit = 100  # Limit scanning to avoid hanging
                                        scan_count = 0
                                        
                                        while scan_count < scan_limit:
                                            result = kernel32.VirtualQueryEx(
                                                debug_handle,
                                                ctypes.c_void_p(address),
                                                ctypes.byref(mem_info),
                                                ctypes.sizeof(mem_info)
                                            )
                                            
                                            if result == 0:
                                                break
                                            
                                            # Check if this is executable memory
                                            if (mem_info.State == MEM_COMMIT and 
                                                (mem_info.Protect == PAGE_EXECUTE or 
                                                mem_info.Protect == PAGE_EXECUTE_READ or 
                                                mem_info.Protect == PAGE_EXECUTE_READWRITE)):
                                                
                                                # Check for anti-debugging code patterns
                                                region_size = min(mem_info.RegionSize, 1024*1024)  # Limit to 1MB max
                                                code_buffer = ctypes.create_string_buffer(region_size)
                                                bytes_read = ctypes.c_size_t(0)
                                                
                                                try:
                                                    success = kernel32.ReadProcessMemory(
                                                        debug_handle,
                                                        mem_info.BaseAddress,
                                                        code_buffer,
                                                        region_size,
                                                        ctypes.byref(bytes_read)
                                                    )
                                                    
                                                    if success and bytes_read.value > 0:
                                                        code_data = code_buffer.raw[:bytes_read.value]
                                                        
                                                        # Look for anti-debugging patterns
                                                        for pattern in anti_debug_patterns:
                                                            if pattern in code_data:
                                                                found_anti_debug = True
                                                                results['suspicious_indicators'].append(
                                                                    f"Potential anti-debugging code at {hex(address)}"
                                                                )
                                                                results['evasion_techniques'].append("Anti-debugging detection")
                                                                break
                                                        
                                                        # Check for NtQueryInformationProcess usage (another anti-debug technique)
                                                        if b"NtQueryInformationProcess" in code_data:
                                                            results['suspicious_indicators'].append(
                                                                f"NtQueryInformationProcess usage detected at {hex(address)}"
                                                            )
                                                            results['evasion_techniques'].append("Process information querying (possible anti-debug)")
                                                except:
                                                    pass
                                            
                                            address += mem_info.RegionSize
                                            scan_count += 1
                                        
                                        if found_anti_debug:
                                            results['is_potentially_malicious'] = True
                    finally:
                        kernel32.CloseHandle(debug_handle)
        except Exception as e:
            results['suspicious_indicators'].append(f"Error checking for anti-debugging: {str(e)}")
        
        # === DETECTION 2: Process Hollowing / Code Injection ===
        if process_id:
            try:
                # Get the list of loaded modules to compare with memory regions
                PROCESS_QUERY_INFORMATION = 0x0400
                PROCESS_VM_READ = 0x0010
                
                process_handle = kernel32.OpenProcess(PROCESS_QUERY_INFORMATION | PROCESS_VM_READ, False, process_id)
                if process_handle:
                    try:
                        # Get module list
                        hModules = (ctypes.c_void_p * 1024)()
                        cb_needed = ctypes.c_ulong()
                        module_list = []
                        
                        if psapi.EnumProcessModules(process_handle, ctypes.byref(hModules), ctypes.sizeof(hModules), ctypes.byref(cb_needed)):
                            num_modules = min(cb_needed.value // ctypes.sizeof(ctypes.c_void_p), 1024)
                            
                            for i in range(num_modules):
                                module_name = ctypes.create_unicode_buffer(260)
                                if psapi.GetModuleFileNameExW(process_handle, hModules[i], module_name, 260):
                                    module_info = ctypes.c_void_p()
                                    module_info_size = ctypes.sizeof(module_info)
                                    
                                    if psapi.GetModuleInformation(process_handle, hModules[i], ctypes.byref(module_info), module_info_size):
                                        module_list.append({
                                            'name': module_name.value,
                                            'base_address': hModules[i]
                                        })
                        
                        # Now scan memory to find executable regions not in module list
                        class MEMORY_BASIC_INFORMATION(ctypes.Structure):
                            _fields_ = [
                                ("BaseAddress", ctypes.c_void_p),
                                ("AllocationBase", ctypes.c_void_p),
                                ("AllocationProtect", ctypes.c_ulong),
                                ("RegionSize", ctypes.SIZE_T),
                                ("State", ctypes.c_ulong),
                                ("Protect", ctypes.c_ulong),
                                ("Type", ctypes.c_ulong)
                            ]
                        
                        MEM_COMMIT = 0x1000
                        MEM_PRIVATE = 0x20000
                        PAGE_EXECUTE = 0x10
                        PAGE_EXECUTE_READ = 0x20
                        PAGE_EXECUTE_READWRITE = 0x40
                        PAGE_EXECUTE_WRITECOPY = 0x80
                        
                        address = 0
                        suspicious_regions = []
                        scan_limit = 1000  # Limit to avoid hanging
                        scan_count = 0
                        while scan_count < scan_limit:
                            mem_info = MEMORY_BASIC_INFORMATION()
                            result = kernel32.VirtualQueryEx(
                                process_handle,
                                ctypes.c_void_p(address),
                                ctypes.byref(mem_info),
                                ctypes.sizeof(mem_info)
                            )
                            
                            if result == 0:
                                break  # End of address space or error
                            
                            # Check for executable private memory that's not part of a known module
                            if (mem_info.State == MEM_COMMIT and 
                                mem_info.Type == MEM_PRIVATE and
                                (mem_info.Protect == PAGE_EXECUTE or
                                 mem_info.Protect == PAGE_EXECUTE_READ or
                                 mem_info.Protect == PAGE_EXECUTE_READWRITE or
                                 mem_info.Protect == PAGE_EXECUTE_WRITECOPY)):
                                
                                # Check if this memory region is part of a known module
                                is_known_module = False
                                for module in module_list:
                                    module_addr = int(module['base_address'])
                                    # Assume module size is at least 4KB for this check
                                    if (module_addr <= int(mem_info.BaseAddress) < module_addr + (4 * 1024 * 1024)):
                                        is_known_module = True
                                        break
                                
                                if not is_known_module:
                                    # This is executable memory not associated with a loaded module - suspicious!
                                    suspicious_regions.append({
                                        'address': hex(int(mem_info.BaseAddress)),
                                        'size': mem_info.RegionSize,
                                        'protection': mem_info.Protect
                                    })
                                    
                                    # Read a sample of the memory to check for shellcode signatures
                                    sample_size = min(mem_info.RegionSize, 256)  # Just check first 256 bytes
                                    mem_sample = ctypes.create_string_buffer(sample_size)
                                    bytes_read = ctypes.c_size_t(0)
                                    
                                    success = kernel32.ReadProcessMemory(
                                        process_handle,
                                        mem_info.BaseAddress,
                                        mem_sample,
                                        sample_size,
                                        ctypes.byref(bytes_read)
                                    )
                                    
                                    if success and bytes_read.value > 0:
                                        # Check for common shellcode patterns
                                        shellcode_patterns = [
                                            b"\xfc\xe8",  # Common shellcode starter
                                            b"\x31\xc0\x50\x68",  # xor eax,eax + push + push - common in shellcode
                                            b"\x68\x2e\x65\x78\x65",  # push ".exe"
                                            b"\x90\x90\x90\x90\x90"  # NOP sled
                                        ]
                                        
                                        for pattern in shellcode_patterns:
                                            if pattern in mem_sample.raw[:bytes_read.value]:
                                                results['suspicious_indicators'].append(
                                                    f"Potential shellcode detected at {hex(int(mem_info.BaseAddress))}"
                                                )
                                                results['is_potentially_malicious'] = True
                                                break
                                    
                                    results['memory_integrity_issues'].append(
                                        f"Executable private memory outside module space at {hex(int(mem_info.BaseAddress))}"
                                    )
                            
                            # Move to next region
                            address += mem_info.RegionSize
                            scan_count += 1
                        
                        # Record findings
                        if suspicious_regions:
                            results['suspicious_memory_regions'] = suspicious_regions
                            results['evasion_techniques'].append("Memory code injection detected")
                            results['is_potentially_malicious'] = True
                    
                    finally:
                        kernel32.CloseHandle(process_handle)
            
            except Exception as e:
                results['suspicious_indicators'].append(f"Error checking for code injection: {str(e)}")
        
        # === DETECTION 3: Handle Manipulation ===
        try:
            if original_handle_value:
                # Check handle properties for tampering signs
                handle_info = ctypes.c_ulong(0)
                handle_info_size = ctypes.sizeof(handle_info)
                
                # Store expected size for security validation
                results['expected_handle_info_size'] = handle_info_size
                
                # Try to get handle info
                GetHandleInformation = kernel32.GetHandleInformation
                GetHandleInformation.argtypes = [ctypes.wintypes.HANDLE, ctypes.POINTER(ctypes.c_ulong)]
                GetHandleInformation.restype = ctypes.wintypes.BOOL
                
                try:
                    # Security check: Verify memory before and after our buffer hasn't been tampered with
                    canary_before = ctypes.c_ulong(0xDEADBEEF)
                    canary_after = ctypes.c_ulong(0xBEEFDEAD)
                    
                    # Call the Windows API function
                    success = GetHandleInformation(handle, ctypes.byref(handle_info))
                    
                    # Check for return code manipulation
                    if not success:
                        error = ctypes.get_last_error()
                        if error != 0:
                            results['suspicious_indicators'].append(f"Handle manipulation detected: Error {error}")
                            results['is_potentially_malicious'] = True
                    
                    # Check if our handle info size matches what Windows is using
                    # Some rootkits or hooks might modify structure sizes or memory layouts
                    current_size = ctypes.sizeof(handle_info)
                    if current_size != handle_info_size:
                        results['suspicious_indicators'].append(
                            f"Handle info size inconsistency: Expected {handle_info_size}, got {current_size}"
                        )
                        results['is_potentially_malicious'] = True
                        
                    # Verify our canaries haven't been corrupted (buffer overflow check)
                    if canary_before.value != 0xDEADBEEF or canary_after.value != 0xBEEFDEAD:
                        results['suspicious_indicators'].append(
                            "Memory corruption detected near handle info buffer"
                        )
                        results['is_potentially_malicious'] = True
                        results['evasion_techniques'].append("Memory corruption")
                    
                    # Additional security check: validate handle_info contents are reasonable
                    if success:
                        MAX_EXPECTED_FLAG_VALUE = 0x00000003  # HANDLE_FLAG_INHERIT | HANDLE_FLAG_PROTECT_FROM_CLOSE
                        
                        if handle_info.value > MAX_EXPECTED_FLAG_VALUE:
                            results['suspicious_indicators'].append(
                                f"Suspicious handle flags: 0x{handle_info.value:08X} exceeds expected values"
                            )
                            results['is_potentially_malicious'] = True
                        
                        # Log actual flags for analysis
                        HANDLE_FLAG_INHERIT = 0x00000001
                        HANDLE_FLAG_PROTECT_FROM_CLOSE = 0x00000002
                        
                        results['handle_flags'] = {
                            'raw_value': handle_info.value,
                            'INHERIT': bool(handle_info.value & HANDLE_FLAG_INHERIT),
                            'PROTECT_FROM_CLOSE': bool(handle_info.value & HANDLE_FLAG_PROTECT_FROM_CLOSE),
                            'unexpected_bits': bool(handle_info.value & ~MAX_EXPECTED_FLAG_VALUE)
                        }
                        
                        # Security check: PROTECT_FROM_CLOSE is suspicious in some contexts
                        if handle_info.value & HANDLE_FLAG_PROTECT_FROM_CLOSE:
                            results['suspicious_indicators'].append(
                                "Handle is protected from being closed - potentially used for persistence"
                            )
                except Exception as e:
                    # Exception during handle inspection is suspicious
                    results['suspicious_indicators'].append(
                        f"Handle access triggered an exception - possible tampering: {str(e)}"
                    )
                    results['is_potentially_malicious'] = True
                    
                    # Add memory analysis of the handle structure
                    try:
                        # Use ReadProcessMemory to examine memory around the handle
                        if ctypes.sizeof(handle) == 8:  # 64-bit handle
                            handle_addr = ctypes.cast(handle, ctypes.c_void_p).value
                            buffer = (ctypes.c_byte * (handle_info_size * 2))()
                            bytes_read = ctypes.c_size_t()
                            
                            ReadProcessMemory = kernel32.ReadProcessMemory
                            ReadProcessMemory.argtypes = [
                                ctypes.wintypes.HANDLE,
                                ctypes.c_void_p,
                                ctypes.c_void_p,
                                ctypes.c_size_t,
                                ctypes.POINTER(ctypes.c_size_t)
                            ]
                            
                            current_process = kernel32.GetCurrentProcess()
                            if ReadProcessMemory(
                                current_process,
                                ctypes.c_void_p(handle_addr),
                                buffer,
                                ctypes.c_size_t(handle_info_size * 2),
                                ctypes.byref(bytes_read)
                            ):
                                # Convert buffer to hexdump for analysis
                                hexdump = ' '.join(f'{b:02X}' for b in buffer)
                                results['handle_memory_analysis'] = hexdump
                    except Exception as memory_error:
                        results['handle_memory_analysis_error'] = str(memory_error)
                
                # Check handle duplication attempts
                if process_id:
                    try:
                        # Try to duplicate handle to check for redirection
                        current_process = kernel32.GetCurrentProcess()
                        duplicate_handle = ctypes.wintypes.HANDLE()
                        
                        DuplicateHandle = kernel32.DuplicateHandle
                        DuplicateHandle.argtypes = [
                            ctypes.wintypes.HANDLE,
                            ctypes.wintypes.HANDLE,
                            ctypes.wintypes.HANDLE,
                            ctypes.POINTER(ctypes.wintypes.HANDLE),
                            ctypes.c_ulong,
                            ctypes.c_int,
                            ctypes.c_ulong
                        ]
                        
                        # Try duplicating with minimal permissions
                        DUPLICATE_SAME_ACCESS = 0x00000002
                        success = DuplicateHandle(
                            current_process,
                            handle,
                            current_process,
                            ctypes.byref(duplicate_handle),
                            0,
                            False,
                            DUPLICATE_SAME_ACCESS
                        )
                        
                        if success:
                            # Get process ID from duplicated handle
                            dup_pid = GetProcessId(duplicate_handle)
                            
                            # Verify duplicated handle has the same info size
                            dup_handle_info = ctypes.c_ulong(0)
                            dup_success = GetHandleInformation(duplicate_handle, ctypes.byref(dup_handle_info))
                            
                            if dup_success:
                                # Compare against original handle_info
                                if dup_handle_info.value != handle_info.value:
                                    results['suspicious_indicators'].append(
                                        f"Handle flag manipulation: Original 0x{handle_info.value:08X}, " + 
                                        f"Duplicate 0x{dup_handle_info.value:08X}"
                                    )
                                    results['is_potentially_malicious'] = True
                            
                            # Check duplicated handle size (should match expected size)
                            dup_handle_size = ctypes.sizeof(duplicate_handle)
                            if dup_handle_size != ctypes.sizeof(handle):
                                results['suspicious_indicators'].append(
                                    f"Handle size inconsistency: Original {ctypes.sizeof(handle)}, " + 
                                    f"Duplicate {dup_handle_size}"
                                )
                                results['is_potentially_malicious'] = True
                            
                            # Close the duplicate handle
                            kernel32.CloseHandle(duplicate_handle)
                            
                            # Check if the process IDs match
                            if dup_pid != process_id:
                                results['suspicious_indicators'].append(
                                    f"Handle redirection detected: reports PID {process_id} but resolves to {dup_pid}"
                                )
                                results['evasion_techniques'].append("Handle redirection")
                                results['is_potentially_malicious'] = True
                    except Exception as e:
                        results['suspicious_indicators'].append(f"Error in handle duplication check: {str(e)}")

        except Exception as e:
            results['suspicious_indicators'].append(f"Error checking handle integrity: {str(e)}")

        # Mark scan as completed successfully
        results['scan_successful'] = True
        return results
    def check_process_info(self, process_info):
        """
        Validate process information before attempting to use it.
        
        Args:
            process_info: Either a dictionary with 'pid' key or a direct PID value
            
        Returns:
            int or None: Valid PID if available, None otherwise
        """
        # Check if process_info is a dictionary or a pid
        if isinstance(process_info, dict):
            pid = process_info.get('pid', None)
        else:
            pid = process_info  # Assume it's a PID
        
        # Validate the PID
        if pid is None or not isinstance(pid, int) or pid <= 0:
            caller = traceback.extract_stack()[-2]
            logging.debug(f"Invalid PID: {pid} (called from {caller.name}:{caller.lineno})")
            return None
        
        return pid

    def memory_region_raw(self, region, pid):
        """Read a memory region with proper error handling for partial reads using Windows API"""
        try:
            self.pid = self.safe_int_conversion(pid)
        except Exception as e:
            logging.debug(f"Error converting PID '{pid}': {str(e)}")
            self.pid = 0
        
        # Define constants
        PROCESS_VM_READ = 0x0010
        PROCESS_QUERY_INFORMATION = 0x0400
        
        # Initialize kernel32 with handle attribute
        kernel32 = ctypes.windll.kernel32
        # Define _handle as the loaded DLL handle
        kernel32._handle = kernel32._handle if hasattr(kernel32, '_handle') else kernel32._handle
        
        print(f"kernel32 handle is valid: {bool(kernel32._handle)}")
        
        # Configure function signatures
        OpenProcess = kernel32.OpenProcess
        OpenProcess.argtypes = [ctypes.wintypes.DWORD, ctypes.wintypes.BOOL, ctypes.wintypes.DWORD]
        OpenProcess.restype = ctypes.wintypes.HANDLE
        
        ReadProcessMemory = kernel32.ReadProcessMemory
        ReadProcessMemory.argtypes = [
            ctypes.wintypes.HANDLE,
            ctypes.wintypes.LPCVOID,
            ctypes.wintypes.LPVOID,
            ctypes.c_size_t,
            ctypes.POINTER(ctypes.c_size_t)
        ]
        ReadProcessMemory.restype = ctypes.wintypes.BOOL
        
        process_handle = None
        try:
            # Open process
            process_handle = kernel32.OpenProcess(
                PROCESS_VM_READ | PROCESS_QUERY_INFORMATION,
                False,
                self.pid
            )
            
            if not process_handle:
                logging.debug(f"Failed to open process {self.pid}. Error: {kernel32.GetLastError()}")
                return b''
            
            # Get base address and size from region info
            base_addr = 0
            size = 0
            
            if isinstance(region, dict):
                # Log the actual values for debugging
                logging.debug(f"Region data: addr={region.get('addr', 'N/A')}, size={region.get('size', 'N/A')}")
                
                # Use safe conversion for address
                addr_value = region.get('addr', 0)
                if isinstance(addr_value, str):
                    base_addr = self.safe_int_conversion(addr_value, base=16 if '0x' in addr_value.lower() or all(c in '0123456789abcdefABCDEF' for c in addr_value) else 10)
                else:
                    base_addr = self.safe_int_conversion(addr_value)
                    
                # Use safe conversion for size
                size = self.safe_int_conversion(region.get('size', 0))
            else:
                # Handle other region formats
                if hasattr(region, 'addr'):
                    addr_str = region.get('addr', '')
                    logging.debug(f"Region addr attribute: {addr_str} (type: {type(addr_str)})")
                    base_addr = self.safe_int_conversion(addr_str, base=16 if isinstance(addr_str, str) and (any(c.lower() in 'abcdef' for c in addr_str) or '0x' in addr_str.lower()) else 10)
                
                if hasattr(region, 'size'):
                    size = self.safe_int_conversion(region.size)
                    logging.debug(f"Region size attribute: {region.size} (type: {type(region.size)})")
            
            logging.debug(f"Converted values: base_addr={hex(base_addr)}, size={size}")
            
            if size <= 0:
                logging.debug("Invalid memory region size")
                return b''
            
            # Read in smaller chunks (e.g., 4KB pages) to avoid partial read issues
            chunk_size = 4096
            memory_data = bytearray()
            
            for offset in range(0, size, chunk_size):
                try:
                    # Calculate current chunk size (might be smaller at the end)
                    current_chunk_size = min(chunk_size, size - offset)
                    
                    # Prepare buffer for ReadProcessMemory
                    buffer = ctypes.create_string_buffer(current_chunk_size)
                    bytes_read = ctypes.c_size_t(0)
                    
                    success = kernel32.ReadProcessMemory(
                        process_handle,
                        ctypes.c_void_p(base_addr + offset),
                        buffer,
                        current_chunk_size,
                        ctypes.byref(bytes_read)
                    )
                    
                    if success and bytes_read.value > 0:
                        memory_data.extend(buffer.raw[:bytes_read.value])
                    else:
                        # Add zeros for that chunk if read failed
                        memory_data.extend(b'\x00' * current_chunk_size)
                    
                except Exception as e:
                    # For any error, add zeros for that chunk and continue
                    logging.debug(f"Error reading memory at offset {offset}: {str(e)}")
                    memory_data.extend(b'\x00' * current_chunk_size)
            
            # Store the kernel32 handle for future use
            self._kernel32_handle = kernel32._handle
            
            return bytes(memory_data)
            
        except Exception as e:
            logging.debug(f"Failed to read memory region: {str(e)}")
            return b''
        finally:
            # Close handle
            if process_handle:
                kernel32.CloseHandle(process_handle)
    def _scan_memory_content_winapi(self, memory_content: bytes, region, process_info: dict, suspicious_patterns: dict):
        """Scan memory content with YARA rules and custom patterns"""
        if not all([memory_content, region, process_info, suspicious_patterns]):
            logging.debug(f"Missing required parameters for memory scanning")
            return suspicious_patterns
        # YARA scanning
        # Ensure rules are properly initialized
        if not self.yara_manager or not self.yara_manager.combined_rules:
            # Try to initialize rules if missing
            if not hasattr(self, 'yara_manager') or not self.yara_manager:
                self.yara_manager = YaraRuleManager()
                self.yara_manager.fetch_all_rules()
            
            if not self.yara_manager.combined_rules:
                self.yara_manager.combined_rules = self.yara_manager.compile_combined_rules()
                
            if not self.yara_manager.combined_rules:
                raise ValueError("YARA rules have not been compiled or loaded.")
        logging.debug(f'yararules: {self.yara_manager.combined_rules}')
        # Run YARA scan        
        matches = self.yara_manager.combined_rules.match(data=memory_content)
        if matches:
            for match in matches:
                key = f"{hex(region['BaseAddress'])}_yara_{match.rule}"
                suspicious_patterns[key] = {
                    'type': 'yara_match',
                    'rule': match.rule,
                    'strings': match.strings,
                    'tags': match.tags,
                    'meta': match.meta,
                    'process_info': process_info
                }
        logging.debug(f"YARA matches: {matches}")
        # Injection pattern scanning with regex
        for pattern_name, pattern in self.injection_patterns.items():
            if re.search(pattern, memory_content):
                key = f"{hex(region['BaseAddress'])}_pattern_{pattern_name}"
                suspicious_patterns[key] = {
                    'type': 'pattern_match',
                    'pattern': pattern_name,
                    'process_info': process_info
                }
        logging.debug(f"suspicious patterns: {suspicious_patterns}")        
        return suspicious_patterns
    def scan_bytes(self, data):
        """Scan a byte array with YARA rules"""
        self.yara_manager = YaraRuleManager()
        self.yara_manager.fetch_all_rules()
        self.yara_manager.combined_rules = self.yara_manager.compile_combined_rules()
        
        matches = []
        for rule in self.yara_manager.load_yara_rules():
            try:
                match = rule.match(data=data)
                if match:
                    matches.extend(match)
            except Exception:
                continue
        logging.debug(f"YARA matches: {matches}")
        return matches
    def get_entry_point(self, code_bytes, base_address=0, is_pe_file=False):
        entry_points = []
        
        # Early return if the input is invalid
        if not code_bytes or len(code_bytes) < 4:
            return entry_points
        
        try:
            # For PE files, extract the entry point from the PE header
            if is_pe_file and len(code_bytes) >= 64:
                try:
                    # Try to parse as PE file
                    import pefile
                    pe = pefile.PE(data=code_bytes)
                    entry_rva = pe.OPTIONAL_HEADER.AddressOfEntryPoint
                    entry_offset = pe.get_offset_from_rva(entry_rva)
                    
                    if 0 <= entry_offset < len(code_bytes):
                        entry_points.append({
                            'offset': entry_offset,
                            'address': base_address + entry_offset,
                            'type': 'pe_entry_point',
                            'confidence': 100,
                            'disassembly': self._try_disassemble(code_bytes[entry_offset:entry_offset+64], base_address + entry_offset)
                        })
                    return entry_points
                except Exception as e:
                    # Not a valid PE file or pefile module not available
                    logging.debug(f"PE parsing failed: {str(e)}")
                    pass
            
            # ===== Shellcode entry point detection =====
            
            # 1. Look for common shellcode entry patterns
            shellcode_patterns = [
                # JMP/CALL/POP technique (common in position-independent shellcode)
                (rb'\xEB\x0E.{14}\xE8.{4}', 'jmp_call_pop_pattern', 90),
                (rb'\xE8.{4}\x59', 'call_pop_pattern', 80),
                (rb'\xE8.{4}\x5e', 'call_pop_pattern', 80),
                (rb'\xE8.{4}\x58', 'call_pop_pattern', 80),
                
                # Function prologues (common entry points)
                (rb'\x55\x8B\xEC', 'x86_function_prologue', 70),
                (rb'\x55\x48\x89\xE5', 'x64_function_prologue', 80),
                (rb'\x53\x56\x57', 'push_registers_prologue', 60),
                
                # XOR/PUSH patterns (common in shellcode starters)
                (rb'\x31\xc0[\x00-\xff]{0,10}\x50[\x00-\xff]{0,10}\x68', 'xor_push_pattern', 75),
                (rb'\x33\xc0[\x00-\xff]{0,10}\x50', 'xor_push_pattern', 70),
                (rb'\x48\x31\xc0[\x00-\xff]{0,15}\x50', 'x64_xor_push_pattern', 80),
                
                # Shellcode decoder stubs
                (rb'\xBF.{4}\xFC\xAD', 'findi_decoder', 85),
                (rb'\xEB\x10.{16}\xE8.{4}', 'metasploit_pattern', 95)
            ]
            
            for pattern, pattern_type, confidence in shellcode_patterns:
                for match in re.finditer(pattern, code_bytes):
                    entry_offset = match.start()
                    entry_points.append({
                        'offset': entry_offset,
                        'address': base_address + entry_offset,
                        'type': pattern_type,
                        'confidence': confidence,
                        'disassembly': self._try_disassemble(code_bytes[entry_offset:entry_offset+64], base_address + entry_offset)
                    })
            
            # 2. NOP sled detection (entry point would be at the end of NOPs)
            nop_pattern = rb'\x90{5,}'
            for match in re.finditer(nop_pattern, code_bytes):
                # Entry point is likely right after the NOP sled
                entry_offset = match.end()
                if entry_offset < len(code_bytes) - 5:  # Ensure we have enough bytes after
                    entry_points.append({
                        'offset': entry_offset,
                        'address': base_address + entry_offset,
                        'type': 'post_nop_sled',
                        'confidence': 65,
                        'disassembly': self._try_disassemble(code_bytes[entry_offset:entry_offset+64], base_address + entry_offset)
                    })
            
            # 3. If we have a disassembler, try to find function starts through heuristic disassembly
            if hasattr(self, 'disassembler') and self.disasembler:
                try:
                    # Ask the disassembler to find likely code entry points
                    disasm_entry_points = self.disasembler.find_entry_points(code_bytes, base_address)
                    
                    for addr, size in disasm_entry_points:
                        # Convert absolute address to relative offset
                        entry_offset = addr - base_address
                        if 0 <= entry_offset < len(code_bytes):
                            entry_points.append({
                                'offset': entry_offset,
                                'address': addr,
                                'type': 'disasm_function_start',
                                'confidence': 75,
                                'disassembly': self._try_disassemble(code_bytes[entry_offset:entry_offset+size], addr)
                            })
                except Exception as e:
                    logging.debug(f"Disassembler analysis failed: {str(e)}")
            
            # 4. Special case: if the code starts with a valid instruction that's not a NOP, it might be an entry point
            if len(code_bytes) >= 10:
                try:
                    # Try to disassemble first few bytes
                    first_inst = self._try_disassemble(code_bytes[:10], base_address)
                    # Check if it's a valid instruction excluding NOPs
                    if first_inst and "nop" not in first_inst.lower():
                        entry_points.append({
                            'offset': 0,
                            'address': base_address,
                            'type': 'code_start',
                            'confidence': 50,
                            'disassembly': first_inst
                        })
                except:
                    pass
                    
            # Sort entry points by confidence (highest first)
            return sorted(entry_points, key=lambda x: x['confidence'], reverse=True)
            
        except Exception as e:
            logging.error(f"Error in get_entry_point: {str(e)}")
            return entry_points
    def detect_unconventional_execution(self, process_handle, memory_regions=None):
        suspicious_executions = []
        
        try:
            # Get memory regions if not provided
            if not memory_regions:
                memory_regions = self.get_process_memory_regions(process_handle)
            
            # 1. Detect indirect call/jump targets
            indirect_targets = self._find_indirect_call_targets(process_handle, memory_regions)
            suspicious_executions.extend(indirect_targets)
            
            # 2. Detect memory marked as executable but not in module list
            unmarked_exec_regions = self._find_unmarked_executable_regions(process_handle, memory_regions)
            suspicious_executions.extend(unmarked_exec_regions)
            
            # 3. Detect function pointers pointing to suspicious memory
            function_ptr_targets = self._find_function_pointer_targets(process_handle, memory_regions)
            suspicious_executions.extend(function_ptr_targets)
            
            # 4. Detect stack execution attempts
            stack_exec_attempts = self._detect_stack_execution(process_handle, memory_regions)
            suspicious_executions.extend(stack_exec_attempts)
            
            # 5. Detect thread creation with suspicious entry points
            thread_entries = self._find_suspicious_thread_entries(process_handle)
            suspicious_executions.extend(thread_entries)
            
            return suspicious_executions
            
        except Exception as e:
            logging.debug(f"Error in detect_unconventional_execution: {str(e)}")
            return suspicious_executions

    def _find_indirect_call_targets(self, process_handle, memory_regions):
        """
        Find potential indirect call/jump targets in executable memory regions
        """
        suspicious_targets = []
        
        try:
            # Iterate through executable memory regions
            for region in memory_regions:
                if not region.get('is_executable', False):
                    continue
                    
                region_base = region.get('base_address', 0)
                region_size = region.get('region_size', 0)
                
                # Skip very large regions to avoid performance issues
                if region_size > 10 * 1024 * 1024:  # Skip regions > 10MB
                    continue
                    
                try:
                    # Read memory region
                    region_data = self.read_process_memory(
                        process_handle, 
                        region_base, 
                        region_size
                    )
                    
                    if not region_data:
                        continue
                        
                    # Look for common indirect call/jump instructions
                    # MOV reg, [address] followed by CALL reg or JMP reg
                    patterns = [
                        (rb'\x8B[\x00-\x3F].{2,8}\xFF[\xD0-\xD7]', 'mov_call_indirect'),  # mov reg, mem; call reg
                        (rb'\x8B[\x00-\x3F].{2,8}\xFF[\xE0-\xE7]', 'mov_jmp_indirect'),   # mov reg, mem; jmp reg
                        (rb'\xFF[\x10-\x17]', 'call_mem_indirect'),                       # call [reg]
                        (rb'\xFF[\x20-\x27]', 'jmp_mem_indirect'),                        # jmp [reg]
                        (rb'\xFF[\x50-\x57].', 'call_mem_offset'),                        # call [reg+offset]
                        (rb'\xFF[\x60-\x67].', 'jmp_mem_offset')                          # jmp [reg+offset]
                    ]
                    
                    for pattern, pattern_type in patterns:
                        for match in re.finditer(pattern, region_data):
                            offset = match.start()
                            address = region_base + offset
                            
                            suspicious_targets.append({
                                'address': address,
                                'type': pattern_type,
                                'region_base': region_base,
                                'region_size': region_size,
                                'data': region_data[offset:offset+min(16, len(region_data)-offset)],
                                'detection_method': 'indirect_call_detection',
                                'disassembly': self._try_disassemble(
                                    region_data[offset:offset+min(32, len(region_data)-offset)], 
                                    address
                                )
                            })
                except Exception as e:
                    logging.debug(f"Error analyzing region at {hex(region_base)}: {str(e)}")
                    
            return suspicious_targets
            
        except Exception as e:
            logging.debug(f"Error in _find_indirect_call_targets: {str(e)}")
            return suspicious_targets

    def _find_unmarked_executable_regions(self, process_handle, memory_regions):
        """
        Find memory regions that are executable but not part of legitimate modules
        """
        suspicious_regions = []
        
        try:
            # Get list of legitimate modules
            legitimate_modules = self._get_process_modules_winapi(process_handle)
            legitimate_ranges = []
            
            for module in legitimate_modules:
                base = module.get('base_address', 0)
                size = module.get('size', 0)
                if base and size:
                    legitimate_ranges.append((base, base + size))
            
            # Check executable regions against legitimate modules
            for region in memory_regions:
                if not region.get('is_executable', False):
                    continue
                    
                region_base = region.get('base_address', 0)
                region_size = region.get('region_size', 0)
                
                # Skip small regions (likely not substantial code)
                if region_size < 256:
                    continue
                    
                # Check if region falls within any legitimate module
                is_legitimate = False
                for mod_start, mod_end in legitimate_ranges:
                    if region_base >= mod_start and region_base + region_size <= mod_end:
                        is_legitimate = True
                        break
                        
                if not is_legitimate:
                    # This is an executable region not within any known module
                    try:
                        # Read the first part of the region to analyze
                        read_size = min(region_size, 4096)  # Read up to 4KB
                        region_data = self.read_process_memory(
                            process_handle, 
                            region_base, 
                            read_size
                        )
                        
                        # Check if it contains valid code
                        if region_data and self._contains_valid_code(region_data):
                            suspicious_regions.append({
                                'address': region_base,
                                'size': region_size,
                                'type': 'unmarked_executable_memory',
                                'data': region_data[:min(64, len(region_data))],
                                'detection_method': 'unmarked_executable_detection',
                                'entry_points': self.get_entry_point(region_data, region_base)
                            })
                    except Exception as e:
                        logging.debug(f"Error reading memory at {hex(region_base)}: {str(e)}")
            
            return suspicious_regions
            
        except Exception as e:
            logging.debug(f"Error in _find_unmarked_executable_regions: {str(e)}")
            return suspicious_regions

    def _contains_valid_code(self, data):
        """
        Check if a memory region contains what appears to be valid code
        """
        if not data or len(data) < 10:
            return False
            
        # Quick heuristic check: look for common instruction patterns
        instruction_patterns = [
            b'\x55\x8B\xEC',      # push ebp; mov ebp, esp
            b'\x48\x89\x5C',      # mov [rsp+...], rbx
            b'\x48\x83\xEC',      # sub rsp, ...
            b'\x83\xEC',          # sub esp, ...
            b'\xFF\x15',          # call [...]
            b'\xFF\x25',          # jmp [...]
            b'\xE8',              # call ...
            b'\xE9',              # jmp ...
            b'\x8B\x45',          # mov eax, [ebp+...]
            b'\x8B\x4D',          # mov ecx, [ebp+...]
            b'\x8B\x55',          # mov edx, [ebp+...]
            b'\x89'               # mov ...
        ]
        
        # Count instruction pattern matches
        match_count = sum(1 for pattern in instruction_patterns if pattern in data)
        
        # Check for reasonable entropy (not encrypted/compressed)
        entropy = self._calculate_entropy(data)
        
        # Valid code typically has some instruction patterns and reasonable entropy
        return match_count >= 3 and 4.0 <= entropy <= 7.5
    def get_memory_pe_header(self, process_handle, base_address, max_size=4096):
       
        try:
            # Read potential PE header from memory
            header_data = self.read_process_memory(process_handle, base_address, max_size)
            
            if not header_data or len(header_data) < 64:
                return None
                
            # Check for MZ signature at the beginning (DOS header)
            if header_data[:2] != b'MZ':
                return None
                
            # Try to parse with pefile if available
            try:
                import pefile
                pe = pefile.PE(data=header_data)
                
                # Extract key information
                pe_info = {
                    'is_valid': True,
                    'machine_type': pe.FILE_HEADER.Machine,
                    'timestamp': pe.FILE_HEADER.TimeDateStamp,
                    'characteristics': pe.FILE_HEADER.Characteristics,
                    'entry_point': pe.OPTIONAL_HEADER.AddressOfEntryPoint,
                    'image_base': pe.OPTIONAL_HEADER.ImageBase,
                    'size_of_image': pe.OPTIONAL_HEADER.SizeOfImage,
                    'checksum': pe.OPTIONAL_HEADER.CheckSum,
                    'subsystem': pe.OPTIONAL_HEADER.Subsystem,
                    'dll_characteristics': pe.OPTIONAL_HEADER.DllCharacteristics,
                    'sections': []
                }
                
                # Add section information
                for section in pe.sections:
                    section_info = {
                        'name': section.Name.decode('utf-8', errors='replace').rstrip('\x00'),
                        'virtual_address': section.VirtualAddress,
                        'virtual_size': section.Misc_VirtualSize,
                        'raw_size': section.SizeOfRawData,
                        'characteristics': section.Characteristics,
                        'is_executable': bool(section.Characteristics & 0x20000000),  # IMAGE_SCN_MEM_EXECUTE
                        'is_writable': bool(section.Characteristics & 0x80000000)     # IMAGE_SCN_MEM_WRITE
                    }
                    pe_info['sections'].append(section_info)
                    
                # Get imports if available
                if hasattr(pe, 'DIRECTORY_ENTRY_IMPORT'):
                    pe_info['imports'] = []
                    for entry in pe.DIRECTORY_ENTRY_IMPORT:
                        import_entry = {
                            'dll': entry.dll.decode('utf-8', errors='replace'),
                            'functions': []
                        }
                        for imp in entry.imports:
                            if imp.name:
                                import_entry['functions'].append(imp.name.decode('utf-8', errors='replace'))
                            else:
                                import_entry['functions'].append(f"Ordinal_{imp.ordinal}")
                        pe_info['imports'].append(import_entry)
                
                return pe_info
                
            except ImportError:
                # Fallback to manual parsing if pefile is not available
                return self._manual_parse_pe_header(header_data, base_address)
                
        except Exception as e:
            logging.debug(f"Error parsing PE header from memory at {hex(base_address)}: {str(e)}")
            return None

    def get_disk_pe_header(self, file_path):
        """
        Extract and parse PE header information from a file on disk
        
        Args:
            file_path: Path to the PE file
            
        Returns:
            Dictionary containing PE header information or None if invalid
        """
        
        try:
            # Check if file exists
            if not os.path.isfile(file_path):
                logging.debug(f"File not found: {file_path}")
                return None
                
            # Try to parse with pefile if available
            try:
                import pefile
                pe = pefile.PE(file_path)
                
                # Extract key information
                pe_info = {
                    'is_valid': True,
                    'file_path': file_path,
                    'file_size': os.path.getsize(file_path),
                    'machine_type': pe.FILE_HEADER.Machine,
                    'timestamp': pe.FILE_HEADER.TimeDateStamp,
                    'characteristics': pe.FILE_HEADER.Characteristics,
                    'entry_point': pe.OPTIONAL_HEADER.AddressOfEntryPoint,
                    'image_base': pe.OPTIONAL_HEADER.ImageBase,
                    'size_of_image': pe.OPTIONAL_HEADER.SizeOfImage,
                    'checksum': pe.OPTIONAL_HEADER.CheckSum,
                    'subsystem': pe.OPTIONAL_HEADER.Subsystem,
                    'dll_characteristics': pe.OPTIONAL_HEADER.DllCharacteristics,
                    'sections': []
                }
                
                # Add section information
                for section in pe.sections:
                    section_info = {
                        'name': section.Name.decode('utf-8', errors='replace').rstrip('\x00'),
                        'virtual_address': section.VirtualAddress,
                        'virtual_size': section.Misc_VirtualSize,
                        'raw_size': section.SizeOfRawData,
                        'raw_ptr': section.PointerToRawData,
                        'characteristics': section.Characteristics,
                        'is_executable': bool(section.Characteristics & 0x20000000),  # IMAGE_SCN_MEM_EXECUTE
                        'is_writable': bool(section.Characteristics & 0x80000000)     # IMAGE_SCN_MEM_WRITE
                    }
                    pe_info['sections'].append(section_info)
                    
                # Calculate file hashes
                pe_info['md5'] = self._calculate_file_hash(file_path, 'md5')
                pe_info['sha1'] = self._calculate_file_hash(file_path, 'sha1')
                pe_info['sha256'] = self._calculate_file_hash(file_path, 'sha256')
                
                # Get imports if available
                if hasattr(pe, 'DIRECTORY_ENTRY_IMPORT'):
                    pe_info['imports'] = []
                    for entry in pe.DIRECTORY_ENTRY_IMPORT:
                        import_entry = {
                            'dll': entry.dll.decode('utf-8', errors='replace'),
                            'functions': []
                        }
                        for imp in entry.imports:
                            if imp.name:
                                import_entry['functions'].append(imp.name.decode('utf-8', errors='replace'))
                            else:
                                import_entry['functions'].append(f"Ordinal_{imp.ordinal}")
                        pe_info['imports'].append(import_entry)
                
                # Get exports if available
                if hasattr(pe, 'DIRECTORY_ENTRY_EXPORT'):
                    DIRECTORY_ENTRY_EXPORT          = 0   # Export Directory
                    DIRECTORY_ENTRY_IMPORT          = 1   # Import Directory
                    DIRECTORY_ENTRY_RESOURCE        = 2   # Resource Directory
                    DIRECTORY_ENTRY_EXCEPTION       = 3   # Exception Directory
                    DIRECTORY_ENTRY_SECURITY        = 4   # Security Directory
                    DIRECTORY_ENTRY_BASERELOC       = 5   # Base Relocation Table
                    DIRECTORY_ENTRY_DEBUG           = 6   # Debug Directory
                    DIRECTORY_ENTRY_COPYRIGHT       = 7   # Description String
                    DIRECTORY_ENTRY_GLOBALPTR       = 8   # Machine Value (MIPS GP)
                    DIRECTORY_ENTRY_TLS             = 9   # TLS Directory
                    DIRECTORY_ENTRY_LOAD_CONFIG     = 10  # Load Configuration Directory
                    DIRECTORY_ENTRY_BOUND_IMPORT    = 11  # Bound Import Directory
                    DIRECTORY_ENTRY_IAT             = 12  # Import Address Table
                    DIRECTORY_ENTRY_DELAY_IMPORT    = 13  # Delay Load Import Descriptors
                    DIRECTORY_ENTRY_COM_DESCRIPTOR  = 14  # COM Runtime descriptor
                    pe_info['exports'] = []
                    for exp in pe.DIRECTORY_ENTRY_EXPORT.symbols:
                        if exp.name:
                            pe_info['exports'].append({
                                'name': exp.name.decode('utf-8', errors='replace'),
                                'address': exp.address,
                                'ordinal': exp.ordinal
                            })
                
                return pe_info
                
            except ImportError:
                # Read file and use manual parsing
                with open(file_path, 'rb') as f:
                    header_data = f.read(4096)  # Read enough for headers
                    return self._manual_parse_pe_header(header_data, 0, file_path)
                    
        except Exception as e:
            logging.debug(f"Error parsing PE header from file {file_path}: {str(e)}")
            return None

    def _manual_parse_pe_header(self, header_data, base_address=0, file_path=None):
        """
        Manually parse PE header when pefile is not available
        
        Args:
            header_data: Raw bytes of the PE header
            base_address: Base address where the PE is loaded (for memory)
            file_path: Optional file path (for disk files)
            
        Returns:
            Dictionary containing basic PE header information
        """
        try:
            # Verify MZ signature
            if header_data[:2] != b'MZ':
                return None
                
            # Get PE header offset from e_lfanew field (at offset 0x3C)
            pe_offset = int.from_bytes(header_data[0x3C:0x40], byteorder='little')
            
            # Ensure PE header is within the data we read
            if pe_offset + 24 > len(header_data):
                return None
                
            # Check for PE signature
            if header_data[pe_offset:pe_offset+4] != b'PE\0\0':
                return None
                
            # Parse File Header (follows PE signature)
            file_header_offset = pe_offset + 4
            machine = int.from_bytes(header_data[file_header_offset:file_header_offset+2], byteorder='little')
            num_sections = int.from_bytes(header_data[file_header_offset+2:file_header_offset+4], byteorder='little')
            timestamp = int.from_bytes(header_data[file_header_offset+4:file_header_offset+8], byteorder='little')
            characteristics = int.from_bytes(header_data[file_header_offset+18:file_header_offset+20], byteorder='little')
            
            # Parse Optional Header (follows File Header)
            opt_header_offset = file_header_offset + 20
            magic = int.from_bytes(header_data[opt_header_offset:opt_header_offset+2], byteorder='little')
            
            # Determine if it's PE32 or PE32+ (64-bit)
            is_64bit = (magic == 0x20B)
            
            # Get image base, entry point, and size of image
            if is_64bit:
                entry_point = int.from_bytes(header_data[opt_header_offset+16:opt_header_offset+20], byteorder='little')
                image_base = int.from_bytes(header_data[opt_header_offset+24:opt_header_offset+32], byteorder='little')
                size_of_image = int.from_bytes(header_data[opt_header_offset+56:opt_header_offset+60], byteorder='little')
                sections_offset = opt_header_offset + 112  # PE32+ optional header size
            else:
                entry_point = int.from_bytes(header_data[opt_header_offset+16:opt_header_offset+20], byteorder='little')
                image_base = int.from_bytes(header_data[opt_header_offset+28:opt_header_offset+32], byteorder='little')
                size_of_image = int.from_bytes(header_data[opt_header_offset+56:opt_header_offset+60], byteorder='little')
                sections_offset = opt_header_offset + 96   # PE32 optional header size
            
            # Create result structure
            pe_info = {
                'is_valid': True,
                'machine_type': machine,
                'timestamp': timestamp,
                'characteristics': characteristics,
                'entry_point': entry_point,
                'image_base': image_base,
                'size_of_image': size_of_image,
                'is_64bit': is_64bit,
                'sections': [],
                'base_address': base_address
            }
            
            if file_path:
                pe_info['file_path'] = file_path
                pe_info['file_size'] = os.path.getsize(file_path) if os.path.exists(file_path) else 0
            
            # Parse section headers (limited by how much we read)
            for i in range(min(num_sections, 16)):  # Limit to reasonable number
                section_offset = sections_offset + (i * 40)  # Each section header is 40 bytes
                
                # Ensure we have enough data
                if section_offset + 40 > len(header_data):
                    break
                    
                section_name_bytes = header_data[section_offset:section_offset+8]
                section_name = section_name_bytes.decode('utf-8', errors='replace').rstrip('\0')
                virtual_addr = int.from_bytes(header_data[section_offset+12:section_offset+16], byteorder='little')
                virtual_size = int.from_bytes(header_data[section_offset+8:section_offset+12], byteorder='little')
                raw_size = int.from_bytes(header_data[section_offset+16:section_offset+20], byteorder='little')
                characteristics = int.from_bytes(header_data[section_offset+36:section_offset+40], byteorder='little')
                
                section_info = {
                    'name': section_name,
                    'virtual_address': virtual_addr,
                    'virtual_size': virtual_size,
                    'raw_size': raw_size,
                    'characteristics': characteristics,
                    'is_executable': bool(characteristics & 0x20000000),  # IMAGE_SCN_MEM_EXECUTE
                    'is_writable': bool(characteristics & 0x80000000)     # IMAGE_SCN_MEM_WRITE
                }
                pe_info['sections'].append(section_info)
            
            return pe_info
            
        except Exception as e:
            logging.debug(f"Error in manual PE parsing: {str(e)}")
            return None

    def _calculate_file_hash(self, file_path, hash_type='sha256'):
        try:
            import hashlib
            
            hash_obj = None
            if hash_type.lower() == 'md5':
                hash_obj = hashlib.md5()
            elif hash_type.lower() == 'sha1':
                hash_obj = hashlib.sha1()
            else:  # Default to sha256
                hash_obj = hashlib.sha256()
                
            with open(file_path, 'rb') as f:
                # Read file in chunks to handle large files
                for chunk in iter(lambda: f.read(4096), b''):
                    hash_obj.update(chunk)
                    
            return hash_obj.hexdigest()
            
        except Exception as e:
            logging.debug(f"Error calculating {hash_type} hash for {file_path}: {str(e)}")
            return None
    def _calculate_entropy(self, data):
        """Calculate Shannon entropy of data"""
        if not data:
            return 0
            
        entropy = 0
        for x in range(256):
            p_x = data.count(x) / len(data)
            if p_x > 0:
                entropy += -p_x * math.log2(p_x)
                
        return entropy

    def _find_function_pointer_targets(self, process_handle, memory_regions):
        """
        Find function pointers that point to suspicious memory regions
        """
        suspicious_pointers = []
        
        try:
            # Get list of legitimate modules
            legitimate_modules = self._get_process_modules_winapi(process_handle)
            legitimate_ranges = []
            
            for module in legitimate_modules:
                base = module.get('base_address', 0)
                size = module.get('size', 0)
                if base and size:
                    legitimate_ranges.append((base, base + size))
            
            # Examine readable regions for potential pointers
            for region in memory_regions:
                if not region.get('is_readable', True):
                    continue
                    
                region_base = region.get('base_address', 0)
                region_size = region.get('region_size', 0)
                
                # Skip very large regions
                if region_size > 10 * 1024 * 1024:  # Skip regions > 10MB
                    continue
                    
                try:
                    # Read memory region
                    region_data = self.read_process_memory(
                        process_handle, 
                        region_base, 
                        region_size
                    )
                    
                    if not region_data or len(region_data) < 4:
                        continue
                        
                    # Extract potential pointers (4-byte aligned values)
                    for i in range(0, len(region_data) - 4, 4):
                        # Extract a potential pointer value
                        if len(region_data) >= i + 4:
                            ptr_value = int.from_bytes(region_data[i:i+4], byteorder='little')
                            
                            # Check if pointer is a reasonable value and points outside legitimate modules
                            if ptr_value > 0x10000:  # Skip very low addresses
                                is_legitimate = False
                                for mod_start, mod_end in legitimate_ranges:
                                    if ptr_value >= mod_start and ptr_value < mod_end:
                                        is_legitimate = True
                                        break
                                        
                                if not is_legitimate:
                                    # Check if pointer target is in an executable region
                                    target_region = None
                                    for mem_region in memory_regions:
                                        mem_base = mem_region.get('base_address', 0)
                                        mem_size = mem_region.get('region_size', 0)
                                        if ptr_value >= mem_base and ptr_value < mem_base + mem_size:
                                            target_region = mem_region
                                            break
                                            
                                    if target_region and target_region.get('is_executable', False):
                                        # We found a pointer to executable memory outside legitimate modules
                                        try:
                                            # Read some bytes from the target
                                            target_data = self.read_process_memory(
                                                process_handle,
                                                ptr_value,
                                                min(64, target_region.get('region_size', 0) - (ptr_value - target_region.get('base_address', 0)))
                                            )
                                            
                                            if target_data:
                                                suspicious_pointers.append({
                                                    'pointer_address': region_base + i,
                                                    'target_address': ptr_value,
                                                    'type': 'suspicious_function_pointer',
                                                    'target_data': target_data,
                                                    'detection_method': 'function_pointer_detection',
                                                    'disassembly': self._try_disassemble(target_data, ptr_value)
                                                })
                                        except Exception as e:
                                            logging.debug(f"Error reading pointer target at {hex(ptr_value)}: {str(e)}")
                except Exception as e:
                    logging.debug(f"Error analyzing region at {hex(region_base)}: {str(e)}")
                    
            return suspicious_pointers
            
        except Exception as e:
            logging.debug(f"Error in _find_function_pointer_targets: {str(e)}")
            return suspicious_pointers
    def _detect_stack_execution(self, process_handle, memory_regions):
        """
        Detect attempts to execute code on the stack
        """
        suspicious_stacks = []
        
        try:
            # Find stack regions (usually marked with MEM_PRIVATE and has specific permissions)
            stack_regions = []
            for region in memory_regions:
                mem_type = region.get('type', '')
                protection = region.get('protection', 0)
                is_stack = (
                    mem_type == 0x1000000 and  # MEM_PRIVATE
                    region.get('is_readable', False) and
                    region.get('is_writable', False) and
                    not region.get('module_name')  # Not part of a module
                )
                
                # Add to stack regions if it looks like a stack
                if is_stack:
                    stack_regions.append(region)
            
            # Find thread information to help identify stack regions
            thread_info = self._get_thread_information(process_handle)
            for protection in memory_regions:
                region_base = protection.get('base_address', 0)
                region_size = protection.get('region_size', 0)

            # Check stack regions for suspicious characteristics
            for region in stack_regions:
                region_base = region.get('base_address', 0)
                region_size = region.get('region_size', 0)
                
                # Check #1: Is the stack region executable? (highly suspicious)
                if region.get('is_executable', False):
                    try:
                        # Read some of the stack memory
                        stack_data = self.read_process_memory(
                            process_handle,
                            region_base,
                            min(region_size, 4096)  # Read up to 4KB
                        )
                        
                        if stack_data:
                            suspicious_stacks.append({
                                'address': region_base,
                                'size': region_size,
                                'type': 'executable_stack',
                                'data': stack_data[:min(64, len(stack_data))],
                                'protection': region.get('protection', 0),
                                'detection_method': 'executable_stack_detection',
                                'thread_association': self._get_thread_for_stack(region, thread_info),
                                'entry_points': self.get_entry_point(stack_data, region_base)
                            })
                    except Exception as e:
                        logging.debug(f"Error reading stack memory at {hex(region_base)}: {str(e)}")
                
                # Check #2: Even if not executable, look for code-like patterns on the stack
                else:
                    try:
                        # Read stack memory
                        stack_data = self.read_process_memory(
                            process_handle,
                            region_base,
                            min(region_size, 4096)  # Read up to 4KB
                        )
                        
                        if stack_data and self._contains_code_patterns(stack_data):
                            suspicious_stacks.append({
                                'address': region_base,
                                'size': region_size,
                                'type': 'code_patterns_on_stack',
                                'data': stack_data[:min(64, len(stack_data))],
                                'protection': region.get('protection', 0),
                                'detection_method': 'stack_code_pattern_detection',
                                'thread_association': self._get_thread_for_stack(region, thread_info)
                            })
                    except Exception as e:
                        logging.debug(f"Error reading stack memory at {hex(region_base)}: {str(e)}")
            
            return suspicious_stacks
            
        except Exception as e:
            logging.debug(f"Error in _detect_stack_execution: {str(e)}")
            return suspicious_stacks

    def _get_thread_information(self, process_handle):
        """
        Get information about threads in the process, including their stack regions
        """
        thread_info = []
        
        try:
            TH32CS_SNAPTHREAD = 0x00000004
            INVALID_HANDLE_VALUE = 0xFFFFFFFF
            # Get process ID
            kernel32 = ctypes.windll.kernel32
            process_id = kernel32.GetProcessId(process_handle)
            
            # Take a snapshot of the system threads
            h_snapshot = kernel32.CreateToolhelp32Snapshot(
                win32con.TH32CS_SNAPTHREAD, 
                0  # 0 means all processes
            )
            
            if h_snapshot == win32con.INVALID_HANDLE_VALUE:
                return thread_info
                
            try:
                # Set up THREADENTRY32 structure
                thread_entry = THREADENTRY32()
                thread_entry.dwSize = ctypes.sizeof(THREADENTRY32)
                
                # Get the first thread
                success = kernel32.Thread32First(h_snapshot, ctypes.byref(thread_entry))
                
                while success:
                    # Check if this thread belongs to our process
                    if thread_entry.th32OwnerProcessID == process_id:
                        thread_id = thread_entry.th32ThreadID
                        
                        try:
                            # Open the thread
                            thread_handle = kernel32.OpenThread(
                                win32con.THREAD_QUERY_INFORMATION | win32con.THREAD_GET_CONTEXT, 
                                False, 
                                thread_id
                            )
                            
                            if thread_handle:
                                try:
                                    # Get thread context to find stack pointers
                                    context = self._get_thread_context(thread_handle)
                                    
                                    if context:
                                        thread_info.append({
                                            'thread_id': thread_id,
                                            'stack_pointer': context.get('esp', context.get('rsp', 0)),
                                            'base_pointer': context.get('ebp', context.get('rbp', 0))
                                        })
                                finally:
                                    kernel32.CloseHandle(thread_handle)
                        except Exception as e:
                            logging.debug(f"Error getting thread context for thread {thread_id}: {str(e)}")
                    
                    # Get next thread
                    success = kernel32.Thread32Next(h_snapshot, ctypes.byref(thread_entry))
                    
            finally:
                kernel32.CloseHandle(h_snapshot)
                
            return thread_info
            
        except Exception as e:
            logging.debug(f"Error in _get_thread_information: {str(e)}")
            return thread_info

    def _get_thread_context(self, thread_handle):
        """
        Get the context (register values) of a thread
        """
        try:
            kernel32 = ctypes.windll.kernel32
            # Determine architecture (32-bit or 64-bit)
            is_wow64 = ctypes.c_bool()
            kernel32.IsWow64Process(thread_handle, ctypes.byref(is_wow64))
            
            if is_wow64.value:
                # 32-bit thread in 64-bit process (WOW64)
                # This is simplified - a full implementation would use 
                # architecture-specific structures like WOW64_CONTEXT
                context_flags = 0x10007  # CONTEXT_CONTROL | CONTEXT_INTEGER
                context = ctypes.create_string_buffer(716)  # Size of 32-bit CONTEXT
                context_ptr = ctypes.byref(context)
                
                ctypes.memmove(context_ptr, ctypes.byref(ctypes.c_ulong(context_flags)), 4)
                
                if kernel32.GetThreadContext(thread_handle, context_ptr):
                    # Extract ESP and EBP (offsets based on CONTEXT structure)
                    esp = ctypes.cast(ctypes.byref(context, 0xC4), ctypes.POINTER(ctypes.c_ulong)).contents.value
                    ebp = ctypes.cast(ctypes.byref(context, 0xB8), ctypes.POINTER(ctypes.c_ulong)).contents.value
                    
                    return {'esp': esp, 'ebp': ebp}
            else:
                # 64-bit thread
                context_flags = 0x100007  # CONTEXT_CONTROL | CONTEXT_INTEGER
                context = ctypes.create_string_buffer(1232)  # Size of 64-bit CONTEXT
                context_ptr = ctypes.byref(context)
                
                ctypes.memmove(context_ptr, ctypes.byref(ctypes.c_ulong(context_flags)), 4)
                
                if kernel32.GetThreadContext(thread_handle, context_ptr):
                    # Extract RSP and RBP (offsets based on CONTEXT structure)
                    rsp = ctypes.cast(ctypes.byref(context, 0x98), ctypes.POINTER(ctypes.c_ulonglong)).contents.value
                    rbp = ctypes.cast(ctypes.byref(context, 0x88), ctypes.POINTER(ctypes.c_ulonglong)).contents.value
                    
                    return {'rsp': rsp, 'rbp': rbp}
                    
            return None
            
        except Exception as e:
            logging.debug(f"Error getting thread context: {str(e)}")
            return None

    def _get_thread_for_stack(self, stack_region, thread_info):
        """
        Find which thread a stack region belongs to
        """
        region_base = stack_region.get('base_address', 0)
        region_end = region_base + stack_region.get('region_size', 0)
        
        for thread in thread_info:
            # Check if thread's stack pointer is within this region
            stack_ptr = thread.get('stack_pointer', 0)
            if stack_ptr >= region_base and stack_ptr < region_end:
                return thread.get('thread_id', 0)
                
        return 0  # No associated thread found

    def _contains_code_patterns(self, data):
        """
        Look for code-like patterns in data
        """
        if not data or len(data) < 10:
            return False
            
        # Common shellcode patterns
        shellcode_patterns = [
            rb'\x90{5,}',                                       # NOP sled
            rb'\xeb[\x00-\xff]\xe8[\x00-\xff]{4}',              # jmp short + call
            rb'\x31\xc0[\x00-\xff]{0,10}\x50[\x00-\xff]{0,10}', # xor eax,eax + push eax
            rb'\x33\xc0[\x00-\xff]{0,10}\x50',                  # xor eax,eax + push eax
            rb'\x48\x31\xc0[\x00-\xff]{0,15}\x50',              # x64 xor rax,rax + push
            rb'\x68.{4}\xc3',                                   # push + ret
            rb'\xe8.{4}',                                       # call with offset
            rb'\xff\xd0',                                       # call eax
            rb'\xff\xd1',                                       # call ecx
            rb'\xff\xd2',                                       # call edx
            rb'\xff\xd3',                                       # call ebx
            rb'\xff\xe0',                                       # jmp eax
            rb'\xff\xe1',                                       # jmp ecx
            rb'\xff\xe2',                                       # jmp edx
            rb'\xff\xe3',                                       # jmp ebx
        ]
        
        # Check for any shellcode patterns
        for pattern in shellcode_patterns:
            if re.search(pattern, data):
                return True
                
        # Check for code-like entropy
        entropy = self._calculate_entropy(data)
        if 5.0 <= entropy <= 7.0:  # Typical range for code
            # Count instruction-like byte sequences
            instruction_prefixes = [b'\x8B', b'\x89', b'\x8D', b'\xFF', b'\xE8', b'\xE9', b'\xEB', b'\x83', b'\x81']
            prefix_count = sum(data.count(prefix) for prefix in instruction_prefixes)
            
            # If we have a significant number of instruction prefixes, it's likely code
            return prefix_count > len(data) / 30
                
        return False
    
    def get_process_memory_regions(self, process_handle):
        """
        Enumerate and return all memory regions in a process
        
        Args:
            process_handle: Handle to the process
            
        Returns:
            List of dictionaries containing memory region information
        """
        memory_regions = []
        
        try:
            # Initialize variables for VirtualQueryEx
            system_info = win32api.GetSystemInfo()
            min_address = system_info[2]
            max_address = system_info[3]
            
            # Create MEMORY_BASIC_INFORMATION structure for results
            mbi = ctypes.create_string_buffer(28)  # Size of MEMORY_BASIC_INFORMATION
            
            # Iterate through the address space
            current_address = min_address
            
            while current_address < max_address:
                # Query memory region information
                kernel32 = ctypes.windll.kernel32
                if kernel32.VirtualQueryEx(
                    process_handle,
                    current_address,
                    ctypes.byref(mbi),
                    ctypes.sizeof(mbi)
                ) > 0:
                    # Parse the memory region information
                    mbi_struct = ctypes.cast(mbi, ctypes.POINTER(MEMORY_BASIC_INFORMATION)).contents
                    
                    # Get base address and region size (convert from c_void_p/c_ulong to int)
                    base_address = self.sanitize_value(mbi_struct.BaseAddress, 0)
                    region_size = self.sanitize_value(mbi_struct.RegionSize, 0)
                    
                    # Get protection and type information
                    protection = self.sanitize_value(mbi_struct.Protect, 0)
                    mem_type = self.sanitize_value(mbi_struct.Type, 0)
                    state = self.sanitize_value(mbi_struct.State, 0)
                    
                    # Convert protection flags to attributes
                    is_readable = (protection & 0x01) or (protection & 0x02) or (protection & 0x04) or (protection & 0x08)
                    is_writable = (protection & 0x02) or (protection & 0x04) or (protection & 0x08) or (protection & 0x40)
                    is_executable = (protection & 0x10) or (protection & 0x20) or (protection & 0x40) or (protection & 0x80)
                    
                    # Add to our list if it's committed memory
                    if state == 0x1000:  # MEM_COMMIT
                        region_info = {
                            'base_address': base_address,
                            'region_size': region_size,
                            'protection': protection,
                            'type': mem_type,
                            'state': state,
                            'is_readable': is_readable,
                            'is_writable': is_writable,
                            'is_executable': is_executable
                        }
                        
                        # Try to get module information for this region
                        region_info['module_name'] = self._get_module_for_address(process_handle, base_address)
                        
                        memory_regions.append(region_info)
                    
                    # Move to the next region
                    current_address += region_size
                else:
                    # VirtualQueryEx failed, advance by page size and try again
                    current_address += system_info[1]  # PageSize
            
            return memory_regions
            
        except Exception as e:
            logging.debug(f"Error in get_process_memory_regions: {str(e)}")
            return memory_regions
    def sanitize_value(self, value, default=0):
        """
        Safely converts memory values to integers
        
        Args:
            value: The value to sanitize (could be c_void_p, c_ulong, or other C types)
            default: Default value to return if conversion fails
            
        Returns:
            Integer representation of the value
        """
        try:
            # Handle c_void_p
            if isinstance(value, ctypes.c_void_p):
                return value.value or default
                
            # Handle other ctypes
            if hasattr(value, 'value'):
                return value.value
                
            # Try direct integer conversion
            return int(value)
            
        except (ValueError, TypeError, AttributeError):
            return default
    def _get_module_for_address(self, process_handle, address):
        """
        Find the module name for a given address in the process
        """
        try:
            modules = self._get_process_modules_winapi(process_handle)
            for module in modules:
                base = module.get('base_address', 0)
                size = module.get('size', 0)
                if address >= base and address < base + size:
                    return module.get('name', 'Unknown')
            return None
        except Exception:
            return None

    def _find_suspicious_thread_entries(self, process_handle):
        """
        Find threads with entry points in suspicious memory regions
        
        Args:
            process_handle: Handle to the process
            
        Returns:
            List of suspicious thread entries
        """
        suspicious_threads = []
        
        try:
            # Get process ID
            kernel32 = ctypes.windll.kernel32
            ntdll = ctypes.windll.ntdll
            process_id = kernel32.GetProcessId(process_handle)
            
            # Get all memory regions
            memory_regions = self.get_process_memory_regions(process_handle)
            
            # Get legitimate module ranges
            legitimate_modules = self._get_process_modules_winapi(process_handle)
            legitimate_ranges = []
            
            for module in legitimate_modules:
                base = module.get('base_address', 0)
                size = module.get('size', 0)
                if base and size:
                    legitimate_ranges.append((base, base + size, module.get('name', 'Unknown')))
            
            # Take a snapshot of the system processes and threads
            h_snapshot = kernel32.CreateToolhelp32Snapshot(
                win32con.TH32CS_SNAPTHREAD, 
                0  # 0 means all processes
            )
            
            if h_snapshot == win32con.INVALID_HANDLE_VALUE:
                return suspicious_threads
                
            try:
                # Set up THREADENTRY32 structure
                thread_entry = THREADENTRY32()
                thread_entry.dwSize = ctypes.sizeof(THREADENTRY32)
                
                # Get the first thread
                success = kernel32.Thread32First(h_snapshot, ctypes.byref(thread_entry))
                
                while success:
                    # Check if this thread belongs to our process
                    if thread_entry.th32OwnerProcessID == process_id:
                        # Get thread information
                        thread_id = thread_entry.th32ThreadID
                        
                        try:
                            # Open the thread
                            thread_handle = kernel32.OpenThread(
                                win32con.THREAD_QUERY_INFORMATION, 
                                False, 
                                thread_id
                            )
                            
                            if thread_handle:
                                try:
                                    # Get thread start address
                                    start_address = ctypes.c_void_p(0)
                                    
                                    # Use NtQueryInformationThread to get thread start address
                                    status = ntdll.NtQueryInformationThread(
                                        thread_handle,
                                        9,  # ThreadQuerySetWin32StartAddress
                                        ctypes.byref(start_address),
                                        ctypes.sizeof(start_address),
                                        None
                                    )
                                    
                                    if status == 0:  # STATUS_SUCCESS
                                        # Convert to integer
                                        thread_start = self._get_process_info_winapi(start_address.value, 0)
                                        
                                        # Check if thread entry point is in a legitimate module
                                        is_legitimate = False
                                        module_name = self._get_process_modules_winapi(process_handle, thread_start)
                                        
                                        for start, end, module_name in memory_regions:
                                            if thread_start >= start and thread_start < end:
                                                is_legitimate = True
                                                module_name = self.get_module_info(module_name, 0)
                                                break
                                        
                                        # If not legitimate, it's suspicious
                                        if not is_legitimate:
                                            # Find which memory region this falls into
                                            region_info = None
                                            for region in memory_regions:
                                                base = region.get('base_address', 0)
                                                size = region.get('region_size', 0)
                                                if thread_start >= base and thread_start < base + size:
                                                    region_info = region
                                                    break
                                            
                                            # If we found a region and it's executable, it's very suspicious
                                            if region_info and region_info.get('is_executable', False):
                                                try:
                                                    # Read some bytes from the start address
                                                    code_bytes = self.read_process_memory(
                                                        process_handle,
                                                        thread_start,
                                                        min(64, (region_info.get('base_address', 0) + 
                                                            region_info.get('region_size', 0) - thread_start))
                                                    )
                                                    
                                                    suspicious_threads.append({
                                                        'thread_id': thread_id,
                                                        'start_address': thread_start,
                                                        'type': 'suspicious_thread_entry',
                                                        'region': {
                                                            'base_address': region_info.get('base_address', 0),
                                                            'region_size': region_info.get('region_size', 0),
                                                            'protection': region_info.get('protection', 0)
                                                        },
                                                        'code_bytes': code_bytes if code_bytes else b'',
                                                        'detection_method': 'thread_entry_point_detection',
                                                        'disassembly': self._try_disassemble(
                                                            code_bytes if code_bytes else b'', 
                                                            thread_start
                                                        )
                                                    })
                                                except Exception as e:
                                                    logging.debug(f"Error reading thread start memory: {str(e)}")
                                finally:
                                    # Close thread handle
                                    kernel32.CloseHandle(thread_handle)
                        except Exception as e:
                            logging.debug(f"Error analyzing thread {thread_id}: {str(e)}")
                    
                    # Get next thread
                    success = kernel32.Thread32Next(h_snapshot, ctypes.byref(thread_entry))
                    
            finally:
                # Close snapshot handle
                kernel32.CloseHandle(h_snapshot)
            
            return suspicious_threads
            
        except Exception as e:
            logging.debug(f"Error in _find_suspicious_thread_entries: {str(e)}")
            return suspicious_threads
    def read_process_memory(self, process_handle, address, size):
        """
        Read memory from a process
        
        Args:
            process_handle: Handle to the process
            address: Base address to read from
            size: Number of bytes to read
            
        Returns:
            Bytes object containing the read memory
        """
        try:
            # Create a buffer for the data
            buffer = ctypes.create_string_buffer(size)
            bytes_read = ctypes.c_size_t(0)
            
            # Read the memory
            kernel32 = ctypes.windll.kernel32
            success = kernel32.ReadProcessMemory(
                process_handle,
                ctypes.c_void_p(address),
                buffer,
                size,
                ctypes.byref(bytes_read)
            )
            
            if success and bytes_read.value > 0:
                # Convert buffer to bytes
                return bytes(buffer[:bytes_read.value])
            return None
        except Exception as e:
            logging.debug(f"Error reading process memory at {hex(address)}: {str(e)}")
            return None
    def _try_disassemble(self, data, address):
        self.disassembler = CodeDisassembler()
        """Try to disassemble the given data"""
        if not hasattr(self, 'disassembler') or not self.disassembler:
            return "Disassembler not available"
        
        try:
            return self.disassembler.disassemble(data, address)
        except Exception as e:
            return f"Disassembly failed: {str(e)}"
    def dump_process_memory(self, pid: int, output_dir: Path):
        try:
            # Define process first
            process = psutil.Process(pid)
            process_handle = win32api.OpenProcess(
            win32con.PROCESS_QUERY_INFORMATION | win32con.PROCESS_VM_READ,
            False,
            pid
        )
            output_dir.mkdir(exist_ok=True)
            logging.debug(f"Error creating output directory: {str(e)}")
        except Exception as e:
            return False       
        try:
            process = psutil.Process(pid)
            process_handle = win32api.OpenProcess(
            win32con.PROCESS_QUERY_INFORMATION | win32con.PROCESS_VM_READ,
            False,
            pid
        )
            output_dir.mkdir(exist_ok=True)
            
            # Get process information for metadata
            process_info = {
                'name': process.name(),
                'exe': process.exe(),
                'create_time': process.create_time(),
                'cmdline': process.cmdline()
            }
            
            # Save process metadata
            metadata_path = output_dir / f"pid_{pid}_metadata.json"
            with open(metadata_path, 'w') as f:
                json.dump(process_info, f, indent=4, default=str)
            
            current_address = 0
            while True:
                mem_info = self.get_memory_info(process_handle, current_address)
                if not mem_info:
                    break
                    
                if mem_info.State & self.MEM_COMMIT:
                    try:
                        memory_content = win32process.ReadProcessMemory(
                            process_handle,
                            mem_info.BaseAddress,
                            mem_info.RegionSize
                        )
                        
                        dump_path = output_dir / f"pid_{pid}_{process.name()}_{hex(mem_info.BaseAddress)}.dump"
                        with open(dump_path, 'wb') as dst:
                            dst.write(memory_content)
                            
                    except Exception as region_error:
                        logging.debug(f"Failed to dump region at {hex(mem_info.BaseAddress)} for {process.name()}: {str(region_error)}")
                        
                current_address = mem_info.BaseAddress + mem_info.RegionSize
                
            win32api.CloseHandle(process_handle)
            return True
            
        except :
            logging.error(f"Memory dump failed for PID {pid} ({process.name() if process else 'unknown'}): {str(e)}")
            return False
    def quarantine_process(self, pid: int) -> bool:
        """Quarantines a suspicious process by dumping its memory and terminating it.
        
        Args: 
            pid: Process ID to quarantine 
        Returns: 
            bool: True if quarantine successful, False otherwise
        """
        try:
            kernel32 = ctypes.windll.kernel32
            process = psutil.Process(pid)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # Create quarantine directory structure
            quarantine_dir = Path("quarantine") / "processes"
            quarantine_dir.mkdir(exist_ok=True, parents=True)
            
            # Create specific directory for this process
            process_dir = quarantine_dir / f"{process.name()}_{pid}_{timestamp}"
            process_dir.mkdir(exist_ok=True)
            
            # Collect process information
            process_info = {
                'pid': pid,
                'name': process.name(),
                'exe': process.exe() if hasattr(process, 'exe') else 'Unknown',
                'cmdline': process.cmdline() if hasattr(process, 'cmdline') else [],
                'create_time': process.create_time() if hasattr(process, 'create_time') else None,
                'username': process.username() if hasattr(process, 'username') else 'Unknown',
                'connections': [
                    {
                        'local_addr': f"{conn.laddr.ip}:{conn.laddr.port}" if hasattr(conn, 'laddr') else None,
                        'remote_addr': f"{conn.raddr.ip}:{conn.raddr.port}" if hasattr(conn, 'raddr') and conn.raddr else None,
                        'status': conn.status if hasattr(conn, 'status') else None
                    }
                    for conn in process.net_connections() if hasattr(process, 'connections')
                ],
                'quarantine_time': timestamp,
                'status': 'quarantined'
            }
            
            # Save process metadata
            with open(process_dir / "metadata.json", "w") as f:
                json.dump(process_info, f, indent=4, default=str)
            
            # Dump process memory if possible
            memory_dir = process_dir / "memory_dumps"
            memory_dir.mkdir(exist_ok=True)
            
            # Get process handle for memory operations
            process_handle = win32api.OpenProcess(
                win32con.PROCESS_QUERY_INFORMATION | win32con.PROCESS_VM_READ,
                False,
                pid
            )
            
            # Enumerate and dump memory regions
            try:
                memory_regions = self._enumerate_memory_regions_winapi(int(process_handle))
                
                for i, region in enumerate(memory_regions):
                    if region['State'] & 0x1000:  # MEM_COMMIT
                        try:
                            # Read memory content
                            buffer = ctypes.create_string_buffer(region['RegionSize'])
                            bytes_read = ctypes.c_size_t(0)
                            
                            success = ctypes.windll.kernel32.ReadProcessMemory(
                                process_handle,
                                ctypes.c_void_p(region['BaseAddress']),
                                buffer,
                                region['RegionSize'],
                                ctypes.byref(bytes_read)
                            )
                            
                            if success and bytes_read.value > 0:
                                # Save memory dump
                                with open(memory_dir / f"region_{i}_{hex(region['BaseAddress'])}.bin", "wb") as f:
                                    f.write(buffer.raw[:bytes_read.value])
                                
                                # Save region metadata
                                with open(memory_dir / f"region_{i}_{hex(region['BaseAddress'])}.json", "w") as f:
                                    json.dump({
                                        'base_address': hex(region['BaseAddress']),
                                        'size': region['RegionSize'],
                                        'protection': region['Protect'],
                                        'state': region['State'],
                                        'type': region['Type']
                                    }, f, indent=4)
                        except Exception as e:
                            logging.error(f"Error dumping memory region at {hex(region['BaseAddress'])}: {str(e)}")
            except Exception as e:
                logging.error(f"Error enumerating memory regions: {str(e)}")
            finally:
                win32api.CloseHandle(process_handle)
                
            # Dump process executable
            if hasattr(process, 'exe') and process.exe():
                try:
                    exe_path = process.exe()
                    if os.path.exists(exe_path):
                        shutil.copy2(exe_path, process_dir / "executable.bin")
                except Exception as e:
                    logging.error(f"Error copying executable: {str(e)}")
            
            # Terminate the process
            process.kill()
            
            logging.info(f"Process {pid} ({process.name()}) successfully quarantined")
            return True
            
        except psutil.NoSuchProcess:
            logging.error(f"Process {pid} not found")
            return False
        except psutil.AccessDenied:
            logging.error(f"Access denied when quarantining process {pid}")
            return False
        except Exception as e:
            logging.error(f"Error quarantining process {pid}: {str(e)}")
            logging.error(traceback.format_exc())
            return False

            return False    
class ShellcodeCapture:
    def __init__(self):
        self.shellcode_tome = {}  # Our magical tome to store shellcode
        self.scanner = MemoryScanner()
    def capture_shellcode(self, memory_region, start_addr=0, size=None, source_info=None):
        """
        Captures shellcode from a memory region and stores it in the shellcode tome
        
        Args:
            memory_region: The memory buffer/region containing potential shellcode
            start_addr: Starting address of the memory region (for reference)
            size: Size to capture (None means capture all)
            source_info: Additional context about where this shellcode was found
            
        Returns:
            shellcode_id: Identifier for the captured shellcode in the tome
        """
        # Extract the relevant portion of memory
        if size is None:
            extracted_data = memory_region
        else:
            extracted_data = memory_region[:size]
            
        # Generate a unique ID for this shellcode (using hash)
        shellcode_hash = hashlib.sha256(extracted_data).hexdigest()[:16]
        
        # Only store if we haven't seen this exact shellcode before
        if shellcode_hash not in self.shellcode_tome:
            self.shellcode_tome[shellcode_hash] = {
                'data': extracted_data,
                'size': len(extracted_data),
                'hex': binascii.hexlify(extracted_data).decode('utf-8'),
                'first_seen': datetime.now(),
                'seen_count': 1,
                'sources': [source_info] if source_info else [],
                'memory_addresses': [start_addr] if start_addr is not None else []
            }
        else:
            # Update existing entry
            self.shellcode_tome[shellcode_hash]['seen_count'] += 1
            if source_info and source_info not in self.shellcode_tome[shellcode_hash]['sources']:
                self.shellcode_tome[shellcode_hash]['sources'].append(source_info)
            if start_addr is not None and start_addr not in self.shellcode_tome[shellcode_hash]['memory_addresses']:
                self.shellcode_tome[shellcode_hash]['memory_addresses'].append(start_addr)
        
        return shellcode_hash
    
    def get_shellcode(self, shellcode_id):
        """Retrieve a specific shellcode entry from the tome"""
        return self.shellcode_tome.get(shellcode_id)
    
    def list_all_shellcodes(self):
        """Returns a list of all shellcode IDs in the tome"""
        return list(self.shellcode_tome.keys())
    
    def export_tome(self, filename):
        """Export the shellcode tome to a file"""
        import json
        with open(filename, 'w') as f:
            # Convert binary data to hex strings for JSON serialization
            export_data = {}
            for sc_id, sc_data in self.shellcode_tome.items():
                export_data[sc_id] = sc_data.copy()
                if isinstance(export_data[sc_id]['data'], bytes):
                    export_data[sc_id]['data'] = binascii.hexlify(export_data[sc_id]['data']).decode('utf-8')
                export_data[sc_id]['first_seen'] = export_data[sc_id]['first_seen'].isoformat()
            
            json.dump(export_data, f, indent=2) 
class ThreatQuarantine:
    def __init__(self, quarantine_dir=None):
        self.quarantine_dir = quarantine_dir or os.path.join(os.path.expanduser("~"), "scanner_quarantine")
        if not os.path.exists(self.quarantine_dir):
            os.makedirs(self.quarantine_dir)
        self.logger = logging.getLogger(__name__)
        
    def quarantine_process(self, pid, process_info, threat_details):
        """Quarantine a malicious process by suspending it and logging details"""
        try:
            # Safety check - return early if quarantine is disabled
            if not getattr(self, 'quarantine_enabled', False):
                return False
                
            # Safety check - return early if quarantine directory isn't available
            if not getattr(self, 'quarantine_dir', None):
                logging.error("Quarantine directory not available")
                return False
                
            # Get process handle with PROCESS_SUSPEND_RESUME rights
            process_handle = ctypes.windll.kernel32.OpenProcess(
                0x0800,  # PROCESS_SUSPEND_RESUME
                False,
                pid
            )
            
            if not process_handle:
                logging.error(f"Failed to open process {pid} for quarantine")
                return False
                
            # Suspend the process
            suspension_successful = self._suspend_process(process_handle)
            
            # Close the handle regardless of suspension success
            ctypes.windll.kernel32.CloseHandle(process_handle)
            
            if not suspension_successful:
                logging.error(f"Process suspension failed for PID {pid}")
                
            # Generate unique ID and prepare info even if suspension failed
            quarantine_id = str(uuid.uuid4())
            quarantine_info = {
                "quarantine_id": quarantine_id,
                "timestamp": datetime.datetime.now().isoformat(),
                "pid": pid,
                "process_name": process_info.get("Name", "Unknown"),
                "path": process_info.get("Path", "Unknown"),
                "threat_details": threat_details,
                "action": "process_suspended" if suspension_successful else "suspension_failed"
            }
            
            # Save quarantine info
            try:
                with open(os.path.join(self.quarantine_dir, f"{quarantine_id}.json"), "w") as f:
                    json.dump(quarantine_info, f, indent=2)
                    
                logging.warning(f"Process {pid} ({process_info.get('Name', 'Unknown')}) quarantined - ID: {quarantine_id}")
                return True
            except Exception as e:
                logging.error(f"Failed to save quarantine info: {str(e)}")
                return suspension_successful
            
        except Exception as e:
            logging.error(f"Error quarantining process {pid}: {str(e)}")
            return False
            
    def _suspend_process(self, process_handle):
        """Suspend a process using NtSuspendProcess from ntdll.dll"""
        try:
            ntdll = ctypes.windll.ntdll
            NtSuspendProcess = ntdll.NtSuspendProcess
            NtSuspendProcess(process_handle)
        except Exception as e:
            self.logger.error(f"Failed to suspend process: {str(e)}")
            raise
class OTXSubmitter:
    def __init__(self, api_key):
        self.base_url = "https://otx.alienvault.com/api/v1"
        self.headers = {
            'X-OTX-API-KEY': 'Insert API Key',
            'Accept': 'application/json',
            'Content-Type': 'application/json'
        }

    def submit_file(self, file_path, file_name=None):
        """Submit file to OTX for analysis"""
        url = f"{self.base_url}/indicators/submit_file"
        
        with open(file_path, 'rb') as f:
            files = {'file': (file_name or os.path.basename(file_path), f)}
            response = requests.post(url, headers=self.headers, files=files)
            return response.json() if response.status_code == 200 else None

    def submit_url(self, url):
        """Submit single URL to OTX"""
        submit_url = f"{self.base_url}/indicators/submit_url"
        data = {'url': url}
        response = requests.post(submit_url, headers=self.headers, json=data)
        return response.json() if response.status_code == 200 else None

    def submit_urls(self, urls):
        """Submit multiple URLs to OTX"""
        submit_url = f"{self.base_url}/indicators/submit_urls"
        data = {'urls': urls}
        response = requests.post(submit_url, headers=self.headers, json=data)
        return response.json() if response.status_code == 200 else None

    def create_pulse(self, name, description, indicators, public=True, tlp='white'):
        """Create a new OTX pulse with indicators"""
        url = f"{self.base_url}/pulses/create"
        
        pulse_data = {
            'name': name,
            'description': description,
            'public': public,
            'TLP': tlp,
            'indicators': indicators
        }
        
        response = requests.post(url, headers=self.headers, json=pulse_data)
        return response.json() if response.status_code == 200 else None

    def submit_all_detections(self, detections):
        """Process and submit all types of detections to OTX"""
        results = {
            'files': [],
            'urls': [],
            'pulse': None
        }
        
        # Collect URLs and files
        urls = []
        files = []
        
        for detection in detections:
            if detection.get('type') == 'url':
                urls.append(detection['value'])
            elif detection.get('type') == 'file':
                files.append(detection['path'])
        
        # Submit URLs in batch
        if urls:
            results['urls'] = self.submit_urls(urls)
        
        # Submit files individually
        for file_path in files:
            result = self.submit_file(file_path)
            if result:
                results['files'].append(result)
        
        # Create a pulse with all indicators
        if urls or files:
            indicators = []
            indicators.extend([{'type': 'URL', 'indicator': url} for url in urls])
            indicators.extend([{'type': 'file', 'indicator': file} for file in files])
            
            pulse_result = self.create_pulse(
                name=f"Automated Detection Submission {datetime.now().strftime('%Y-%m-%d %H:%M')}",
                description="Automated submission of detected threats",
                indicators=indicators
            )
            results['pulse'] = pulse_result
            
        return results
class ShellcodeDetector:
    def __init__(self):
        self.root = None
        self.shellcode_tome = {}  # Dictionary to store discovered shellcode
        self.scanner = MemoryScanner()
        # Common shellcode patterns/signatures
        self.shellcode_patterns = [
            # Common x86/x64 shellcode patterns
            rb'\x31\xc0[\x00-\xff]{0,10}\x50[\x00-\xff]{0,10}\x68',  # xor eax,eax + push eax + push DWORD
            rb'\x48\x31\xc0[\x00-\xff]{0,15}\x50',                   # x64 xor rax,rax + push
            rb'\x31\xd2[\x00-\xff]{0,10}\x31\xc0',                   # xor edx,edx + xor eax,eax
            rb'\x68.{4}\xc3',                                         # push + ret
            rb'\x68.{4}\xc3',                                         # push + ret 
            rb'\xe8.{4}',                                             # call instruction with offset
            rb'\xeb\x0e',                                             # jmp short
            rb'\x90{5,}',                                             # NOP sled
        ]
        self.Detector = ShellcodeDetector()
        self.Magic = MagicAnalyzer()
    def detect_shellcode_in_memory(self, memory_region, base_address=0, region_name="Unknown"):
        """
        Detect potential shellcode in a memory region
        
        Args:
            memory_region: Bytes object containing memory data
            base_address: The starting address of this memory region
            region_name: Identifier for the memory region
            
        Returns:
            List of dictionaries containing detected shellcode entries
        """
        detected_shellcodes = []
        
        # Skip if memory region is empty or None
        if not memory_region:
            return detected_shellcodes
            
        # Search for known shellcode patterns
        for pattern in self.shellcode_patterns:
            for match in re.finditer(pattern, memory_region):
                # Extract shellcode with context (expand to include surrounding bytes)
                start_pos = max(0, match.start() - 16)
                end_pos = min(len(memory_region), match.end() + 64)
                
                shellcode_fragment = memory_region[start_pos:end_pos]
                fragment_addr = base_address + start_pos
                
                # Create a unique ID
                shellcode_hash = hashlib.sha256(shellcode_fragment).hexdigest()[:16]
                
                # Create shellcode entry
                shellcode_entry = {
                    'id': shellcode_hash,
                    'data': shellcode_fragment,
                    'address': fragment_addr,
                    'size': len(shellcode_fragment),
                    'pattern_matched': binascii.hexlify(match.group(0)).decode('utf-8'),
                    'region_name': region_name,
                    'detection_time': datetime.now()
                }
                
                # Add to results
                detected_shellcodes.append(shellcode_entry)
                
                # Optionally store in the tome
                self._add_to_tome(shellcode_hash, shellcode_entry)
                
        return detected_shellcodes
    
    def get_shellcode(self, memory_region, base_address=0, region_name="Unknown"):
        """
        Get shellcode from a specific memory region
        
        Args:
            memory_region: The memory buffer to scan
            base_address: Starting address of the memory region
            region_name: Name or identifier for this region
            
        Returns:
            List of detected shellcode objects
        """
        return self.detect_shellcode_in_memory(memory_region, base_address, region_name)
    
    def list_all_shellcodes(self, memory_regions_dict):
        self.MagicAnalyzer = MagicAnalyzer()
        
        """Scans multiple memory regions and lists all detected shellcode using the existing analyzers and detection patterns. Args:memory_regions_dict: Dictionary mapping region names to (memory_data, base_address) tuples Returns:
            Dictionary of region names to lists of detected shellcode"""
        results = {}
        
        for region_name, (memory_data, base_address) in memory_regions_dict.items():
            # Initialize results for this region
            results[region_name] = []
            
            # Skip empty regions
            if not memory_data:
                continue
                
            # Check memory with the magic analyzer
            magic_analysis = self.MagicAnalyzer.analyze_memory(memory_data)
            if magic_analysis and "shellcode" in magic_analysis.lower():
                shellcode_entry = self.Detector._create_shellcode_entry(
                    memory_data, 
                    base_address, 
                    region_name, 
                    "magic_detection"
                )
                results[region_name].append(shellcode_entry)
                
            # Check for shellcode patterns with regex
            for pattern_name, pattern in self.shellcode_patterns.items():
                matches = self.Detector._find_pattern_matches(memory_data, pattern)
                for match_start, match_end in matches:
                    # Extract the shellcode with some context
                    extract_start = max(0, match_start - 16)
                    extract_end = min(len(memory_data), match_end + 64)
                    shellcode_fragment = memory_data[extract_start:extract_end]
                    
                    shellcode_entry = self.Detector._create_shellcode_entry(
                        shellcode_fragment,
                        base_address + extract_start,
                        region_name,
                        f"pattern_match:{pattern_name}"
                    )
                    results[region_name].append(shellcode_entry)
                    
            # Apply heuristic detection
            if len(memory_data) >= 10:
                # Check for NOP sleds
                nop_sled_results = self.Detector._detect_nop_sleds(memory_data, base_address)
                results[region_name].extend(nop_sled_results)
                
                # Check for API usage patterns common in shellcode
                api_pattern_results = self.Detector._detect_api_patterns(memory_data, base_address)
                results[region_name].extend(api_pattern_results)
                
                # Look for characteristic shellcode encoders/decoders
                decoder_results = self.Detector._detect_shellcode_decoders(memory_data, base_address)
                results[region_name].extend(decoder_results)
                
            # Check for executable memory indicators
            if self.Detector._is_likely_executable(memory_data):
                executable_regions = self.Detector._analyze_executable_content(
                    memory_data, 
                    base_address,
                    region_name
                )
                results[region_name].extend(executable_regions)
                
            # Apply your custom detection engine
            custom_detections = self.Detector.scan_for_shellcode(
                memory_data,
                base_address,
                region_name
            )
            results[region_name].extend(custom_detections)
            
            # Store all detected shellcode in the tome
            for shellcode_entry in results[region_name]:
                self.Detector._add_to_tome(shellcode_entry['id'], shellcode_entry)
                
        return results
class MagicAnalyzer:
    def __init__(self):
        self.signatures = self._load_signatures()
        # Try to use python-magic if available
        try:
            import magic
            self.magic_lib = magic.Magic()
            self.has_magic_lib = True
        except ImportError:
            self.has_magic_lib = False
            logging.debug("python-magic library not available, using built-in signatures only")
    def _load_signatures(self):
        """Load built-in signatures for memory content identification"""
        return [
            # Shellcode signatures
            {
                'name': 'x86 shellcode',
                'patterns': [
                    rb'\x31\xc0[\x00-\xff]{0,10}\x50[\x00-\xff]{0,10}\x68',  # xor eax,eax + push eax + push DWORD
                    rb'\x33\xc0[\x00-\xff]{0,10}\x50',                       # xor eax,eax + push eax
                    rb'\xeb[\x00-\xff]\xe8[\x00-\xff]{4}',                   # jmp short + call
                    rb'\xe8[\x00-\xff]{4}\x59',                              # call + pop ecx
                    rb'\x68.{4}\xc3',                                        # push + ret
                    rb'\x90{10,}',                                           # NOP sled
                ],
                'description': 'x86 shellcode patterns'
            },
            {
                'name': 'x64 shellcode',
                'patterns': [
                    rb'\x48\x31\xc0[\x00-\xff]{0,15}\x50',                  # x64 xor rax,rax + push
                    rb'\x48\x83\xec',                                       # sub rsp, X
                    rb'\x48\x8d',                                           # lea r64
                ],
                'description': 'x64 shellcode patterns'
            },
            # PE file signatures
            {
                'name': 'PE executable',
                'patterns': [
                    rb'MZ.{30,200}PE\x00\x00',                              # MZ/PE header
                ],
                'description': 'Windows PE executable'
            },
            # .NET assembly
            {
                'name': '.NET assembly',
                'patterns': [
                    rb'BSJB',                                               # .NET metadata signature
                    rb'\x42\x53\x4A\x42',                                   # BSJB in hex
                ],
                'description': '.NET managed code assembly'
            },
            # Script signatures
            {
                'name': 'script',
                'patterns': [
                    rb'<script',                                            # JavaScript in HTML
                    rb'function\s*\(',                                      # JavaScript function
                    rb'import\s+[a-zA-Z_]',                                 # Python import
                    rb'#!/usr/bin/(env\s+)?python',                         # Python shebang
                ],
                'description': 'Script code (JavaScript, Python, etc.)'
            },
            # Encrypted/compressed data signatures
            {
                'name': 'encrypted data',
                'patterns': [],  # No specific pattern, will use entropy analysis
                'description': 'Possibly encrypted or compressed data'
            }
        ]
    
    def analyze_memory(self, memory_data):
        """
        Analyze memory data to determine its content type
        
        Args:
            memory_data: Bytes object containing memory to analyze
            
        Returns:
            String description of the content type, or None if unknown
        """
        if not memory_data or len(memory_data) < 4:
            return None
            
        # First try python-magic if available
        if self.has_magic_lib:
            try:
                magic_result = self.magic_lib.from_buffer(memory_data)
                # If magic identifies as executable, it might be shellcode
                if 'executable' in magic_result.lower() and 'PE' not in magic_result:
                    return "Possible shellcode (executable content)"
                return magic_result
            except Exception:
                pass  # Fall back to our signatures
        
        # Check against our built-in signatures
        for sig in self.signatures:
            for pattern in sig['patterns']:
                if re.search(pattern, memory_data):
                    return f"{sig['name']} ({sig['description']})"
        
        # Check for high entropy (possible encryption or compression)
        entropy = self._calculate_entropy(memory_data)
        if entropy > 7.0:
            return "Possibly encrypted or compressed data (high entropy)"
            
        # Check for executable characteristics
        if self._has_executable_characteristics(memory_data):
            return "Probable shellcode (executable characteristics)"
            
        return None
    
    def _calculate_entropy(self, data):
        """Calculate Shannon entropy of data"""
        if not data:
            return 0
            
        import math
        from collections import Counter
            
        entropy = 0
        data_len = len(data)
        counter = Counter(data)
            
        for count in counter.values():
            p_x = count / data_len
            entropy += -p_x * math.log2(p_x)
                
        return entropy
    
    def _has_executable_characteristics(self, data):
        """
        Check if the data has characteristics of executable code
        This is a heuristic approach to detect code even without specific signatures
        """
        if len(data) < 20:
            return False
            
        # Count instruction prefixes common in x86/x64 code
        instruction_prefixes = [
            b'\x8B', b'\x89', b'\x8D',  # MOV variations
            b'\xFF', b'\xE8', b'\xE9',  # CALL/JMP variations
            b'\x83', b'\x81',           # ADD/SUB/CMP with immediate
            b'\x55', b'\x56', b'\x57',  # PUSH reg
            b'\x5D', b'\x5E', b'\x5F',  # POP reg
            b'\x68',                     # PUSH immediate
            b'\xC3', b'\xC2',           # RET variations
            b'\x74', b'\x75', b'\x7C',  # Jcc (conditional jumps)
            b'\xB8', b'\xB9',           # MOV reg, imm32
            b'\x48'                      # REX prefix (64-bit)
        ]
        
        # Count occurrences of instruction prefixes
        prefix_count = sum(data.count(prefix) for prefix in instruction_prefixes)
        
        # Check if the density of instruction prefixes is reasonable for code
        # Typical code has around 1 prefix per 3-5 bytes
        prefix_density = prefix_count / len(data)
        
        # Calculate entropy - code typically has entropy between 5.5 and 7.0
        entropy = self._calculate_entropy(data)
        
        # Executable code should have both reasonable prefix density and entropy
        return (prefix_density > 0.1) and (5.5 <= entropy <= 7.0)
class ShellcodeDetector:
    def __init__(self):
        self.shellcode_tome = {}  # Dictionary to store discovered shellcode
        self.scanner = MemoryScanner()
        # Initialize the magic analyzer
        self.magic_analyzer = MagicAnalyzer()
        self.disassembler = CodeDisassembler()
        self.ShellCode_Capture = ShellcodeCapture()
        self.tome = ShellCodeTome()
        # Set detector reference to avoid circular dependency
        self.tome.set_shellcode_detector(self)
        # Common shellcode patterns/signatures
        self.shellcode_patterns = [
            # Common x86/x64 shellcode patterns
            rb'\x31\xc0[\x00-\xff]{0,10}\x50[\x00-\xff]{0,10}\x68',  # xor eax,eax + push eax + push DWORD
            rb'\x48\x31\xc0[\x00-\xff]{0,15}\x50',                   # x64 xor rax,rax + push
            rb'\x31\xd2[\x00-\xff]{0,10}\x31\xc0',                   # xor edx,edx + xor eax,eax
            rb'\x68.{4}\xc3',                                         # push + ret
            rb'\x68.{4}\xc3',                                         # push + ret 
            rb'\xe8.{4}',                                             # call instruction with offset
            rb'\xeb\x0e',                                             # jmp short
            rb'\x90{5,}',                                             # NOP sled
        ]
        
    def _create_shellcode_entry(self, data, address, region_name, detection_method):
        """Create a standardized shellcode entry"""
        import hashlib
        import binascii
        from datetime import datetime
        
        shellcode_hash = hashlib.sha256(data).hexdigest()[:16]
        
        return {
            'id': shellcode_hash,
            'data': data,
            'address': address,
            'size': len(data),
            'region_name': region_name,
            'detection_method': detection_method,
            'hex': binascii.hexlify(data[:64]).decode('utf-8'),
            'detection_time': datetime.now(),
            'disassembly': self._try_disassemble(data, address) if self.disassembler else None
        }

    def _find_pattern_matches(self, data, pattern):
        """Find all instances of pattern in data"""
        import re
        return [(m.start(), m.end()) for m in re.finditer(pattern, data)]

    def _detect_nop_sleds(self, data, base_address):
        """Detect NOP sleds in memory"""
        results = []
        # Classic x86 NOP sled
        nop_matches = self._find_pattern_matches(data, b'\x90{10,}')
        
        for start, end in nop_matches:
            shellcode_entry = self._create_shellcode_entry(
                data[start:end], 
                base_address + start,
                "memory_scan", 
                "nop_sled_detection"
            )
            results.append(shellcode_entry)
            
        # Multi-byte NOP instructions used for sleds
        multi_nop_patterns = [
            b'\x66\x90{5,}',  # 2-byte NOP
            b'(\x0f\x1f\x00){3,}',  # 3-byte NOP
            b'(\x0f\x1f\x40\x00){3,}'  # 4-byte NOP
        ]
        
        for pattern in multi_nop_patterns:
            matches = self._find_pattern_matches(data, pattern)
            for start, end in matches:
                entry = self._create_shellcode_entry(
                    data[start:end],
                    base_address + start,
                    "memory_scan",
                    "multi_byte_nop_detection"
                )
                results.append(entry)
                
        return results

    def _detect_api_patterns(self, data, base_address):
        """Detect API usage patterns common in shellcode"""
        results = []
        # Common shellcode API resolution patterns
        api_patterns = [
            (b'\x68.{4}\xB8.{4}\xFF\xD0', "call_via_eax"),
            (b'\xE8.{4}\x59', "call_pop_pattern"),
            (b'\x31\xc0[\x00-\xff]{0,10}\x50[\x00-\xff]{0,10}\x68', "xor_push_pattern"),
            # ... other API patterns from your existing code
        ]
        
        for pattern, name in api_patterns:
            matches = self._find_pattern_matches(data, pattern)
            for start, end in matches:
                context_start = max(0, start - 32)
                context_end = min(len(data), end + 64)
                
                entry = self._create_shellcode_entry(
                    data[context_start:context_end],
                    base_address + context_start,
                    "memory_scan",
                    f"api_pattern:{name}"
                )
                results.append(entry)
                
        return results

    def _detect_shellcode_decoders(self, data, base_address):
        """Detect shellcode decoder stubs"""
        results = []
        # Common decoder patterns
        decoder_patterns = [
            (b'\xEB\x0E.{14}\xE8.{4}', "jmp_call_pop_decoder"),
            (b'\x31\xC9[\x00-\xff]{0,6}\xB1.{1}[\x00-\xff]{0,6}\x80.{2}', "xor_decoder"),
            # ... other decoder patterns from your existing code
        ]
        
        for pattern, name in decoder_patterns:
            matches = self._find_pattern_matches(data, pattern)
            for start, end in matches:
                context_start = max(0, start - 16)
                context_end = min(len(data), end + 128)  # Include more bytes to capture decoded shellcode
                
                entry = self._create_shellcode_entry(
                    data[context_start:context_end],
                    base_address + context_start,
                    "memory_scan",
                    f"decoder:{name}"
                )
                results.append(entry)
                
        return results

    def _is_likely_executable(self, data):
        """Check if memory region is likely executable code"""
        # Simple heuristic: check for common instruction prefixes
        # and reasonable entropy
        if len(data) < 20:
            return False
            
        # Count instruction prefixes
        instruction_prefixes = [b'\x8B', b'\x89', b'\x8D', b'\xFF', b'\xE8', b'\xE9', b'\xEB']
        prefix_count = sum(data.count(prefix) for prefix in instruction_prefixes)
        
        # Calculate simple entropy
        import math
        from collections import Counter
        
        entropy = 0
        counter = Counter(data)
        for count in counter.values():
            p = count / len(data)
            entropy += -p * math.log2(p)
        
        # Executable code typically has entropy between 5.5 and 7.2
        return (prefix_count > len(data) / 30) and (5.5 <= entropy <= 7.2)

    def _analyze_executable_content(self, data, base_address, region_name):
        """Analyze regions that appear to be executable"""
        results = []
        
        # Look for function prologues
        prologue_patterns = [
            (b'\x55\x8B\xEC', "x86_function_prologue"),
            (b'\x55\x48\x89\xE5', "x64_function_prologue")
        ]
        
        for pattern, name in prologue_patterns:
            matches = self._find_pattern_matches(data, pattern)
            for start, end in matches:
                # Extract a reasonable function size (up to 512 bytes)
                end = min(len(data), start + 512)
                
                entry = self._create_shellcode_entry(
                    data[start:end],
                    base_address + start,
                    region_name,
                    f"executable:{name}"
                )
                results.append(entry)
        
        # If we have a disassembler, do more in-depth analysis
        if hasattr(self, 'disassembler') and self.disassembler:
            # Attempt to find code entry points
            entry_points = self.disassembler.find_entry_points(data, base_address)
            for addr, size in entry_points:
                offset = addr - base_address
                if 0 <= offset < len(data):
                    entry = self._create_shellcode_entry(
                        data[offset:offset+size],
                        addr,
                        region_name,
                        "disasm_entry_point"
                    )
                    results.append(entry)
                    
        return results

    def _try_disassemble(self, data, address):
        """Try to disassemble the given data"""
        if not hasattr(self, 'disassembler') or not self.disassembler:
            return "Disassembler not available"
            
        try:
            return self.disassembler.disassemble(data, address)
        except Exception as e:
            return f"Disassembly failed: {str(e)}"
    
    def _add_to_tome(self, shellcode_id, shellcode_entry):
        """Internal method to add detected shellcode to the tome"""
        if shellcode_id not in self.shellcode_tome:
            self.shellcode_tome[shellcode_id] = {
                'data': shellcode_entry['data'],
                'size': shellcode_entry['size'],
                'hex': binascii.hexlify(shellcode_entry['data']).decode('utf-8'),
                'first_seen': datetime.now(),
                'seen_count': 1,
                'locations': [{
                    'address': shellcode_entry['address'],
                    'region_name': shellcode_entry['region_name']
                }]
            }
        else:
            # Update existing entry
            self.shellcode_tome[shellcode_id]['seen_count'] += 1
            location = {
                'address': shellcode_entry['address'],
                'region_name': shellcode_entry['region_name']
            }
            if location not in self.shellcode_tome[shellcode_id]['locations']:
                self.shellcode_tome[shellcode_id]['locations'].append(location)   
    def analyze_shellcode_characteristics(self, shellcode_id):
        """
        Perform deeper analysis on a specific shellcode
        
        Args:
            shellcode_id: ID of the shellcode to analyze
            
        Returns:
            Dictionary of analysis results
        """
        shellcode = self.shellcode_tome.get(shellcode_id)
        if not shellcode:
            return {"error": "Shellcode not found"}
            
        results = {
            "id": shellcode_id,
            "size": shellcode['size'],
            "obfuscation_likelihood": self._detect_obfuscation(shellcode['data']),
            "api_calls": self._extract_potential_api_calls(shellcode['data']),
            "execution_characteristics": self._analyze_execution_flow(shellcode['data']),
            "similarity": self._find_similar_shellcodes(shellcode_id)
        }
        
        return results
    def _detect_obfuscation(self, shellcode_data, address=0):
        import re
        from collections import Counter
        from math import log2
        
        results = {
            'techniques': [],
            'confidence': 0,
            'details': {}
        }
        
        if not shellcode_data or len(shellcode_data) < 10:
            return results
            
        # Check entropy (high entropy suggests encryption or packing)
        entropy = 0
        counter = Counter(shellcode_data)
        for count in counter.values():
            p_x = count / len(shellcode_data)
            entropy += -p_x * log2(p_x)
            
        results['details']['entropy'] = entropy
        
        if entropy > 7.2:
            results['techniques'].append('encrypted')
            results['confidence'] += 0.8
        elif entropy > 6.8:
            results['techniques'].append('possibly_packed')
            results['confidence'] += 0.5
            
        # Look for XOR patterns (common in encoders)
        xor_patterns = [
            # XOR reg, reg followed by a loop
            rb'\x33[\xC0-\xFF][\x00-\xFF]{0,10}\xE2',  # xor reg, reg + loop
            rb'\x31[\xC0-\xFF][\x00-\xFF]{0,10}\xE2',  # xor reg, reg + loop
            
            # XOR byte ptr patterns
            rb'\x80\x34[\x00-\xFF]{1,4}[\x00-\xFF]',   # xor byte ptr [...], imm8
            rb'\x81\x34[\x00-\xFF]{1,4}[\x00-\xFF]{4}', # xor dword ptr [...], imm32
            
            # XOR with counter
            rb'\x30[\xC0-\xFF][\x00-\xFF]{0,4}\xFE',   # xor reg8, reg8 + inc/dec
            rb'\x31[\xC0-\xFF][\x00-\xFF]{0,4}\xFF'    # xor reg32, reg32 + inc/dec
        ]
        
        for pattern in xor_patterns:
            matches = re.finditer(pattern, shellcode_data)
            xor_count = sum(1 for _ in matches)
            if xor_count > 0:
                results['techniques'].append('xor_encoding')
                results['details']['xor_patterns'] = xor_count
                results['confidence'] += min(0.3 + (0.1 * xor_count), 0.7)
                break
        
        # Check for ADD/SUB encoding
        add_sub_patterns = [
            rb'\x80\xC0[\x00-\xFF][\x00-\xFF]{0,10}\xE2',  # add al, imm8 + loop
            rb'\x80\xE8[\x00-\xFF][\x00-\xFF]{0,10}\xE2',  # sub al, imm8 + loop
            rb'\x04[\x00-\xFF][\x00-\xFF]{0,10}\xE2',      # add al, imm8 + loop
            rb'\x2C[\x00-\xFF][\x00-\xFF]{0,10}\xE2'       # sub al, imm8 + loop
        ]
        
        for pattern in add_sub_patterns:
            matches = re.finditer(pattern, shellcode_data)
            addsub_count = sum(1 for _ in matches)
            if addsub_count > 0:
                results['techniques'].append('add_sub_encoding')
                results['details']['addsub_patterns'] = addsub_count
                results['confidence'] += min(0.2 + (0.1 * addsub_count), 0.6)
                break
        
        # Check for ROL/ROR encoding
        rotation_patterns = [
            rb'\xC0[\xC0-\xCF][\x00-\xFF][\x00-\xFF]{0,10}\xE2',  # rol/ror reg8, imm8 + loop
            rb'\xC1[\xC0-\xCF][\x00-\xFF][\x00-\xFF]{0,10}\xE2',  # rol/ror reg32, imm8 + loop
            rb'\xD0[\xC0-\xCF][\x00-\xFF]{0,10}\xE2',             # rol/ror reg8, 1 + loop
            rb'\xD1[\xC0-\xCF][\x00-\xFF]{0,10}\xE2'              # rol/ror reg32, 1 + loop
        ]
        
        for pattern in rotation_patterns:
            matches = re.finditer(pattern, shellcode_data)
            rot_count = sum(1 for _ in matches)
            if rot_count > 0:
                results['techniques'].append('rotation_encoding')
                results['details']['rotation_patterns'] = rot_count
                results['confidence'] += min(0.3 + (0.1 * rot_count), 0.7)
                break
        
        # Check for self-modifying code
        self_mod_patterns = [
            rb'\x89[\x00-\xFF]\x24[\x00-\xFF]',     # mov [esp+...], reg
            rb'\xC7[\x00-\xFF]{1,4}[\x00-\xFF]{4}',  # mov dword ptr [...], imm32
            rb'\x88[\x00-\xFF]\x24[\x00-\xFF]'      # mov byte ptr [esp+...], reg
        ]
        
        for pattern in self_mod_patterns:
            matches = re.finditer(pattern, shellcode_data)
            selfmod_count = sum(1 for _ in matches)
            if selfmod_count > 3:  # Need multiple instances to confirm
                results['techniques'].append('self_modifying')
                results['details']['selfmod_patterns'] = selfmod_count
                results['confidence'] += min(0.2 + (0.05 * selfmod_count), 0.7)
        
        # Look for push+ret JMP (common in obfuscation)
        push_ret_pattern = rb'\x68[\x00-\xFF]{4}\xC3'  # push addr + ret
        push_ret_count = len(re.findall(push_ret_pattern, shellcode_data))
        if push_ret_count > 0:
            results['techniques'].append('push_ret_jumps')
            results['details']['push_ret_count'] = push_ret_count
            results['confidence'] += min(0.1 * push_ret_count, 0.5)
        
        # If we have a disassembler, do more advanced checks
        if hasattr(self, 'disassembler') and self.disassembler:
            try:
                disasm = self.disassembler.disassemble(shellcode_data, address)
                
                # Look for instruction reordering/obfuscation (jmps between close addresses)
                if 'jmp short' in disasm and disasm.count('jmp short') > 3:
                    results['techniques'].append('instruction_reordering')
                    results['confidence'] += 0.5
                
                # Look for API hashing
                if self.disassembler._has_api_hashing(shellcode_data):
                    results['techniques'].append('api_hashing')
                    results['confidence'] += 0.7
            except Exception:
                pass
        
        # Normalize confidence between 0-1
        results['confidence'] = min(results['confidence'], 1.0)
        
        return results

    def _extract_potential_api_calls(self, shellcode_data, address=0):
        """
        Extract potential Windows API calls from shellcode
        
        Args:
            shellcode_data: The binary shellcode data
            address: Base address for disassembly reference
            
        Returns:
            List of dictionaries containing potential API call information
        """
        import re
        
        api_calls = []
        
        if not shellcode_data or len(shellcode_data) < 10:
            return api_calls
        
        # Common API call patterns
        direct_call_patterns = [
            # CALL dword ptr [...]
            (rb'\xFF\x15[\x00-\xFF]{4}', 'call_indirect'),
            
            # CALL register
            (rb'\xFF[\xD0-\xD7]', 'call_register'),
            
            # CALL immediate
            (rb'\xE8[\x00-\xFF]{4}', 'call_immediate')
        ]
        
        # Check for direct API calls
        for pattern, call_type in direct_call_patterns:
            for match in re.finditer(pattern, shellcode_data):
                offset = match.start()
                
                # Get the bytes of the call instruction
                call_bytes = shellcode_data[offset:offset+6 if call_type == 'call_indirect' else offset+5]
                
                # For CALL dword ptr [...], extract the pointer address
                target_addr = None
                if call_type == 'call_indirect' and len(call_bytes) >= 6:
                    # Extract the address from call instruction (little endian)
                    ptr_bytes = call_bytes[2:6]
                    target_addr = int.from_bytes(ptr_bytes, byteorder='little')
                
                # For CALL immediate, calculate target
                elif call_type == 'call_immediate' and len(call_bytes) >= 5:
                    rel_offset = int.from_bytes(call_bytes[1:5], byteorder='little')
                    # Target is: current position + instruction size + relative offset
                    target_addr = address + offset + 5 + rel_offset
                
                # Create API call entry
                api_call = {
                    'offset': offset,
                    'address': address + offset,
                    'type': call_type,
                    'bytes': call_bytes.hex(),
                    'target_addr': target_addr
                }
                
                # Look for potential API name pushes before the call
                pre_call_region = max(0, offset - 50)
                pre_call_bytes = shellcode_data[pre_call_region:offset]
                
                # Look for common patterns before API calls
                
                # PUSH immediate strings (often function name/hash)
                push_imm_matches = list(re.finditer(rb'\x68[\x00-\xFF]{4}', pre_call_bytes))
                if push_imm_matches:
                    last_push = push_imm_matches[-1]
                    push_value = pre_call_bytes[last_push.start()+1:last_push.start()+5]
                    api_call['potential_param'] = push_value.hex()
                
                # Check for common API setup patterns (LoadLibraryA, GetProcAddress)
                if b'LoadLibrary' in pre_call_bytes or b'GetProcAddress' in pre_call_bytes:
                    api_call['api_resolution'] = True
                
                api_calls.append(api_call)
        
        # Look for API hashing patterns
        api_hash_patterns = [
            # Common GetProcAddress hash calculation
            (rb'\x33\xC0\xAC\xC1[\x00-\xFF]{2}[\x00-\xFF]{0,10}\x03[\xC0-\xFF]', 'api_hashing'),
            (rb'\x31\xC0\xAC\xC1[\x00-\xFF]{2}[\x00-\xFF]{0,10}\x03[\xC0-\xFF]', 'api_hashing'),
        ]
        
        for pattern, hash_type in api_hash_patterns:
            for match in re.finditer(pattern, shellcode_data):
                offset = match.start()
                hash_bytes = shellcode_data[offset:offset+20]  # Capture enough of the hashing routine
                
                api_calls.append({
                    'offset': offset,
                    'address': address + offset,
                    'type': hash_type,
                    'bytes': hash_bytes.hex(),
                    'target_addr': None,
                    'is_hash_routine': True
                })
        
        # Use disassembler for more accurate analysis if available
        if hasattr(self, 'disassembler') and self.disassembler:
            try:
                # Find more sophisticated API calls through disassembly
                disasm_api_calls = self.disassembler._identify_api_calls(shellcode_data, address)
                
                # Merge with existing findings, avoiding duplicates
                existing_offsets = {call['offset'] for call in api_calls}
                for api_call in disasm_api_calls:
                    if api_call['offset'] not in existing_offsets:
                        api_calls.append(api_call)
                        existing_offsets.add(api_call['offset'])
            except Exception:
                pass
        
        return api_calls
    def _analyze_execution_flow(self, shellcode_data, address=0):
        import re
        
        results = {
            'entry_point': address,
            'branches': [],
            'loops': [],
            'calls': [],
            'complexity': 0,
            'linearized_flow': [],
            'suspicious_patterns': []
        }
        
        if not shellcode_data or len(shellcode_data) < 10:
            return results
        
        # Simple pattern-based analysis for branches and jumps
        jmp_patterns = [
            (rb'\xEB[\x00-\xFF]', 'jmp_short'),           # JMP short (relative)
            (rb'\xE9[\x00-\xFF]{4}', 'jmp_near'),         # JMP near (relative)
            (rb'\xFF[\xE0-\xE7]', 'jmp_register'),        # JMP register
            (rb'\xFF\x25[\x00-\xFF]{4}', 'jmp_indirect')  # JMP dword ptr [...]
        ]
        
        conditional_jmp_patterns = [
            (rb'\x0F[\x80-\x8F][\x00-\xFF]{4}', 'jcc_near'),  # Jcc near (relative)
            (rb'\x70[\x00-\xFF]', 'jo_short'),               # JO short
            (rb'\x71[\x00-\xFF]', 'jno_short'),              # JNO short
            (rb'\x72[\x00-\xFF]', 'jb_short'),               # JB/JNAE/JC short
            (rb'\x73[\x00-\xFF]', 'jnb_short'),              # JNB/JAE/JNC short
            (rb'\x74[\x00-\xFF]', 'je_short'),               # JE/JZ short
            (rb'\x75[\x00-\xFF]', 'jne_short'),              # JNE/JNZ short
            (rb'\x76[\x00-\xFF]', 'jbe_short'),              # JBE/JNA short
            (rb'\x77[\x00-\xFF]', 'jnbe_short'),             # JNBE/JA short
            (rb'\x78[\x00-\xFF]', 'js_short'),               # JS short
            (rb'\x79[\x00-\xFF]', 'jns_short'),              # JNS short
            (rb'\x7A[\x00-\xFF]', 'jp_short'),               # JP/JPE short
            (rb'\x7B[\x00-\xFF]', 'jnp_short'),              # JNP/JPO short
            (rb'\x7C[\x00-\xFF]', 'jl_short'),               # JL/JNGE short
            (rb'\x7D[\x00-\xFF]', 'jnl_short'),              # JNL/JGE short
            (rb'\x7E[\x00-\xFF]', 'jle_short'),              # JLE/JNG short
            (rb'\x7F[\x00-\xFF]', 'jnle_short')              # JNLE/JG short
        ]
        
        call_patterns = [
            (rb'\xE8[\x00-\xFF]{4}', 'call_near'),         # CALL near (relative)
            (rb'\xFF[\xD0-\xD7]', 'call_register'),        # CALL register
            (rb'\xFF\x15[\x00-\xFF]{4}', 'call_indirect')  # CALL dword ptr [...]
        ]
        
        loop_patterns = [
            (rb'\xE0[\x00-\xFF]', 'loopne'),              # LOOPNE/LOOPNZ
            (rb'\xE1[\x00-\xFF]', 'loope'),               # LOOPE/LOOPZ
            (rb'\xE2[\x00-\xFF]', 'loop'),                # LOOP
            (rb'\xE3[\x00-\xFF]', 'jcxz')                 # JECXZ/JCXZ
        ]
        
        # Find all jumps and branches
        for pattern, jump_type in jmp_patterns + conditional_jmp_patterns:
            for match in re.finditer(pattern, shellcode_data):
                offset = match.start()
                instruction_bytes = shellcode_data[offset:offset + len(pattern) - 2 + (4 if 'near' in jump_type or 'indirect' in jump_type else 1)]
                
                # Calculate target address
                target = None
                if jump_type in ('jmp_short', 'jo_short', 'jno_short', 'jb_short', 'jnb_short', 
                                'je_short', 'jne_short', 'jbe_short', 'jnbe_short', 'js_short', 
                                'jns_short', 'jp_short', 'jnp_short', 'jl_short', 'jnl_short', 
                                'jle_short', 'jnle_short'):
                    # Short jump: 1 byte offset (signed)
                    displacement = instruction_bytes[-1]
                    if displacement > 127:  # Convert to signed
                        displacement -= 256
                    target = address + offset + len(instruction_bytes) + displacement
                
                elif jump_type in ('jmp_near', 'jcc_near', 'call_near'):
                    # Near jump: 4 byte offset (signed)
                    displacement = int.from_bytes(instruction_bytes[-4:], byteorder='little', signed=True)
                    target = address + offset + len(instruction_bytes) + displacement
                
                elif jump_type in ('jmp_indirect', 'call_indirect'):
                    # Indirect jump through memory
                    ptr_address = int.from_bytes(instruction_bytes[-4:], byteorder='little')
                    target = ptr_address  # This is the address of the pointer, not the actual target
                
                # Add to appropriate list
                branch_info = {
                    'type': jump_type,
                    'offset': offset,
                    'address': address + offset,
                    'instruction_bytes': instruction_bytes.hex(),
                    'target': target
                }
                
                if 'call' in jump_type:
                    results['calls'].append(branch_info)
                elif any(x in jump_type for x in ('jo', 'jno', 'jb', 'jnb', 'je', 'jne', 'jbe', 'jnbe', 
                                                'js', 'jns', 'jp', 'jnp', 'jl', 'jnl', 'jle', 'jnle', 'jcc')):
                    results['branches'].append(branch_info)
                    results['complexity'] += 1
                else:
                    # Unconditional jumps
                    results['linearized_flow'].append(branch_info)
        
        # Find all loops
        for pattern, loop_type in loop_patterns:
            for match in re.finditer(pattern, shellcode_data):
                offset = match.start()
                instruction_bytes = shellcode_data[offset:offset + 2]
                
                # Calculate target (loops use short jumps: 1 byte signed offset)
                displacement = instruction_bytes[1]
                if displacement > 127:  # Convert to signed
                    displacement -= 256
                target = address + offset + 2 + displacement
                
                loop_info = {
                    'type': loop_type,
                    'offset': offset,
                    'address': address + offset,
                    'instruction_bytes': instruction_bytes.hex(),
                    'target': target
                }
                
                results['loops'].append(loop_info)
                results['complexity'] += 2  # Loops add more complexity
        
        # Look for suspicious patterns
        
        # Self-modifying code indicators
        self_mod_patterns = [
            rb'\x89[\x00-\xFF]\x24[\x00-\xFF]',     # mov [esp+...], reg
            rb'\xC7[\x00-\xFF]{1,4}[\x00-\xFF]{4}',  # mov dword ptr [...], imm32
            rb'\x88[\x00-\xFF]\x24[\x00-\xFF]'      # mov byte ptr [esp+...], reg
        ]
        
        for pattern in self_mod_patterns:
            for match in re.finditer(pattern, shellcode_data):
                offset = match.start()
                
                # Check if this instruction appears to be modifying code in the same region
                target_region = False
                if len(shellcode_data) > offset + 6:
                    # This is a simplistic check - more sophisticated analysis would need disassembly
                    mod_address = address + offset
                    
                    # If there are jumps/branches to an address after this instruction,
                    # it might be modifying executable code
                    for branch in results['branches'] + results['linearized_flow']:
                        if branch['target'] and mod_address <= branch['target'] < mod_address + 100:
                            target_region = True
                            break
                
                if target_region:
                    results['suspicious_patterns'].append({
                        'type': 'self_modifying_code',
                        'offset': offset,
                        'address': address + offset,
                        'instruction_bytes': shellcode_data[offset:offset+6].hex()
                    })
                    results['complexity'] += 3  # Self-modifying code is complex
        for call_pattern, call_type in call_patterns:
            for match in re.finditer(call_pattern, shellcode_data):
                offset = match.start()
                instruction_bytes = shellcode_data[offset:offset + len(call_pattern) - 2 + (4 if 'near' in call_type or 'indirect' in call_type else 1)]
                
                # Calculate target address
                target = None
                if call_type in ('call_near', 'call_indirect'):
                    # Near call: 4 byte offset (signed)
                    displacement = int.from_bytes(instruction_bytes[-4:], byteorder='little', signed=True)
                    target = address + offset + len(instruction_bytes) + displacement
                
                # Add to appropriate list
                branch_info = {
                    'type': call_type,
                    'offset': offset,
                    'address': address + offset,
                    'instruction_bytes': instruction_bytes.hex(),
                    'target': target
                }
                
                results['calls'].append(branch_info)
                results['complexity'] += 0.5  # Calls add some complexity
        # Use disassembler for more accurate analysis if available
        if hasattr(self, 'disassembler') and self.disassembler:
            try:
                # Enhanced flow analysis using disassembler
                disasm_flow = self.disassembler._analyze_flow(shellcode_data, address)
                
                # Merge with pattern-based results
                if disasm_flow:
                    # Keep specialized patterns that might be missed in disassembly
                    for key in ['suspicious_patterns', 'complexity']:
                        if key in disasm_flow:
                            results[key] = disasm_flow[key]
                    
                    # Update control flow information
                    for key in ['branches', 'loops', 'calls', 'linearized_flow']:
                        if key in disasm_flow and disasm_flow[key]:
                            # Add entries without duplicating
                            existing_addresses = {entry['address'] for entry in results[key]}
                            results[key].extend([
                                entry for entry in disasm_flow[key] 
                                if entry['address'] not in existing_addresses
                            ])
            except Exception:
                pass
        
        # Estimate overall complexity based on number and types of control flow structures
        # More branches, loops, and calls indicate higher complexity
        results['complexity'] += len(results['branches']) * 1
        results['complexity'] += len(results['loops']) * 2
        results['complexity'] += len(results['calls']) * 0.5
        
        # Normalize complexity to a 0-10 scale
        results['complexity'] = min(10, results['complexity'])
        
        return results
    def _find_similar_shellcodes(self, shellcode_data, threshold=0.7):
        
        from difflib import SequenceMatcher
        import hashlib
        
        similar_shellcodes = []
        
        if not shellcode_data or len(shellcode_data) < 10 or not self.shellcode_tome:
            return similar_shellcodes
        
        # Calculate various hashes for quick filtering
        shellcode_hash = hashlib.sha256(shellcode_data).hexdigest()
        shellcode_md5 = hashlib.md5(shellcode_data).hexdigest()
        
        # Function to calculate fuzzy hash (ssdeep-like but simpler)
        def simple_fuzzy_hash(data, block_size=64):
            if len(data) < block_size:
                return hashlib.md5(data).hexdigest()[:16]
            
            chunks = [data[i:i+block_size] for i in range(0, len(data), block_size)]
            return hashlib.md5(b''.join([hashlib.md5(chunk).digest() for chunk in chunks])).hexdigest()
        
        fuzzy_hash = simple_fuzzy_hash(shellcode_data)
        
        # Function to calculate N-gram similarity
        def calculate_ngram_similarity(data1, data2, n=3):
            if len(data1) < n or len(data2) < n:
                return 0.0
                
            # Generate n-grams for both sequences
            def get_ngrams(data, n):
                return [data[i:i+n] for i in range(len(data)-n+1)]
            
            ngrams1 = set(get_ngrams(data1, n))
            ngrams2 = set(get_ngrams(data2, n))
            
            # Calculate Jaccard similarity
            if not ngrams1 or not ngrams2:
                return 0.0
                
            intersection = len(ngrams1.intersection(ngrams2))
            union = len(ngrams1.union(ngrams2))
            
            return intersection / union if union > 0 else 0.0
        
        # Function to calculate instruction similarity (if disassembler available)
        def calculate_instruction_similarity(data1, data2):
            if not hasattr(self, 'disassembler') or not self.disassembler:
                return None
                
            try:
                # Extract instructions without specific addresses/offsets
                instrs1 = self._extract_instructions(data1)
                instrs2 = self._extract_instructions(data2)
                
                if not instrs1 or not instrs2:
                    return None
                    
                # Compare instruction sequences
                matcher = SequenceMatcher(None, instrs1, instrs2)
                return matcher.ratio()
            except Exception:
                return None
        
        # Iterate through shellcode tome to find matches
        for sc_id, sc_entry in self.shellcode_tome.items():
            # Skip comparing with self
            if sc_id == shellcode_hash[:16]:
                continue
                
            # Get comparison shellcode
            tome_shellcode = sc_entry.get('data')
            if not tome_shellcode or not isinstance(tome_shellcode, bytes):
                # Try to convert hex string to bytes if necessary
                tome_hex = sc_entry.get('hex')
                if tome_hex:
                    try:
                        import binascii
                        tome_shellcode = binascii.unhexlify(tome_hex)
                    except Exception:
                        continue
                else:
                    continue
            
            # Quick size comparison first
            size_similarity = min(len(shellcode_data), len(tome_shellcode)) / max(len(shellcode_data), len(tome_shellcode))
            if size_similarity < threshold * 0.5:
                continue  # Size too different, skip detailed comparison
            
            # Calculate similarity using multiple metrics
            similarity_scores = {
                'size': size_similarity
            }
            
            # Byte-level sequence similarity
            if abs(len(shellcode_data) - len(tome_shellcode)) < 1024:  # Don't compare very different sizes
                # For large shellcodes, compare only parts to save time
                if len(shellcode_data) > 2048:
                    # Sample beginning, middle, and end
                    parts1 = [shellcode_data[:512], shellcode_data[len(shellcode_data)//2-256:len(shellcode_data)//2+256], shellcode_data[-512:]]
                    parts2 = [tome_shellcode[:512], tome_shellcode[len(tome_shellcode)//2-256:len(tome_shellcode)//2+256], tome_shellcode[-512:]]
                    
                    byte_similarity = 0
                    for i in range(3):
                        byte_similarity += SequenceMatcher(None, parts1[i], parts2[i]).ratio() / 3
                else:
                    # Compare entire sequences
                    byte_similarity = SequenceMatcher(None, shellcode_data, tome_shellcode).ratio()
                    
                similarity_scores['byte'] = byte_similarity
            
            # N-gram similarity (captures structural patterns)
            ngram_similarity = calculate_ngram_similarity(shellcode_data, tome_shellcode)
            similarity_scores['ngram'] = ngram_similarity
            
            # Instruction-level similarity (if disassembler available)
            instr_similarity = calculate_instruction_similarity(shellcode_data, tome_shellcode)
            if instr_similarity is not None:
                similarity_scores['instruction'] = instr_similarity
            
            # Calculate overall similarity score (weighted average)
            weights = {
                'size': 0.1,
                'byte': 0.3,
                'ngram': 0.4,
                'instruction': 0.6  # Higher weight if available
            }
            
            total_weight = sum(weights[key] for key in similarity_scores.keys() if key in weights)
            overall_similarity = sum(similarity_scores[key] * weights[key] for key in similarity_scores.keys() if key in weights) / total_weight
            
            # If similarity is above threshold, add to results
            if overall_similarity >= threshold:
                similar_shellcodes.append({
                    'id': sc_id,
                    'similarity': overall_similarity,
                    'metrics': similarity_scores,
                    'entry': sc_entry
                })
        
        # Sort by similarity (highest first)
        similar_shellcodes.sort(key=lambda x: x['similarity'], reverse=True)
        
        return similar_shellcodes
    def scan_for_shellcode(self, memory_data, base_address=0, process_info=None, options=None):
        """
        Scan memory data for shellcode patterns and suspicious code constructs
        
        Args:
            memory_data (bytes): Binary data to scan for shellcode
            base_address (int): Base memory address of the data for proper address calculation
            process_info (dict): Information about the process (name, pid, etc.)
            options (dict): Scanning options and thresholds
        
        Returns:
            dict: Detection results including found patterns and disassembly
        """
        # Default process info and options if not provided
        if process_info is None:
            process_info = {
                'name': 'unknown',
                'pid': 0,
                'path': '',
                'cmdline': '',
                'user': '',
                'start_time': '',
                'memory_region': 'unknown'
            }
            
        if options is None:
            options = {
                'entropy_threshold': 6.8,         # Threshold for high entropy detection
                'min_pattern_count': 2,           # Minimum patterns to consider as suspicious
                'max_disassembly_size': 8192,     # Maximum bytes to disassemble
                'show_disassembly': True,         # Whether to produce disassembly
                'search_xor': True,               # Look for XOR encoding
                'detect_nop_sleds': True,         # Look for NOP sleds
                'scan_depth': 'full'              # 'quick', 'normal', or 'full'
            }
            
        # Initialize result structure
        results = {
            'timestamp': self._get_timestamp(),
            'process': process_info,
            'base_address': base_address,
            'data_size': len(memory_data),
            'entropy': 0.0,
            'patterns_found': [],
            'shellcode_score': 0,
            'is_shellcode': False,
            'disassembly': [],
            'signatures_matched': []
        }
        
        # Check if enough data to analyze
        if len(memory_data) < 16:
            results['error'] = "Insufficient data for analysis"
            return results
            
        # Calculate entropy
        results['entropy'] = self._calculate_entropy(memory_data)
        
        # Perform shellcode pattern detection
        patterns = self.detect_shellcode(memory_data)
        
        # Add results
        for pattern_name, offset in patterns:
            pattern_info = {
                'pattern': pattern_name,
                'offset': offset,
                'address': base_address + offset,
                'hex_signature': self._bytes_to_hex(memory_data[offset:offset+16])
            }
            results['patterns_found'].append(pattern_info)
            results['shellcode_score'] += 10  # Increment score for each pattern
            
        # Check for high entropy
        if results['entropy'] > options['entropy_threshold']:
            results['patterns_found'].append({
                'pattern': 'High Entropy Data',
                'offset': 0,
                'address': base_address,
                'hex_signature': self._bytes_to_hex(memory_data[0:16])
            })
            results['shellcode_score'] += 15
            
        # Check for NOP sleds if enabled
        if options['detect_nop_sleds'] and b'\x90\x90\x90\x90\x90\x90\x90\x90' in memory_data:
            nop_offset = memory_data.find(b'\x90\x90\x90\x90\x90\x90\x90\x90')
            results['patterns_found'].append({
                'pattern': 'NOP Sled',
                'offset': nop_offset,
                'address': base_address + nop_offset,
                'hex_signature': self._bytes_to_hex(memory_data[nop_offset:nop_offset+16])
            })
            results['shellcode_score'] += 20
            
        # Check for XOR encoding if enabled
        if options['search_xor'] and self._detect_xor_encoding(memory_data):
            results['patterns_found'].append({
                'pattern': 'Possible XOR Encoding',
                'offset': 0,
                'address': base_address,
                'hex_signature': self._bytes_to_hex(memory_data[0:16])
            })
            results['shellcode_score'] += 15
        
        # Determine if this is likely shellcode
        results['is_shellcode'] = (
            results['shellcode_score'] >= 20 or 
            len(results['patterns_found']) >= options['min_pattern_count'] or
            (results['entropy'] > options['entropy_threshold'] and len(results['patterns_found']) > 0)
        )
        
        # Generate disassembly if requested and shellcode is detected
        if options['show_disassembly'] and results['is_shellcode']:
            # Limit disassembly size
            disasm_size = min(len(memory_data), options['max_disassembly_size'])
            results['disassembly'] = self.disassembler.disassemble_bytes(
                memory_data[:disasm_size], 
                base_address
            )
            
            # If this is running in a GUI context and shellcode is detected, 
            # show the disassembly in a viewer if available
            if results['is_shellcode'] and hasattr(self, 'show_disassembly') and callable(self.disassembler.show_disassembly):
                try:
                    process_name = process_info.get('name', 'unknown')
                    pid = process_info.get('pid', 0)
                    pattern_name = results['patterns_found'][0]['pattern'] if results['patterns_found'] else 'Suspicious Code'
                    
                    # Pass to UI thread to show in viewer
                    if hasattr(self, 'root') and hasattr(self.root, 'after'):
                        self.root.after(10, lambda: self.disassembler.show_disassembly(
                            results['disassembly'],
                            base_address,
                            pattern_name,
                            process_name,
                            pid
                        ))
                except Exception as e:
                    import logging
                    logging.debug(f"Error showing disassembly: {str(e)}")
        
        # Add detection entry if shellcode is found
        if results['is_shellcode']:
            self.tome.add_entry('shellcode_patterns', {
                'process': process_info.get('name', 'unknown'),
                'pid': process_info.get('pid', 0),
                'address': hex(base_address),
                'size': len(memory_data),
                'patterns': [p['pattern'] for p in results['patterns_found']],
                'entropy': results['entropy'],
                'timestamp': results['timestamp']
            })
            
        return results
    def detect_shellcode(self, memory_content, base_address=0, detailed=True):
        """
        Comprehensive shellcode detection with advanced heuristics
        
        Args:
            memory_content (bytes): Binary data to analyze
            base_address (int): Memory base address for reporting
            detailed (bool): Whether to return detailed analysis or simple findings
            
        Returns:
            If detailed=True: Dictionary with comprehensive analysis
            If detailed=False: List of tuples (pattern_name, offset)
        """
        # Initialize both simple and detailed result structures
        findings = []
        analysis = {
            'found': False,
            'patterns': [],
            'characteristics': [],
            'risk_level': 0,
            'location': hex(base_address),
            'entropy': 0.0,
            'size': len(memory_content),
            'disassembly_preview': []
        }
        
        # Skip analysis if content is too small
        if len(memory_content) < 8:
            if detailed:
                return analysis
            return findings
        
        # Calculate entropy first for early bailout optimization
        entropy = self._calculate_entropy(memory_content)
        analysis['entropy'] = entropy
        
        # Common shellcode patterns (combined from both implementations)
        PATTERNS = {
            # Core shellcode techniques
            'API_Hashing': rb'\x33\xC0\x68.*?\x00\x50\x68.*?\x00\x50|\x74\x0c\x75\x14\xb8[\x00-\xff]{4}',
            'Function_Prologue': rb'\x55\x8B\xEC|\x55\x89\xE5|\x48\x89\x5c',
            'Stack_Setup': rb'\x83\xec[\x00-\xff]\x83\xe4\xf0',
            'GetEIP': rb'\xE8\x00\x00\x00\x00\x58',
            'PEB_Access': rb'\x64\xA1\x30\x00\x00\x00',
            'SEH_Setup': rb'\x33\xC0\x64\x8B',
            'Egg_Hunter': rb'\x66\x81\xCA\xFF\x0F\x42|\x66\x81\xca\xff\x0f\x42\x52\x6a\x02',
            'NOP_Sled': rb'\x90\x90\x90\x90\x90\x90',
            'Syscall': rb'\x0f\x34|\x0f\x05|\xcd\x80',
            'Register_Zero': rb'\x33\xc0|\x31\xc0|\x48\x31',
            'ROP_Gadget': rb'\xc3|\xc2[\x00-\xff]{2}',
            'Memory_Allocation': rb'\x68[\x00-\xff]{4}\x54\xff\xd5',
            'String_Copy_Loop': rb'\xac\xaa\xe2\xfa',
            'XOR_Decoder': rb'\x30[\x00-\xff]\x40\x39[\x00-\xff]\x75',
            'Stack_Strings': rb'\x68[\x20-\x7f]{4}|\x6a[\x20-\x7f]'
        }
        
        # Scan for all patterns
        for name, pattern in PATTERNS.items():
            try:
                matches = re.finditer(pattern, memory_content, re.DOTALL)
                for match in matches:
                    offset = match.start()
                    
                    # Add to simple findings list
                    findings.append((name, offset))
                    
                    # Add to detailed analysis
                    pattern_info = {
                        'type': name,
                        'offset': offset,
                        'address': base_address + offset,
                        'bytes': memory_content[offset:min(offset+16, len(memory_content))].hex(' ')
                    }
                    analysis['patterns'].append(pattern_info)
                    
                    # Adjust risk level based on pattern type
                    if name in ['Egg_Hunter', 'PEB_Access', 'XOR_Decoder']:
                        analysis['risk_level'] += 3  # Higher risk patterns
                    elif name in ['NOP_Sled', 'GetEIP', 'Syscall']:
                        analysis['risk_level'] += 2  # Medium risk patterns
                    else:
                        analysis['risk_level'] += 1  # Standard patterns
            except Exception as e:
                import logging
                logging.debug(f"Error matching pattern {name}: {str(e)}")
        
        # Advanced heuristics
        characteristics = []
        
        # Check for position-independent code indicators
        if b'\xff\x34\x24' in memory_content or b'\x58\x59\x5a' in memory_content:
            characteristics.append('position_independent')
            analysis['risk_level'] += 2
        
        # High entropy indicates encryption/encoding
        if entropy > 7.0:
            characteristics.append('high_entropy')
            analysis['risk_level'] += 3
        elif entropy > 6.5:
            characteristics.append('medium_entropy')
            analysis['risk_level'] += 1
        
        # Check for small code blocks (common in shellcode)
        if len(memory_content) < 2048 and len(memory_content) > 40:
            characteristics.append('small_code_block')
            analysis['risk_level'] += 1
        
        # Check for stack/heap operations
        if b'\x89\xe5' in memory_content or b'\x8b\xe5' in memory_content:
            characteristics.append('stack_manipulation')
            analysis['risk_level'] += 1
        
        # Check for null-free sections (common in shellcode constraints)
        null_free_sections = self._find_null_free_sections(memory_content)
        if null_free_sections and max(null_free_sections, key=lambda x: x[1]-x[0])[1] - max(null_free_sections, key=lambda x: x[1]-x[0])[0] > 30:
            characteristics.append('null_free')
            analysis['risk_level'] += 2
        
        # Check for suspicious call patterns (commonly used in shellcode to get EIP)
        if b'\xe8' in memory_content and b'\x59' in memory_content:
            characteristics.append('call_pop_sequence')
            analysis['risk_level'] += 2
        
        # Executable stack indicators
        if b'\x64\x8f\x05\x00\x00\x00\x00' in memory_content:
            characteristics.append('executable_stack')
            analysis['risk_level'] += 3
        
        # Update analysis dictionary
        analysis['characteristics'] = characteristics
        analysis['found'] = analysis['risk_level'] > 3 or len(analysis['patterns']) >= 2
        
        # Generate brief disassembly preview if available
        if hasattr(self, 'disassembler') and callable(getattr(self.disassembler, 'disassemble_bytes', None)):
            try:
                preview_size = min(len(memory_content), 64)  # First 64 bytes
                preview = self.disassembler.disassemble_bytes(memory_content[:preview_size], base_address)
                analysis['disassembly_preview'] = preview[:10]  # First 10 instructions
            except Exception:
                pass
        
        # Return appropriate result based on detailed flag
        if detailed:
            return analysis
        return findings

    def _calculate_entropy(self, data):
        """Calculate Shannon entropy of binary data"""
        import math
        if not data:
            return 0
            
        entropy = 0
        size = len(data)
        # Count byte occurrences
        counts = {}
        for byte in data:
            counts[byte] = counts.get(byte, 0) + 1
            
        # Calculate entropy
        for count in counts.values():
            probability = count / size
            entropy -= probability * math.log(probability, 2)
            
        return entropy

    def _find_null_free_sections(self, data, min_length=20):
        """Find sections of data without null bytes"""
        sections = []
        start = None
        
        for i, byte in enumerate(data):
            if byte != 0 and start is None:
                start = i
            elif byte == 0 and start is not None:
                if i - start >= min_length:
                    sections.append((start, i))
                start = None
        
        # Handle case where section extends to end
        if start is not None and len(data) - start >= min_length:
            sections.append((start, len(data)))
            
        return sections
    def _calculate_entropy(self, data):
        """Calculate Shannon entropy of binary data"""
        import math
        if not data:
            return 0
            
        entropy = 0
        size = len(data)
        # Count byte occurrences
        counts = {}
        for byte in data:
            counts[byte] = counts.get(byte, 0) + 1
            
        # Calculate entropy
        for count in counts.values():
            probability = count / size
            entropy -= probability * math.log(probability, 2)
            
        return entropy

    def _bytes_to_hex(self, data, max_len=32):
        """Convert bytes to hex string representation"""
        if len(data) > max_len:
            data = data[:max_len]
        return ' '.join(f'{b:02x}' for b in data)

    def _detect_xor_encoding(self, data, sample_size=256):
        """Detect possible XOR encoding in data"""
        if len(data) < 20:
            return False
            
        # Limit the sample size for performance
        sample = data[:min(len(data), sample_size)]
        
        # Look for repeating XOR patterns
        for key in range(1, 256):
            decoded = bytes(b ^ key for b in sample)
            
            # Check if decoded data looks like code or text
            text_chars = sum(1 for b in decoded if 32 <= b <= 126)
            if text_chars > len(decoded) * 0.7:
                return True
                
            # Check for code patterns in decoded data
            code_patterns = [b'\x55\x8b\xec', b'\x48\x89\x5c', b'\x48\x83\xec', b'\x55\x48\x8b\xec']
            if any(pattern in decoded for pattern in code_patterns):
                return True
                
        return False

    def _get_timestamp(self):
        """Get current timestamp string"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    def _extract_instructions(self, shellcode_data, address=0):
       
        if not shellcode_data:
            return []
            
        normalized_instructions = []
        
        try:
            # Try to use capstone if available
            if hasattr(self, 'cs'):
                instructions = list(self.cs.disasm(shellcode_data, address))
                
                for instr in instructions:
                    # Normalize the instruction by removing specific addresses
                    # Keep only mnemonic and register/immediate operands
                    normalized = instr.mnemonic
                    
                    # For instructions with operands, normalize them
                    if instr.op_str:
                        # Replace memory addresses with placeholder
                        op_normalized = re.sub(r'0x[0-9a-f]+', 'ADDR', instr.op_str)
                        # Replace specific offsets with placeholder
                        op_normalized = re.sub(r'\+[0-9a-f]+\]', '+OFFSET]', op_normalized)
                        # Keep register names and immediate values that aren't addresses
                        normalized += " " + op_normalized
                        
                    normalized_instructions.append(normalized)
            else:
                # Fallback to a more basic approach if no disassembler
                # This is a simplified approach that looks for common instruction patterns
                patterns = [
                    # mov instructions
                    (rb'\x89[\xC0-\xFF]', 'mov reg, reg'),
                    (rb'\x8B[\xC0-\xFF]', 'mov reg, reg'),
                    (rb'\xB8[\x00-\xFF]{4}', 'mov eax, imm32'),
                    (rb'\xB9[\x00-\xFF]{4}', 'mov ecx, imm32'),
                    # push/pop
                    (rb'\x50[\x00-\x57]', 'push reg'),
                    (rb'\x58[\x00-\x5F]', 'pop reg'),
                    # jumps
                    (rb'\xEB[\x00-\xFF]', 'jmp short'),
                    (rb'\xE9[\x00-\xFF]{4}', 'jmp near'),
                    # calls
                    (rb'\xE8[\x00-\xFF]{4}', 'call'),
                    (rb'\xFF[\xD0-\xD7]', 'call reg'),
                    # arithmetic
                    (rb'\x01[\xC0-\xFF]', 'add reg, reg'),
                    (rb'\x29[\xC0-\xFF]', 'sub reg, reg'),
                    (rb'\x31[\xC0-\xFF]', 'xor reg, reg'),
                    (rb'\x33[\xC0-\xFF]', 'xor reg, reg'),
                    # common shellcode instructions
                    (rb'\xC3', 'ret'),
                    (rb'\xC9', 'leave'),
                    (rb'\x90', 'nop'),
                ]
                
                # Scan shellcode for instruction patterns
                for i in range(len(shellcode_data)):
                    for pattern, instruction in patterns:
                        if i + len(pattern) - 1 < len(shellcode_data):
                            chunk = shellcode_data[i:i+len(pattern)]
                            if re.match(pattern, chunk):
                                normalized_instructions.append(instruction)
                                break
        except Exception as e:
            # Log error and return what we have so far
            if hasattr(self, 'logger'):
                logging.debug(f"Error extracting instructions: {str(e)}")
        
        return normalized_instructions
    def transfer_detected_to_capture(self, ShellCode_Capture):
        """
        Transfer all detected shellcode to a ShellcodeCapture instance
        
        Args:
            ShellCode_Capture (ShellcodeCapture): Instance of ShellcodeCapture to store the shellcode
        
        Returns:
            Number of shellcode entries transferred
        """
        sc_id = hashlib.sha256(sc_data['data']).hexdigest()[:16]
        count = 0
        for sc_id, sc_data in self.shellcode_tome.items():
            for location in sc_data['locations']:
                source_info = f"Region: {location['region_name']}, Address: {location['address']}"
                self.ShellCode_Capture.capture_shellcode(
                    sc_data['data'],
                    start_addr=location['address'],
                    source_info=source_info
                )
                count += 1
        return count
    def export_to_reporting(self, Reporter):
        """
        Export all shellcodes in the tome to the reporting system
        
        Args:
            reporter: Instance of ShellcodeReporter
            
        Returns:
            Number of shellcodes exported
        """
        self.Reporter = ShellcodeReporter
        count = 0
        for sc_id, sc_data in self.shellcode_tome.items():
            for location in sc_data.get('locations', []):
                shellcode_entry = {
                    'id': sc_id,
                    'data': sc_data.get('data', b''),
                    'size': sc_data.get('size', 0),
                    'address': location.get('address', 0),
                    'region_name': location.get('region_name', 'unknown'),
                    'detection_method': 'shellcode_detector_tome'
                }
                
                if self.Reporter.log_shellcode(shellcode_entry):
                    count += 1
                    
        return count
class ShellCodeTome:
    """
    Repository of shellcode and malicious code detections with integrated
    shellcode detector and disassembler capabilities
    """
    def __init__(self, shellcode_detector=None, disassembler=None):
        self.detections = {
            'api_hashing': [],
            'egg_hunters': [],
            'process_injection': [],
            'xor_encoding': [],
            'stack_strings': [],
            'peb_access': [],
            'reflective_loading': [],
            'rop_chains': [],
            'shellcode_patterns': [],
            'rwx_memory': [],
            'wx_memory': [],
            'cfg_bypass': [],
            'process_hollowing': [],
            'suspicious_memory': [],
            'unsigned_modules': [],
            'suspicious_registry': [],
            'suspicious_cmdline': [],
            'yara_matches': []
        }
        self.ShellCodeDetector = None  # Will be set later to avoid circular dependency
        self.Disassembler = CodeDisassembler()
        self.total_detections = 0
        # Use provided components or create built-in versions
    
    def set_shellcode_detector(self, detector):
        """Set the shellcode detector to avoid circular dependency"""
        self.ShellCodeDetector = detector
    def _create_default_shellcode_detector(self):
        """Create a default shellcode detector instance"""
        return self.ShellCodeDetector()

    def _create_default_disassembler(self):
        """Create a default disassembler instance"""
        return self.Disassembler()
    def add_entry(self, category, entry):
        """Add a detection entry to the appropriate category"""
        if category in self.detections:
            self.detections[category].append(entry)
            self.total_detections += 1
            return True
        return False
    def analyze_shellcode(self, data, base_address=0):
        """Analyze shellcode data using the built-in detector and disassembler"""
        results = {
            'patterns': self.ShellCodeDetector.detect_shellcode(data) if self.ShellCodeDetector else [],
            'flow_analysis': self.ShellCodeDetector._analyze_execution_flow(data, base_address) if self.ShellCodeDetector else {},
            'disassembly': self.Disassembler.disassemble_bytes(data, base_address),
            'entropy': self._calculate_entropy(data),
            'size': len(data)
        }
        return results
    
    def _calculate_entropy(self, data):
        """Calculate Shannon entropy of data"""
        import math
        if not data:
            return 0
            
        entropy = 0
        size = len(data)
        # Count byte occurrences
        counts = {}
        for byte in data:
            counts[byte] = counts.get(byte, 0) + 1
            
        # Calculate entropy
        for count in counts.values():
            probability = count / size
            entropy -= probability * math.log(probability, 2)
            
        return entropy
    def get_entries(self, category=None):
        """Get all entries in a category or all categories if None"""
        if category:
            return self.detections.get(category, [])
        return self.detections
    
    def analyze_memory_region(self, memory_content, pid, process_name, base_addr, region_size):
        """
        Analyzes a memory region using the shellcode detector and disassembler
        Returns a list of detection dictionaries
        """
        detections = []
        
        # Skip if content is too small for meaningful analysis
        if not memory_content or len(memory_content) < 32:
            return detections
            
        # 1. Run shellcode detector analysis
        shellcode_findings = self.shellcode_detector.analyze(memory_content)
        
        for finding in shellcode_findings:
            detection = {
                'pid': pid,
                'process': process_name,
                'type': f'Shellcode: {finding["type"]}',
                'details': finding["description"],
                'confidence': finding.get("confidence", "medium"),
                'location': f'Memory region at {hex(base_addr)}, offset: {finding.get("offset", 0)}'
            }
            
            # Add the detection and the category is auto-determined
            self.add_detection(detection)
            detections.append(detection)
            
        # 2. Disassemble the region for deeper analysis
        try:
            instructions = self.disassembler.disassemble(memory_content, base_addr)
            
            # Add disassembled code to any existing detections
            for detection in detections:
                offset = int(detection.get('offset', 0))
                context_start = max(0, offset - 10)
                context_end = min(len(instructions), offset + 20)
                
                # Add the relevant instructions as context
                disasm_context = instructions[context_start:context_end]
                detection['disassembly'] = disasm_context
                
            # 3. Analyze disassembly for additional patterns not caught by shellcode detector
            disasm_findings = self.analyze_disassembly(instructions, base_addr)
            
            for finding in disasm_findings:
                detection = {
                    'pid': pid,
                    'process': process_name,
                    'type': finding["type"],
                    'details': finding["details"],
                    'confidence': finding.get("confidence", "medium"),
                    'location': f'Memory region at {hex(base_addr)}, offset: {finding.get("offset", 0)}',
                    'disassembly': finding.get("context", [])
                }
                
                self.add_detection(detection)
                detections.append(detection)
                
        except Exception as e:
            logging.debug(f"Disassembly failed: {str(e)}")
        
        return detections
    
    def analyze_disassembly(self, instructions, base_addr):
        """
        Analyzes disassembly for common shellcode patterns
        Returns a list of findings
        """
        findings = []
        
        if not instructions:
            return findings
            
        # Track sequences of instructions for pattern matching
        api_call_seq = []
        stack_string_seq = []
        xor_seq = []
        
        # Analyze instruction patterns
        for i, instr in enumerate(instructions):
            # Look for API call preparation
            if instr.mnemonic in ['push', 'mov'] and i < len(instructions) - 3:
                api_call_seq.append(instr)
                if len(api_call_seq) >= 4 and instructions[i+1].mnemonic == 'call':
                    findings.append({
                        "type": "API Call Sequence",
                        "details": "Possible API call preparation",
                        "confidence": "medium",
                        "offset": instructions[i-3].address - base_addr,
                        "context": instructions[i-3:i+2]
                    })
                    api_call_seq = []
            else:
                api_call_seq = []
                
            # Look for stack string construction
            if instr.mnemonic in ['push', 'mov'] and 'byte ptr' in instr.op_str:
                stack_string_seq.append(instr)
                if len(stack_string_seq) >= 4:
                    findings.append({
                        "type": "Stack String Construction",
                        "details": "String being built on stack",
                        "confidence": "high",
                        "offset": stack_string_seq[0].address - base_addr,
                        "context": stack_string_seq.copy()
                    })
            else:
                stack_string_seq = []
                
            # Look for XOR loops
            if instr.mnemonic == 'xor':
                xor_seq.append(instr)
                if len(xor_seq) >= 2:
                    next_instr = instructions[i+1] if i+1 < len(instructions) else None
                    if next_instr and next_instr.mnemonic in ['inc', 'dec', 'add', 'sub', 'loop', 'jnz']:
                        findings.append({
                            "type": "XOR Encoding",
                            "details": "Possible decryption/encoding loop",
                            "confidence": "medium",
                            "offset": xor_seq[0].address - base_addr,
                            "context": instructions[i-1:i+2]
                        })
            else:
                if len(xor_seq) < 3:  # Only reset if not part of a larger sequence
                    xor_seq = []
                    
            # Detect PEB access
            if 'fs:0x30' in instr.op_str or 'fs:[0x30]' in instr.op_str:
                findings.append({
                    "type": "PEB Access",
                    "details": "Access to Process Environment Block (common shellcode technique)",
                    "confidence": "high",
                    "offset": instr.address - base_addr,
                    "context": instructions[i:i+5] if i+5 < len(instructions) else instructions[i:]
                })
                
            # Detect GetPC techniques (common in position-independent shellcode)
            if instr.mnemonic == 'call' and instructions[i+1].mnemonic == 'pop' and i+1 < len(instructions):
                findings.append({
                    "type": "GetPC Technique",
                    "details": "Self-referencing code (position independent shellcode)",
                    "confidence": "high", 
                    "offset": instr.address - base_addr,
                    "context": instructions[i:i+3] if i+3 < len(instructions) else instructions[i:]
                })
                
            # Detect egg hunters
            if (instr.mnemonic == 'cmp' and i+3 < len(instructions) and 
                instructions[i+1].mnemonic in ['jne', 'jnz'] and
                instructions[i+2].mnemonic == 'cmp'):
                findings.append({
                    "type": "Egg Hunter",
                    "details": "Memory scanning code pattern",
                    "confidence": "medium",
                    "offset": instr.address - base_addr,
                    "context": instructions[i:i+4]
                })
        
        return findings
    
    def add_detection(self, detection):
        """
        Adds a detection to the appropriate category based on its type
        """
        detection_type = detection.get('type', '').lower()
        
        # Map detection type to category
        category = 'shellcode_patterns'  # Default category
        
        if 'api' in detection_type and ('hash' in detection_type or 'call sequence' in detection_type):
            category = 'api_hashing'
        elif 'egg hunter' in detection_type:
            category = 'egg_hunters'
        elif 'injection' in detection_type:
            category = 'process_injection'
        elif 'xor' in detection_type:
            category = 'xor_encoding'
        elif 'stack string' in detection_type:
            category = 'stack_strings'
        elif 'peb access' in detection_type:
            category = 'peb_access'
        elif 'reflective' in detection_type or 'getpc' in detection_type:
            category = 'reflective_loading'
        elif 'rop' in detection_type:
            category = 'rop_chains'
        elif 'rwx' in detection_type.lower():
            category = 'rwx_memory'
        elif 'wx memory' in detection_type.lower():
            category = 'wx_memory'
        elif 'cfg bypass' in detection_type:
            category = 'cfg_bypass'
        elif 'hollowing' in detection_type:
            category = 'process_hollowing'
        elif 'memory protection' in detection_type:
            category = 'suspicious_memory'
        elif 'unsigned' in detection_type:
            category = 'unsigned_modules'
        elif 'registry' in detection_type:
            category = 'suspicious_registry'
        elif 'command line' in detection_type:
            category = 'suspicious_cmdline'
        elif 'yara rule' in detection_type:
            category = 'yara_matches'
        
        # Add detection to the appropriate category
        self.detections[category].append(detection)
        self.total_detections += 1
        
        # Log the detection
        logging.info(f"Added {detection_type} detection to ShellCodeTome: {detection.get('details', '')}")
        
        return category

    # Other existing methods remain the same

class CodeDisassembler:
    def __init__(self):
        self.use_capstone = False
        self.use_distorm = False
        self.cs = None
        self.cs_mode = None
        self.md = None
        
        # Try to initialize Capstone (preferred)
        try:
            import capstone
            self.cs = capstone
            self.cs_mode = {
                '32bit': capstone.CS_MODE_32,
                '64bit': capstone.CS_MODE_64
            }
            self.x86_md = capstone.Cs(capstone.CS_ARCH_X86, capstone.CS_MODE_32)
            self.x64_md = capstone.Cs(capstone.CS_ARCH_X86, capstone.CS_MODE_64)
            self.x86_md.detail = True
            self.x64_md.detail = True
            self.use_capstone = True
            logging.debug("Initialized Capstone disassembler")
        except ImportError:
            logging.debug("Capstone not available, trying distorm3")
            
            # Try to initialize distorm3 as fallback
            try:
                import distorm3
                self.distorm = distorm3
                self.use_distorm = True
                logging.debug("Initialized distorm3 disassembler")
            except ImportError:
                logging.debug("No disassembly engine available. Limited functionality.")
        
        # Common instruction patterns for analysis
        self.branch_instructions = {
            'x86': [b'\xff\x25', b'\xff\x15', b'\xe8', b'\xe9', b'\xeb', b'\xff\xe0'],  # jmp/call
            'x64': [b'\xff\x25', b'\xff\x15', b'\xe8', b'\xe9', b'\xeb', b'\xff\xe0']   # jmp/call
        }
        
        # Entry point patterns (function prologues, common shellcode starters)
        self.entry_point_patterns = [
            rb'\x55\x8b\xec',           # push ebp; mov ebp, esp (x86 prologue)
            rb'\x55\x48\x89\xe5',       # push rbp; mov rbp, rsp (x64 prologue) 
            rb'\x53\x56\x57',           # push ebx; push esi; push edi
            rb'\x48\x83\xec',           # sub rsp, XX
            rb'\x48\x89\x5c\x24',       # mov [rsp+XX], rbx (x64 prologue)
            rb'\x31\xc0',               # xor eax, eax (common shellcode start)
            rb'\x33\xc0',               # xor eax, eax (alternate)
            rb'\x48\x31\xc0',           # xor rax, rax (x64 version)
            rb'\xeb[\x00-\xff]\xe8',    # jmp short XX; call (common shellcode pattern)
            rb'\x90{5,}[\x00-\xff]{1,2}\x31' # NOP sled followed by code
        ]
    
    def disassemble(self, code_bytes, address=0, architecture='auto', max_instructions=100):
        """
        Disassemble binary code into human-readable assembly
        
        Args:
            code_bytes: The binary code to disassemble
            address: Base address for the code
            architecture: '32bit', '64bit', or 'auto'
            max_instructions: Maximum number of instructions to disassemble
            
        Returns:
            String containing disassembled code or error message
        """
        if not code_bytes:
            return "No code to disassemble"
            
        # Auto-detect architecture if not specified
        if architecture == 'auto':
            architecture = self._detect_architecture(code_bytes)
        
        # Use Capstone if available
        if self.use_capstone:
            return self._disassemble_with_capstone(code_bytes, address, architecture, max_instructions)
        
        # Use distorm3 if available
        elif self.use_distorm:
            return self._disassemble_with_distorm(code_bytes, address, architecture, max_instructions)
        
        # Fallback to simple hex dump with basic pattern matching
        else:
            return self._simple_disassemble(code_bytes, address, max_instructions)
    def disassemble_bytes(self, bytes_data, base_address=0):
        """
        Disassembles a byte array into readable assembly instructions.
        
        Args:
            bytes_data (bytes): The binary data to disassemble
            base_address (int): The starting address for the disassembly
            
        Returns:
            list: List of disassembled instructions
        """
        try:
            # Import capstone here to handle potential import issues gracefully
            import capstone
            
            # Initialize disassembler for x86-64 architecture
            md = capstone.Cs(capstone.CS_ARCH_X86, capstone.CS_MODE_64)
            md.detail = True  # Enable detailed disassembly
            
            # Perform disassembly
            disassembled = []
            for instr in md.disasm(bytes_data, base_address):
                instruction = {
                    'address': f"0x{instr.address:x}",
                    'mnemonic': instr.mnemonic,
                    'op_str': instr.op_str,
                    'bytes': binascii.hexlify(instr.bytes).decode(),
                    'size': instr.size
                }
                disassembled.append(instruction)
            
            return disassembled
        except ImportError:
            logging.warning("Capstone disassembly engine not available")
            return [{"error": "Disassembly engine not available"}]
        except Exception as e:
            logging.error(f"Disassembly error: {str(e)}")
            return [{"error": f"Disassembly failed: {str(e)}"}]
    def _analyze_flow(self, disassembly, base_address=0, memory_data=None):
        """
        Analyze the control flow of disassembled code to identify suspicious patterns
        common in shellcode and malicious code.
        
        Args:
            disassembly (list): Disassembled instructions
            base_address (int): Base memory address of the code
            memory_data (bytes, optional): Original binary data for additional analysis
            
        Returns:
            dict: Analysis results including suspicious flows, API calls, gadgets
        """
        results = {
            'suspicious_flows': [],
            'api_calls': [],
            'rop_gadgets': [],
            'self_modifying_code': False,
            'indirect_calls': [],
            'stack_manipulation': [],
            'register_usage': {},
            'loop_constructs': [],
            'flow_graph': {},
            'flow_score': 0
        }
        
        if not disassembly or len(disassembly) < 5:
            return results
        
        # Track register values and memory accesses
        reg_states = {
            'eax': None, 'ebx': None, 'ecx': None, 'edx': None,
            'esi': None, 'edi': None, 'ebp': None, 'esp': None
        }
        
        # Track jump targets and function calls
        jump_targets = set()
        call_targets = set()
        
        # Track memory writes
        memory_writes = []
        
        # Maps for instruction addresses
        instr_addr_map = {}
        
        # Process each instruction for initial mapping
        for i, instr in enumerate(disassembly):
            # Extract address from disassembly format (expected: "0xADDR: INSTR")
            addr_part = instr.split(':', 1)[0].strip()
            try:
                addr = int(addr_part, 16) if addr_part.startswith('0x') else int(addr_part)
                instr_addr_map[addr] = i
            except (ValueError, IndexError):
                continue  # Skip if not in expected format
        
        # Analyze instruction sequence for flow patterns
        for i, instr in enumerate(disassembly):
            if i >= len(disassembly) - 1:
                break

            # Extract address and instruction parts
            try:
                parts = instr.split(':', 1)
                addr_str = parts[0].strip()
                instr_text = parts[1].strip() if len(parts) > 1 else ""
                
                current_addr = int(addr_str, 16) if addr_str.startswith('0x') else int(addr_str)
            except (ValueError, IndexError):
                continue

            # Check for CALL instructions
            if 'CALL' in instr_text:
                # Extract call target if it's direct
                target = self._extract_target_address(instr_text, current_addr)
                
                if target is not None:
                    call_targets.add(target)
                    
                    # Check if it's an API call to a known address
                    api_name = self._resolve_api_address(target)
                    if api_name:
                        results['api_calls'].append({
                            'address': current_addr,
                            'target': target,
                            'api': api_name
                        })
                        results['flow_score'] += 5
                else:
                    # Indirect call (e.g., CALL EAX)
                    results['indirect_calls'].append({
                        'address': current_addr,
                        'instruction': instr_text
                    })
                    results['flow_score'] += 10  # Indirect calls are more suspicious
            
            # Check for JMP instructions
            elif instr_text.startswith('JMP'):
                # Extract jump target
                target = self._extract_target_address(instr_text, current_addr)
                
                if target is not None:
                    jump_targets.add(target)
                    
                    # Check for backward jumps (loops)
                    if target < current_addr:
                        results['loop_constructs'].append({
                            'from': current_addr,
                            'to': target,
                            'distance': current_addr - target
                        })
                        results['flow_score'] += 3
                    
                    # Check for far jumps (could be suspicious)
                    jump_dist = abs(target - current_addr)
                    if jump_dist > 1024:
                        results['suspicious_flows'].append({
                            'type': 'far_jump',
                            'from': current_addr,
                            'to': target,
                            'distance': jump_dist
                        })
                        results['flow_score'] += 2
            
            # Check for conditional jumps
            elif any(jcc in instr_text for jcc in ['JE', 'JNE', 'JZ', 'JNZ', 'JG', 'JL', 'JA', 'JB']):
                target = self._extract_target_address(instr_text, current_addr)
                
                if target is not None:
                    jump_targets.add(target)
                    
                    # Add to flow graph
                    if current_addr not in results['flow_graph']:
                        results['flow_graph'][current_addr] = []
                    
                    results['flow_graph'][current_addr].append({
                        'target': target,
                        'type': 'conditional'
                    })
            
            # Check for stack manipulation
            elif 'ESP' in instr_text or 'EBP' in instr_text:
                if any(op in instr_text for op in ['ADD', 'SUB', 'LEA']):
                    results['stack_manipulation'].append({
                        'address': current_addr,
                        'instruction': instr_text
                    })
                    
                    # Large stack adjustments could indicate shellcode
                    if 'SUB ESP' in instr_text:
                        try:
                            # Try to extract immediate value
                            imm_value = int(instr_text.split(',')[1].strip(), 16)
                            if imm_value > 0x1000:  # Large stack allocation
                                results['suspicious_flows'].append({
                                    'type': 'large_stack_allocation',
                                    'address': current_addr,
                                    'size': imm_value
                                })
                                results['flow_score'] += 10
                        except (ValueError, IndexError):
                            pass
            
            # Check for push/pop sequences that could be ROP gadgets
            elif instr_text.startswith('POP') and i > 0 and disassembly[i-1].split(':', 1)[1].strip().startswith('PUSH'):
                results['rop_gadgets'].append({
                    'address': current_addr,
                    'instructions': [disassembly[i-1], instr]
                })
                results['flow_score'] += 1
            
            # Check for memory writes
            elif any(op in instr_text for op in ['MOV', 'STOSB', 'STOSD']):
                # Check for memory destinations (e.g., MOV [address], value)
                if '[' in instr_text and ']' in instr_text:
                    memory_writes.append({
                        'address': current_addr,
                        'instruction': instr_text
                    })
                    
                    # Check for potential self-modifying code
                    # Self-modifying code often writes to a memory address and then jumps to it
                    if i < len(disassembly) - 2:
                        next_instr = disassembly[i+1].split(':', 1)[1].strip()
                        if 'JMP' in next_instr or 'CALL' in next_instr:
                            results['self_modifying_code'] = True
                            results['suspicious_flows'].append({
                                'type': 'self_modifying_code',
                                'address': current_addr,
                                'sequence': [instr, disassembly[i+1]]
                            })
                            results['flow_score'] += 25  # Very suspicious
            
            # Track register usage and values
            for reg in reg_states.keys():
                reg_pattern = f"{reg},"
                if reg_pattern in instr_text:
                    if reg not in results['register_usage']:
                        results['register_usage'][reg] = 0
                    results['register_usage'][reg] += 1
                    
                    # Try to track immediate values assigned to registers
                    if instr_text.startswith(f'MOV {reg},'):
                        try:
                            value_part = instr_text.split(',')[1].strip()
                            if value_part.startswith('0x'):
                                reg_states[reg] = int(value_part, 16)
                        except (ValueError, IndexError):
                            pass
        
        # Analyze potential function prologue/epilogue patterns
        for i, instr in enumerate(disassembly):
            if i >= len(disassembly) - 3:
                break
                
            instr_text = instr.split(':', 1)[1].strip() if ':' in instr else instr
            
            # Check for function prologue (PUSH EBP; MOV EBP, ESP)
            if instr_text == 'PUSH EBP':
                next_instr = disassembly[i+1].split(':', 1)[1].strip() if ':' in disassembly[i+1] else disassembly[i+1]
                if next_instr == 'MOV EBP, ESP':
                    addr_str = instr.split(':', 1)[0].strip()
                    try:
                        func_addr = int(addr_str, 16) if addr_str.startswith('0x') else int(addr_str)
                        results['flow_graph'][func_addr] = {'type': 'function_entry'}
                    except (ValueError, IndexError):
                        pass
        
        # Identify chains of jumps that could indicate obfuscation
        jump_chain = []
        for addr in sorted(jump_targets):
            if addr in instr_addr_map:
                i = instr_addr_map[addr]
                if i < len(disassembly):
                    instr = disassembly[i]
                    if 'JMP' in instr:
                        jump_chain.append(addr)
        
        if len(jump_chain) > 3:
            results['suspicious_flows'].append({
                'type': 'jump_chain',
                'addresses': jump_chain
            })
            results['flow_score'] += 15  # Jump chains are often used in obfuscation
        
        # Analyze the structure for API resolution patterns
        if memory_data and len(memory_data) > 20:
            # Check for GetProcAddress pattern
            if results['register_usage'].get('eax', 0) > 5 and results['indirect_calls']:
                # Common API resolution pattern using GetProcAddress
                getproc_pattern = False
                for i, instr in enumerate(disassembly):
                    if 'PUSH' in instr and i < len(disassembly) - 3:
                        next_instr = disassembly[i+1]
                        next_next_instr = disassembly[i+2]
                        if 'PUSH' in next_instr and 'CALL' in next_next_instr:
                            getproc_pattern = True
                            break
                
                if getproc_pattern:
                    results['suspicious_flows'].append({
                        'type': 'api_resolution',
                        'method': 'GetProcAddress'
                    })
                    results['flow_score'] += 20  # API resolution is common in shellcode
        
        # Check for PEB access pattern (common in shellcode)
        peb_access = False
        for i, instr in enumerate(disassembly):
            if 'FS:[' in instr and '0x30' in instr:  # PEB access at FS:[0x30]
                peb_access = True
                addr_str = instr.split(':', 1)[0].strip()
                try:
                    peb_addr = int(addr_str, 16) if addr_str.startswith('0x') else int(addr_str)
                    results['suspicious_flows'].append({
                        'type': 'peb_access',
                        'address': peb_addr
                    })
                    results['flow_score'] += 20  # PEB access is common in shellcode
                except (ValueError, IndexError):
                    pass
        
        # Final score adjustments
        if results['self_modifying_code']:
            results['flow_score'] += 30
        
        if peb_access and results['indirect_calls']:
            results['flow_score'] += 25  # PEB access + indirect calls is highly suspicious
        
        if len(results['stack_manipulation']) > 5:
            results['flow_score'] += 15  # Extensive stack manipulation
        
        # Calculate shellcode likelihood
        results['is_shellcode_flow'] = results['flow_score'] >= 40
        results['flow_confidence'] = min(100, results['flow_score'])
        
        return results

    def _extract_target_address(self, instruction_text, current_address):
        """Extract target address from a jump or call instruction"""
        try:
            parts = instruction_text.split()
            if len(parts) < 2:
                return None
            
            target_str = parts[1].strip()
            
            # Handle direct addresses
            if target_str.startswith('0x'):
                return int(target_str, 16)
            
            # Handle relative offsets
            if '+' in target_str:
                offset_parts = target_str.split('+')
                if len(offset_parts) == 2 and offset_parts[1].startswith('0x'):
                    offset = int(offset_parts[1], 16)
                    return current_address + offset
            
            return None
        except (ValueError, IndexError):
            return None

    def _resolve_api_address(self, address):
        """
        Attempt to resolve an address to a known API name
        This is a placeholder - implement with your actual API resolution logic
        """
        # This would normally use a loaded module database
        # For this example, we'll return None for all addresses
        # In a real implementation, you would check if the address falls within
        # a known DLL's address range and resolve the export name
        
        # Mock implementation for demonstration
        common_api_addresses = {
            0x77e12345: 'kernel32.CreateProcessA',
            0x77e23456: 'kernel32.VirtualAlloc',
            0x77e34567: 'kernel32.GetProcAddress',
            0x77e45678: 'kernel32.LoadLibraryA',
            0x77e56789: 'ntdll.NtAllocateVirtualMemory',
            0x77e67890: 'ntdll.ZwProtectVirtualMemory'
        }
        
        return common_api_addresses.get(address)
    def calculate_entropy(self, data):
        """
        Calculate Shannon entropy of binary data
        
        Args:
            data (bytes): Binary data
            
        Returns:
            float: Entropy value (0.0 to 8.0)
        """
        if not data:
            return 0.0
        
        entropy = 0
        for x in range(256):
            p_x = float(data.count(x)) / len(data)
            if p_x > 0:
                entropy += -p_x * math.log(p_x, 2)
        
        return entropy

    def detect_api_references(self, data):
        """
        Detect potential API call references in the binary data
        
        Args:
            data (bytes): Binary data to analyze
            
        Returns:
            bool: True if API references are detected
        """
        # Common API call patterns (simplified check)
        api_patterns = [
            b'LoadLibrary', b'GetProc', b'VirtualAlloc', b'CreateThread',
            b'WriteProcess', b'ReadProcess', b'CreateFile', b'WinExec',
            b'ShellExecute', b'socket', b'connect', b'recv', b'send'
        ]
        
        for pattern in api_patterns:
            if pattern in data:
                return True
        
        # Also check for common API call instruction patterns in x86/x64
        # E8 is CALL in x86/x64
        call_offsets = [i for i in range(len(data)-5) if data[i] == 0xE8]
        if len(call_offsets) > 2:  # Multiple CALL instructions may indicate API usage
            return True
        
        return False

    def create_binary_signature(self, data):
        """
        Create a fuzzy signature of the binary data for pattern matching
        
        Args:
            data (bytes): Binary data
            
        Returns:
            str: A signature string that represents the binary pattern
        """
        try:
            import ssdeep
            return ssdeep.hash(data)
        except ImportError:
            # Fallback if ssdeep not available
            return hashlib.md5(data).hexdigest()

    def schedule_pattern_learning(self, detection_id, data_sample):
        """
        Schedule a background task to learn from this shellcode pattern
        
        Args:
            detection_id (str): Unique ID for this detection
            data_sample (bytes): Sample of the detected shellcode
        """
        try:
            if not hasattr(self, 'pattern_learning_queue'):
                self.pattern_learning_queue = queue.Queue()
            
            self.pattern_learning_queue.put({
                'detection_id': detection_id,
                'data_sample': data_sample,
                'timestamp': time.time()
            })
            
            # Start the learning thread if not already running
            if not hasattr(self, 'learning_thread_running') or not self.learning_thread_running:
                self.learning_thread_running = True
                threading.Thread(target=self.process_pattern_learning_queue, daemon=True).start()
        except Exception as e:
            logging.debug(f"Error scheduling pattern learning: {str(e)}")

    def process_pattern_learning_queue(self):
        """
        Background thread to process shellcode patterns for learning
        """
        try:
            while self.learning_thread_running:
                try:
                    # Get item from queue with timeout to allow thread to exit
                    item = self.pattern_learning_queue.get(timeout=1.0)
                    
                    # Process the pattern
                    if hasattr(self, 'tome') and self.tome:
                        # Extract features from the sample
                        features = self.extract_shellcode_features(item['data_sample'])
                        
                        # Update the Tome entry with learned features
                        self.tome.update_entry(
                            'shellcode_patterns', 
                            {'detection_id': item['detection_id']},
                            {'features': features, 'last_analyzed': time.time()}
                        )
                    
                    # Mark task as done
                    self.pattern_learning_queue.task_done()
                except queue.Empty:
                    # Queue is empty, just continue
                    continue
                except Exception as e:
                    logging.error(f"Error in pattern learning: {str(e)}")
                    # Mark task as done even if it failed
                    try:
                        self.pattern_learning_queue.task_done()
                    except:
                        pass
        except Exception as e:
            logging.error(f"Pattern learning thread error: {str(e)}")
        finally:
            self.learning_thread_running = False

    def extract_shellcode_features(self, data_sample):
        """
        Extract features from shellcode for machine learning purposes
        
        Args:
            data_sample (bytes): Binary data to analyze
            
        Returns:
            dict: Features extracted from the shellcode
        """
        features = {}
        
        try:
            # Basic statistical features
            features['size'] = len(data_sample)
            features['entropy'] = self.calculate_entropy(data_sample)
            
            # Byte frequency distribution
            byte_freq = {}
            for i in range(256):
                byte_freq[i] = data_sample.count(i)
            features['byte_frequency'] = byte_freq
            
            # Instruction statistics
            disasm = self.disassemble_bytes(data_sample)
            if isinstance(disasm, list) and len(disasm) > 0 and not disasm[0].get('error'):
                # Count instruction types
                instr_types = {}
                for instr in disasm:
                    mnemonic = instr.get('mnemonic', '')
                    instr_types[mnemonic] = instr_types.get(mnemonic, 0) + 1
                
                features['instruction_count'] = len(disasm)
                features['instruction_types'] = instr_types
                
                # Count likely API calls
                call_count = sum(1 for instr in disasm if instr.get('mnemonic') == 'call')
                features['call_count'] = call_count
                
                # Detect JMP/CALL patterns that might indicate obfuscation
                jmp_count = sum(1 for instr in disasm if instr.get('mnemonic') in ('jmp', 'je', 'jne', 'jz', 'jnz'))
                features['jump_count'] = jmp_count
            
            # Calculate potentially obfuscated strings
            features['potential_strings'] = self.detect_obfuscated_strings(data_sample)
        except Exception as e:
            logging.debug(f"Error extracting shellcode features: {str(e)}")
        
        return features

    def detect_obfuscated_strings(self, data):
        """
        Detect potentially obfuscated strings in the binary data
        
        Args:
            data (bytes): Binary data to analyze
            
        Returns:
            list: List of potential string patterns
        """
        results = []
        
        # Check for ASCII strings (at least 4 chars)
        current_string = ""
        for byte in data:
            if 32 <= byte <= 126:  # Printable ASCII range
                current_string += chr(byte)
            else:
                if len(current_string) >= 4:
                    results.append(current_string)
                current_string = ""
        
        # Add last string if it exists
        if len(current_string) >= 4:
            results.append(current_string)
        
        # Check for potential obfuscated/encoded strings
        # Look for repeating patterns that might be encoded data
        # This is a simplified approach - real implementation would use more advanced heuristics
        potential_patterns = []
        for i in range(len(data) - 8):
            pattern = data[i:i+8]
            # Check if this 8-byte pattern repeats with variations (possible encoding)
            count = 0
            for j in range(i+8, len(data) - 8, 8):
                comparison = data[j:j+8]
                diff_bytes = sum(1 for b1, b2 in zip(pattern, comparison) if b1 != b2)
                if diff_bytes <= 2:
                    count += 1
            if count >= 2:  # Found a repeating pattern with variations
                potential_patterns.append(pattern)
        
        return potential_patterns
    def _detect_architecture(self, code_bytes):   
        if not code_bytes or len(code_bytes) < 4:
            return '32bit'  # Default to 32-bit

        # Look for indicators of 64-bit code (REX prefixes, typical x64 instructions)
        rex_prefixes = [b'\x48', b'\x49', b'\x4A', b'\x4B', b'\x4C', b'\x4D', b'\x4E', b'\x4F']
        for prefix in rex_prefixes:
            if prefix in code_bytes[:20]:  # Check first 20 bytes for REX prefixes
                return '64bit'
                
        # Check for typical x64 function prologues
        x64_prologues = [b'\x55\x48\x89\xe5', b'\x48\x83\xec', b'\x48\x89\x5c\x24']
        for prologue in x64_prologues:
            if code_bytes.startswith(prologue):
                return '64bit'
                
        # Default to 32-bit
        return '32bit'
   
    def _disassemble_with_capstone(self, code_bytes, address, architecture, max_instructions):
        """Use Capstone engine for disassembly"""
        try:
            # Select the appropriate disassembler
            md = self.x64_md if architecture == '64bit' else self.x86_md
            
            # Disassemble the code
            result = []
            for i, (address, size, mnemonic, op_str) in enumerate(md.disasm_lite(code_bytes, address)):
                if i >= max_instructions:
                    result.append("... (truncated)")
                    break
                
                # Format the instruction
                instruction = f"0x{address:08x}: {mnemonic} {op_str}"
                result.append(instruction)
                
                # Include hex bytes (up to 10 bytes per instruction)
                hex_bytes = ' '.join(f'{b:02x}' for b in code_bytes[i:i+min(size, 10)])
                if len(hex_bytes) > 0:
                    result.append(f"  [{hex_bytes}]")
            
            if not result:
                return "No valid instructions found"
                
            return '\n'.join(result)
            
        except Exception as e:
            return f"Disassembly error: {str(e)}"
    
    def _disassemble_with_distorm(self, code_bytes, address, architecture, max_instructions):
        """Use distorm3 engine for disassembly"""
        try:
            # Select the appropriate mode
            mode = self.distorm.Decode64Bits if architecture == '64bit' else self.distorm.Decode32Bits
            
            # Disassemble the code
            instructions = self.distorm.Decode(address, code_bytes, mode)
            
            result = []
            
            for i, (offset, size, instruction, hexdump) in enumerate(instructions):
                if i >= max_instructions or size in self.branch_instructions.get(architecture, []):
                    result.append("... (truncated)")
                    break
                    
                # Format the instruction
                instr_line = f"0x{offset:08x}: {instruction}"
                result.append(instr_line)
                
                # Include hex bytes
                result.append(f"  [{hexdump}]")
            
            if not result:
                return "No valid instructions found"
                
            return '\n'.join(result)
            
        except Exception as e:
            return f"Disassembly error: {str(e)}"
    
    def _simple_disassemble(self, code_bytes, address, max_instructions):
        """
        Simple disassembly fallback when no engine is available
        Just shows hex dump with basic pattern recognition
        """
        result = ["Warning: No disassembly engine available. Showing hex dump with basic patterns."]
        
        offset = 0
        seen_instructions = 0
        
        while offset < len(code_bytes) and seen_instructions < max_instructions:
            # Get current address
            current_addr = address + offset
            
            # Get a slice of the remaining bytes (up to 16 bytes)
            remaining = min(16, len(code_bytes) - offset)
            byte_slice = code_bytes[offset:offset+remaining]
            
            # Format hex representation
            hex_str = ' '.join(f'{b:02x}' for b in byte_slice)
            
            # Try to identify common instructions
            instruction = self._identify_simple_instruction(byte_slice)
            
            if instruction:
                result.append(f"0x{current_addr:08x}: {hex_str:<47} ; {instruction}")
                # Move forward by the identified instruction length
                offset += instruction[1]
                seen_instructions += 1
            else:
                # If we can't identify, just show the hex and move forward 1 byte
                result.append(f"0x{current_addr:08x}: {hex_str}")
                offset += 1
        
        return '\n'.join(result)
    
    def _identify_simple_instruction(self, byte_slice):
        """Identify some common x86/x64 instructions without a disassembler"""
        if not byte_slice:
            return None
            
        # Some common instruction patterns with their lengths
        patterns = [
            (b'\x90', 1, "NOP"),
            (b'\xc3', 1, "RET"),
            (b'\x55', 1, "PUSH EBP"),
            (b'\x5d', 1, "POP EBP"),
            (b'\x50', 1, "PUSH EAX"),
            (b'\x51', 1, "PUSH ECX"),
            (b'\x52', 1, "PUSH EDX"),
            (b'\x53', 1, "PUSH EBX"),
            (b'\x56', 1, "PUSH ESI"),
            (b'\x57', 1, "PUSH EDI"),
            (b'\x58', 1, "POP EAX"),
            (b'\x59', 1, "POP ECX"),
            (b'\x5a', 1, "POP EDX"),
            (b'\x5b', 1, "POP EBX"),
            (b'\x5e', 1, "POP ESI"),
            (b'\x5f', 1, "POP EDI"),
            (b'\x31\xc0', 2, "XOR EAX, EAX"),
            (b'\x31\xd2', 2, "XOR EDX, EDX"),
            (b'\x31\xc9', 2, "XOR ECX, ECX"),
            (b'\x31\xdb', 2, "XOR EBX, EBX"),
            (b'\x33\xc0', 2, "XOR EAX, EAX"),
            (b'\x48\x31\xc0', 3, "XOR RAX, RAX"),
            (b'\x48\x89\xe5', 3, "MOV RBP, RSP"),
            (b'\xff\xd0', 2, "CALL EAX"),
            (b'\xff\xd1', 2, "CALL ECX"),
            (b'\xff\xd2', 2, "CALL EDX"),
            (b'\xff\xd3', 2, "CALL EBX"),
            (b'\xff\xe0', 2, "JMP EAX"),
            (b'\xff\xe1', 2, "JMP ECX"),
            (b'\xff\xe2', 2, "JMP EDX"),
            (b'\xff\xe3', 2, "JMP EBX"),
        ]
        
        # Specific handling for call/jmp with offset
        if byte_slice and byte_slice[0] == 0xe8 and len(byte_slice) >= 5:
            offset = int.from_bytes(byte_slice[1:5], byteorder='little', signed=True)
            return (f"CALL {offset:+#x}", 5)
        
        if byte_slice and byte_slice[0] == 0xe9 and len(byte_slice) >= 5:
            offset = int.from_bytes(byte_slice[1:5], byteorder='little', signed=True)
            return (f"JMP {offset:+#x}", 5)
            
        if byte_slice and byte_slice[0] == 0xeb and len(byte_slice) >= 2:
            offset = int.from_bytes(byte_slice[1:2], byteorder='little', signed=True)
            return (f"JMP SHORT {offset:+#x}", 2)
            
        # Check for standard patterns
        for pattern, length, name in patterns:
            if byte_slice.startswith(pattern) and len(byte_slice) >= length:
                return (name, length)
        
        return None
    def find_entry_points(self, code_bytes, base_address=0):
        """
        Find potential code entry points in a memory region
        
        Args:
            code_bytes: The binary code to analyze
            base_address: Base address for the code
            
        Returns:
            List of tuples (entry_address, estimated_size) of potential code entry points
        """
        if not code_bytes or len(code_bytes) < 4:
            return []

        entry_points = []
        
        # Scan for function prologues and shellcode entry patterns
        for pattern in self.entry_point_patterns:
            for match in re.finditer(pattern, code_bytes):
                offset = match.start()
                entry_addr = base_address + offset
                
                # Estimate code size by looking for return instructions or next prologue
                estimated_size = self._estimate_code_size(code_bytes, offset)
                
                entry_points.append((entry_addr, estimated_size))
        
        # If using Capstone or distorm, try to identify more entry points by analyzing code flow
        if self.use_capstone or self.use_distorm:
            flow_entries = self._find_entries_by_flow_analysis(code_bytes, base_address)
            for entry_addr, size in flow_entries:
                if (entry_addr, size) not in entry_points:
                    entry_points.append((entry_addr, size))
        
        return entry_points
    
    def _estimate_code_size(self, code_bytes, start_offset, max_size=1024):
        """
        Estimate the size of a code section starting at offset
        Looks for return instructions (ret, retn) or next function prologue
        """
        if start_offset >= len(code_bytes):
            return 0
            
        # Common return instructions
        ret_instructions = [b'\xc3', b'\xc2', b'\xcb', b'\xca']
        
        # Look for return instructions
        for i in range(start_offset + 1, min(len(code_bytes), start_offset + max_size)):
            # Check for return instructions
            if any(code_bytes[i:i+len(ret)] == ret for ret in ret_instructions):
                return i - start_offset + 1
                
            # Check for next function prologue
            for pattern in [rb'\x55\x8b\xec', rb'\x55\x48\x89\xe5']:
                if i + len(pattern) <= len(code_bytes) and code_bytes[i:i+len(pattern)] == pattern:
                    return i - start_offset
        
        # Couldn't find end, return a reasonable size
        return min(512, len(code_bytes) - start_offset)
    
    def _find_entries_by_flow_analysis(self, code_bytes, base_address):
        """
        Find entry points by analyzing code flow (call/jmp targets)
        More effective with Capstone or distorm available
        """
        entry_points = []
        
        # If Capstone is available
        if self.use_capstone:
            try:
                # Detect architecture
                arch = self._detect_architecture(code_bytes)
                md = self.x64_md if arch == '64bit' else self.x86_md
                
                for insn in md.disasm(code_bytes, base_address):
                    # Look for call/jmp instructions
                    if insn.mnemonic in ('call', 'jmp'):
                        # Check if operand is a direct address within our region
                        for op in insn.operands:
                            if op.type == self.cs.CS_OP_IMM:
                                target = op.imm
                                if target >= base_address and target < base_address + len(code_bytes):
                                    # Found a potential entry point
                                    offset = target - base_address
                                    size = self._estimate_code_size(code_bytes, offset)
                                    entry_points.append((target, size))
            except Exception as e:
                logging.debug(f"Error in flow analysis with Capstone: {str(e)}")
        
        # If distorm is available
        elif self.use_distorm:
            try:
                mode = self.distorm.Decode64Bits if self._detect_architecture(code_bytes) == '64bit' else self.distorm.Decode32Bits
                instructions = self.distorm.Decode(base_address, code_bytes, mode)
                
                for (addr, size, instr_text, hexbytes) in instructions:
                    if 'CALL' in instr_text or 'JMP' in instr_text:
                        # Parse the instruction to get target
                        # This is simplified and may need improvement
                        match = re.search(r'(CALL|JMP)\s+0x([0-9A-Fa-f]+)', instr_text)
                        if match:
                            target = int(match.group(2), 16)
                            if target >= base_address and target < base_address + len(code_bytes):
                                offset = target - base_address
                                size = self._estimate_code_size(code_bytes, offset)
                                entry_points.append((target, size))
            except Exception as e:
                logging.debug(f"Error in flow analysis with distorm: {str(e)}")
        
        # Without Capstone or distorm, use simple pattern matching
        else:
            # Look for call/jmp instructions with direct offsets
            i = 0
            while i < len(code_bytes) - 5:
                # Check for E8/E9 (CALL/JMP) with 32-bit offset
                if code_bytes[i] in (0xE8, 0xE9):
                    offset = int.from_bytes(code_bytes[i+1:i+5], byteorder='little', signed=True)
                    target = base_address + i + 5 + offset  # Current position + instruction size + offset
                    
                    # Check if target is within our buffer
                    if target >= base_address and target < base_address + len(code_bytes):
                        # Found a potential entry point
                        buffer_offset = target - base_address
                        size = self._estimate_code_size(code_bytes, buffer_offset)
                        entry_points.append((target, size))
                
                i += 1
                
        return entry_points
    
    def analyze_suspicious_code(self, code_bytes, base_address=0):
        """
        Perform detailed analysis of suspicious code
        
        Args:
            code_bytes: The binary code to analyze
            base_address: Base address for the code
            
        Returns:
            Dictionary with analysis results
        """
        result = {
            'disassembly': self.disassemble(code_bytes, base_address),
            'entry_points': self.find_entry_points(code_bytes, base_address),
            'api_calls': self._identify_api_calls(code_bytes, base_address),
            'techniques': self._identify_techniques(code_bytes),
            'strings': self._extract_strings(code_bytes),
            'architecture': self._detect_architecture(code_bytes)
        }
        
        return result
    
    def _identify_api_calls(self, code_bytes, base_address):
        """Identify potential API calls in the code"""
        api_calls = []
        
        # Common API calling patterns
        api_patterns = [
            # LoadLibrary/GetProcAddress pattern
            (rb'\x68(.{4})\xff\x15(.{4})', "LoadLibrary"),
            (rb'\x68(.{4})\x50\xff\x15(.{4})', "GetProcAddress"),
            # WinExec/CreateProcess pattern
            (rb'\x6a\x00\x68(.{4})\xff\x15(.{4})', "WinExec/CreateProcess"),
            # Socket API patterns
            (rb'\x6a\x06\x6a\x01\x6a\x02\xff\x15', "socket"),
            (rb'\x68(.{4})\x68(.{4})\xff\x15', "connect"),
            # Memory allocation patterns
            (rb'\x6a\x40\x68(.{4})\x6a\x00\xff\x15', "VirtualAlloc"),
            (rb'\x68(.{4})\x6a\x00\xff\x15', "HeapAlloc")
        ]
        
        for pattern, api_name in api_patterns:
            for match in re.finditer(pattern, code_bytes):
                api_calls.append({
                    'offset': base_address + match.start(),
                    'name': api_name,
                    'pattern': binascii.hexlify(match.group(0)).decode('utf-8')
                })
        
        return api_calls
    
    def _identify_techniques(self, code_bytes):
        """Identify shellcode techniques used"""
        techniques = []
        
        # Technique patterns
        technique_patterns = [
            (rb'\x90{5,}', "NOP sled"),
            (rb'\xeb.\xe8', "JMP/CALL/POP decoder"),
            (rb'\x31\xc9.*\xfe\xc1.*\x80', "XOR decoder loop"),
            (rb'\xac.*\xaa.*\xe2', "MOVSx decoder loop"),
            (rb'\x54\x68\x73\x20\x70\x72\x6f\x67\x72\x61\x6d', "This program cannot be run in DOS mode"),
            (rb'\x64\xa1\x30\x00\x00\x00', "PEB access"),
            (rb'\x64\x8b\x1d\x30\x00\x00\x00', "PEB access (alt)"),
            (rb'\x48\x65\x61\x70', "Heap strings"),
            (rb'\x56\x69\x72\x74\x75\x61\x6c', "Virtual strings"),
            (rb'\x6b\x65\x72\x6e\x65\x6c\x33\x32', "kernel32"),
            (rb'\x6e\x74\x64\x6c\x6c', "ntdll")
        ]
        
        for pattern, name in technique_patterns:
            if re.search(pattern, code_bytes):
                techniques.append(name)
                
        # Check for specific techniques
        # Stack strings
        if self._has_stack_strings(code_bytes):
            techniques.append("Stack strings")
            
        # Position-independent code indicators
        if self._has_pic_indicators(code_bytes):
            techniques.append("Position-independent code")
            
        # API hashing
        if self._has_api_hashing(code_bytes):
            techniques.append("API hashing")
            
        return techniques
    
    def _has_stack_strings(self, code_bytes):
        """Check for stack string building pattern (push sequence of characters)"""
        # Look for sequences of push instructions with ASCII values
        push_sequence = 0
        for i in range(len(code_bytes) - 5):
            if code_bytes[i] == 0x68:  # PUSH imm32
                dword = int.from_bytes(code_bytes[i+1:i+5], byteorder='little')
                # Check if value is printable ASCII
                if all(0x20 <= ((dword >> (8*j)) & 0xFF) <= 0x7E for j in range(4)):
                    push_sequence += 1
                    if push_sequence >= 2:  # At least 2 consecutive string pushes
                        return True
            else:
                push_sequence = 0
                
        return False
    
    def _has_pic_indicators(self, code_bytes):
        """Check for position-independent code indicators"""
        # Common PIC patterns: call-pop sequence
        for i in range(len(code_bytes) - 6):
            if code_bytes[i] == 0xE8 and code_bytes[i+5] == 0x59:  # CALL + POP ECX
                return True
                
        # GetPC patterns
        getpc_patterns = [
            b'\xe8\x00\x00\x00\x00\x58',  # call $+5; pop eax
            b'\xe8\x00\x00\x00\x00\x59',  # call $+5; pop ecx
            b'\xd9\xee\xd9\x74\x24\xf4',  # fldz; fstenv [esp-0xc]
            b'\xeb\x03\x5e\xeb\x05'       # jmp short; pop esi; jmp short
        ]
        
        for pattern in getpc_patterns:
            if pattern in code_bytes:
                return True
                
        return False
    
    def _has_api_hashing(self, code_bytes):
        """Check for API hashing techniques"""
        # Patterns typical in API hashing routines
        hash_patterns = [
            rb'\x33\xc0[\x00-\xff]{0,6}\xac[\x00-\xff]{0,6}\xc1[\x00-\xff]{0,6}\x03',  # xor eax,eax + lodsb + rol + add
            rb'\x31\xc0[\x00-\xff]{0,6}\xac[\x00-\xff]{0,6}\xc1[\x00-\xff]{0,6}\x03',  # xor eax,eax + lodsb + rol + add
            rb'\xb9[\x00-\xff]{4}[\x00-\xff]{0,4}\x31\xc0[\x00-\xff]{0,6}\xac[\x00-\xff]{0,6}\x01\xc2',  # mov ecx + xor eax + lodsb + add edx
            rb'\x66[\x00-\xff]{0,2}\x8b[\x00-\xff]{1,4}\x31\xd2[\x00-\xff]{0,6}\x66[\x00-\xff]{1,6}\xc1'  # mov reg + xor edx + rol
        ]
        
        for pattern in hash_patterns:
            if re.search(pattern, code_bytes):
                return True
                
        # Look for repeated rotate/shift/add/xor sequences (common in hash loops)
        rotate_opcodes = [0xc0, 0xc1, 0xd2, 0xd3]  # ROR/ROL/SHR/SHL opcodes
        hash_loop_count = 0
        
        for i in range(len(code_bytes) - 10):
            # Check for rotate/shift instruction
            if code_bytes[i] in rotate_opcodes:
                # Look for arithmetic op within next few bytes
                for j in range(i+1, min(i+8, len(code_bytes))):
                    if code_bytes[j] in [0x01, 0x03, 0x33]:  # ADD/XOR opcodes
                        hash_loop_count += 1
                        if hash_loop_count >= 2:
                            return True
        
        return False
    
    def _extract_strings(self, code_bytes, min_length=4):
        """Extract ASCII and Unicode strings from code"""
        strings = []
        
        # ASCII strings
        ascii_regex = rb'[\x20-\x7E]{' + str(min_length).encode() + rb',}'
        for match in re.finditer(ascii_regex, code_bytes):
            strings.append({
                'type': 'ascii',
                'value': match.group(0).decode('ascii'),
                'offset': match.start()
            })
            
        # Unicode strings (UTF-16LE)
        i = 0
        while i < len(code_bytes) - (min_length * 2):
            # Check for Unicode sequence (ASCII char + null byte repeating)
            if all(0x20 <= code_bytes[i+j*2] <= 0x7E and code_bytes[i+j*2+1] == 0 for j in range(min_length)):
                # Found a potential Unicode string
                end = i
                while end < len(code_bytes) - 1 and 0x20 <= code_bytes[end] <= 0x7E and code_bytes[end+1] == 0:
                    end += 2
                    
                # Extract the string
                unicode_bytes = code_bytes[i:end]
                try:
                    string_value = unicode_bytes.decode('utf-16le')
                    strings.append({
                        'type': 'unicode',
                        'value': string_value,
                        'offset': i
                    })
                except UnicodeDecodeError:
                    pass
                    
                i = end
            else:
                i += 1
                
        return strings
    def show_disassembly(self, obj, *, depth=0, show_line_numbers=True, show_bytecode=True):
        # Set disassembly options
        dis_options = {}
        if not show_line_numbers:
            dis_options['show_lineno'] = False
        if not show_bytecode:
            dis_options['show_codevalue'] = False
        
        # Handle different types of objects
        if isinstance(obj, types.CodeType):
            print(f"Disassembly of code object at {hex(id(obj))}:")
            dis.dis(obj, **dis_options)
        elif inspect.isfunction(obj) or inspect.ismethod(obj):
            print(f"Disassembly of {obj.__name__}:")
            dis.dis(obj, **dis_options)
        elif inspect.isclass(obj):
            print(f"Disassembly of class {obj.__name__}:")
            for name, method in inspect.getmembers(obj, predicate=inspect.isfunction):
                print(f"\nMethod: {name}")
                dis.dis(method, **dis_options)
        elif inspect.ismodule(obj):
            print(f"Disassembly of module {obj.__name__}:")
            for name, func in inspect.getmembers(obj, predicate=inspect.isfunction):
                print(f"\nFunction: {name}")
                dis.dis(func, **dis_options)
        else:
            try:
                code = compile(obj, '<string>', 'exec')
                print("Disassembly of compiled code:")
                dis.dis(code, **dis_options)
            except (TypeError, ValueError):
                print(f"Cannot disassemble object of type {type(obj).__name__}")
        
        # Handle recursion for nested code objects if depth > 0
        if depth > 0 and hasattr(obj, '__code__'):
            code = obj.__code__
            for const in code.co_consts:
                if isinstance(const, types.CodeType):
                    print("\n" + "-" * 40)
                    self.show_disassembly(const, depth=depth-1, 
                                show_line_numbers=show_line_numbers,
                                show_bytecode=show_bytecode)
    def _init_disassembler(self):
        """Initialize the disassembler component"""
        try:
            return CodeDisassembler()
        except Exception as e:
            logging.debug(f"Failed to initialize disassembler: {str(e)}")
            return None

class ShellcodeReporter:
    """
    Handles reporting and logging of shellcode analysis results to a separate
    database/file system for long-term storage and analysis.
    """
    
    def __init__(self, db_path="ShellCodeForTomeAndAnalysis.db"):
        """
        Initialize the shellcode reporter with a database path.
        
        Args:
            db_path: Path to the SQLite database file
        """
        self.db_path = db_path
        self._initialize_db()
        
    def _initialize_db(self):
        """Set up the database schema if it doesn't exist"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Create tables if they don't exist
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS shellcode_entries (
            id TEXT PRIMARY KEY,
            first_seen TIMESTAMP,
            last_seen TIMESTAMP,
            seen_count INTEGER,
            size INTEGER,
            hash TEXT,
            hex_preview TEXT,
            classification TEXT,
            threat_level TEXT
        )
        ''')
        
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS shellcode_data (
            id TEXT PRIMARY KEY,
            raw_data BLOB,
            disassembly TEXT,
            FOREIGN KEY (id) REFERENCES shellcode_entries (id)
        )
        ''')
        
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS shellcode_locations (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            shellcode_id TEXT,
            process_id INTEGER,
            region_name TEXT,
            address TEXT,
            timestamp TIMESTAMP,
            detection_method TEXT,
            FOREIGN KEY (shellcode_id) REFERENCES shellcode_entries (id)
        )
        ''')
        
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS analysis_results (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            shellcode_id TEXT,
            analysis_type TEXT,
            analysis_result TEXT,
            timestamp TIMESTAMP,
            FOREIGN KEY (shellcode_id) REFERENCES shellcode_entries (id)
        )
        ''')
        
        conn.commit()
        conn.close()
        
    def log_shellcode(self, shellcode_entry, process_id=None, detection_method="unknown"):
        """
        Log a detected shellcode to the database.
        
        Args:
            shellcode_entry: Dictionary containing shellcode information
            process_id: ID of the process where shellcode was found (optional)
            detection_method: Method used to detect the shellcode
            
        Returns:
            True if successful, False otherwise
        """
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            shellcode_id = shellcode_entry.get('id')
            if not shellcode_id:
                # Generate ID if not present
                shellcode_id = hashlib.sha256(shellcode_entry['data']).hexdigest()[:16]
                
            # Check if shellcode exists
            cursor.execute('SELECT seen_count FROM shellcode_entries WHERE id = ?', (shellcode_id,))
            existing = cursor.fetchone()
            
            now = datetime.now()
            
            if existing:
                # Update existing entry
                cursor.execute('''
                UPDATE shellcode_entries 
                SET last_seen = ?, seen_count = seen_count + 1
                WHERE id = ?
                ''', (now, shellcode_id))
            else:
                # Create new entry
                cursor.execute('''
                INSERT INTO shellcode_entries 
                (id, first_seen, last_seen, seen_count, size, hash, hex_preview, classification, threat_level)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    shellcode_id,
                    now,
                    now,
                    1,
                    shellcode_entry.get('size', len(shellcode_entry.get('data', b''))),
                    hashlib.sha256(shellcode_entry.get('data', b'')).hexdigest(),
                    binascii.hexlify(shellcode_entry.get('data', b'')[:64]).decode('utf-8'),
                    self._classify_shellcode(shellcode_entry),
                    self._determine_threat_level(shellcode_entry)
                ))
                
                # Store raw data and disassembly separately
                cursor.execute('''
                INSERT INTO shellcode_data (id, raw_data, disassembly)
                VALUES (?, ?, ?)
                ''', (
                    shellcode_id,
                    shellcode_entry.get('data', b''),
                    shellcode_entry.get('disassembly', '')
                ))
            
            # Add location information
            cursor.execute('''
            INSERT INTO shellcode_locations 
            (shellcode_id, process_id, region_name, address, timestamp, detection_method)
            VALUES (?, ?, ?, ?, ?, ?)
            ''', (
                shellcode_id,
                process_id,
                shellcode_entry.get('region_name', 'unknown'),
                str(shellcode_entry.get('address', 0)),
                now,
                detection_method or shellcode_entry.get('detection_method', 'unknown')
            ))
            
            conn.commit()
            conn.close()
            return True
            
        except Exception as e:
            print(f"Error logging shellcode: {str(e)}")
            return False
            
    def log_analysis_result(self, shellcode_id, analysis_type, result):
        """
        Log an analysis result for a specific shellcode.
        
        Args:
            shellcode_id: ID of the shellcode
            analysis_type: Type of analysis performed
            result: Result data (will be JSON serialized)
            
        Returns:
            True if successful, False otherwise
        """
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Store analysis result
            cursor.execute('''
            INSERT INTO analysis_results (shellcode_id, analysis_type, analysis_result, timestamp)
            VALUES (?, ?, ?, ?)
            ''', (
                shellcode_id,
                analysis_type,
                json.dumps(result) if not isinstance(result, str) else result,
                datetime.now()
            ))
            
            conn.commit()
            conn.close()
            return True
            
        except Exception as e:
            print(f"Error logging analysis result: {str(e)}")
            return False
            
    def get_shellcode(self, shellcode_id):
        """
        Retrieve a shellcode entry and its analysis history.
        
        Args:
            shellcode_id: ID of the shellcode to retrieve
            
        Returns:
            Dictionary containing shellcode data and analysis history
        """
        try:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            
            # Get shellcode entry
            cursor.execute('''
            SELECT * FROM shellcode_entries WHERE id = ?
            ''', (shellcode_id,))
            entry = dict(cursor.fetchone() or {})
            
            if not entry:
                return None
                
            # Get raw data
            cursor.execute('''
            SELECT raw_data, disassembly FROM shellcode_data WHERE id = ?
            ''', (shellcode_id,))
            data_row = cursor.fetchone()
            
            if data_row:
                entry['data'] = data_row['raw_data']
                entry['disassembly'] = data_row['disassembly']
            
            # Get locations
            cursor.execute('''
            SELECT * FROM shellcode_locations WHERE shellcode_id = ?
            ''', (shellcode_id,))
            entry['locations'] = [dict(row) for row in cursor.fetchall()]
            
            # Get analysis results
            cursor.execute('''
            SELECT * FROM analysis_results WHERE shellcode_id = ? ORDER BY timestamp DESC
            ''', (shellcode_id,))
            entry['analysis'] = [dict(row) for row in cursor.fetchall()]
            
            # Parse JSON in analysis results
            for analysis in entry['analysis']:
                try:
                    analysis['analysis_result'] = json.loads(analysis['analysis_result'])
                except:
                    pass  # Keep as string if not valid JSON
            
            conn.close()
            return entry
            
        except Exception as e:
            print(f"Error retrieving shellcode: {str(e)}")
            return None
            
    def search_shellcode(self, criteria):
        """
        Search for shellcode entries matching the given criteria.
        
        Args:
            criteria: Dictionary of search criteria
            
        Returns:
            List of matching shellcode entries (without raw data)
        """
        try:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            
            query = "SELECT id, first_seen, last_seen, seen_count, size, hash, hex_preview, classification, threat_level FROM shellcode_entries WHERE 1=1"
            params = []
            
            if 'classification' in criteria:
                query += " AND classification = ?"
                params.append(criteria['classification'])
                
            if 'threat_level' in criteria:
                query += " AND threat_level = ?"
                params.append(criteria['threat_level'])
                
            if 'min_size' in criteria:
                query += " AND size >= ?"
                params.append(criteria['min_size'])
                
            if 'max_size' in criteria:
                query += " AND size <= ?"
                params.append(criteria['max_size'])
                
            if 'hex_pattern' in criteria:
                query += " AND hex_preview LIKE ?"
                params.append(f"%{criteria['hex_pattern']}%")
                
            if 'first_seen_after' in criteria:
                query += " AND first_seen >= ?"
                params.append(criteria['first_seen_after'])
                
            cursor.execute(query, params)
            results = [dict(row) for row in cursor.fetchall()]
            
            conn.close()
            return results
            
        except Exception as e:
            print(f"Error searching shellcode: {str(e)}")
            return []
            
    def generate_report(self, output_format="json", output_file=None):
        """
        Generate a comprehensive report of shellcode findings.
        
        Args:
            output_format: Format of the report ("json", "html", "csv")
            output_file: Path to save the report (None for stdout)
            
        Returns:
            Path to the generated report or report string
        """
        try:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            
            # Get statistics
            cursor.execute("SELECT COUNT(*) as total FROM shellcode_entries")
            total_count = cursor.fetchone()['total']
            
            cursor.execute("SELECT classification, COUNT(*) as count FROM shellcode_entries GROUP BY classification")
            classifications = {row['classification']: row['count'] for row in cursor.fetchall()}
            
            cursor.execute("SELECT threat_level, COUNT(*) as count FROM shellcode_entries GROUP BY threat_level")
            threat_levels = {row['threat_level']: row['count'] for row in cursor.fetchall()}
            
            # Get recently detected shellcode
            cursor.execute("""
            SELECT se.*, sl.region_name, sl.detection_method
            FROM shellcode_entries se
            JOIN shellcode_locations sl ON se.id = sl.shellcode_id
            ORDER BY sl.timestamp DESC LIMIT 20
            """)
            recent_detections = [dict(row) for row in cursor.fetchall()]
            
            # Get most frequently seen shellcode
            cursor.execute("SELECT * FROM shellcode_entries ORDER BY seen_count DESC LIMIT 10")
            frequent_shellcode = [dict(row) for row in cursor.fetchall()]
            
            # Compile report data
            report_data = {
                "generated_at": datetime.now().isoformat(),
                "statistics": {
                    "total_shellcode_count": total_count,
                    "classifications": classifications,
                    "threat_levels": threat_levels
                },
                "recent_detections": recent_detections,
                "frequent_shellcode": frequent_shellcode
            }
            
            # Generate report in specified format
            if output_format == "json":
                report = json.dumps(report_data, indent=2, default=str)
            elif output_format == "html":
                report = self._generate_html_report(report_data)
            elif output_format == "csv":
                report = self._generate_csv_report(report_data)
            else:
                report = json.dumps(report_data, indent=2, default=str)
            
            # Save or return report
            if output_file:
                with open(output_file, 'w') as f:
                    f.write(report)
                return output_file
            else:
                return report
                
        except Exception as e:
            print(f"Error generating report: {str(e)}")
            return f"Error generating report: {str(e)}"
    def _generate_html_report(self, shellcode_entries, output_file, detailed=True):
        """Generate a detailed HTML report of detected shellcode"""
        try:
            import datetime, os, base64, binascii, logging, re
            from io import BytesIO
            from collections import Counter
            from math import log2
            
            # Process entries into uniform format
            all_entries = []
            if isinstance(shellcode_entries, dict):
                for region, entries in shellcode_entries.items():
                    for entry in entries:
                        entry['region_name'] = region
                        all_entries.append(entry)
            else:
                all_entries = shellcode_entries
                
            if not all_entries:
                logging.warning("No shellcode entries to report")
                return False
            
            # Basic HTML template
            html = f"""<!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <title>Shellcode Analysis Report</title>
        <style>
            body {{ font-family: 'Segoe UI', sans-serif; line-height: 1.6; margin: 0; padding: 20px; background-color: #f5f5f5; }}
            .container {{ max-width: 1200px; margin: 0 auto; background-color: #fff; padding: 20px; box-shadow: 0 0 10px rgba(0,0,0,0.1); }}
            h1, h2, h3 {{ color: #2c3e50; }}
            h1 {{ border-bottom: 2px solid #3498db; padding-bottom: 10px; }}
            table {{ width: 100%; border-collapse: collapse; margin-bottom: 20px; }}
            th, td {{ padding: 12px 15px; border: 1px solid #ddd; text-align: left; }}
            th {{ background-color: #3498db; color: white; }}
            .shellcode-section {{ margin-bottom: 30px; padding: 15px; background-color: #fff; border-radius: 5px; box-shadow: 0 2px 5px rgba(0,0,0,0.1); }}
            .hex-dump {{ font-family: monospace; background-color: #f8f8f8; padding: 10px; overflow-x: auto; white-space: pre-wrap; }}
            .disassembly {{ font-family: monospace; background-color: #282c34; color: #abb2bf; padding: 15px; overflow-x: auto; }}
            .collapsible {{ cursor: pointer; user-select: none; }}
            .content {{ display: none; overflow: hidden; }}
        </style>
        <script>
            document.addEventListener('DOMContentLoaded', function() {{
                var coll = document.getElementsByClassName("collapsible");
                for (var i = 0; i < coll.length; i++) {{
                    coll[i].addEventListener("click", function() {{
                        this.classList.toggle("active");
                        var content = this.nextElementSibling;
                        content.style.display = content.style.display === "block" ? "none" : "block";
                    }});
                }}
            }});
        </script>
    </head>
    <body>
        <div class="container">
            <h1>Shellcode Analysis Report</h1>
            <div class="summary">
                <h2>Summary</h2>
                <p><strong>Generated:</strong> {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
                <p><strong>Total Shellcode Detected:</strong> {len(all_entries)}</p>
            </div>
    """

            # Add overview table
            html += """
            <h2>Shellcode Overview</h2>
            <table>
                <tr>
                    <th>ID</th>
                    <th>Region</th>
                    <th>Size</th>
                    <th>Address</th>
                    <th>Detection Method</th>
                </tr>
    """
            for i, entry in enumerate(all_entries):
                html += f"""
                <tr>
                    <td>{entry.get('id', f'SC{i}')}</td>
                    <td>{entry.get('region_name', 'Unknown')}</td>
                    <td>{entry.get('size', 0)} bytes</td>
                    <td>0x{entry.get('address', 0):08x}</td>
                    <td>{entry.get('detection_method', entry.get('pattern_matched', 'Unknown'))}</td>
                </tr>
    """
            html += "</table>"

            # Add visualization placeholders (actual visualization code omitted for brevity)
            html += "<h2>Visualizations</h2>"
            html += "<p>Size distribution and detection method charts would appear here if matplotlib is available.</p>"
            
            # Detailed shellcode sections
            html += "<h2>Detailed Analysis</h2>"
            
            for i, entry in enumerate(all_entries):
                shellcode_id = entry.get('id', f'SC{i}')
                region_name = entry.get('region_name', 'Unknown')
                size = entry.get('size', 0)
                address = entry.get('address', 0)
                detection = entry.get('detection_method', entry.get('pattern_matched', 'Unknown'))
                
                # Get shellcode bytes and format hex dump
                shellcode_data = entry.get('data', b'')
                hex_dump = ""
                if shellcode_data:
                    for j in range(0, len(shellcode_data), 16):
                        line_bytes = shellcode_data[j:j+16]
                        hex_line = ' '.join(f'{b:02x}' for b in line_bytes)
                        ascii_line = ''.join(chr(b) if 32 <= b <= 126 else '.' for b in line_bytes)
                        hex_dump += f"0x{address+j:08x}: {hex_line:<47} | {ascii_line}\n"
                
                html += f"""
                <div class="shellcode-section">
                    <h3>{shellcode_id} - {region_name}</h3>
                    <div>
                        <strong>Address:</strong> 0x{address:08x} | 
                        <strong>Size:</strong> {size} bytes | 
                        <strong>Detection:</strong> {detection}
                    </div>
    """
                
                # Calculate entropy if data available
                if shellcode_data and len(shellcode_data) > 0:
                    try:
                        entropy = 0
                        counter = Counter(shellcode_data)
                        for count in counter.values():
                            p_x = count / len(shellcode_data)
                            entropy += -p_x * log2(p_x)
                        html += f"<div><strong>Entropy:</strong> {entropy:.2f}</div>"
                    except Exception as e:
                        logging.debug(f"Error calculating entropy: {str(e)}")
                
                # Add hex dump (collapsible)
                html += f"""
                    <h4 class="collapsible">Hex Dump</h4>
                    <div class="content hex-dump">
    {hex_dump}
                    </div>
    """

                # Add disassembly if available
                if 'disassembly' in entry and entry['disassembly']:
                    html += f"""
                    <h4 class="collapsible">Disassembly</h4>
                    <div class="content disassembly">
    {entry['disassembly']}
                    </div>
    """
                
                html += """
                </div>
    """
            
            # Close HTML tags
            html += """
        </div>
    </body>
    </html>
    """

            # Write report to file
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(html)
                
            logging.info(f"HTML report generated: {output_file}")
            return True
        
        except Exception as e:
            logging.error(f"Error generating HTML report: {str(e)}")
            return False


    def _generate_csv_report(self, shellcode_entries, output_file):
        """
        Generate a CSV report of detected shellcode
        
        Args:
            shellcode_entries: List of shellcode entries or dictionary of region names to lists
            output_file: Path where the CSV file will be saved
            
        Returns:
            True if report was successfully generated, False otherwise
        """
        try:
            import csv
            import datetime
            import binascii
            import logging
            
            # Process entries into uniform format
            all_entries = []
            if isinstance(shellcode_entries, dict):
                for region, entries in shellcode_entries.items():
                    for entry in entries:
                        entry['region_name'] = region
                        all_entries.append(entry)
            else:
                all_entries = shellcode_entries
                
            if not all_entries:
                logging.warning("No shellcode entries to report")
                return False
            
            # Define CSV fields
            fields = [
                'id', 'region_name', 'address', 'size', 'detection_method', 
                'pattern_matched', 'detection_time', 'hex_preview'
            ]
            
            # Write CSV file
            with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:
                writer = csv.DictWriter(csvfile, fieldnames=fields)
                writer.writeheader()
                
                for entry in all_entries:
                    # Prepare row data
                    row = {
                        'id': entry.get('id', 'Unknown'),
                        'region_name': entry.get('region_name', 'Unknown'),
                        'address': f"0x{entry.get('address', 0):08x}",
                        'size': entry.get('size', 0),
                        'detection_method': entry.get('detection_method', 'Unknown'),
                        'pattern_matched': entry.get('pattern_matched', ''),
                        'detection_time': entry.get('detection_time', ''),
                    }
                    
                    # Add hex preview (first 32 bytes)
                    shellcode_data = entry.get('data', b'')
                    if shellcode_data:
                        preview_size = min(32, len(shellcode_data))
                        row['hex_preview'] = binascii.hexlify(shellcode_data[:preview_size]).decode('utf-8')
                    else:
                        row['hex_preview'] = ''
                    
                    writer.writerow(row)
            
            logging.info(f"CSV report generated: {output_file}")
            return True
            
        except Exception as e:
            logging.error(f"Error generating CSV report: {str(e)}")
        return False
    def log_shellcodes_from_tome(self, shellcode_detector):
        """
        Import shellcodes from a ShellcodeDetector tome into the reporting database.
        
        Args:
            shellcode_detector: ShellcodeDetector instance containing shellcode tome
            
        Returns:
            Number of shellcodes imported
        """
        count = 0
        self.shellcode_detector = ShellcodeDetector()
        try:
            for sc_id, sc_data in self.shellcode_detector.shellcode_tome.items():
                # Convert tome entry to reporting format
                for location in sc_data.get('locations', []):
                    shellcode_entry = {
                        'id': sc_id,
                        'data': sc_data.get('data', b''),
                        'size': sc_data.get('size', 0),
                        'address': location.get('address', 0),
                        'region_name': location.get('region_name', 'unknown'),
                        'detection_method': 'imported_from_tome'
                    }
                    
                    if self.log_shellcode(shellcode_entry):
                        count += 1
                        
            return count
            
        except Exception as e:
            print(f"Error importing shellcodes from tome: {str(e)}")
            return count
    
    def _classify_shellcode(self, shellcode_entry):
        """Classify shellcode based on its characteristics"""
        # Get the actual shellcode data bytes
        data = shellcode_entry.get('data', b'')
        detection_method = shellcode_entry.get('detection_method', '')
        
        # Classification logic based on byte patterns
        if b'\x90\x90\x90\x90\x90' in data:
            return "nop_sled_shellcode"
        elif b'\x31\xc0\x50\x68' in data:
            return "api_call_shellcode"
        elif b'\x48\x31\xc0\x50\x68' in data:
            return "x64_api_call_shellcode"
        elif detection_method and 'decoder' in detection_method.lower():
            return "encoder_decoder_shellcode"
        elif detection_method and 'pattern' in detection_method.lower():
            return "pattern_matched_shellcode"
        else:
            return "unknown_shellcode"

    def log_unidentified_shellcode(self, raw_data, source_info=None, address=0, region_name="unknown"):
        """
        Log shellcode that might not be in the standard format or wasn't identified by detection methods
        
        Args:
            raw_data: The raw bytes of the shellcode
            source_info: Information about where the shellcode was found
            address: Memory address where the shellcode was found
            region_name: Name of the memory region
            
        Returns:
            Shellcode ID if successful, None otherwise
        """
        try:
            # Generate a unique ID
            shellcode_id = hashlib.sha256(raw_data).hexdigest()[:16]
            
            # Create a shellcode entry
            shellcode_entry = {
                'id': shellcode_id,
                'data': raw_data,
                'size': len(raw_data),
                'address': address,
                'region_name': region_name,
                'detection_method': "manual_submission",
                'hex': binascii.hexlify(raw_data[:64]).decode('utf-8'),
            }
            
            # Log it to the database
            if self.log_shellcode(shellcode_entry):
                # Add source info as analysis
                if source_info:
                    self.log_analysis_result(
                        shellcode_id, 
                        "source_information", 
                        source_info
                    )
                return shellcode_id
            return None
            
        except Exception as e:
            print(f"Error logging unidentified shellcode: {str(e)}")
            return None

    def _determine_threat_level(self, shellcode_entry):
    
        data = shellcode_entry.get('data', b'')
        detection_method = shellcode_entry.get('detection_method', '')
        pattern_matched = shellcode_entry.get('pattern_matched', '')
        
        # Combine all detection info for comprehensive matching
        all_detection_info = (detection_method + ' ' + pattern_matched).lower()
        
        # Check for dangerous API patterns in binary data
        dangerous_patterns = [
            b'\x68\x33\x32\x00\x00',  # push "32" (WinExec, etc.)
            b'\x68\x73\x41\x00\x00',  # push "As" (CreateProcessA)
            b'\x68\x6C\x6C\x00\x00',  # push "ll" (DLL loading)
            b'\x68\x6F\x63\x00\x00',  # push "oc" (memory allocation)
            b'\x68\x65\x78\x65\x00'   # push "exe"
        ]
        
        # Check for network-related patterns in binary data
        network_patterns = [
            b'\x68\x74\x63\x70\x00',  # push "tcp"
            b'\x68\x73\x6F\x63\x6B',  # push "sock"
            b'\x68\x73\x65\x6E\x64',  # push "send"
            b'\x68\x72\x65\x63\x76'   # push "recv"
        ]
        
        # Categories of keywords for detection methods
        dangerous_keywords = [
            'api', 'dll', 'createprocess', 'win', 'exec', 'process', 
            'kernel', 'memory', 'inject', 'hook', 'loadlibrary', 
            'shellcode', 'malicious', 'exploit', 'code_injection',
            'evasion', 'obfuscated', 'privilege', 'allocation',
            'suspicious', 'execute', 'heap', 'stack', 'vulnerable'
        ]
        
        network_keywords = [
            'network', 'socket', 'connect', 'dns', 'http', 'https', 
            'ftp', 'tcp', 'udp', 'ip', 'icmp', 'recv', 'send', 
            'download', 'upload', 'url', 'web', 'remote', 'connection'
        ]
        
        # Count matched binary patterns
        dangerous_pattern_count = sum(1 for pattern in dangerous_patterns if pattern in data)
        network_pattern_count = sum(1 for pattern in network_patterns if pattern in data)
        
        # Check for keyword matches in detection methods
        dangerous_keyword_match = any(keyword in all_detection_info for keyword in dangerous_keywords)
        network_keyword_match = any(keyword in all_detection_info for keyword in network_keywords)
        
        # Calculate final counts
        dangerous_count = dangerous_pattern_count + (1 if dangerous_keyword_match else 0)
        network_count = network_pattern_count + (1 if network_keyword_match else 0)
        
        # Additional threat indicators from analysis
        has_obfuscation = 'obfuscation' in all_detection_info or 'encoded' in all_detection_info
        has_evasion = 'evasion' in all_detection_info or 'anti_' in all_detection_info
        has_known_exploit = 'exploit' in all_detection_info or 'cve' in all_detection_info
        
        # Determine threat level with enhanced logic
        if (dangerous_count >= 2 or 
            (dangerous_count >= 1 and network_count >= 1) or
            has_known_exploit or
            (has_obfuscation and (dangerous_count >= 1 or network_count >= 1))):
            return "high"
        elif (dangerous_count >= 1 or 
            network_count >= 1 or 
            has_obfuscation or 
            has_evasion):
            return "medium"
        else:
            return "low"
            

if __name__ == "__main__":
    
    # Set up logging first before any logging calls
    def setup_application_logging():

        """Set up centralized application logging"""
        # Create logs directory
        log_dir = Path('logs')
        log_dir.mkdir(exist_ok=True)
        
        # Configure handlers
        file_handler = logging.FileHandler(str(log_dir / 'scanner.log'))
        file_handler.setLevel(logging.DEBUG)  # Use constant, not function
        
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)  # Use constant, not function
        
        # Create formatters
        detailed_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(filename)s:%(lineno)d - %(message)s')
        file_handler.setFormatter(detailed_formatter)
        console_handler.setFormatter(detailed_formatter)
        
        # Configure root logger
        root_logger = logging.getLogger()
        root_logger.setLevel(logging.DEBUG)  # Use constant, not function
        
        # Clear any existing handlers to avoid duplicates
        if root_logger.handlers:
            root_logger.handlers.clear()
            
        # Add handlers
        root_logger.addHandler(file_handler)
        root_logger.addHandler(console_handler)
        
        return root_logger
    # Initialize logging before any logging calls
    logger = setup_application_logging()
    
    logging.debug("Starting application")

    def is_admin():
        try:
            return ctypes.windll.shell32.IsUserAnAdmin()
        except Exception as e:
            logging.error(f"Error checking admin status: {str(e)}")
            return False
    if not is_admin():
        logging.debug("Not running as admin, requesting elevation")
        try:
            ctypes.windll.shell32.ShellExecuteW(None, "runas", sys.executable, f'"{__file__}"', None, 1)
        except Exception as e:
            logging.error(f"Failed to elevate privileges: {str(e)}")
        sys.exit()
    else:
        logging.debug("Running with admin privileges")
        try:
            logging.debug("Creating root window")
            root = tk.Tk()
            root.geometry("800x600")
            
            # Set icon if available
            try:
                root.iconbitmap("icon.ico")
            except:
                logging.debug("Icon file not found, using default")
            
            logging.debug("Initializing ScannerGUI")
            
            logging.debug("Creating ScannerGUI instance")
            app = ScannerGui(root)
            app.setup_gui()  # Call setup_gui explicitly
            root.mainloop()
            # Initialize scanning engine and rules
            try:
                app.load_rules_async()
                logging.debug("Rules loading started")
            except Exception as e:
                logging.error(f"Error loading rules: {str(e)}")
            
            logging.debug("Starting mainloop")
            
        except Exception as e:
            logging.exception("Fatal error occurred:")
            print(f"\n\nERROR: {str(e)}")
            traceback.print_exc()
            logging.exception("Error in main GUI loop")
            print(f"Error occurred: {str(e)}")
        finally:
            # This ensures the console stays open regardless of success or failure
            print("\nPress Enter to exit...")
            input()  # This keeps the console window open until user presses Enter
